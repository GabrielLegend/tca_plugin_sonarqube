(window.webpackJsonp=window.webpackJsonp||[]).push([[262,15,354,360],{1076:function(e){e.exports=JSON.parse('[{"title":"Requirements","children":["/requirements/requirements/","/requirements/hardware-recommendations/"]},{"title":"Analyzing Source Code","children":["/analysis/overview/",{"title":"Scanners","children":["/analysis/scan/sonarscanner-for-gradle/","/analysis/scan/sonarscanner-for-msbuild/","/analysis/scan/sonarscanner-for-maven/","/analysis/scan/sonarscanner-for-azure-devops/","/analysis/scan/sonarscanner-for-jenkins/","/analysis/scan/sonarscanner-for-ant/","/analysis/scan/sonarscanner/"]},"/analysis/analysis-parameters/",{"title":"Languages","children":["/analysis/languages/overview/","/analysis/languages/abap/","/analysis/languages/apex/","/analysis/languages/csharp/","/analysis/languages/cfamily/","/analysis/languages/cobol/","/analysis/languages/css/","/analysis/languages/flex/","/analysis/languages/go/","/analysis/languages/html/","/analysis/languages/java/","/analysis/languages/javascript/","/analysis/languages/kotlin/","/analysis/languages/php/","/analysis/languages/pli/","/analysis/languages/plsql/","/analysis/languages/python/","/analysis/languages/rpg/","/analysis/languages/ruby/","/analysis/languages/scala/","/analysis/languages/swift/","/analysis/languages/tsql/","/analysis/languages/vbnet/","/analysis/languages/vb6/","/analysis/languages/xml/"]},"/analysis/coverage/",{"title":"Importing External Issues","children":["/analysis/external-issues/","/analysis/generic-issue/"]},"/analysis/background-tasks/","/analysis/generic-test/","/analysis/pull-request/",{"title":"Branches","children":["/branches/overview/","/branches/branches-faq/"]},{"title":"CI Integration","children":["/analysis/branch-pr-analysis-overview/","/analysis/jenkins/"]},"/analysis/scm-integration/","/analysis/security_configuration/","/analysis/analysis-with-java-11/"]},{"title":"ALM Integration","children":["/analysis/github-integration/","/analysis/gitlab-integration/","/analysis/bitbucket-integration/","/analysis/bitbucket-cloud-integration/","/analysis/azuredevops-integration/"]},{"title":"User Guide","children":["/user-guide/concepts/","/user-guide/clean-as-you-code/","/user-guide/metric-definitions/","/user-guide/quality-gates/",{"title":"Rules","children":["/user-guide/rules/","/user-guide/security-rules/","/user-guide/built-in-rule-tags/"]},{"title":"User Account","children":["/user-guide/user-account/","/user-guide/user-token/"]},"/user-guide/issues/","/user-guide/security-hotspots/","/user-guide/portfolios/","/user-guide/applications/","/user-guide/security-reports/","/user-guide/activity-history/","/user-guide/project-page/","/user-guide/visualizations/","/user-guide/sonarlint-notifications/","/user-guide/keyboard-shortcuts/"]},{"title":"Project Administration","children":["/project-administration/project-existence/","/project-administration/managing-project-history/","/project-administration/narrowing-the-focus/","/project-administration/new-code-period/","/project-administration/managing-portfolios/","/project-administration/managing-applications/","/project-administration/portfolio-pdf-configuration/","/project-administration/project-settings/","/project-administration/webhooks/"]},{"title":"Instance Administration","children":["/instance-administration/quality-profiles/","/instance-administration/security/","/instance-administration/delegated-auth/","/instance-administration/look-and-feel/","/instance-administration/marketplace/","/instance-administration/housekeeping/","/instance-administration/notifications/","/instance-administration/system-info/","/instance-administration/license-manager/","/instance-administration/monitoring/","/instance-administration/project-move/","/instance-administration/custom-measures/","/instance-administration/compute-engine-performance/","/instance-administration/db-copy/","/instance-administration/backup-restore/"]},{"title":"Extension Guide","children":["/extend/web-api/","/extend/adding-coding-rules/",{"title":"Developing a plugin","children":["/extend/developing-plugin/","/extend/new-languages/","/extend/executable-lines/","/extend/extend-web-app/","/extend/adding-scm/"]},"/extend/i18n/","/extend/contributing/"]},"/faq/"]')},1140:function(e,n,t){"use strict";function o(e){let n,t;for(let o=0;o<e.length;o++){if("---"===e[o].trim()){if(void 0!==n){t=o;break}n=o}}return void 0!==t?{firstLine:n,lastLine:t}:void 0}function a(e){const n={};for(let t=0;t<e.length;t++){const o=e[t].split(":").map(e=>e.trim());2===o.length&&(n[o[0]]=o[1])}return n}function s(e,n){const t="\x3c!-- ".concat(n," --\x3e"),o="\x3c!-- /".concat(n," --\x3e");let a=e,s=a.indexOf(t),i=a.indexOf(o);for(;-1!==s&&-1!==i;)s<i?a=a.substring(0,s)+a.substring(i+o.length):(console.error(new Error('Documentation - incorrect usage of conditional formatting tags here: "'.concat(a.substring(i,s+t.length),'"'))),a=a.substring(0,i)+a.substring(i+o.length,s)+a.substring(s+t.length)),s=a.indexOf(t),i=a.indexOf(o);return a}e.exports={getFrontMatter:function(e){const n=e.split("\n"),t=o(n);return t?a(n.slice(t.firstLine+1,t.lastLine)):{}},separateFrontMatter:function(e){const n=e.split("\n"),t=o(n);if(t){const e=a(n.slice(t.firstLine+1,t.lastLine)),o=n.slice(t.lastLine+1).join("\n");return{frontmatter:e,content:o}}return{frontmatter:{},content:e}},filterContent:function(e){const n="\x3c!-- \\/?(sonarqube|sonarcloud|static) --\x3e",{isSonarCloud:o,getInstance:a}=t(6),i=s(e.replace(/{instance}/gi,a()),"static");return(o()?s(i,"sonarqube"):s(i,"sonarcloud")).replace(new RegExp("^".concat(n,"(\n|\r|\r\n|$)"),"gm"),"").replace(new RegExp("".concat(n),"g"),"")}}},1160:function(e,n,t){"use strict";t.r(n),t.d(n,"default",(function(){return X}));var o=t(311),a=t(2),s=t(1077),i=t.n(s),r=t(1096),l=t.n(r),c=t(1098),u=t.n(c),d=t(752),h=t.n(d),p=t(1121),m=t.n(p),g=t(1122),y=t.n(g),f=t(435),b=t(453),v=t.n(b);class w extends a.PureComponent{constructor(){super(...arguments),this.state={open:!1},this.handleClick=e=>{this.setState(e=>({open:!e.open})),e.stopPropagation(),e.preventDefault()}}renderTitle(e){return a.createElement("a",{"aria-expanded":this.state.open,"aria-haspopup":!0,role:"button",className:"link-no-underline",href:"#",onClick:this.handleClick},a.createElement(v.a,{className:"text-middle little-spacer-right",open:this.state.open}),e.props?e.props.children:e)}render(){const e=a.Children.toArray(this.props.children);if(e.length<1)return null;const n=a.Children.toArray(e[0].props.children);return n.length<2?null:a.createElement("div",{className:"collapse-container"},this.renderTitle(n[0]),this.state.open&&n.slice(1))}}var S=t(339);function k(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},s=Object.keys(e);for(o=0;o<s.length;o++)t=s[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(o=0;o<s.length;o++)t=s[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}function x(e){const{alt:n,src:t}=e,o=k(e,["alt","src"]);return a.createElement("img",Object.assign({alt:n,className:"max-width-100",src:Object(S.getBaseUrl)()+"/images/embed-doc"+t},o))}var A=t(318),C=t(383),T=t.n(C),P=t(6),j=t(441);function E(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},s=Object.keys(e);for(o=0;o<s.length;o++)t=s[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(o=0;o<s.length;o++)t=s[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}class I extends a.PureComponent{constructor(){super(...arguments),this.handleClickOnAnchor=e=>{const{customProps:n,href:t="#"}=this.props;n&&n.onAnchorClick&&n.onAnchorClick(t,e)}}render(){const e=this.props,{appState:n,children:t,href:o,customProps:s}=e,i=E(e,["appState","children","href","customProps"]);if(o&&o.startsWith("#"))return a.createElement("a",{href:"#",onClick:this.handleClickOnAnchor},t);if(o&&o.startsWith("/")){if(o.startsWith("/#sonarcloud#/"))return a.createElement(O,{url:o},t);if(o.startsWith("/#sonarqube#/"))return a.createElement(N,{url:o},t);if(o.startsWith("/#sonarqube-admin#/"))return a.createElement(M,{canAdmin:n.canAdmin,url:o},t);{const e="/documentation"+o;return a.createElement(A.c,Object.assign({to:e},i),t)}}return a.createElement(a.Fragment,null,a.createElement("a",Object.assign({href:o,rel:"noopener noreferrer",target:"_blank"},i),t),a.createElement(T.a,{className:"text-muted little-spacer-left little-spacer-right text-baseline",size:12}))}}var R=Object(j.a)(I);function O({children:e,url:n}){if(Object(P.isSonarCloud)()){const t="/".concat(n.substr("/#sonarcloud#/".length));return a.createElement(A.c,{to:t},e)}return a.createElement(a.Fragment,null,e)}function N({children:e,url:n}){if(Object(P.isSonarCloud)())return a.createElement(a.Fragment,null,e);{const t="/".concat(n.substr("/#sonarqube#/".length));return a.createElement(A.c,{target:"_blank",to:t},e)}}function M({canAdmin:e,children:n,url:t}){if(Object(P.isSonarCloud)()||!e)return a.createElement(a.Fragment,null,n);{const e="/".concat(t.substr("/#sonarqube-admin#/".length));return a.createElement(A.c,{target:"_blank",to:e},n)}}t(936);var D=t(588),L=t.n(D),q=t(382),Q=t.n(q),_=t(467),G=t(1132),B=t.n(G),F=t(31),H=t(1138),z=t.n(H);function U(){return function(e){const n=z()(e,{heading:"doctoc",maxDepth:2});null!==n.index&&-1!==n.index&&n.map?e.children=[n.map]:e.children=[]}}class W extends a.PureComponent{constructor(e){super(e),this.node=null,this.state={anchors:[]},this.scrollHandler=()=>{const e=Object(_.findDOMNode)(this);if(!e||!e.parentNode)return;const n=e.parentNode.querySelectorAll("h2[id]"),t=window.pageYOffset||document.body.scrollTop;let o;for(let e=0,a=n.length;e<a&&!(n.item(e).offsetTop>t+120);e++)o="#".concat(n.item(e).id);this.setState({highlightAnchor:o})},this.debouncedScrollHandler=Q()(this.scrollHandler)}static getDerivedStateFromProps(e){const{content:n}=e;return{anchors:W.getAnchors(n)}}componentDidMount(){window.addEventListener("scroll",this.debouncedScrollHandler,!0),this.scrollHandler()}componentWillUnmount(){window.removeEventListener("scroll",this.debouncedScrollHandler,!0)}render(){const{anchors:e,highlightAnchor:n}=this.state;return 0===e.length?null:a.createElement("div",{className:"markdown-toc"},a.createElement("div",{className:"markdown-toc-content"},a.createElement("h4",null,Object(F.translate)("documentation.on_this_page")),e.map(e=>a.createElement("a",{className:o({active:n===e.href}),href:e.href,key:e.title,onClick:n=>{this.props.onAnchorClick(e.href,n)}},e.title))))}}W.getAnchors=L()(e=>{const n=h()().use(B.a).use(U).processSync("\n## doctoc\n"+e);if(n&&n.contents.props.children){let e=n.contents,t=10;for(;t&&e.props.children.length&&"ul"!==e.type;)e=e.props.children[0],t--;if("ul"===e.type&&e.props.children.length)return e.props.children.map(e=>{if("string"==typeof e)return null;const n=e.props.children[0];return{href:n.props.href,title:n.props.children[0]}}).filter(e=>e)}return[]});var J=t(805),Y=t.n(J);function V(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},s=Object.keys(e);for(o=0;o<s.length;o++)t=s[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(o=0;o<s.length;o++)t=s[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}function K(e){let{children:n,customProps:t,href:o}=e,s=V(e,["children","customProps","href"]);return t&&Y()(t,(e,n)=>{o&&(o=o.replace("#".concat(n,"#"),encodeURIComponent(e)))}),o&&o.startsWith("/")?(o=o.startsWith("/#sonarcloud#/")?"/".concat(o.substr("/#sonarcloud#/".length)):"/documentation/".concat(o.substr(1)),a.createElement(A.c,Object.assign({rel:"noopener noreferrer",target:"_blank",to:o},s),n)):a.createElement(a.Fragment,null,a.createElement("a",Object.assign({href:o,rel:"noopener noreferrer",target:"_blank"},s),n),a.createElement(T.a,{className:"little-spacer-left little-spacer-right text-baseline",size:12}))}class X extends a.PureComponent{constructor(){super(...arguments),this.node=null,this.handleAnchorClick=(e,n)=>{if(this.node){const t=this.node.querySelector(e);t&&(n&&n.preventDefault(),Object(f.scrollToElement)(t,{bottomOffset:window.innerHeight-80}),history.pushState&&history.pushState(null,"",e))}}}componentDidMount(){const{scrollToHref:e}=this.props;e&&setTimeout(()=>{this.handleAnchorClick(e)},500)}render(){const{childProps:e,content:n,className:t,title:s,stickyToc:r,isTooltip:c}=this.props,d=h()();return d.use(m.a,{danger:{classes:"alert alert-danger"},warning:{classes:"alert alert-warning"},info:{classes:"alert alert-info"},success:{classes:"alert alert-success"},collapse:{classes:"collapse"}}).use(y.a,{allowDangerousHTML:!0}).use(u.a).use(i.a).use(l.a,{createElement:a.createElement,components:{div:Z,a:c?$(K,e):$(R,{onAnchorClick:this.handleAnchorClick}),img:x}}),a.createElement("div",{className:o("markdown",t,{"has-toc":r}),ref:e=>this.node=e},a.createElement("div",{className:"markdown-content"},void 0!==s&&a.createElement("h1",{className:"documentation-title"},s),d.processSync(n).contents),r&&a.createElement(W,{content:n,onAnchorClick:this.handleAnchorClick}))}}function $(e,n){return function(t){return a.createElement(e,Object.assign({customProps:n},t))}}function Z(e){return e.className?e.className.includes("collapse")?a.createElement(w,null,e.children):a.createElement("div",{className:o("cut-margins",e.className)},e.children):e.children}},1665:function(e,n,t){"use strict";e.exports=[{path:"404",content:"---\ntitle: Page not found\nnav: Not found\nurl: /404/\n---\n\n# Error\n\nThis page does not exist\n"},{path:"analysis/analysis-parameters",content:"---\ntitle: Analysis Parameters\nurl: /analysis/analysis-parameters/\n---\n\nProject analysis settings can be configured in multiple places. Here is the hierarchy:\n\n* Global properties, defined in the UI, apply to all projects (From the top bar, go to **[Administration > Configuration > General Settings](/#sonarqube-admin#/admin/settings)**)\n* Project properties, defined in the UI, override global property values (At a project level, go to **Project Settings > General Settings**)\n* Project analysis parameters, defined in a project analysis configuration file or scanner configuration file, override the ones defined in the UI\n* Analysis / Command line parameters, defined when launching an analysis (with `-D` on the command line), override project analysis parameters\n\nNote that only parameters set through the UI are stored in the database.\nFor example, if you override the `sonar.exclusions` parameter via command line for a specific project, it will not be stored in the database. Subsequent analyses, or analyses in SonarLint with connected mode, would still be executed with the exclusions defined in the UI and therefore stored in the DB.\n\nMost of the property keys shown in the interface at both global and project levels can also be set as analysis parameters, but the parameters listed below can _only_ be set at analysis time. \n\nFor language-specific parameters related to test coverage and execution, see [Test Coverage & Execution](/analysis/coverage/).  \nFor language-specific parameters related to external issue reports, see [External Issues](/analysis/external-issues/).\n\n## Mandatory Parameters\n\n### Server\nKey | Description | Default\n---|----|---\n`sonar.host.url`| the server URL | http://localhost:9000\n\n### Project Configuration\nKey | Description | Default\n---|----|---\n`sonar.projectKey`|The project's unique key. Allowed characters are: letters, numbers, `-`, `_`, `.` and `:`, with at least one non-digit. | For Maven projects, this defaults to `<groupId>:<artifactId>`\n\n## Optional Parameters\n\n### Project Identity\nKey | Description | Default\n---|----|---\n`sonar.projectName`|Name of the project that will be displayed on the web interface.|`<name>` for Maven projects, otherwise project key. If not provided and there is already a name in the DB, it won't be overwritten\n`sonar.projectVersion` | The project version. | `<version>` for Maven projects, otherwise \"not provided\"\n\n### Authentication\nBy default, user authentication is required to prevent anonymous users from browsing and analyzing projects on your instance, and you need to pass these parameters when running analyses. Authentication is enforced in the global Security(/instance-administration/security/) settings.\n\nWhen authentication is required or the \"Anyone\" pseudo-group does not have permission to perform analyses, you'll need to supply the credentials of a user with Execute Analysis permissions for the analysis to run under.\n\nKey | Description | Default\n---|----|---\n`sonar.login` | The [authentication token](/user-guide/user-token/) or login of a SonarQube user with Execute Analysis permission on the project. |\n`sonar.password` | If you're using an authentication token, leave this blank. If you're using a login, this is the password that goes with your `sonar.login` username. |\n\n### Web Services\nKey | Description | Default\n---|----|---\n`sonar.ws.timeout` | Maximum time to wait for the response of a Web Service call (in seconds). Modifying this value from the default is useful only when you're experiencing timeouts during analysis while waiting for the server to respond to Web Service calls. |  60\n\n### Project Configuration\nKey | Description | Default\n---|----|---\n`sonar.projectDescription` | The project description. | `<description>` for Maven projects\n`sonar.links.homepage` | Project home page. | `<url>` for Maven projects\n`sonar.links.ci` | Continuous integration. | `<ciManagement><url>` for Maven projects\n`sonar.links.issue` | Issue tracker. | `<issueManagement><url>` for Maven projects\n`sonar.links.scm` | Project source repository. | `<scm><url>` for Maven projects\n`sonar.sources` | Comma-separated paths to directories containing main source files. | Read from build system for Maven, Gradle, MSBuild projects. Defaults to project base directory when neither `sonar.sources` nor `sonar.tests` is provided.\n`sonar.tests` | Comma-separated paths to directories containing test source files. | Read from build system for Maven, Gradle, MSBuild projects. Else default to empty.\n`sonar.sourceEncoding` | Encoding of the source files. Ex: `UTF-8`, `MacRoman`, `Shift_JIS`. This property can be replaced by the standard property `project.build.sourceEncoding` in Maven projects. The list of available encodings depends on your JVM. | System encoding\n`sonar.externalIssuesReportPaths` | Comma-delimited list of paths to Generic Issue reports. | \n`sonar.projectDate` | Assign a date to the analysis. This parameter is only useful when you need to retroactively create the history of a not-analyzed-before project. The format is `yyyy-MM-dd`, for example: 2010-12-01. Since you cannot perform an analysis dated prior to the most recent one in the database, you must analyze recreate your project history in chronological order, oldest first. ![](/images/exclamation.svg) Note: You may need to adjust your housekeeping settings if you wish to create a long-running history. | Current date\n`sonar.projectBaseDir` | Use this property when you need analysis to take place in a directory other than the one from which it was launched. E.G. analysis begins from `jenkins/jobs/myjob/workspace` but the files to be analyzed are in `ftpdrop/cobol/project1`. The path may be relative or absolute. Specify not the the source directory, but some parent of the source directory. The value specified here becomes the new \"analysis directory\", and other paths are then specified as though the analysis were starting from the specified value of `sonar.projectBaseDir`. Note that the analysis process will need write permissions in this directory; it is where the `sonar.working.directory` will be created. |\n`sonar.working.directory` | Set the working directory for an analysis triggered with the SonarScanner or the SonarScanner for Ant (versions greater than 2.0). This property is not compatible with the SonarScanner for MSBuild. Path must be relative, and unique for each project. ![](/images/exclamation.svg) Beware: the specified folder is deleted before each analysis. | `.scannerwork`\n`sonar.scm.provider` | This property can be used to explicitly tell SonarQube which SCM you're using on the project (in case auto-detection doesn't work). The value of this property is always lowercase and depends on the SCM (ex. \"git\" if you're using Git). Check the [SCM integration](/analysis/scm-integration/) documentation for more. |  \n`sonar.scm.forceReloadAll` | By default, blame information is only retrieved for changed files. Set this property to `true` to load blame information for all files. This can be useful is you feel that some SCM data is outdated but SonarQube does not get the latest information from the SCM engine. | \n`sonar.scm.exclusions.disabled`| For supported engines, files ignored by the SCM, i.e. files listed in `.gitignore`, will automatically be ignored by analysis too. Set this property to `true` to disable that feature. SCM exclusions are always disabled if `sonar.scm.disabled` is set to `true`. |\n`sonar.scm.revision`| Overrides the revision, for instance the Git sha1, displayed in analysis results. By default value is provided by the CI environment or guessed by the checked-out sources.| \n`sonar.buildString`| The string passed with this property will be stored with the analysis and available in the results of `api/project_analyses/search`, thus allowing you to later identify a specific analysis and obtain its ID for use with `api/project_analyses/set_baseline`. | |\n`sonar.analysis.[yourKey]`| This property stub allows you to insert custom key/value pairs into the analysis context, which will also be passed forward to [webhooks](/project-administration/webhooks/). | |\n\n\n### Duplications\nKey | Description | Default\n---|----|---\n`sonar.cpd.${language}.minimumtokens` | A piece of code is considered duplicated as soon as there are at least 100 duplicated tokens in a row (override with `sonar.cpd.${language}.minimumTokens`) spread across at least 10 lines of code (override with `sonar.cpd.${language}.minimumLines`). For Java projects, a piece of code is considered duplicated when there is a series of at least 10 statements in a row, regardless of the number of tokens and lines. This threshold cannot be overridden.  | 100\n`sonar.cpd.${language}.minimumLines` | (see above) | 10\n\n\n### Analysis Logging\nKey | Description | Default\n---|----|---\n`sonar.log.level` | Control the quantity / level of logs produced during an analysis. `DEBUG`: Display `INFO` logs + more details at `DEBUG` level. Similar to `sonar.verbose=true`. `TRACE`: Display `DEBUG` logs + the timings of all ElasticSearch queries and Web API calls executed by the SonarScanner. | `INFO`\n`sonar.verbose` | Add more detail to both client and server-side analysis logs. Activates `DEBUG` mode for the scanner, and adds client-side environment variables and system properties to server-side log of analysis report processing. ![](/images/exclamation.svg)NOTE: There is the potential for this setting to expose sensitive information such as passwords if they are stored as server-side environment variables. | false\n`sonar.scanner.dumpToFile` | Outputs to the specified file the full list of properties passed to the scanner API as a means to debug analysis. |  \n`sonar.scanner.metadataFilePath` | Set the location where the scanner writes the `report-task.txt` file containing among other things the `ceTaskId`. | value of `sonar.working.directory`\n\n### Quality Gate \nKey | Description | Default\n---|----|---\n`sonar.qualitygate.wait` | Forces the analysis step to poll the SonarQube instance and wait for the Quality Gate status. If there are no other options, you can use this to fail a pipeline build when the Quality Gate is failing. See the [CI Integration](/analysis/branch-pr-analysis-overview/) page for more information. | \n`sonar.qualitygate.timeout` | Sets the number of seconds that the scanner should wait for a report to be processed. | 300\n\n### Deprecated\n[[danger]]\n| These parameters are listed for completeness, but are deprecated and should not be used in new analyses.\n\nKey | Description\n---|----|--- \n`sonar.links.scm_dev` **![](/images/cross.svg)Deprecated since SQ 7.1** | Developer connection. | `<scm><developerConnection>` for Maven projects"},{path:"analysis/azuredevops-integration",content:"---\ntitle: Azure DevOps Integration\nurl: /analysis/azuredevops-integration/\n---\nSonarQube's integration with Azure DevOps allows you to maintain code quality and security in your Azure DevOps repositories. It is compatible with both Azure DevOps Server and Azure DevOps Services.\n\nWith this integration, you'll be able to:\n\n- **Import your Azure DevOps repositories** - Import your Azure DevOps repositories into SonarQube to easily set up SonarQube projects. \n- **Analyze projects with Azure Pipelines** - Integrate analysis into your build pipeline. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), SonarScanners running in Azure Pipelines jobs can automatically detect branches or pull requests being built, so you don't need to specifically pass them as parameters to the scanner.\n- **Add pull request decoration** - (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)) See your Quality Gate and code metric results right in Azure DevOps so you know if it's safe to merge your changes.\n\n## Prerequisites\nIntegration with Azure DevOps Server requires Azure DevOps Server 2020, Azure DevOps Server 2019, TFS 2018, or TFS 2017 Update 2.\n\n### Branch Analysis\nCommunity Edition doesn't support the analysis of multiple branches, so you can only analyze your main branch. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can analyze multiple branches and pull requests.\n\n## Importing your Azure DevOps repositories into SonarQube\nSetting up the import of Azure DevOps repositories into SonarQube allows you to easily create SonarQube projects from your Azure DevOps repositories. If you're using [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) or above, this is also the first step in adding pull request decoration. \n\nTo set up the import of Azure DevOps repositories:  \n\n1. Set your global settings\n2. Add a personal access token for importing repositories  \n\n### Setting your global settings\nTo import your Azure DevOps repositories into SonarQube, you need to first set your global SonarQube settings. Navigate to **Administration > Configuration > General Settings > ALM Integrations**, select the **Azure DevOps** tab, and click the **Create configuration** button. Specify the following settings:\n \n- **Configuration Name** (Enterprise and Data Center Edition only) – The name used to identify your Azure DevOps configuration at the project level. Use something succinct and easily recognizable.\n- **Azure DevOps collection/organization URL** – If you are using Azure DevOps Server, provide your full Azure DevOps collection URL. For example, `https://ado.your-company.com/DefaultCollection`. If you are using Azure DevOps Services, provide your full Azure DevOps organization URL. For example, `https://dev.azure.com/your_organization`.\n- **Personal Access Token** – An Azure DevOps user account is used to decorate Pull Requests. We recommend using a dedicated Azure DevOps account with Administrator permissions. You need a [personal access token](https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=tfs-2017&tabs=preview-page) from this account with the scope authorized for **Code > Read & Write** for the repositories that will be analyzed. This personal access token is used for pull request decoration, and you'll be asked for another personal access token for importing projects in the following section.\n\n### Adding a personal access token for importing repositories\nAfter setting your global settings, you can add a project from Azure DevOps by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting  **Azure DevOps**.\n\nThen, you'll be asked to provide a personal access token with `Code (Read & Write)` scope so SonarQube can access and list your Azure DevOps projects. This token will be stored in SonarQube and can be revoked at anytime in Azure DevOps.\n\nAfter saving your personal access token, you'll see a list of your Azure DevOps projects that you can **set up** to add them to SonarQube. Setting up your projects this way also sets your project settings for pull request decoration. \n\nFor information on analyzing your projects with Azure Pipelines, see the **Analyzing projects with Azure Pipelines** section below.\n\n## Analyzing projects with Azure Pipelines\nSonarScanners running in Azure Pipelines jobs can automatically detect branches or pull requests being built, so you don't need to specifically pass them as parameters to the scanner.\n\n[[info]]\n| Automatic branch detection is only available when using Git.\n\n### Installing your extension\nFrom Visual Studio Marketplace, install the [SonarQube extension](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarqube) by clicking the **Get it free** button. \n\n#### **Azure DevOps Server - build agents**\n\nIf you are using [Microsoft-hosted build agents](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops) then there is nothing else to install. The extension will work with all of the hosted agents (Windows, Linux, and macOS).\n\nIf you are self-hosting the build agents, make sure you have at least the minimum SonarQube-supported version of Java installed.\n\n### Adding a new SonarQube Service Endpoint\nAfter installing your extension, you need to declare your SonarQube server as a service endpoint in your Azure DevOps project settings:\n\n1. In Azure DevOps, go to **Project Settings > Service connections**. \n2. Click **New service connection** and select **SonarQube** from the service connection list.\n3. Enter your SonarQube **Server URL**, an [Authentication Token](/user-guide/user-token/), and a memorable **Service connection name**. Then, click **Save**.\n\n### Configuring branch analysis\nAfter adding your SonarQube service endpoint, you'll need to configure branch analysis. You'll use the following tasks in your build definitions to analyze your projects:\n\n- **Prepare Analysis Configuration** - This task configures the required settings before executing the build.\n\n- **Run Code Analysis** - (Not used in Maven or Gradle projects) This task executes the analysis of source code.\n\n- **Publish Quality Gate Result** - this task displays the Quality Gate status in the build summary letting you know if your code meets quality standards for production. This task may increase your build time as your pipeline has to wait for SonarQube to process the analysis report. It is highly recommended but optional.\n\nSelect your build technology below to expand the instructions for configuring branch analysis and to see an example `.yml` file.\n\n[[collapse]]\n| ## .NET\n| 1. In Azure DevOps, create or edit a **Build Pipeline**, and add a new **Prepare Analysis Configuration** task _before_ your build task:\n|    - Select the SonarQube server endpoint you created in the **Adding a new SonarQube Service Endpoint** section.\n|    - Under **Choose a way to run the analysis**, select **Integrate with MSBuild**.\n|    - In the **project key** field, enter your project key.\n| 1. Add a new **Run Code Analysis** task _after_ your build task.\n| 1. Add a new **Publish Quality Gate Result** on your build pipeline summary.\n| 1. Under the **Triggers** tab of your pipeline, check **Enable continuous integration**, and select all of the branches for which you want SonarQube analysis to run automatically.\n| 1. Save your pipeline.\n|\n| **.yml example**:\n| ```\n| trigger:\n| - master\n| - feature/*\n|\n| steps:\n| # Prepare Analysis Configuration task\n| - task: SonarQubePrepare@4\n|   inputs:\n|     SonarQube: 'YourSonarqubeServerEndpoint'\n|     scannerMode: 'MSBuild'\n|     projectKey: 'YourProjectKey'\n|\n| # Run Code Analysis task\n| - task: SonarQubeAnalyze@4\n|\n| # Publish Quality Gate Result task\n| - task: SonarQubePublish@4\n|   inputs:\n|     pollingTimeoutSec: '300'\n| ```\n\n[[collapse]]\n| ## Maven or Gradle\n| 1. In Azure DevOps, create or edit a **Build Pipeline**, and add a new **Prepare Analysis Configuration** task _before_ your build task:\n|    - Select the SonarQube server endpoint you created in the **Adding a new SonarQube Service Endpoint** section.\n|    - Under **Choose a way to run the analysis**, select **Integrate with Maven or Gradle**.\n|    - Expand the **Advanced section** and replace the **Additional Properties** with the following snippet:\n| ```\n|    # Additional properties that will be passed to the scanner,\n|    # Put one key=value per line, example:\n|    # sonar.exclusions=**/*.bin\n|    sonar.projectKey=YourProjectKey\n| ```\n| 2. Edit or add a new Maven or Gradle task\n|    - Under **Code Analysis**, check **Run SonarQube or SonarCloud Analysis**.\n| 3. Add a new **Publish Quality Gate Result** on your build pipeline summary.\n| 4. Under the **Triggers** tab of your pipeline, check **Enable continuous integration**, and select all of the branches for which you want SonarQube analysis to run automatically.\n| 5. Save your pipeline.\n|\n| **.yml example**:\n| ```\n| trigger:\n| - master\n| - feature/*\n|\n| steps:\n| # Prepare Analysis Configuration task\n| - task: SonarQubePrepare@4\n|   inputs:\n|     SonarQube: 'YourSonarqubeServerEndpoint'\n|     scannerMode: 'Other'\n|     extraProperties: 'sonar.projectKey=YourProjectKey'\n|\n| # Publish Quality Gate Result task\n| - task: SonarQubePublish@4\n|   inputs:\n|     pollingTimeoutSec: '300'\n| ```\n\n[[collapse]]\n| ## Other (JavaScript, TypeScript, Go, Python, PHP, etc.)\n| 1. In Azure DevOps, create or edit a **Build Pipeline**, and add a new **Prepare Analysis Configuration** task _before_ your build task:\n|    - Select the SonarQube server endpoint you created in the **Adding a new SonarQube Service Endpoint** section.\n|    - Under **Choose a way to run the analysis**, select **Use standalone scanner**.\n|    - Select the **Manually provide configuration** mode.\n|    - In the **project key** field, enter your project key.\n| 1. Add a new **Run Code Analysis** task _after_ your build task.\n| 1. Add a new **Publish Quality Gate Result** on your build pipeline summary.\n| 1. Under the **Triggers** tab of your pipeline, check **Enable continuous integration**, and select all of the branches for which you want SonarQube analysis to run automatically.\n| 1. Save your pipeline.\n|\n| **.yml example**:\n| ```\n| trigger:\n| - master\n| - feature/*\n|\n| steps:\n| # Prepare Analysis Configuration task\n| - task: SonarQubePrepare@4\n|   inputs:\n|     SonarQube: 'YourSonarqubeServerEndpoint'\n|     scannerMode: 'CLI'\n|     configMode: 'manual'\n|     cliProjectKey: 'YourProjectKey'\n|\n| # Run Code Analysis task\n| - task: SonarQubeAnalyze@4\n|\n| # Publish Quality Gate Result task\n| - task: SonarQubePublish@4\n|   inputs:\n|     pollingTimeoutSec: '300'\n| ```\n\n[[collapse]]\n| ## Analyzing a C/C++/Obj-C project\n| In your build pipeline, insert the following steps in the order they appear here. These steps can be interweaved with other steps of your build as long as the following order is followed. All steps have to be executed on the same agent.\n| \n| 1. Make the **Build Wrapper** available on the build agent: \n|    \n|    Download and unzip the **Build Wrapper** on the build agent (see the **Prerequisites** section of the [C/C++/Objective-C](/analysis/languages/cfamily/) page). The archive to download and decompress depends on the platform of the host.\n|    Please, note that:\n|    - For the Microsoft-hosted build agent, you will need to make the **Build Wrapper** available on the build agent every time (as part of the build pipeline). To accomplish this, you can add a **PowerShell script** task by inserting a **Command Line** task.\n|     Example of PowerShell commands on a Windows host:\n|     ```\n|     Invoke-WebRequest -Uri '<sonarqube_url>/static/cpp/build-wrapper-win-x86.zip' -OutFile 'build-wrapper.zip'\n|     Expand-Archive -Path 'build-wrapper.zip' -DestinationPath '.'\n|     ```\n|     Example of bash commands on a linux host:\n|     ```\n|     curl '<sonarqube_url>/static/cpp/build-wrapper-linux-x86.zip' --output build-wrapper.zip\n|     unzip build-wrapper.zip\n|     ```\n|     Example of bash commands on a macos host:\n|     ```\n|     curl '<sonarqube_url>/static/cpp/build-wrapper-macosx-x86.zip' --output build-wrapper.zip\n|     unzip build-wrapper.zip\n|     ```  \n|    - For the self-hosted build agent you can either download it every time (using the same scripts) or only once (as part of manual setup of build agent).\n| 1. Add a **Prepare analysis Configuration** task and configure it as follow:\n|     Click on the **Prepare analysis on SonarQube** task to configure it:\n|    * Select the **SonarQube Server**\n|    * In *Choose the way to run the analysis*, select *standalone scanner* (even if you build with *Visual Studio*/*MSBuild*) \n|    * In *Additional Properties* in the *Advanced* section, add the property `sonar.cfamily.build-wrapper-output` with, as its value, the output directory to which the Build Wrapper should write its results: `sonar.cfamily.build-wrapper-output=<output directory>`\n| 1. Add a **Command Line** task to run your build.\n|    For the analysis to happen, your build has to be run through a command line so that it can be wrapped-up by the build-wrapper.\n|    To do so, \n|    * Run **Build Wrapper** executable. Pass in as the arguments (1) the output directory configured in the previous task and (2) the command that runs a clean build of your project (not an incremental build).\n|    Example of PowerShell commands on a Windows host with an *MSBuild* build:\n|      ```\n|     build-wrapper-win-x86/build-wrapper-win-x86-64.exe --out-dir <output directory> MSBuild.exe /t:Rebuild\n|      ```\n|      Example of bash commands on a linux host with a *make* build:\n|      ```\n|      build-wrapper-linux-x86/build-wrapper-linux-x86-64 --out-dir <output directory> make clean all\n|      ```\n|      Example of bash commands on a macos host with a *xcodebuild* build:\n|      ```\n|      build-wrapper-macosx-x86/build-wrapper-macos-x86 --out-dir <output directory> xcodebuild -project myproject.xcodeproj -configuration Release clean build\n|      ```\n| 1. Add a **Run Code Analysis** task to run the code analysis and make the results available to SonarQube. Consider running this task right after the previous one as the build environment should not be significantly altered before running the analysis.\n| 1. Add a **Publish Quality Gate Result** task.\n| \n| **.yml example**:\n| ```\n| trigger:\n| - master\n| - feature/*\n|\n| steps:\n| # Make Build Wrapper available\n| - task: Bash@3\n|   displayName: Download Build Wrapper\n|   inputs:\n|     targetType: inline\n|     script: >\n|       curl  '<SONARQUBE_HOST>/static/cpp/build-wrapper-linux-x86.zip' --output build-wrapper.zip\n|       unzip build-wrapper.zip\n|\n| # Prepare Analysis Configuration task\n| - task: SonarQubePrepare@4\n|   inputs:\n|     SonarQube: 'YourSonarqubeServerEndpoint'\n|     scannerMode: 'CLI'\n|     configMode: 'manual'\n|     cliProjectKey: 'YourProjectKey'\n|     extraProperties: \"sonar.cfamily.build-wrapper-output=bw_output\"\n| # Command Line task to run your build.\n| - task: Bash@3\n|    displayName: Bash Script\n|    inputs:\n|      targetType: inline\n|      script: >\n|        ./build-wrapper-linux-x86/build-wrapper-linux-x86-64 --out-dir bw_output <Your build command>\n|\n| # Run Code Analysis task\n| - task: SonarQubeAnalyze@4\n|\n| # Publish Quality Gate Result task\n| - task: SonarQubePublish@4\n|   inputs:\n|     pollingTimeoutSec: '300'\n| ```\n|  *Note: You need to choose your correct image and adapt the correct wrapper depending on the agent os. See above example to have the correct wrapper.*\n\n### Running your pipeline\nCommit and push your code to trigger the pipeline execution and SonarQube analysis. New pushes on your branches (and pull requests if you set up pull request analysis) trigger a new analysis in SonarQube.\n\n### Maintaining pull request code quality and security \nUsing pull requests allows you to prevent unsafe or substandard code from being merged with your main branch. The following branch policies can help you maintain your code quality and safety by analyzing code and identifying issues in all of the pull requests on your project. These policies are optional, but they're highly recommended so you can quickly track, identify, and remediate issues in your code.\n\n#### **Ensuring your pull requests are automatically analyzed**\nEnsure all of your pull requests get automatically analyzed by adding a [build validation branch policy](https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/azure-repos-git#pr-triggers) on the target branch.\n\n#### **Preventing pull request merges when the Quality Gate fails**\nPrevent the merge of pull requests with a failed Quality Gate by adding a `SonarQube/quality gate` [status check branch policy](https://docs.microsoft.com/en-us/azure/devops/repos/git/pr-status-policy) on the target branch.\n \n[[info]]\n| If your SonarQube project is configured as part of a mono repository in Enterprise Edition or above, you need to use a status check branch policy that uses a SonarQube project key (`SonarQube/quality_gate_[SQ_project_key]`) instead of `SonarQube/quality gate`.\n \nCheck out this [![YouTube link](/images/youtube.png) video](https://www.youtube.com/watch?v=be5aw9_7bBU) for a quick overview on preventing pull requests from being merged when they are failing the Quality Gate.\n\n## Adding pull request decoration to Azure DevOps\nPull request decoration shows your Quality Gate and analysis metrics directly in Azure DevOps.\n\nAfter you've set up SonarQube to import your Azure DevOps repositories as shown in the **Importing your Azure DevOps repositories into SonarQube** above, the simplest way to add pull request decoration is by adding a project from Azure DevOps by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting  **Azure DevOps**.\n\nThen, follow the steps in SonarQube to analyze your project. The project settings for pull request decoration are set automatically.\n\n[[info]]\n| To decorate Pull Requests, a SonarQube analysis needs to be run on your code. You can find the additional parameters required for Pull Request analysis on the [Pull Request Analysis](/analysis/pull-request/) page.\n\n### Adding pull request decoration to a manually created or existing project \nTo add pull request decoration to a manually created or existing project, make sure your global ALM Integration settings are set as shown above in the **Importing your Azure DevOps repositories into SonarQube** section, and set the following project settings at **Project Settings > General Settings > Pull Request Decoration**:\n\n- **Project name**\n- **Repository name**\n\n### Advanced pull request decoration configuration\n\n[[collapse]]\n| ## Adding pull request decoration to projects that are part of a mono repository\n|\n| _Pull request decoration for a mono repository setup is supported starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n|\n| In a mono repository setup, multiple SonarQube projects, each corresponding to a separate project within the mono repository, are all bound to the same Azure DevOps repository. You'll need to set up pull request decoration for each SonarQube project that is part of a mono repository.\n|\n| To add pull request decoration to a project that's part of a mono repository, set your project up manually as shown in the **Adding pull request decoration to a manually created or existing project** section above. You also need to set the **Enable mono repository support** setting to true at **Project Settings > General Settings > Pull Request Decoration**.\n|\n| After setting your project settings, you need to ensure the correct project is being analyzed by adjusting the analysis scope and pass your project names to the scanner. See the following sections for more information.\n|\n| ### Ensuring the correct project is analyzed\n| You need to adjust the analysis scope to make sure SonarQube doesn't analyze code from other projects in your mono repository. To do this set up a **Source File Inclusion** for your  project at **Project Settings > Analysis Scope** with a pattern that will only include files from the appropriate folder. For example, adding `./MyFolderName/**/*` to your inclusions would only include analysis of code in the `MyFolderName` folder. See [Narrowing the Focus](/project-administration/narrowing-the-focus/) for more information on setting your analysis scope.\n|\n| ### Passing project names to the scanner\n| Because of the nature of a mono repository, SonarQube scanners might read all project names of your mono repository as identical. To avoid having multiple projects with the same name, you need to pass the `sonar.projectName` parameter to the scanner. For example, if you're using the Maven scanner, you would pass `mvn sonar:sonar -Dsonar.projectName=YourProjectName`.\n\n[[collapse]]\n| ## Configuring multiple ALM instances\n|You can decorate pull requests from multiple ALM instances by creating a configuration for each ALM instance and then assigning that instance configuration to the appropriate projects. \n|\n|- As part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can create one configuration for each ALM. \n|\n|- Starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), you can create multiple configurations for each ALM. If you have multiple configurations of the same ALM connected to SonarQube, you have to create projects manually.\n\n[[collapse]]\n| ## Linking issues\n| During pull request decoration, individual issues will be linked to their SonarQube counterparts automatically. For this to work correctly, you need to set the instance's **Server base URL** (**[Administration > Configuration > General Settings > General > General](/#sonarqube-admin#/admin/settings/)**) correctly. Otherwise, the links will default to `localhost`.\n\n## FAQ\n\n**Missing Build Agent Capability**\t\n\nIf you add a Windows Build Agent and install a non-oracle Java version on it, the agent will fail to detect a needed capability for the SonarQube Azure DevOps plugin. If you are sure that the `java` executable is available in the `PATH` environment variable, you can add the missing capability manually by going to **your build agent > capabilities > user capabilities > add capability**. Here, you can add the key, value pair java, and null which should allow the SonarQube plugin to be scheduled on that build agent.\t\nThis Bug has been reported to the Microsoft Team with [azure-pipelines-agent#2046](https://github.com/microsoft/azure-pipelines-agent/issues/2046) but is currently not followed up upon.\n"},{path:"analysis/background-tasks",content:'---\ntitle: Background Tasks\nurl: /analysis/background-tasks/\n---\n\nA Background Task can be:\n* the import of an Analysis Report\n* the computation of a Portfolio\n* the import or export of a project\n\n## What happens after the scanner is done analyzing?\n\nAnalysis is not complete until the relevant Background Task has been completed. Even though the SonarScanner\'s log shows `EXECUTION SUCCESS`, the analysis results will not be visible in the {instance} project until the Background Task has been completed. After a SonarScanner has finished analyzing your code, the result of the analysis (Sources, Issues, Metrics) -  the Analysis Report - is sent to {instance} Server for final processing by the Compute Engine. Analysis Reports are queued and processed serially.\n\nAt the Project level, when there is a pending Analysis Report waiting to be consumed, you have a "Pending" notification in the header, next to the date of the most recent completed analysis.\n\nGlobal Administrators can view the current queue at **[Administration > Projects > Background Tasks](/#sonarqube-admin#/admin/background_tasks)**. Project administrators can see the tasks for a project at **Project Settings > Background Tasks**.\n\n## How do I know when analysis report processing fails?\nBackground tasks usually succeed, but sometimes unusual circumstances cause processing to fail. Examples include:\n\n* running out of memory while processing a report from a very large project\n* hitting a clash between the key of an existing module or project and one in the report\n* ...\n\nWhen that happens, the failed status is reflected on the project homepage, but that requires someone to notice it. You can also choose to be notified by email when background tasks fail - either on a project by project basis, or globally on all projects where you have administration rights, in the **Notifications** section of your profile.\n\n## How do I diagnose a failing background task?\nFor each Analysis Report there is a dropdown menu allowing you to access to the "Scanner Context" showing you the configuration of the Scanner at the moment when the code scan has been run.\n\nIf processing failed for the task, an additional option will be available: "Show Error Details", to get the technical details why the processing of the Background Task failed.\n\n## How do I cancel a pending analysis report?\nAdministrators can cancel the processing of a pending task by clicking:\n\n* on the red \'x\' available on each line of a `Pending` task\n* on the red "bulk cancel" option next to the pending jobs count. This button cancels all pending tasks.\n\nOnce processing has begun on a report, it\'s too late to cancel it.\n\n'},{path:"analysis/bitbucket-cloud-integration",content:"---\ntitle: Bitbucket Cloud Integration\nurl: /analysis/bitbucket-cloud-integration/\n---\n\nSonarQube's integration with Bitbucket Cloud allows you to maintain code quality and security in your Bitbucket Cloud repositories.\n\nWith this integration, you'll be able to:\n\n- **Analyze projects with Bitbucket Pipelines** - Integrate analysis into your build pipeline. SonarScanners running in Bitbucket Pipelines can automatically detect branches or pull requests being built so you don't need to specifically pass them as parameters to the scanner (branch and pull request analysis is available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)).\n- **Add pull request decoration** - (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)) See your Quality Gate and code metric results right in Bitbucket Cloud so you know if it's safe to merge your changes.\n\n## Analyzing projects with Bitbucket Pipelines\nSonarScanners running in Bitbucket Pipelines can automatically detect branches or pull requests being built so you don't need to specifically pass them as parameters to the scanner.\n\nTo analyze your projects with Bitbucket Pipelines, you need to:\n- Set your environment variables.\n- Configure your `bitbucket-pipelines.yml file`.\n\n### Setting environment variables\nYou can set environment variables securely for all pipelines in Bitbucket Cloud's settings. See [User-defined variables](https://support.atlassian.com/bitbucket-cloud/docs/variables-and-secrets/#User-defined-variables) for more information.\n\n[[info]]\n| You may need to commit your `bitbucket-pipelines.yml` before being able to set environment variables for pipelines.\n\nYou need to set the following environment variables in Bitbucket Cloud for analysis:\n\n- `SONAR_TOKEN` – Generate a SonarQube [token](/user-guide/user-token/) for Bitbucket Cloud and create a custom **secured** environment variable in Bitbucket Cloud with `SONAR_TOKEN` as the **Name** and the token you generated as the **Value**.\n- `SONAR_HOST_URL` – Create a custom environment variable with `SONAR_HOST_URL` as the **Name** and your SonarQube server URL as the **Value**.\n\n### Configuring your bitbucket-pipelines.yml file\nThis section shows you how to configure your `bitbucket-pipelines.yml` file.\n\nYou'll set up your build according to your SonarQube edition:\n\n- **Community Edition** – Community Edition doesn't support multiple branches, so you should only analyze your main branch. You can restrict analysis to your main branch by setting it as the only branch in your `branches` pipeline in your `bitbucket-pipelines.yml` file and not using the `pull-requests` pipeline.\n- **Developer Edition and above** – Bitbucket Pipelines can build specific branches and pull requests if you use the `branches` and `pull-requests` pipelines as shown in the example configurations below.\n\nClick the scanner you're using below to expand the example configuration:\n\n**Note:** This assumes a typical Gitflow workflow. See [Use glob patterns on the Pipelines yaml file](https://support.atlassian.com/bitbucket-cloud/docs/use-glob-patterns-on-the-pipelines-yaml-file/) provided by Atlassian for more information on customizing what branches or pull requests trigger an analysis.\n\n[[collapse]]\n| ## SonarScanner for Gradle\n|\n| **Note:** A project key might have to be provided through a `build.gradle` file, or through the command line parameter. For more information, see the [SonarScanner for Gradle](/analysis/scan/sonarscanner-for-gradle/) documentation.\n|\n| Add the following to your `build.gradle` file:\n|\n| ```\n| plugins {\n|   id \"org.sonarqube\" version \"3.1\"\n| }\n| ```\n|\n| Write the following in your `bitbucket-pipelines.yml`:\n|\n| ```\n| image: openjdk:8\n|\n| clone:\n|   depth: full\n|\n| pipelines:\n|   branches:\n|     '{master,develop}':\n|       - step:\n|           name: SonarQube analysis\n|           caches:\n|             - gradle\n|             - sonar\n|           script:\n|             - bash ./gradlew sonarqube\n|\n|   pull-requests:\n|     '**':\n|       - step:\n|           name: SonarQube analysis\n|           caches:\n|             - gradle\n|             - sonar\n|           script:\n|             - bash ./gradlew sonarqube\n|\n| definitions:\n|   caches:\n|     sonar: ~/.sonar\n| ```\n\n[[collapse]]\n| ## SonarScanner for Maven\n|\n| **Note:** A project key might have to be provided through a `pom.xml` file, or through the command line parameter. For more information, see the [SonarScanner for Maven](/analysis/scan/sonarscanner-for-maven/) documentation.\n|\n| Write the following in your `bitbucket-pipelines.yml`:\n|\n| ```\n| image: maven:3.3.9\n|\n| clone:\n|   depth: full\n|\n| pipelines:\n|   branches:\n|     '{master,develop}':\n|       - step:\n|           name: SonarQube analysis\n|           caches:\n|             - maven\n|             - sonar\n|           script:\n|             - mvn verify sonar:sonar\n|\n|   pull-requests:\n|     '**':\n|       - step:\n|           name: SonarQube analysis\n|           caches:\n|             - maven\n|             - sonar\n|           script:\n|             - mvn verify sonar:sonar\n|\n| definitions:\n|   caches:\n|     sonar: ~/.sonar\n| ```\n\n[[collapse]]\n| ## SonarScanner CLI\n|\n| **Note:** A project key has to be provided through a `sonar-project.properties` file, or through the command line parameter. For more information, see the [SonarScanner](/analysis/scan/sonarscanner/) documentation.\n|\n| Write the following in your `bitbucket-pipelines.yml`:\n|\n| ```\n| clone:\n|   depth: full\n|\n| pipelines:\n|   branches:\n|     '{master,develop}':\n|       - step:\n|           name: SonarQube analysis\n|           image: sonarsource/sonar-scanner-cli:latest\n|           caches:\n|             - sonar\n|           script:\n|             - sonar-scanner\n|\n|   pull-requests:\n|     '**':\n|       - step:\n|           name: SonarQube analysis\n|           image: sonarsource/sonar-scanner-cli:latest\n|           caches:\n|             - sonar\n|           script:\n|             - sonar-scanner\n|\n| definitions:\n|   caches:\n|     sonar: /opt/sonar-scanner/.sonar\n| ```\n\n#### **Failing the pipeline job when the Quality Gate fails**\nIn order for the Quality Gate to fail the pipeline when it is red on the SonarQube side, the scanner needs to wait for the SonarQube Quality Gate status. To enable this, pass the `-Dsonar.qualitygate.wait=true` parameter to the scanner in the `bitbucket-pipelines.yml` file.\n\nExample:\n\n```\nmvn verify sonar:sonar -Dsonar.qualitygate.wait=true\n```\n\nThis will make the analysis step poll SonarQube regularly until the Quality Gate is computed. This will increase your pipeline duration. Note that, if the Quality Gate is red, this will make the analysis step fail, even if the actual analysis itself is successful. We advise only using this parameter when necessary (for example, to block a deployment pipeline if the Quality Gate is red). It should not be used to report the Quality Gate status in a pull request, as this is already done with pull request decoration.\n\nYou can set the `sonar.qualitygate.timeout` property to an amount of time (in seconds) that the scanner should wait for a report to be processed. The default is 300 seconds. \n\n### For more information\nFor more information on configuring your build with Bitbucket Pipelines, see the [Configure bitbucket-pipelines.yml](https://support.atlassian.com/bitbucket-cloud/docs/configure-bitbucket-pipelinesyml/) documentation provided by Atlassian.\n\n## Adding Pull Request decoration to Bitbucket Cloud\n\nPull request decoration shows your Quality Gate and analysis metrics directly in Bitbucket Cloud. To set up pull request decoration, you need to do the following:\n\n1. Set up a dedicated OAuth consumer to decorate your pull requests.\n1. Set your global **ALM Integration** settings.\n1. Set your project-level **Pull Request Decoration** settings.\n\n[[info]]\n| To decorate Pull Requests, a SonarQube analysis needs to be run on your code. You can find the additional parameters required for Pull Request analysis on the [Pull Request Analysis](/analysis/pull-request/) page.\n\n### Setting up your OAuth consumer\nSonarQube uses a dedicated OAuth consumer to decorate pull requests. You need to create the OAuth consumer in your Bitbucket Cloud workspace settings and specify the following:\n\n- **Name** – the name of your OAuth consumer\n- **Callback URL** – Bitbucket Cloud requires this field, but it's not used by SonarQube so you can use any URL.\n- **This is a private consumer** – Your OAuth consumer needs to be private. Make sure this check box is selected.\n- **Permissions** – Grant **Read** access for the **Pull requests** permission.\n\n### Setting your global ALM Integration settings\nTo set your global ALM Integration settings, navigate to **Administration > ALM Integrations**, select the **Bitbucket** tab, and select **Bitbucket Cloud** as the variant you want to configure. From here, specify the following settings:\n\n- **Configuration Name** (Enterprise and Data Center Edition only) – The name used to identify your GitHub configuration at the project level. Use something succinct and easily recognizable.\n- **Workspace ID** – The workspace ID is part of your bitbucket cloud URL `https://bitbucket.org/{WORKSPACE-ID}/{repository-slug}`\n- **OAuth Key** – Bitbucket automatically creates an OAuth key when you create your OAuth consumer. You can find it in your Bitbucket Cloud workspace settings under **OAuth consumers**.\n- **OAuth Secret** – Bitbucket automatically creates an OAuth secret when you create your OAuth consumer. You can find it in your Bitbucket Cloud workspace settings under **OAuth consumers**.\n\n### Setting your project-level Pull Request Decoration settings\nFrom your project **Overview**, navigate to **Project Settings > General Settings > Pull Request Decoration**.\n\nFrom here, set your:\n\n- **Configuration name** – The configuration name that corresponds to your Bitbucket Cloud instance.\n- **Repository SLUG** – The repository SLUG is part of your bitbucket cloud URL `https://bitbucket.org/{workspace-id}/{REPOSITORY-SLUG}`\n\n### Advanced pull request decoration configuration\n\n[[collapse]]\n| ## Adding pull request decoration to projects that are part of a mono repository\n|\n| _Pull request decoration for a mono repository setup is supported starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n|\n| In a mono repository setup, multiple SonarQube projects, each corresponding to a separate project within the mono repository, are all bound to the same Bitbucket Cloud repository. You'll need to set up pull request decoration for each SonarQube project that is part of a mono repository.\n|\n| To add pull request decoration to a project that's part of a mono repository, set your project up as shown in the **Adding pull request decoration to Bitbucket Cloud** section above. You also need to set the **Enable mono repository support** setting to true at **Project Settings > General Settings > Pull Request Decoration** .\n|\n| After setting your project settings, you need to ensure the correct project is being analyzed by adjusting the analysis scope and pass your project names to the scanner. See the following sections for more information.\n|\n| ### Ensuring the correct project is analyzed\n| You need to adjust the analysis scope to make sure SonarQube doesn't analyze code from other projects in your mono repository. To do this set up a **Source File Inclusion** for your  project at **Project Settings > Analysis Scope** with a pattern that will only include files from the appropriate folder. For example, adding `./MyFolderName/**/*` to your inclusions would only include analysis of code in the `MyFolderName` folder. See [Narrowing the Focus](/project-administration/narrowing-the-focus/) for more information on setting your analysis scope.\n|\n| ### Passing project names to the scanner\n| Because of the nature of a mono repository, SonarQube scanners might read all project names of your mono repository as identical. To avoid having multiple projects with the same name, you need to pass the `sonar.projectName` parameter to the scanner. For example, if you're using the Maven scanner, you would pass `mvn sonar:sonar -Dsonar.projectName=YourProjectName`.\n\n[[collapse]]\n| ## Configuring multiple ALM instances\n|You can decorate pull requests from multiple ALM instances by creating a configuration for each ALM instance and then assigning that instance configuration to the appropriate projects. \n|\n|- As part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can create one configuration for each ALM. \n|\n|- Starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), you can create multiple configurations for each ALM. If you have multiple configurations of the same ALM connected to SonarQube, you have to create projects manually.\n\n[[collapse]]\n| ## Linking issues\n| During pull request decoration, individual issues will be linked to their SonarQube counterparts automatically. For this to work correctly, you need to set the instance's **Server base URL** (**[Administration > Configuration > General Settings > General > General](/#sonarqube-admin#/admin/settings/)**) correctly. Otherwise, the links will default to `localhost`.\n"},{path:"analysis/bitbucket-integration",content:"---\ntitle: Bitbucket Server Integration\nurl: /analysis/bitbucket-integration/\n---\nSonarQube's integration with Bitbucket Server allows you to maintain code quality and security in your Bitbucket Server repositories.\n\nWith this integration, you'll be able to:\n\n- **Import your BitBucket Server repositories** - Import your Bitbucket Server repositories into SonarQube to easily set up SonarQube projects.  \n- **Add pull request decoration** - (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)) See your Quality Gate and code metric results right in Bitbucket Server so you know if it's safe to merge your changes.\n\n## Prerequisites\nIntegration with Bitbucket Server requires at least Bitbucket Server version 5.15.\n\n### Branch Analysis\nCommunity Edition doesn't support the analysis of multiple branches, so you can only analyze your main branch. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can analyze multiple branches and pull requests.\n\n## Importing your Bitbucket Server repositories into SonarQube\nSetting up the import of BitBucket Server repositories into SonarQube allows you to easily create SonarQube projects from your Bitbucket Server repositories. If you're using [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) or above, this is also the first step in adding pull request decoration.\n\nTo set up the import of BitBucket Server repositories:\n\n1. Set your global ALM integration settings\n1. Add a personal access token for importing repositories\n\n### Setting your global ALM Integration settings\nTo set your global ALM Integration settings, navigate to **Administration > ALM Integrations**, select the **Bitbucket** tab, and select **Bitbucket Server** as the variant you want to configure. From here, specify the following settings:\n\n- **Configuration Name** (Enterprise and Data Center Edition only) – The name used to identify your Bitbucket Server configuration at the project level. Use something succinct and easily recognizable.\n- **Bitbucket Server URL** – your instances URL. For example, `https://bitbucket-server.your-company.com`.\n- **Personal Access Token** – A Bitbucket Server user account is used to decorate Pull Requests. We recommend using a dedicated Bitbucket Server account with Administrator permissions. You need a [Personal Access Token](https://confluence.atlassian.com/bitbucketserver0515/personal-access-tokens-961275199.html) from this account with **Write** permission for the repositories that will be analyzed. This personal access token is used for pull request decoration, and you'll be asked for another personal access token for importing projects in the following section.\n\n### Adding a personal access token for importing repositories\nAfter setting your global settings, you can add a project from Bitbucket Server by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting **Bitbucket**.\n\nThen, you'll be asked to provide a personal access token from your user account with `Read` permissions for both projects and repositories. This token will be stored in SonarQube and can be revoked at anytime in Bitbucket Server.\n\nAfter saving your personal access token, you'll see a list of your Bitbucket Server projects that you can **set up** to add them to SonarQube. Setting up your projects this way also sets your project settings for pull request decoration.\n\n## Adding pull request decoration to Bitbucket Server\nPull request decoration shows your Quality Gate and analysis metrics directly in Bitbucket Server:\n\nAfter you've set up SonarQube to import your Bitbucket Server repositories as shown in the previous section, the simplest way to add pull request decoration is by adding a project from Bitbucket Server by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting **Bitbucket**.\n\nThen, follow the steps in SonarQube to analyze your project. The project settings for pull request decoration are set automatically.\n\n[[info]]\n| To decorate Pull Requests, a SonarQube analysis needs to be run on your code. You can find the additional parameters required for Pull Request analysis on the [Pull Request Analysis](/analysis/pull-request/) page.\n\n### Adding pull request decoration to a manually created or existing project\nTo add pull request decoration to a manually created or existing project, make sure your global ALM Integration settings are configured as shown in the **Importing your Bitbucket Server repositories into SonarQube** section above, and set the following project settings at **Project Settings > General Settings > Pull Request Decoration**:\n\n- **Configuration name** – The configuration name that corresponds to your ALM instance.\n- **Project Key** – the project key is part of your BitBucket Server repository URL (.../projects/**{KEY}**/repos/{SLUG}/browse).\n- **Repository SLUG** – The repository slug is part of your BitBucket Server repository URL (.../projects/{KEY}/repos/**{SLUG}**/browse).\n\n### Advanced pull request decoration configuration\n\n[[collapse]]\n| ## Adding pull request decoration to projects that are part of a mono repository\n|\n| _Pull request decoration for a mono repository setup is supported starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n|\n| In a mono repository setup, multiple SonarQube projects, each corresponding to a separate project within the mono repository, are all bound to the same Bitbucket Server repository. You'll need to set up pull request decoration for each SonarQube project that is part of a mono repository.\n|\n| To add pull request decoration to a project that's part of a mono repository, set your project up manually as shown in the **Adding pull request decoration to a manually created or existing project** section above. You also need to set the **Enable mono repository support** setting to true at **Project Settings > General Settings > Pull Request Decoration**.\n|\n| After setting your project settings, you need to ensure the correct project is being analyzed by adjusting the analysis scope and pass your project names to the scanner. See the following sections for more information.\n|\n| ### Ensuring the correct project is analyzed\n| You need to adjust the analysis scope to make sure SonarQube doesn't analyze code from other projects in your mono repository. To do this set up a **Source File Inclusion** for your  project at **Project Settings > Analysis Scope** with a pattern that will only include files from the appropriate folder. For example, adding `./MyFolderName/**/*` to your inclusions would only include analysis of code in the `MyFolderName` folder. See [Narrowing the Focus](/project-administration/narrowing-the-focus/) for more information on setting your analysis scope.\n|\n| ### Passing project names to the scanner\n| Because of the nature of a mono repository, SonarQube scanners might read all project names of your mono repository as identical. To avoid having multiple projects with the same name, you need to pass the `sonar.projectName` parameter to the scanner. For example, if you're using the Maven scanner, you would pass `mvn sonar:sonar -Dsonar.projectName=YourProjectName`.\n\n[[collapse]]\n| ## Configuring multiple ALM instances\n|You can decorate pull requests from multiple ALM instances by creating a configuration for each ALM instance and then assigning that instance configuration to the appropriate projects.\n|\n|- As part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can create one configuration for each ALM.\n|\n|- Starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), you can create multiple configurations for each ALM. If you have multiple configurations of the same ALM connected to SonarQube, you have to create projects manually.\n\n[[collapse]]\n| ## Linking issues\n| During pull request decoration, individual issues will be linked to their SonarQube counterparts automatically. For this to work correctly, you need to set the instance's **Server base URL** (**[Administration > Configuration > General Settings > General > General](/#sonarqube-admin#/admin/settings/)**) correctly. Otherwise, the links will default to `localhost`.\n\n## Preventing pull request merges when the Quality Gate fails\nAfter setting up pull request analysis, you can block pull requests from being merged if it is failing the Quality Gate. To do this:\n1. In Bitbucket Server, navigate to **Repository settings > Code Insights**.\n2. Add a **Required report** called `com.sonarsource.sonarqube`\n\n[[info]]\n|If your SonarQube project is configured as part of a mono repository in Enterprise Edition or above, you need to use a **Required report** that uses a SonarQube project key (`com.sonarsource.sonarqube_{sq-project-key}` instead of `com.sonarsource.sonarqube`).\n\n3. Select **Must pass** as the **Required status**.\n4. Select **Must not have any annotations** as the **Annotation requirements**.\n"},{path:"analysis/branch-pr-analysis-overview",content:"---\ntitle: Overview\nurl: /analysis/branch-pr-analysis-overview/\n---\n\n_Merge and Pull Request analysis is available as part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) and [above](https://www.sonarsource.com/plans-and-pricing/)._\n\nSonarScanners running in GitLab CI/CD, Azure Pipelines, Cirrus CI, and Jenkins with a Branch Source plugin configured can automatically detect branches and merge or pull requests by using environment variables set in the jobs.\n\n[[warning]]\n| Automatic configuration is disabled if any branch or pull request properties have been set manually.\n\n## Failing a pipeline job when the Quality Gate fails\nIf you're using Jenkins, you can suspend pipeline execution until the analysis' Quality Gate status is known. See the [Jenkins](/analysis/jenkins/) integration page.\n\nFor other CIs, you can use the `sonar.qualitygate.wait=true` analysis parameter in your configuration file. Setting `sonar.qualitygate.wait` to true forces the analysis step to poll your SonarQube instance until the Quality Gate status is available. This increases the pipeline duration and causes the analysis step to fail any time the Quality Gate fails, even if the actual analysis is successful. You should only use this parameter if it's necessary.\n\nYou can set the `sonar.qualitygate.timeout` property to the number of seconds that the scanner should wait for a report to be processed. The default is 300 seconds.\n\n## GitLab CI/CD\nFor GitLab CI/CD configuration, see the [GitLab ALM integration](/analysis/gitlab-integration/) page.\n\n## Azure Pipelines\nFor Azure Pipelines configuration, see the [Azure DevOps integration](/analysis/azuredevops-integration/) page.\n\n## Bitbucket Pipelines\nFor Bitbucket Pipelines configuration, see the [Bitbucket Cloud integration](/analysis/bitbucket-cloud-integration/) page.\n\n## Jenkins\nFor Jenkins configuration, see [Jenkins](/analysis/jenkins/).\n"},{path:"analysis/coverage",content:'---\ntitle: Test Coverage & Execution\nurl: /analysis/coverage/\n---\n\nThis page lists analysis parameters related to test coverage and execution reports. For more other parameters, see [Analysis Parameters](/analysis/analysis-parameters/).\n\nSonarQube doesn\'t run your tests or generate reports. It only imports pre-generated reports. Below you\'ll find language- and tool-specific analysis parameters for importing coverage and execution reports.\n\nIn the [Guides](https://community.sonarsource.com/c/announce/guides) category of the [SonarSource Community forum](https://community.sonarsource.com/) you might find instructions on generating these reports.\n\nSome properties support the following wildcards in paths. The remarks for properties that support wildcards will mention that fact. If the remarks do not say wildcards are supported, then they are not.:\n\nSymbol|Meaning\n---|---\n`?`|a single character\n`*`|any number of characters\n`**`|any number of directories\n\n## Test Coverage\nUnless otherwise specified, these properties require values that are relative to project root.\n\nLanguage|Property|Remarks\n----|----|----\n**Any**|`sonar.coverageReportPaths`|Path to coverage report in the [Generic Test Data](/analysis/generic-test/) format.\nApex|`sonar.apex.coverage.reportPath`|Path to the `test-result-codecoverage.json` report file generated by the [`apex:test:run`](https://developer.salesforce.com/docs/atlas.en-us.sfdx_cli_reference.meta/sfdx_cli_reference/cli_reference_force_apex.htm?search_text=apex%20test#cli_reference_test_run) command of the [Salesforce CLI](https://developer.salesforce.com/tools/sfdxcli). Note, you must have a [Salesforce DX project](https://developer.salesforce.com/docs/atlas.en-us.sfdx_dev.meta/sfdx_dev/sfdx_dev_workspace_setup.htm) set up and linked to your Org\nC / C++ / Objective-C|`sonar.cfamily.gcov.reportsPath`|Path to the directory containing native `*.gcov` reports (not the XML reports generated by gcovr)\nC / C++ / Objective-C|`sonar.cfamily.llvm-cov.reportPath`| Path to a llvm-cov report\nC / C++ / Objective-C|`sonar.cfamily.vscoveragexml.reportsPath`|Path may be absolute or relative to the solution directory. Path wildcards (see above) are supported. Note that the `.coveragexml` report format offered by Visual Studio is not supported.\nC / C++ / Objective-C|`sonar.cfamily.bullseye.reportPath`| Path to the report from Bullseye, version >= 8.9.63 (use [covxml](http://www.bullseye.com/help/ref-covxml.html) tool)\nC#|`sonar.cs.vscoveragexml.reportsPaths`|Path to Visual Studio Code Coverage report. Multiple paths may be comma-delimited, or included via wildcards. See _Notes on importing .NET reports_ below.\nC#|`sonar.cs.dotcover.reportsPaths`|Path to dotCover coverage report. See _Notes on importing .NET reports_ below.\nC#|`sonar.cs.opencover.reportsPaths`|Path to OpenCover coverage report. See _Notes on importing .NET reports_ below.\nC#|`sonar.cs.ncover3.reportsPaths`![](/images/cross.svg)|**Deprecated.** Path to NCover3 coverage report. See _Notes on importing .NET reports_ below.\nFlex|`sonar.flex.cobertura.reportPaths`|Path to the Cobertura XML reports. Multiple paths may be comma-delimited. May be absolute or relative to the project base directory.\nGo|`sonar.go.coverage.reportPaths`|Comma-delimited list of paths to coverage report files. Path wildcards are supported (see above) since SonarGo 1.1.\nJava / Kotlin / Scala / JVM|`sonar.coverage.jacoco.xmlReportPaths`|Path to JaCoCo XML coverage reports. Path wildcards are supported (see above).\nJavaScript / TypeScript|`sonar.javascript.lcov.reportPaths`|Comma-delimited list of paths to LCOV coverage report files. Paths may be absolute or relative to project root.\nPHP|`sonar.php.coverage.reportPaths`|Comma-delimited list of paths to Clover XML-format coverage report files. Paths may be absolute or relative to project root.\nPython|`sonar.python.coverage.reportPaths`|Comma-delimited list of paths to coverage reports in the Cobertura XML format. Path wildcards are supported (see above). Leave unset to use the default (`coverage-reports/*coverage-*.xml`).\nRuby|`sonar.ruby.coverage.reportPaths`|Comma-delimited list of paths to SimpleCov report files generated with the [JSON formatter](https://github.com/simplecov-ruby/simplecov#json-formatter) (availaible from SimpleCov 0.20). For SimpleCov versions < 0.18, you can provide `.resultset.json` report files (not recommended). Paths may be absolute or relative to project-root.\nScala|`sonar.scala.coverage.reportPaths`|Comma-separated list of paths to `scoverage.xml` report files generaged by Scoverage.\nSwift, Xcode 9.3+|&nbsp;|You can use the [xccov-to-sonarqube-generic.sh](https://github.com/SonarSource/sonar-scanning-examples/blob/master/swift-coverage/swift-coverage-example/xccov-to-sonarqube-generic.sh) script from the [sonar-scanning-examples/swift-coverage](https://github.com/SonarSource/sonar-scanning-examples/tree/master/swift-coverage) project convert output from Xcode 9.3\'s xccov tool to the [Generic Test Data](/analysis/generic-test/) format.\nSwift, Xcode 7-9.2|`sonar.swift.coverage.reportPath`|Path to the report generated by `llvm-cov show`. Path may be absolute or relative to project root.\nVB.NET|`sonar.vbnet.vscoveragexml.reportsPaths`|Path to Visual Studio Code Coverage report. Multiple paths may be comma-delimited, or included via wildcards. See _Notes on importing .NET reports_ below.\nVB.NET|`sonar.vbnet.dotcover.reportsPaths`|Path to dotCover coverage report. See _Notes on importing .NET reports_ below.\nVB.NET|`sonar.vbnet.opencover.reportsPaths`|Path to OpenCover coverage report. See _Notes on importing .NET reports_ below.\nVB.Net|`sonar.vbnet.ncover3.reportsPaths`![](/images/cross.svg)|**Deprecated.** Path to NCover3 coverage report. See _Notes on importing .NET reports_ below.\n\n\n## Test Execution\nUnless otherwise specified, these properties require values that are relative to project root.\n\nLanguage|Property|Remarks\n---|---|---\n**All**|`sonar.testExecutionReportPaths`|Comma-delimited list of paths to execution reports in the [Generic Execution Data](/analysis/generic-test/) format.\nC / C++ / Objective-C|`sonar.cfamily.cppunit.reportsPath`|Path to the directory holding the [CPPUnit](http://sourceforge.net/projects/cppunit/) reports. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\nC#|`sonar.cs.vstest.reportsPaths`|Paths to VSTest reports. Multiple paths may be comma-delimited, or included via wildcards. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\nC#|`sonar.cs.nunit.reportsPaths`|Paths to NUnit execution reports. Multiple paths may be comma-delimited, or included via wildcards. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\nC#|`sonar.cs.xunit.reportsPaths`|Paths to xUnit execution reports. Multiple paths may be comma-delimited, or included via wildcards. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\nGo|`sonar.go.tests.reportPaths`|Comma-delimited list of paths to unit test report files. Paths may be absolute or relative to project root.\nJava / Kotlin|`sonar.junit.reportPaths`|Comma-delimited list of paths to Surefire XML-format reports.\nJavaScript / TypeScript |&nbsp;|You can use [jest-sonar-reporter](https://www.npmjs.com/package/jest-sonar-reporter) or [karma-sonarqube-unit-reporter](https://github.com/tornaia/karma-sonarqube-unit-reporter) to create reports in the [Generic Execution Data](/analysis/generic-test/) format. Both packages are available on npm.\nPHP|`sonar.php.tests.reportPath`|Path to the PHPUnit unit test execution report file. Path may be absolute or relative to project root.\nPython|`sonar.python.xunit.reportPath`|Path to unit test execution report. Leave unset to use the default (`xunit-reports/xunit-result-*.xml`). Path wildcards (see above) are supported. If any paths in the report are invalid, set `sonar.python.xunit.skipDetails=true` to collect only project-level details.\nVB.NET|`sonar.vbnet.vstest.reportsPaths`|Paths to VSTest execution reports. Multiple paths may be comma-delimited, or included via wildcards. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\nVB.NET|`sonar.vbnet.nunit.reportsPaths`|Paths to NUnit execution reports. Multiple paths may be comma-delimited, or included via wildcards. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\nVB.NET|`sonar.vbnet.xunit.reportsPaths`|Paths to xUnit execution reports. Multiple paths may be comma-delimited, or included via wildcards. Note that while measures such as the number of tests are displayed at project level, no drilldown is available.\n\n## Importing .NET reports\nTo import .NET reports, the report generation process must be executed after the begin step and before the end MSBuild command. The following steps detail importing .NET reports:\n\n1. Run the SonarScanner.MSBuild.exe `begin` command, specifying the absolute path where the reports _will be_ available using the `/d:propertyKey="path"` syntax ("propertyKey" depends on the tool)\n1. Build your project using MSBuild\n1. Run your test tool, instructing it to produce a report at the same location specified earlier to the MSBuild SonarQube Runner ([How to generate reports with different tools](https://community.sonarsource.com/t/coverage-test-data-generate-reports-for-c-vb-net/9871)) \n1. Run the SonarScanner.MSBuild.exe `end` command\n\nFor more information, see the [Generate Reports for C#, VB.net Community Post](https://community.sonarsource.com/t/coverage-test-data-generate-reports-for-c-vb-net/9871).\n'},{path:"analysis/external-issues",content:"---\ntitle: Importing Third-Party Issues\nurl: /analysis/external-issues/\n---\n\nThis page lists analysis parameters related to the import of issues raised by external, third-party analyzers. If your analyzer isn't on this page, see the [Generic Issue Import Format](/analysis/generic-issue/) for a generic way to import external issues.\n\nSonarQube doesn't run your external analyzers or generate reports. It only imports pre-generated reports. Below you'll find language- and tool-specific analysis parameters for importing reports generated by external analyzers. \n\nIn the [Guides](https://community.sonarsource.com/c/announce/guides) category of the [SonarSource Community forum](https://community.sonarsource.com/) you might find instructions on generating these reports.\n\nSome properties support the following wildcards in paths. The remarks for properties that support wildcards will mention that fact. If the remarks do not say wildcards are supported, then they are not.:\n\nSymbol|Meaning\n---|---\n`?`|a single character\n`*`|any number of characters\n`**`|any number of directories\n\nUnless otherwise specified, the following properties accept both absolute paths and paths relative to project root.\n\nLanguage|Property|Remarks\n----|----|----\nApex|`sonar.apex.pmd.reportPaths`|Comma-delimited list of paths to [PMD Apex](https://pmd.github.io/pmd-5.5.7/pmd-apex/rules/index.html) [XML reports](https://pmd.github.io/latest/pmd_userdocs_installation.html#running-pmd-via-command-line)|\nCSS|`sonar.css.stylelint.reportPaths`|Comma-delimited list of paths to [StyleLint.io](https://stylelint.io/) reports|\nGo|`sonar.go.govet.reportPaths`|Comma-delimited list of paths to [GoVet](https://golang.org/cmd/vet/) reports|\nGo|`sonar.go.golint.reportPaths`|Comma-delimited list of paths to [GoLint](https://github.com/golang/lint) reports|\nGo|`sonar.go.gometalinter.reportPaths`|Comma-delimited list of paths to [GoMetaLinter](https://github.com/alecthomas/gometalinter) reports|\nGo|`sonar.go.golangci-lint.reportPaths`|Comma-delimited list of paths to [golangci-lint](https://github.com/golangci/golangci-lint) reports in checkstyle format (use `--out-format checkstyle` golangci-lint option)|\nJava|`sonar.java.spotbugs.reportPaths`|Comma-delimited list of paths to reports from [SpotBugs](https://spotbugs.github.io/), FindSecBugs, or FindBugs|\nJava|`sonar.java.pmd.reportPaths`|Comma-delimited list of paths to reports from [PMD](http://maven.apache.org/plugins/maven-pmd-plugin/usage.html)\nJava|`sonar.java.checkstyle.reportPaths`|Comma-delimited list of paths to reports from [Checkstyle](http://maven.apache.org/plugins/maven-checkstyle-plugin/checkstyle-mojo)\nJavaScript|`sonar.eslint.reportPaths`|Comma-delimited list of paths to JSON [ESLint](https://eslint.org/) reports (use `-f json` ESLint option)\nKotlin|`sonar.androidLint.reportPaths`|Comma-delimited list of paths to AndroidLint reports\nKotlin|`sonar.kotlin.detekt.reportPaths`|Comma-delimited list of paths to [Detekt](https://github.com/arturbosch/detekt) reports\nPython|`sonar.python.pylint.reportPaths`|Comma-delimited list of paths to [Pylint](http://www.pylint.org/) reports (use `--output-format=parseable` [Pylint option](https://docs.pylint.org/en/1.6.0/output.html))\nPython|`sonar.python.bandit.reportPaths`|Comma-delimited list of paths to [Bandit](https://github.com/PyCQA/bandit/blob/master/README.rst) reports\nPython|`sonar.python.flake8.reportPaths`|Comma-delimited list of paths to [Flake8](https://flake8.pycqa.org/en/latest/) reports\nRuby|`sonar.ruby.rubocop.reportPaths`|Comma-delimited list of paths to [Rubocop](https://github.com/rubocop-hq/rubocop) reports\nScala|`sonar.scala.scalastyle.reportPaths`|Comma-delimited list of paths to [Scalastyle](http://www.scalastyle.org/) reports\nScala|`sonar.scala.scapegoat.reportPaths`|Comma-delimited list of paths to [Scapegoat](https://github.com/sksamuel/scapegoat) reports in the **Scalastyle format**\nSwift|`sonar.swift.swiftLint.reportPaths`|Comma-delimited list of paths to [SwiftLint](https://github.com/realm/SwiftLint) reports in JSON format\nTypeScript|`sonar.typescript.tslint.reportPaths`|Comma-delimited list of paths to [TSLint](https://palantir.github.io/tslint/) reports in JSON format (use `-t json` TSLint option)|\n\n**Notes on external .NET issues**  \nIssues from third-party Roslyn analyzers (including Roslyn analyzers provided by Microsoft) are included in the MSBuild output and imported by default into {instance} so no properties exist to enable that behavior. Instead, properties are available to adjust the import and to _stop_ importing those issues.\n\nNote that Roslyn issues with an *error* severity automatically fail the build. We don't recommended running the Scanner for MSBuild's end step if the MSBuild step fails for any reason because it will result in an essentially empty analysis.\n\nLanguage|Property|Remarks\n----|----|----\nC#|`sonar.cs.roslyn.ignoreIssues`|Set to `true` to disable import of external issues. Defaults to `false`.\nC#|`sonar.cs.roslyn.bugCategories` `sonar.cs.roslyn.vulnerabilityCategories` `sonar.cs.roslyn.codeSmellCategories`|Comma-delimited list of categories whose issues should be classified as Bugs, Vulnerabilities, or Code Smells. \nVB.NET|`sonar.vbnet.roslyn.ignoreIssues`|Set to `true` to disable import of external issues. Defaults to `false`.\nVB.NET|`sonar.vbnet.roslyn.bugCategories` `sonar.vbnet.roslyn.vulnerabilityCategories` `sonar.vbnet.roslyn.codeSmellCategories`|Comma-delimited list of categories whose issues should be classified as Bugs, Vulnerabilities, or Code Smells. \n"},{path:"analysis/generic-issue",content:'---\ntitle: Generic Issue Import Format\nurl: /analysis/generic-issue/\n---\n\nSonarQube supports a generic import format for raising external issues in code. You can use this format to import issues from your favorite linter even if there\'s no plugin for it. SonarQube also supports many third-party issue report formats, see [Importing Third-Party Issues](/analysis/external-issues/) for more information.\n\nThere are a couple of limitations with importing external issues:\n\n* you can\'t manage them within SonarQube; for instance, there is no ability to mark them False Positive.\n* you can\'t manage the activation of the rules that raise these issues within SonarQube. External rules aren\'t visible on the Rules page or reflected in Quality Profiles.\n\nExternal issues and the rules that raise them must be managed in the configuration of your linter. \n\n## Import \nThe analysis parameter `sonar.externalIssuesReportPaths` accepts a comma-delimited list of paths to reports.\n\nEach report must contain, at top-level, an array of `Issue` objects named `issues`.\n\n#### Issue fields:\n\n* `engineId` - string\n* `ruleId` - string\n* `primaryLocation` - Location object \n* `type` - string. One of BUG, VULNERABILITY, CODE_SMELL\n* `severity` - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO\n* `effortMinutes` - integer, optional. Defaults to 0\n* `secondaryLocations` - array of Location objects, optional\n\n#### Location fields:\n\n* `message` - string\n* `filePath` - string\n* `textRange` - TextRange object, optional for secondary locations only\n\n#### TextRange fields:\n\n* `startLine` - integer. 1-indexed\n* `endLine` - integer, optional. 1-indexed\n* `startColumn` - integer, optional. 0-indexed\n* `endColumn` - integer, optional. 0-indexed\n\n## Example\nHere is an example of the expected format:\n\n\t{ "issues": [\n\t\t{\n\t\t  "engineId": "test",\n\t\t  "ruleId": "rule1",\n\t\t  "severity":"BLOCKER",\n\t\t  "type":"CODE_SMELL",\n\t\t  "primaryLocation": {\n\t\t\t"message": "fully-fleshed issue",\n\t\t\t"filePath": "sources/A.java",\n\t\t\t"textRange": {\n\t\t\t  "startLine": 30,\n\t\t\t  "endLine": 30,\n\t\t\t  "startColumn": 9,\n\t\t\t  "endColumn": 14\n\t\t\t}\n\t\t  },\n\t\t  "effortMinutes": 90,\n\t\t  "secondaryLocations": [\n\t\t\t{\n\t\t\t  "message": "cross-file 2ndary location",\n\t\t\t  "filePath": "sources/B.java",\n\t\t\t  "textRange": {\n\t\t\t\t"startLine": 10,\n\t\t\t\t"endLine": 10,\n\t\t\t\t"startColumn": 6,\n\t\t\t\t"endColumn": 38\n\t\t\t  }\n\t\t\t}\n\t\t  ]\n\t\t},\n\t\t{\n\t\t  "engineId": "test",\n\t\t  "ruleId": "rule2",\n\t\t  "severity": "INFO",\n\t\t  "type": "BUG",\n\t\t  "primaryLocation": {\n\t\t\t"message": "minimal issue raised at file level",\n\t\t\t"filePath": "sources/Measure.java"\n\t\t  }\n\t\t}\n\t]}\n'},{path:"analysis/generic-test",content:'---\ntitle: Generic Test Data\nurl: /analysis/generic-test/\n---\n\nOut of the box, SonarQube supports generic formats for test coverage and test execution import. If your coverage engines\' native output formats aren\'t supported by SonarQube, simply covert them to these formats:\n\n## Generic Coverage\nReport paths should be passed in a comma-delimited list to:\n\n * `sonar.coverageReportPaths`\n\nThe supported format is described by the `sonar-generic-coverage.xsd`:\n\n\t<xs:schema>\n\t  <xs:element name="coverage">\n\t\t<xs:complexType>\n\t\t  <xs:sequence>\n\t\t\t<xs:element name="file" minOccurs="0" maxOccurs="unbounded">\n\t\t\t  <xs:complexType>\n\t\t\t\t<xs:sequence>\n\t\t\t\t  <xs:element name="lineToCover" minOccurs="0" maxOccurs="unbounded">\n\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t  <xs:attribute name="lineNumber" type="xs:positiveInteger" use="required"/>\n\t\t\t\t\t  <xs:attribute name="covered" type="xs:boolean" use="required"/>\n\t\t\t\t\t  <xs:attribute name="branchesToCover" type="xs:nonNegativeInteger"/>\n\t\t\t\t\t  <xs:attribute name="coveredBranches" type="xs:nonNegativeInteger"/>\n\t\t\t\t\t</xs:complexType>\n\t\t\t\t  </xs:element>\n\t\t\t\t</xs:sequence>\n\t\t\t  <xs:attribute name="path" type="xs:string" use="required"/>\n\t\t\t  </xs:complexType>\n\t\t\t</xs:element>\n\t\t  </xs:sequence>\n\t\t  <xs:attribute name="version" type="xs:positiveInteger" use="required"/>\n\t\t</xs:complexType>\n\t  </xs:element>\n\t</xs:schema>\n\nand looks like this:\n\n\t<coverage version="1">\n\t  <file path="xources/hello/NoConditions.xoo">\n\t\t<lineToCover lineNumber="6" covered="true"/>\n\t\t<lineToCover lineNumber="7" covered="false"/>\n\t  </file>\n\t  <file path="xources/hello/WithConditions.xoo">\n\t\t<lineToCover lineNumber="3" covered="true" branchesToCover="2" coveredBranches="1"/>\n\t  </file>\n\t</coverage>\n\nThe root node should be named `coverage`. Its version attribute should be set to `1`.\n\nInsert a `file` element for each file which can be covered by tests. Its `path` attribute can be either absolute or relative to the root of the module.\nInside a `file` element, insert a `lineToCover` for each line which can be covered by unit tests. It can have the following attributes:\n* `lineNumber` (mandatory)\n* `covered` (mandatory): boolean value indicating whether tests actually hit that line\n* `branchesToCover` (optional): number of branches which can be covered\n* `coveredBranches` (optional): number of branches which are actually covered by tests\n\n## Generic Execution\nReport paths should be passed in a comma-delimited list to:\n\n* `sonar.testExecutionReportPaths`\n\nThe supported format looks like this:\n\n\t<testExecutions version="1">\n\t  <file path="testx/ClassOneTest.xoo">\n\t\t<testCase name="test1" duration="5"/>\n\t\t<testCase name="test2" duration="500">\n\t\t  <skipped message="short message">other</skipped>\n\t\t</testCase>\n\t\t<testCase name="test3" duration="100">\n\t\t  <failure message="short">stacktrace</failure>\n\t\t</testCase>\n\t\t<testCase name="test4" duration="500">\n\t\t  <error message="short">stacktrace</error>\n\t\t</testCase>\n\t  </file>\n\t</testExecutions>\n\t\nThe root node should be named `testExecutions`. Its version attribute should be set to `1`.\n\nInsert a `file` element for each test file. Its `path` attribute can be either absolute or relative to the root of the module.\n\n**Note** unlike for coverage reports, the files present in the report must be test file names, not source code files covered by tests.\n\nInside a `file` element, insert a `testCase` for each test run by unit tests. It can have the following attributes/children:\n\n* `testCase` (mandatory)\n  * `name` (mandatory): name of the test case\n  * `duration` (mandatory): long value in milliseconds\n \n  * `failure|error|skipped` (optional): if the test is not OK, report the cause with a message and a long description\n    * `message` (mandatory): short message describing the cause\n    * `stacktrace` (optional): long message containing details about `failure|error|skipped` status\n'},{path:"analysis/github-integration",content:"---\ntitle: GitHub Integration\nurl: /analysis/github-integration/\n---\n\nSonarQube's integration with GitHub Enterprise and GitHub.com allows you to maintain code quality and security in your GitHub repositories.\n\nWith this integration, you'll be able to:\n\n- **Import your GitHub repositories** - Import your GitHub repositories into SonarQube to easily set up SonarQube projects.  \n- **Analyze projects with GitHub Actions** - Integrate analysis into your build pipeline. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), SonarScanners running in GitHub Actions jobs can automatically detect branches or pull requests being built so you don't need to specifically pass them as parameters to the scanner.\n- **Add pull request decoration** - (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)) See your Quality Gate and code metric results right in GitHub so you know if it's safe to merge your changes.\n- **Authenticate with GitHub** - Sign in to SonarQube with your GitHub credentials.  \n\n## Prerequisites\n- To add pull request decoration to Checks in GitHub Enterprise, you must be running GitHub Enterprise version 2.21+.\n- To analyze projects with GitHub Actions in GitHub Enterprise, you must be running [GitHub Enterprise version 3.0+](https://docs.github.com/en/enterprise-server@2.22/admin/github-actions/getting-started-with-github-actions-for-github-enterprise-server).\n\n### Branch Analysis\nCommunity Edition doesn't support the analysis of multiple branches, so you can only analyze your main branch. With [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can analyze multiple branches and pull requests.\n\n## Importing your GitHub repositories to SonarQube\nYou need to use a GitHub App to connect SonarQube and GitHub so you can import your GitHub repositories into SonarQube. This is also the first step in adding authentication and, if you're using [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) or above, the first step in adding pull request decoration.\n\nIf you want to set up authentication without importing your GitHub repositories, see the **Creating a dedicated app for authentication** section below for instructions on setting up authentication.\n\nIn this section, you'll complete the following steps to connect SonarQube and GitHub with a GitHub App:\n\n1. Create your GitHub App.\n1. Install your GitHub App in your organization.\n1. Update your SonarQube global settings with your GitHub App information.\n\n### Step 1: Creating your GitHub App\nSee GitHub's documentation on [creating a GitHub App](https://docs.github.com/apps/building-github-apps/creating-a-github-app/) for general information on creating your app. \n\nSpecify the following settings in your app:\n\n- **GitHub App Name** – Your app's name.\n- **Homepage URL** – You can use any URL, such as `https://www.sonarqube.org/`.\n- **User authorization callback URL** – Your instance's base URL. For example, `https://yourinstance.sonarqube.com`.\n- **Webhook URL** – Your instance's base URL. For example, `https://yourinstance.sonarqube.com`.\n- Grant access for the following **Repository permissions**:\n\n  | Permission          | Access       |\n  |---------------------|--------------|\n  | Checks              | Read & write |\n  | **GitHub Enterprise:** Repository metadata <br> **GitHub.com:** Metadata <br> (this setting is automatically set by GitHub)| Read-only |\n  | Pull Requests       | Read & write |\n  | Commit statuses     | Read-only    |\n- If setting up **GitHub Authentication**, in addition to the aforementioned Repository permissions, grant access for the following **User permissions**:\n\n  | Permission          | Access       |\n  |---------------------|--------------|\n  | Email addresses     | Read-only    |\n\n  And grant access for the following **Organization permissions**:\n\n  | Permission          | Access       |\n  |---------------------|--------------|\n  | Members             | Read-only    |\n  | Projects            | Read-only    |\n\n- Under \"Where can this GitHub App be installed?,\" select **Any account**.\n\n[[warning]]\n| For security reasons, make sure you're using `HTTPS` protocol for your URLs in your app.\n\n### Step 2: Installing your GitHub App in your organization\nNext, you need to install your GitHub App in your organizations. See GitHub's documentation on [installing GitHub Apps](https://docs.github.com/en/free-pro-team@latest/developers/apps/installing-github-apps) for more information.\n\n### Step 3: Updating your SonarQube global settings with your GitHub App information\nAfter you've created and installed your GitHub App, update your global SonarQube settings to finish integration and allow for the import of GitHub projects.\n\nNavigate to **Administration > Configuration > General Settings > ALM Integrations > GitHub** and specify the following settings:\n\n- **Configuration Name** (Enterprise and Data Center Edition only) – The name used to identify your GitHub configuration at the project level. Use something succinct and easily recognizable.\n- **GitHub URL** – For example, `https://github.company.com/api/v3` for GitHub Enterprise or `https://api.github.com/` for GitHub.com.\n- **GitHub App ID** – The App ID is found on your GitHub App's page on GitHub at **Settings > Developer Settings > GitHub Apps**. \n- **Client ID** – The Client ID is found on your GitHub App's page.\n- **Client secret** – The Client secret is found on your GitHub App's page.\n- **Private Key** – Your GitHub App's private key. You can generate a `.pem` file from your GitHub App's page under **Private keys**. Copy and paste the contents of the file here.\n\n## Analyzing projects with GitHub Actions\nSonarScanners running in GitHub Actions can automatically detect branches and pull requests being built so you don't need to specifically pass them as parameters to the scanner.\n\nTo analyze your projects with GitHub Actions, you need to:\n- Create your GitHub Secrets.\n- Configure your workflow YAML file.\n- Commit and push your code to start the analysis.\n\n### Creating your GitHub Secrets\nYou can create repository secrets from your GitHub repository. See GitHub's documentation on [Encrypted secrets](https://docs.github.com/en/actions/reference/encrypted-secrets) for more information. \n\nYou need to set the following GitHub repository secrets to analyze your projects with GitHub Actions:\n\n- `SONAR_TOKEN` – Generate a SonarQube [token](/user-guide/user-token/) and, in GitHub, create a new repository secret in GitHub with `SONAR_TOKEN` as the **Name** and the token you generated as the **Value**.\n\n- `SONAR_HOST_URL` – In GitHub, create a new repository secret with `SONAR_HOST_URL` as the **Name** and your SonarQube server URL as the **Value**.\n\n### Configuring your .github/workflows/build.yml file\nThis section shows you how to configure your `.github/workflows/build.yml` file. \n\nYou'll set up your build according to your SonarQube edition:\n\n- **Community Edition** – Community Edition doesn't support multiple branches, so you should only analyze your main branch. You can restrict analysis to your main branch by setting it as the only branch in your `on.push.branches` configuration in your workflow YAML file, and not using `on.pull_request`.\n\n- **Developer Edition and above** – GitHub Actions can build specific branches and pull requests if you use `on.push.branches` and `on.pull-requests` configurations as shown in the examples below.\n\nClick the scanner you're using below to expand the example configuration:\n\n[[collapse]]\n| ## SonarScanner for Maven\n|\n| **Note:** A project key might have to be provided through a `pom.xml` file, or through the command line parameter. For more information, see the [SonarScanner for Maven](/analysis/scan/sonarscanner-for-maven/) documentation.\n| \n| Write the following in your workflow YAML file:\n|\n|```\n| name: Build\n| on:\n|   push:\n|     branches:\n|       - master # or the name of your main branch\n|   pull_request:\n|     types: [opened, synchronize, reopened]\n| jobs:\n|   build:\n|     name: Build\n|     runs-on: ubuntu-latest\n|     steps:\n|       - uses: actions/checkout@v2\n|         with:\n|           fetch-depth: 0  # Shallow clones should be disabled for a better relevancy of analysis\n|       - name: Set up JDK 11\n|         uses: actions/setup-java@v1\n|         with:\n|           java-version: 11\n|       - name: Cache SonarQube packages\n|         uses: actions/cache@v1\n|         with:\n|           path: ~/.sonar/cache\n|           key: ${{ runner.os }}-sonar\n|           restore-keys: ${{ runner.os }}-sonar\n|       - name: Cache Maven packages\n|         uses: actions/cache@v1\n|         with:\n|           path: ~/.m2\n|           key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n|           restore-keys: ${{ runner.os }}-m2\n|       - name: Build and analyze\n|         env:\n|           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Needed to get PR information, if any\n|           SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n|           SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n|         run: mvn -B verify org.sonarsource.scanner.maven:sonar-maven-plugin:sonar\n| ```\n\n[[collapse]]\n| ## SonarScanner for Gradle\n|\n| **Note:** A project key might have to be provided through a `build.gradle` file, or through the command line parameter. For more information, see the [SonarScanner for Gradle](/analysis/scan/sonarscanner-for-gradle/) documentation.\n|\n| Add the following to your `build.gradle` file:\n|\n| ```\n| plugins {\n|   id \"org.sonarqube\" version \"3.1\"\n| }\n| ```\n|\n| Write the following in your workflow YAML file:\n|\n| ```\n| name: Build\n| on:\n|   push:\n|     branches:\n|       - master # or the name of your main branch\n|   pull_request:\n|     types: [opened, synchronize, reopened]\n| jobs:\n|   build:\n|     name: Build\n|     runs-on: ubuntu-latest\n|     steps:\n|       - uses: actions/checkout@v2\n|         with:\n|           fetch-depth: 0  # Shallow clones should be disabled for a better relevancy of analysis\n|       - name: Set up JDK 11\n|         uses: actions/setup-java@v1\n|         with:\n|           java-version: 11\n|       - name: Cache SonarQube packages\n|         uses: actions/cache@v1\n|         with:\n|           path: ~/.sonar/cache\n|           key: ${{ runner.os }}-sonar\n|           restore-keys: ${{ runner.os }}-sonar\n|       - name: Cache Gradle packages\n|         uses: actions/cache@v1\n|         with:\n|           path: ~/.gradle/caches\n|           key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle') }}\n|           restore-keys: ${{ runner.os }}-gradle\n|       - name: Build and analyze\n|         env:\n|           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Needed to get PR information, if any\n|           SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n|           SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n|         run: ./gradlew build sonarqube --info \n| ```\n\n\n[[collapse]]\n| ## SonarScanner for .NET\n| \n| Write the following in your workflow YAML file:\n| \n| ```\n| name: Build\n| on:\n|   push:\n|     branches:\n|       - master # or the name of your main branch\n|   pull_request:\n|     types: [opened, synchronize, reopened]\n| jobs:\n|   build:\n|     name: Build\n|     runs-on: windows-latest\n|     steps:\n|       - name: Set up JDK 11\n|         uses: actions/setup-java@v1\n|         with:\n|           java-version: 1.11\n|       - uses: actions/checkout@v2\n|         with:\n|           fetch-depth: 0  # Shallow clones should be disabled for a better relevancy of analysis\n|       - name: Cache SonarQube packages\n|         uses: actions/cache@v1\n|         with:\n|           path: ~\\sonar\\cache\n|           key: ${{ runner.os }}-sonar\n|           restore-keys: ${{ runner.os }}-sonar\n|       - name: Cache SonarQube scanner\n|         id: cache-sonar-scanner\n|         uses: actions/cache@v1\n|         with:\n|           path: .\\.sonar\\scanner\n|           key: ${{ runner.os }}-sonar-scanner\n|           restore-keys: ${{ runner.os }}-sonar-scanner\n|       - name: Install SonarQube scanner\n|         if: steps.cache-sonar-scanner.outputs.cache-hit != 'true'\n|         shell: powershell\n|         run: |\n|           New-Item -Path .\\.sonar\\scanner -ItemType Directory\n|           dotnet tool update dotnet-sonarscanner --tool-path .\\.sonar\\scanner\n|       - name: Build and analyze\n|         env:\n|           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Needed to get PR information, if any\n|         shell: powershell\n|         run: |\n|           .\\.sonar\\scanner\\dotnet-sonarscanner begin /k:\"example\" /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\" /d:sonar.host.url=\"${{ secrets.SONAR_HOST_URL }}\"\n|           dotnet build\n|           .\\.sonar\\scanner\\dotnet-sonarscanner end /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\"\n| ```\n\n\n[[collapse]]\n| ## SonarScanner CLI\n| \n| **Note:** A project key has to be provided through a `sonar-project.properties` file, or through the command line parameter. For more information, see the [SonarScanner](/analysis/scan/sonarscanner/) documentation.\n| \n| Write the following in your workflow YAML file:\n|\n| ```\n| name: Build\n| on:\n|   push:\n|     branches:\n|       - master # or the name of your main branch\n|   pull_request:\n|     types: [opened, synchronize, reopened]\n| jobs:\n|   build:\n|     name: Build\n|     runs-on: ubuntu-latest\n|     steps:\n|       - uses: actions/checkout@v2\n|         with:\n|           fetch-depth: 0\n|       - uses: docker://sonarsource/sonar-scanner-cli:latest\n|         env:\n|           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n|           SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n|           SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n| ```\n\n#### **Failing the pipeline job when the Quality Gate fails**\nIn order for the Quality Gate to fail on the GitLab side when it fails on the SonarQube side, the scanner needs to wait for the SonarQube Quality Gate status. To enable this, set the `sonar.qualitygate.wait` property to `true` (check the above scanners' documentation to know where to set this property).\n\nYou can set the `sonar.qualitygate.timeout` property to an amount of time (in seconds) that the scanner should wait for a report to be processed. The default is 300 seconds. \n\n### Commit and push your code\nCommit and push your code to start the analysis. Each new push you make on your branches or pull requests will trigger a new analysis in SonarQube.\n\n## Adding pull request decoration to GitHub\nAfter creating and installing your GitHub App above, you can add pull request decoration to show your Quality Gate and analysis metrics directly in GitHub: \n\nThe simplest way to add pull request decoration is by adding a project from GitHub by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting **GitHub**.\n\nThen, follow the steps in SonarQube to analyze your project. The project settings for pull request decoration are set automatically.\n\n[[info]]\n| To decorate Pull Requests, a SonarQube analysis needs to be run on your code. You can find the additional parameters required for Pull Request analysis on the [Pull Request Analysis](/analysis/pull-request/) page.\n\n### Adding pull request decoration to a manually created or existing project\nTo add pull request decoration to a manually created or existing project, after you've created and installed your GitHub App and updated your global ALM Integration settings as shown in the **Importing your GitHub repositories into SonarQube** section above, set the following project settings at **Project Settings > General Settings > Pull Request Decoration**: \n\n- **Configuration name** – The configuration name that corresponds to your GitHub instance. \n- **Repository identifier** – The path of your repository URL.\n\n### Advanced pull request decoration configuration\n\n[[collapse]]\n| ## Adding pull request decoration to projects that are part of a mono repository\n|\n| _Pull request decoration for a mono repository setup is supported starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n|\n| In a mono repository setup, multiple SonarQube projects, each corresponding to a separate project within the mono repository, are all bound to the same GitHub repository. You'll need to set up pull request decoration for each SonarQube project that is part of a mono repository.\n|\n| To add pull request decoration to a project that's part of a mono repository, set your project up manually as shown in the **Adding pull request decoration to a manually created or existing project** section above. You also need to set the **Enable mono repository support** setting to true at **Project Settings > General Settings > Pull Request Decoration**. \n|\n| After setting your project settings, you need to ensure the correct project is being analyzed by adjusting the analysis scope and pass your project names to the scanner. See the following sections for more information.\n|\n| ### Ensuring the correct project is analyzed\n| You need to adjust the analysis scope to make sure SonarQube doesn't analyze code from other projects in your mono repository. To do this set up a **Source File Inclusion** for your  project at **Project Settings > Analysis Scope** with a pattern that will only include files from the appropriate folder. For example, adding `./MyFolderName/**/*` to your inclusions would only include analysis of code in the `MyFolderName` folder. See [Narrowing the Focus](/project-administration/narrowing-the-focus/) for more information on setting your analysis scope.\n|\n| ### Passing project names to the scanner\n| Because of the nature of a mono repository, SonarQube scanners might read all project names of your mono repository as identical. To avoid having multiple projects with the same name, you need to pass the `sonar.projectName` parameter to the scanner. For example, if you're using the Maven scanner, you would pass `mvn sonar:sonar -Dsonar.projectName=YourProjectName`.\n\n[[collapse]]\n| ## Showing the analysis summary under the GitHub Conversation tab\n| By default, **Enable analysis summary under the GitHub Conversation tab** is on and your pull request analysis will be shown under both the **Conversation** and **Checks** tabs in GitHub. When off, your pull request analysis summary is only shown under the **Checks** tab.\n\n[[collapse]]\n| ## Configuring multiple ALM instances\n|You can decorate pull requests from multiple ALM instances by creating a configuration for each ALM instance and then assigning that instance configuration to the appropriate projects. \n|\n|- As part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can create one configuration for each ALM. \n|\n|- Starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), you can create multiple configurations for each ALM. If you have multiple configurations of the same ALM connected to SonarQube, you have to create projects manually.\n\n[[collapse]]\n| ## Linking issues\n| During pull request decoration, individual issues will be linked to their SonarQube counterparts automatically. For this to work correctly, you need to set the instance's **Server base URL** (**[Administration > Configuration > General Settings > General > General](/#sonarqube-admin#/admin/settings/)**) correctly. Otherwise, the links will default to `localhost`.\n\n## Setting up GitHub authentication\nTo allow users to log in with GitHub credentials, use the GitHub App that you created above (see the **Importing your GitHub repositories using a GitHub App** section for more information) and update your global SonarQube settings.\n\n[[info]]\n| If you're using Community Edition or you want to use a dedicated app for GitHub authentication, see the **Creating a dedicated app for authentication** section below.\n\nTo update your global SonarQube settings:\n\nNavigate to **Administration > Configuration > General Settings > ALM Integrations > GitHub > GitHub Authentication** and update the following:\n\n1. **Enabled** – set the switch to `true`.\n1. **Client ID** – the Client ID is found below the GitHub App ID on your GitHub App's page.\n1. **Client Secret** – the Client secret is found below the Client ID on your GitHub App's page.\n  \nNow, from the login page, your users can connect their GitHub accounts with the new \"Log in with GitHub\" button.\n\n### Creating a dedicated app for authentication\nIf you want to use a dedicated app for GitHub authentication, you can create a GitHub OAuth app. You'll find general instructions for creating a GitHub OAuth App [here](https://docs.github.com/en/free-pro-team@latest/developers/apps/creating-an-oauth-app). Specify the following settings in your OAuth App:\n\n- **Homepage URL** – the public URL of your SonarQube server. For example, `https://sonarqube.mycompany.com`. For security reasons, HTTP is not supported, and you must use HTTPS. The public URL is configured in SonarQube at **[Administration > General > Server base URL](/#sonarqube-admin#/admin/settings)**.\n- **Authorization callback URL** – your instance's base URL. For example, `https://yourinstance.sonarqube.com`.\n\nAfter creating your app, update your global SonarQube settings: \n\nNavigate to **Administration > Configuration > General Settings > ALM Integrations > GitHub > GitHub Authentication** and update the following:\n\n1. **Enabled** – set the switch to `true`.\n1. **Client ID** – the Client ID is found below the GitHub App ID on your GitHub App's page.\n1. **Client Secret** – the Client secret is found below the Client ID on your GitHub App's page.\n  \nNow, from the login page, your users can connect their GitHub accounts with the new \"Log in with GitHub\" button.\n"},{path:"analysis/gitlab-integration",content:"---\ntitle: GitLab Integration\nurl: /analysis/gitlab-integration/\n---\n\nSonarQube's integration with GitLab Self-Managed and GitLab.com allows you to maintain code quality and security in your GitLab projects.\n\nWith this integration, you'll be able to:\n\n- **Authenticate with GitLab** - Sign in to SonarQube with your GitLab credentials.\n- **Import your GitLab projects** - Import your GitLab Projects into SonarQube to easily set up SonarQube projects.  \n- **Analyze projects with GitLab CI/CD** - Integrate analysis into your build pipeline. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), SonarScanners running in GitLab CI/CD jobs can automatically detect branches or merge requests being built so you don't need to specifically pass them as parameters to the scanner.\n- **Add merge request decoration** - (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)) See your Quality Gate and code metric results right in GitLab so you know if it's safe to merge your changes.\n\n## Prerequisites\nIntegration with GitLab Self-Managed requires at least GitLab Self-Managed version 11.7.\n\n### Branch Analysis\nCommunity Edition doesn't support the analysis of multiple branches, so you can only analyze your main branch. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can analyze multiple branches and pull requests.\n\n## Authenticating with GitLab\nYou can delegate authentication to GitLab using a dedicated GitLab OAuth application.\n\n### Creating a GitLab OAuth app\nYou can find general instructions for creating a GitLab OAuth app [here](https://docs.gitlab.com/ee/integration/oauth_provider.html).\n\nSpecify the following settings in your OAuth app:\n\n- **Name** – your app's name, such as SonarQube.\n- **Redirect URI** – enter your SonarQube URL with the path `/oauth2/callback/gitlab`. For example, `https://sonarqube.mycompany.com/oauth2/callback/gitlab`.\n- **Scopes** – select **api** if you plan to enable group synchronization. Select **read_user** if you only plan to delegate authentication.\n\nAfter saving your application, GitLab takes you to the app's page. Here you find your **Application ID** and **Secret**. Keep these handy, open your SonarQube instance, and navigate to **Administration > Configuration > General Settings > ALM Integrations > GitLab > Authentication**. Set the following settings to finish setting up GitLab authentication:\n\n- **Enabled** – set to `true`.\n- **Application ID** – the Application ID is found on your GitLab app's page.\n- **Secret** – the Secret is found on your GitLab app's page.\n\nOn the login form, the new \"Log in with GitLab\" button allows users to connect with their GitLab accounts.\n\n### GitLab group synchronization\nEnable **Synchronize user groups** at **Administration > Configuration > General Settings > ALM Integrations > GitLab** to associate GitLab groups with existing SonarQube groups of the same name. GitLab users inherit membership to subgroups from parent groups. \n\nTo synchronize a GitLab group or subgroup with a SonarQube group, name the SonarQube group with the full path of the GitLab group or subgroup URL. \n\nFor example, with the following GitLab group setup:\n\n- GitLab group = My Group\n- GitLab subgroup = My Subgroup\n- GitLab subgroup URL = `https://YourGitLabURL.com/my-group/my-subgroup`\n\nYou should name your SonarQube group `my-group` to synchronize it with your GitLab group and `my-group/my-subgroup` to synchronize it with your GitLab subgroup.\n\n## Importing your GitLab projects into SonarQube\nSetting up the import of GitLab projects into SonarQube allows you to easily create SonarQube projects from your GitLab projects. If you're using [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) or above, this is also the first step in adding merge request decoration.\n\nTo set up the import of GitLab projects:\n\n1. Set your global settings\n1. Add a personal access token for importing repositories\n\n### Setting your global settings\nTo import your GitLab projects into SonarQube, you need to first set your global SonarQube settings. Navigate to **Administration > Configuration > General Settings > ALM Integrations**, select the **GitLab** tab, and specify the following settings:\n \n- **Configuration Name** (Enterprise and Data Center Edition only) – The name used to identify your GitLab configuration at the project level. Use something succinct and easily recognizable.\n- **GitLab URL** – The GitLab API URL.\n- **Personal Access Token** – A GitLab user account is used to decorate Merge Requests. We recommend using a dedicated GitLab account with at least **Reporter** [permissions](https://docs.gitlab.com/ee/user/permissions.html) (the account needs permission to leave comments). You need a personal access token from this account with the scope authorized for **api** for the repositories that will be analyzed. This personal access token is used to merge request decoration. You'll be asked for another personal access token for importing projects in the following section. \n\n### Adding a personal access token for importing projects\nAfter setting these global settings, you can add a project from GitLab by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting **GitLab**.\n\nThen, you'll be asked to provide a personal access token with `read_api` scope so SonarQube can access and list your GitLab projects. This token will be stored in SonarQube and can be revoked at anytime in GitLab.\n\nAfter saving your Personal Access Token, you'll see a list of your GitLab projects that you can **set up** to add them to SonarQube. Setting up your projects this way also sets your project settings for merge request decoration. \n\nFor information on analyzing your projects with GitLab CI/CD, see the following section.\n\n## Analyzing projects with GitLab CI/CD\nSonarScanners running in GitLab CI/CD jobs can automatically detect branches or merge requests being built so you don't need to specifically pass them as parameters to the scanner.\n\nTo analyze your projects with GitLab CI/CD, you need to:\n- Set your environment variables.\n- Configure your gilab-ci.yml file.\n\nThe following sections detail these steps.\n\n[[warning]]\n| You need to disable git shallow clone to make sure the scanner has access to all of your history when running analysis with GitLab CI/CD. For more information, see [Git shallow clone](https://docs.gitlab.com/ee/user/project/pipelines/settings.html#git-shallow-clone).\n\n### Setting environment variables \nYou can set environment variables securely for all pipelines in GitLab's settings. See GitLab's documentation on [Creating a Custom Environment Variable](https://docs.gitlab.com/ee/ci/variables/#creating-a-custom-environment-variable) for more information.\n \nYou need to set the following environment variables in GitLab for analysis:\n \n- `SONAR_TOKEN` – Generate a SonarQube [token](/user-guide/user-token/) for GitLab and create a custom environment variable in GitLab with `SONAR_TOKEN` as the **Key** and the token you generated as the **Value**. \n\n- `SONAR_HOST_URL` – Create a custom environment variable with `SONAR_HOST_URL` as the **Key** and your SonarQube server URL as the **Value**.\n\n### Configuring your gitlab-ci.yml file\n\nThis section shows you how to configure your GitLab CI/CD `gitlab-ci.yml` file. The `allow_failure` parameter in the examples allows a job to fail without impacting the rest of the CI suite.\n\nYou'll set up your build according to your SonarQube edition:\n\n- **Community Edition** – Community Edition doesn't support multiple branches, so you should only analyze your main branch. You can restrict analysis to your main branch by adding the branch name to the `only` parameter in your .yml file.\n\n- **Developer Edition and above** By default, GitLab will build all branches but not Merge Requests. To build Merge Requests, you need to update the `.gitlab-ci.yml` file by adding `merge_requests` to the `only` parameter in your .yml. See the example configurations below for more information.\n\nClick the scanner you're using below to expand an example configuration:\n\n[[collapse]]\n| ## SonarScanner for Gradle\n| ```\n| sonarqube-check:\n|   image: gradle:jre11-slim\n|   variables:\n|     SONAR_USER_HOME: \"${CI_PROJECT_DIR}/.sonar\"  # Defines the location of the analysis task cache\n|     GIT_DEPTH: \"0\"  # Tells git to fetch all the branches of the project, required by the analysis task\n|   cache:\n|     key: \"${CI_JOB_NAME}\"\n|     paths:\n|       - .sonar/cache\n|   script: gradle sonarqube -Dsonar.qualitygate.wait=true\n|   allow_failure: true\n|   only:\n|     - merge_requests\n|     - master\n|     - develop\n| ```\n \n[[collapse]]\n| ## SonarScanner for Maven\n| \n| ```\n| sonarqube-check:\n|   image: maven:3.6.3-jdk-11\n|   variables:\n|     SONAR_USER_HOME: \"${CI_PROJECT_DIR}/.sonar\"  # Defines the location of the analysis task cache\n|     GIT_DEPTH: \"0\"  # Tells git to fetch all the branches of the project, required by the analysis task\n|   cache:\n|     key: \"${CI_JOB_NAME}\"\n|     paths:\n|       - .sonar/cache\n|   script:\n|     - mvn verify sonar:sonar -Dsonar.qualitygate.wait=true\n|   allow_failure: true\n|   only:\n|     - merge_requests\n|     - master\n|     - develop\n| ```\n\n[[collapse]]\n| ## SonarScanner CLI\n| \n| ```\n| sonarqube-check:\n|   image:\n|     name: sonarsource/sonar-scanner-cli:latest\n|     entrypoint: [\"\"]\n|   variables:\n|     SONAR_USER_HOME: \"${CI_PROJECT_DIR}/.sonar\"  # Defines the location of the analysis task cache\n|     GIT_DEPTH: \"0\"  # Tells git to fetch all the branches of the project, required by the analysis task\n|   cache:\n|     key: \"${CI_JOB_NAME}\"\n|     paths:\n|       - .sonar/cache\n|   script:\n|     - sonar-scanner -Dsonar.qualitygate.wait=true\n|   allow_failure: true\n|   only:\n|     - merge_requests\n|     - master\n|     - develop\n| ```\n|\n|\n| **Project key**  \n| A project key has to be provided through `sonar-project.properties` or through the command line parameter. For more information, see the [SonarScanner](/analysis/scan/sonarscanner/) documentation.\n|\n| **Self-signed certificates**  \n| If you secure your SonarQube instance with a self-signed certificate, you may need to build a custom image based on `sonarsource/sonar-scanner-cli`. See the section **Advanced Docker Configuration** within the [SonarScanner](/analysis/scan/sonarscanner/) documentation.\n|\n\n#### **Failing the pipeline job when the Quality Gate fails**\nIn order for the Quality Gate to fail on the GitLab side when it fails on the SonarQube side, the scanner needs to wait for the SonarQube Quality Gate status. To enable this, set the `sonar.qualitygate.wait=true` parameter in the `.gitlab-ci.yml` file. \n\nYou can set the `sonar.qualitygate.timeout` property to an amount of time (in seconds) that the scanner should wait for a report to be processed. The default is 300 seconds. \n\n### For more information\nFor more information on configuring your build with GitLab CI/CD, see the [GitLab CI/CD Pipeline Configuration Reference](https://gitlab.com/help/ci/yaml/README.md).\n\n## Adding merge request decoration to GitLab\n\nMerge request decoration shows your Quality Gate and analysis metrics directly in GitLab.\n\nAfter you've set up SonarQube to import your GitLab projects as shown in the previous section, the simplest way to add merge request decoration is by adding a project from GitLab by clicking the **Add project** button in the upper-right corner of the **Projects** homepage and selecting **GitLab**.\n\nThen, follow the steps in SonarQube to analyze your project. The project settings for merge request decoration are set automatically.\n\n[[info]]\n| To decorate merge requests, a SonarQube analysis needs to be run on your code. You can find the additional parameters required for merge request analysis on the [Pull Request Analysis](/analysis/pull-request/) page.\n\n### Adding merge request decoration to a manually created or existing project\nTo add merge request decoration to a manually created or existing project, make sure your global ALM Integration settings are set as shown in the **Importing your GitLab projects into SonarQube** section above, and set the following project settings at **Project Settings > General Settings > Pull Request Decoration**: \n\n- **Configuration name** – The configuration name that corresponds to your GitLab instance. \n- **Project ID** – your GitLab Project ID found in GitLab\n\n### Advanced merge request decoration configuration\n\n[[collapse]]\n| ## Adding merge request decoration to projects that are part of a mono repository\n|\n| _Pull request decoration for a mono repository setup is supported starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n|\n| In a mono repository setup, multiple SonarQube projects, each corresponding to a separate project within the mono repository, are all bound to the same GitLab repository. You'll need to set up merge request decoration for each SonarQube project that is part of a mono repository.\n|\n| To add merge request decoration to a project that's part of a mono repository, set your project up manually as shown in the **Adding merge request decoration to a manually created or existing project** section above. You also need to set the **Enable mono repository support** setting to true at **Project Settings > General Settings > Pull Request Decoration**.\n|\n| After setting your project settings, you need to ensure the correct project is being analyzed by adjusting the analysis scope and pass your project names to the scanner. See the following sections for more information.\n|\n| ### Ensuring the correct project is analyzed\n| You need to adjust the analysis scope to make sure SonarQube doesn't analyze code from other projects in your mono repository. To do this set up a **Source File Inclusion** for your  project at **Project Settings > Analysis Scope** with a pattern that will only include files from the appropriate folder. For example, adding `./MyFolderName/**/*` to your inclusions would only include analysis of code in the `MyFolderName` folder. See [Narrowing the Focus](/project-administration/narrowing-the-focus/) for more information on setting your analysis scope.\n|\n| ### Passing project names to the scanner\n| Because of the nature of a mono repository, SonarQube scanners might read all project names of your mono repository as identical. To avoid having multiple projects with the same name, you need to pass the `sonar.projectName` parameter to the scanner. For example, if you're using the Maven scanner, you would pass `mvn sonar:sonar -Dsonar.projectName=YourProjectName`.\n\n[[collapse]]\n| ## Configuring multiple ALM instances\n|You can decorate merge requests from multiple ALM instances by creating a configuration for each ALM instance and then assigning that instance configuration to the appropriate projects. \n|\n|- As part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can create one configuration for each ALM. \n|\n|- Starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), you can create multiple configurations for each ALM. If you have multiple configurations of the same ALM connected to SonarQube, you have to create projects manually.\n\n[[collapse]]\n| ## Linking issues\n| During merge request decoration, individual issues will be linked to their SonarQube counterparts automatically. For this to work correctly, you need to set the instance's **Server base URL** (**[Administration > Configuration > General Settings > General > General](/#sonarqube-admin#/admin/settings/)**) correctly. Otherwise, the links will default to `localhost`.\n"},{path:"analysis/jenkins",content:"---\ntitle: Jenkins\nurl: /analysis/jenkins/\n---\n\nSonarScanners running in Jenkins can automatically detect branches and Merge or Pull Requests in certain jobs. You don't need to explicitly pass the branch or Pull Request details.\n\n## Analysis Prerequisites\n\nTo run project analysis with Jenkins, you need to install and configure the following Jenkins plugins _in Jenkins_:\n \n- The SonarQube Scanner plugin.\n- The Branch Source plugin that corresponds to your ALM (Bitbucket Server, GitHub, or GitLab) if you're analyzing multibranch pipeline jobs in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) or above. \n\nSee the **Installing and Configuring your Jenkins plugins** section below for more information.\n\n### Configuring Jenkins using the SonarQube tutorial\n\nIf you're using Bitbucket Server, GitHub Enterprise, GitHub.com, GitLab Self-Managed, or GitLab.com, you can easily configure and analyze your projects by following the tutorial in SonarQube. You can access the tutorial by going to your project's **Overview** page and selecting **with Jenkins** under \"How do you want to analyze your repository?\"\n\n[[info]]\n|See the **Installing and Configuring your Jenkins plugins** section below to set up your Jenkins plugins before going through the tutorial. \n\n## Installing and Configuring your Jenkins plugins\n\n### SonarQube Scanner plugin\n\nClick SonarQube Scanner below to expand instructions on installing and configuring the plugin.\n \n[[collapse]]\n| ## SonarQube Scanner\n|\n| [SonarQube Scanner plugin](https://plugins.jenkins.io/sonar/) version 2.11 or later is required. \n|\n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Manage Plugins** and install the **SonarQube Scanner** plugin.\n| 1. Back at the Jenkins Dashboard, navigate to **Credentials > System** from the left navigation. \n| 1. Click the **Global credentials (unrestricted)** link in the **System** table. \n| 1. Click **Add credentials** in the left navigation and add the following information:\n| \t- **Kind**: Secret Text\n| \t- **Scope**: Global  \n| \t- **Secret**: Generate a token at **User > My Account > Security** in SonarQube, and copy and paste it here.\n| 1. Click **OK**.\n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Configure System**. \n| 1. From the **SonarQube Servers** section, click **Add SonarQube**. Add the following information:\n| \t- **Name**: Give a unique name to your SonarQube instance.\n| \t- **Server URL**: Your SonarQube instance URL.\n| \t- **Credentials**: Select the credentials created during step 4.\n| 1. Click **Save**\n\n### Branch Source plugin\n_Required to analyze multibranch pipeline jobs in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) or above_\n\nClick your ALM below to expand the instructions on installing and configuring the Branch Source plugin.\n\n[[collapse]]\n| ## BitBucket Server\n|\n| [Bitbucket Branch Source plugin](https://plugins.jenkins.io/cloudbees-bitbucket-branch-source/) version 2.7 or later is required\n| \n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Manage Plugins** and install the **Bitbucket Branch Source** plugin.\n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Configure System**. \n| 1. From the **Bitbucket Endpoints** section, Click the **Add** drop-down menu and select **Bitbucket Server**. Add the following information:\n| \t- **Name**: Give a unique name to your Bitbucket Server instance.\n| \t- **Server URL**: Your Bitbucket Server instance URL.\n| \t- Check **Manage hooks**\n| \t- **Credentials**: In your credentials, use a Bitbucket Server personal access token with **Read** permissions.\n| \t- **Webhook implementation to use**: Native\t\n| 1. Click **Save**.\n\n[[collapse]]\n| ## GitHub\n|\n| [GitHub Branch Source plugin](https://plugins.jenkins.io/github-branch-source/) version 2.7.1 or later is required\n| \n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Manage Plugins** and install the **GitHub Branch Source** plugin.\n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Configure System**. \n| 1. From the **GitHub** or **GitHub Enterprise Servers** section, add your GitHub server.\n| 1. Click **Save**.\n\n[[collapse]]\n| ## GitLab\n|\n| [GitLab Branch Source plugin](https://plugins.jenkins.io/gitlab-branch-source/) version 1.5.3 or later is required\n| \n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Manage Plugins** and install the **GitLab Branch Source** plugin.\n| 1. From the Jenkins Dashboard, navigate to **Manage Jenkins > Configure System**. \n| 1. From the **GitLab** section, add your GitLab server. Make sure to check the **Manage Web Hooks** checkbox.\n| 1. Click **Save**.\n\n## Configuring Single Branch Pipeline jobs\nWith Community Edition, you can only analyze a single branch. For more information, see the [SonarScanner for Jenkins](/analysis/scan/sonarscanner-for-jenkins/) documentation.\n\n## Configuring Multibranch Pipeline jobs \n \nStarting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can analyze multiple branches and Pull Requests. The automatic configuration of branches and Pull Requests relies on environment variables available in Multibranch Pipeline jobs. These are set based on information exported by Jenkins plugins. \n\nFor configuration examples, see the [SonarScanner for Jenkins](/analysis/scan/sonarscanner-for-jenkins/) documentation.\n\n### Configuring Multibranch Pipeline jobs for Pull Request Decoration\nYou need to configure your Multibranch Pipeline job correctly to avoid issues with Pull Request decoration. From your Multibranch Pipeline job in Jenkins, go to **Configure > Branch Sources > Behaviors**.\n\nFor Bitbucket Server and GitHub, under **Discover pull requests from origin**, make sure **The current pull request revision** is selected.\n\nFor GitLab, under **Discover merge requests from origin**, make sure **Merging the merge request with the current target branch revision** is selected.\n\n## Detecting changed code in Pull Requests\nSonarScanners need access to a Pull Request's target branch to detect code changes in the Pull Request. If you're using a Jenkins Pull Request discovery strategy that only fetches the Pull Request and doesn't merge with the target branch, the target branch is not fetched and is not available in the local git clone for the scanner to read. \n\nIn this case, the code highlighted as “new” in the Pull Request may be inaccurate, and you’ll see the following warning in the scanner’s log:\n\n```\nFile '[name]' was detected as changed but without having changed lines\n```\n\nTo fix this, either change the discovery strategy or manually fetch the target branch before running the SonarScanner. For example:\n\n```\ngit fetch +refs/heads/${CHANGE_TARGET}:refs/remotes/origin/${CHANGE_TARGET}\n```\n\n\n"},{path:"analysis/languages/abap",content:"---\ntitle: ABAP\nurl: /analysis/languages/abap/\n---\n\n_ABAP analysis is available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)._\n\n\n## Language-Specific Properties\n\nDiscover and update the ABAP-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > ABAP](/#sonarqube-admin#/admin/settings?category=abap)**\n\n## Source Code Extraction\n\nIn order to analyze your source code with SonarQube you need to first extract it from SAP onto a filesystem. You can use your own tool or an open source tool; SonarSource does not provide any connectors or source code extraction tools.\n"},{path:"analysis/languages/apex",content:"---\ntitle: Apex\nurl: /analysis/languages/apex/\n---\n\n\x3c!-- sonarqube --\x3e\n\n_Apex analysis is available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n\n\x3c!-- /sonarqube --\x3e\n\n\n## Language-Specific Properties\n\nDiscover and update the Apex-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e[**Administration > General Settings > Apex**](/#sonarqube-admin#/admin/settings?category=apex)\n\n## Related Pages\n\n- [Importing External Issues](/analysis/external-issues/) (PMD Apex)\n- [Test Coverage & Execution](/analysis/coverage/) (For Salesforce DX project)\n"},{path:"analysis/languages/cfamily",content:'---\ntitle: C/C++/Objective-C\nurl: /analysis/languages/cfamily/\n---\n\n_C/C++/Objective-C analysis is available starting with [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)._\n\n\n\nC/C++/Objective-C analysis is officially registered as [CWE Compatible](https://cwe.mitre.org/compatible/).\n\n## Supported Compilers, Language Standards and Operating Systems\n* Any version of Clang, GCC and Microsoft C/C++ compilers\n* Any version of Intel compiler for Linux and macOS\n* ARM5 and ARM6 compilers\n* IAR compiler for ARM, Renesas RL78, Renesas RX, Renesas V850, Texas Instruments MSP430 and for 8051\n* Compilers based wholly on GCC including for instance Linaro GCC and WindRiver GCC are also supported\n* C89, C99, C11, C++03, C++11, C++14 and C++17 standards\n* GNU extensions\n* Microsoft Windows, Linux and macOS for runtime environment\n\n## Language-Specific Properties\n\nDiscover and update the C/C++/Objective-C specific properties in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > C / C++ / Objective-C](/#sonarqube-admin#/admin/settings?category=c+%2F+c%2B%2B+%2F+objective-c)**\n\n## Prerequisites\n### Build Wrapper\nAnalysis of C/C++/Objective-C projects requires the **SonarQube Build Wrapper**. It gathers all the configuration required for correct analysis of C/C++/Objective-C projects (such as macro definitions, include directories, …) directly from your project\'s build process. The Build Wrapper does not impact your build; it merely eavesdrops on it and writes what it learns into files a directory you specify. \n\n\x3c!-- sonarqube --\x3e\nYou can download the *Build Wrapper* directly from your SonarQube server, so that its version perfectly matches your version of the plugin. \n* Download *Build Wrapper* for Linux from [{SonarQube URL}/static/cpp/build-wrapper-linux-x86.zip](/#sonarqube#/static/cpp/build-wrapper-linux-x86.zip)\n* Download *Build Wrapper* for macOS from [{SonarQube URL}/static/cpp/build-wrapper-macosx-x86.zip](/#sonarqube#/static/cpp/build-wrapper-macosx-x86.zip)\n* Download *Build Wrapper* for Windows from [{SonarQube URL}/static/cpp/build-wrapper-win-x86.zip](/#sonarqube#/static/cpp/build-wrapper-win-x86.zip)\n\x3c!-- /sonarqube --\x3e\n\x3c!-- sonarcloud --\x3e\nYou can download the *Build Wrapper* directly from SonarCloud:\n* [Download *Build Wrapper* for Linux](https://sonarcloud.io/static/cpp/build-wrapper-linux-x86.zip)\n* [Download *Build Wrapper* for macOS](https://sonarcloud.io/static/cpp/build-wrapper-macosx-x86.zip)\n* [Download *Build Wrapper* for Windows](https://sonarcloud.io/static/cpp/build-wrapper-win-x86.zip)\n\x3c!-- /sonarcloud --\x3e\n\n\nUnzip the downloaded *Build Wrapper* and configure it in your `PATH` because doing so is just more convenient.\n\n### SonarQube Scanner\nAnalysis of C/C++/Objective-C projects requires the [*SonarScanner*](https://redirect.sonarsource.com/doc/install-configure-scanner.html) CLI.\n\n## Analysis Steps\n* If you use macOS or Linux operating systems make sure your source tree is in a directory called `src`\n* Add execution of the *Build Wrapper* as a prefix to your usual build command (the examples below use `make`, `xcodebuild` and `MSBuild`, but any build tool that performs a full build can be used)\n   ```\n   // example for linux\n   build-wrapper-linux-x86-64 --out-dir build_wrapper_output_directory make clean all \n   // example for macOS\n   build-wrapper-macosx-x86 --out-dir build_wrapper_output_directory xcodebuild clean build\n   // example for Windows\n   build-wrapper-win-x86-64.exe --out-dir  build_wrapper_output_directory MSBuild.exe /t:Rebuild\n   ```\n* In the *sonar-project.properties* file at the root of your project add the property `sonar.cfamily.build-wrapper-output` with the path to the *Build Wrapper* output directory relative to the project directory (`build_wrapper_output_directory` in these examples). \n\n   Sample *sonar-project.properties*:\n   ```\n   sonar.projectKey=myFirstProject\n   sonar.projectName=My First C++ Project\n   sonar.projectVersion=1.0\n   sonar.sources=src\n   sonar.cfamily.build-wrapper-output=build_wrapper_output_directory\n   sonar.sourceEncoding=UTF-8\n   ```\n* Execute the SonarScanner (`sonar-scanner`) from the root directory of the project\n   ```\n   sonar-scanner\n   ```\n* Follow the link provided at the end of the analysis to browse your project\'s quality metrics in the UI\n\n## Multithreaded Code Scan \n\nIt is possible to use all the cores available on the machine running the code scan. This can be activated by configuring the property `sonar.cfamily.threads` at the scanner level. Its default value is 1.\n\n* This feature must not be activated on a machine with only 1 core.\n\n* The analyzer will not guess which value is most suitable for your project. It\'s up to you to test and find the best value.\n\n* If a build machine with 2 cores is already configured to potentially run two code scans at the same time, there is no guarantee that configuring `sonar.cfamily.threads=2` will bring the expected performance benefits. It can even be worse than running with the default value.\n\n* The multithreaded execution requires more memory than single-threaded execution.\n\n* A machine with 64 cores configured with `sonar.cfamily.threads=64` is not certain to bring a large performance gain compared to a machine with 32 cores. The performance tradeoff will vary depending on the machine, project and setup, so some testing will be required to decide if the performance gain justifies moving to a larger machine.\n\n## Solution with a Mix of C# and C++\n\nWhen you have a Solution made of C++ and C#, to both use the SonarQube *Build Wrapper* and have an accurate analysis of the C# code, you must to use the [SonarScanner for MSBuild](https://github.com/SonarSource/sonar-scanner-msbuild).\nNote that in this scenario source code stored in shared folders, not considered as a "Project" by Visual Studio, won\'t be scanned.\n\n* Download and install both the [SonarScanner for MSBuild](https://redirect.sonarsource.com/doc/install-configure-scanner-msbuild.html) and the SonarQube *Build Wrapper* (see *Prerequisites* section).\n* Execute the SonarQube Scanner for MSBuild `begin` step\n* Add execution of *Build Wrapper* to your normal MSBuild build command\n* Execute the SonarQube Scanner for MSBuild `end` step to complete the analysis\n\nFor example:\n```\nSonarScanner.MSBuild.exe begin /k:"cs-and-cpp-project-key" /n:"My C# and C++ project" /v:"1.0" /d:sonar.cfamily.build-wrapper-output="bw_output"\nbuild-wrapper-win-x86-64.exe --out-dir bw_output MSBuild.exe /t:Rebuild\nSonarScanner.MSBuild.exe end\n```\n\n## Measures for Header Files\nEach time we analyze a header file as part of a compilation unit, we compute for this header the measures: statements, functions, classes, cyclomatic complexity and cognitive complexity. That means that each measure may be computed more than once for a given header. In that case, we store the largest value for each measure.\n\n## Building with Bazel\n\n[Bazel](https://www.bazel.build/) recommends that you use the [`--batch`](https://docs.bazel.build/versions/master/bazel-user-manual.html#flag--batch) option when running in a Continuous Build context. When using the *BuildWrapper*, you are in such context. Also, you need to deactivate the ["sandbox"](https://docs.bazel.build/versions/master/bazel-user-manual.html#sandboxing) mechanism of *Bazel* so that the compiled file paths could be retrieved after the compilation phase.\nHere is an example of the *BuildWrapper* command with Bazel parameters on macOS:\n```\nbuild-wrapper-macosx-x86 --out-dir bw bazel\n  --batch\n  --spawn_strategy=standalone\n  --genrule_strategy=standalone\n  --bazelrc=/dev/null build\n  //main:hello-world\n```\n\n## Related Pages\n* [Test Coverage & Execution](/analysis/coverage/) (CPPUnit, GCOV, llvm-cov, Visual Studio, Bullseye)\n* [Sample project](https://github.com/SonarSource/sonar-scanning-examples/tree/master/sonarqube-scanner-build-wrapper-linux) for C/C++ (Linux)\n* [Sample project](https://github.com/SonarSource/sonar-scanning-examples/tree/master/objc-llvm-coverage) for Objective-C\n* [SonarScanner for Azure Devops](https://redirect.sonarsource.com/doc/install-configure-scanner-tfs-ts.html) (analyzing Visual C++ project)\n'},{path:"analysis/languages/cobol",content:'---\ntitle: COBOL\nurl: /analysis/languages/cobol/\n---\n\n_Cobol analysis is available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n\n\n## Language-Specific Properties\n\nYou can discover and update the COBOL-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > Cobol](/#sonarqube-admin#/admin/settings?category=cobol)**\n\n## Source Code Extraction\n\nIn order to analyze your source code with SonarQube you need to first extract it onto a filesystem. You can use your own tool or an open source tool; SonarSource does not provide any connectors or source code extraction tools.\n\n## Advanced Configuration\n\n### Defining Source Code Format\n\nThe supported source code formats are:\n\n- Fixed format\n- Free format\n- Variable format\n\nTo set the format, go to \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > Cobol](/#sonarqube-admin#/admin/settings?category=cobol)** and set the "Source format" property.\n\nThe fixed format has three main areas:\n\n```\nArea1 | Area2                                           | Area3\n000100* MY COMMENT\n000100 IDENTIFICATION DIVISION.\n000200 PROGRAM-ID. HELLOWORLD.                          *xxx\n100000 PROCEDURE DIVISION.                              *yyy\n100100\n100200 START.\n100400 DISPLAY "HELLO COBOL !" LINE 42 POSITION 12.\n100500 STOP RUN.\n```\n\nAreas #1 and #3 contain non-significant characters.\nArea #2 contains the source code. The first character of Area #2 is the Indicator Area, which has a special meaning (for instance `*` means that the line is a comment line, `D` means that the line is only taken into account in debug mode, etc.).\n\nThe free format:\n\n```\nArea1 | Area2\n      * MY COMMENT\n       IDENTIFICATION DIVISION.\n         PROGRAM-ID. HELLOWORLD.\n       PROCEDURE DIVISION.\n         DISPLAY "HELLO COBOL !" LINE 42 POSITION 12.\n         STOP RUN.\n```\n\nThe Indicator Area that has a special meaning (for instance `*` means that the line is a comment line, `D` means that the line in only taken into account in debug mode, etc.) is located at column 0. The size of the source code area is not limited.\n\nVariable format is also supported: it\'s similar to the fixed format but without Area #3.\n\n### Defining COBOL Dialect\n\nGo to \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > Cobol](/#sonarqube-admin#/admin/settings?category=cobol)** and set the "Dialect" property.\n\nThe COBOL analyzer supports the following dialects:\n\n- `bull-gcos-cobol`\n- `hp-tandem-cobol`\n- `ibm-os/vs-cobol`\n- `ibm-ile-cobol`\n- `ibm-cobol/ii`\n- `ibm-cobol/400`\n- `ibm-enterprise-cobol`\n- `microfocus-cobol`\n- `microfocus-acucobol-gt-cobol`\n- `opencobol/cobol-it`\n\n### Making Copybooks Available to the Analysis\n\nCopybooks are, by definition, COBOL files that are not syntactically valid by themselves. However, copybooks are usually needed to properly parse COBOL programs. Thus, paths to the copybooks must be listed through the `sonar.cobol.copy.directories` property.\n\n### Raising Issues Against Copybooks\n\nTo have copybooks imported into a project, and issues logged against them, the copybook directories must be added to `sonar.sources` AND the copybook file suffixes must be added to `sonar.cobol.file.suffixes`. E.G.:\n\n```\nsonar.sources=cobol,copy1,commonCopy\nsonar.cobol.file.suffixes=cbl,cpy\nsonar.cobol.copy.suffixes=cpy\nsonar.cobol.copy.directories=copy1,commonCopy\n```\n\nIn the case where a number of projects share a common set of copybooks, it may not be desirable to increment each project’s technical debt with the issues from the common copybooks. In such cases, the directory holding the common copybooks should be listed in `sonar.cobol.copy.directories` (as before) but left out of sonar.sources, E.G.:\n\n```\nsonar.sources=cobol,copy1\nsonar.cobol.file.suffixes=cbl,cpy\nsonar.cobol.copy.suffixes=cpy\nsonar.cobol.copy.directories=copy1,commonCopy\n```\n\n### Analyzing without file suffixes\n\nNote that it is possible to analyze a COBOL project without file suffixes. To do this, remove the two suffix-related properties from your configuration and substitute the following setting for `sonar.lang.patterns.cobol`:\n\n```\nsonar.lang.patterns.cobol=**/*\n```\n\n### Switching Off Issues\n\nThere are three ways to switch off issues:\n\n- Flagging issues as [false positive](/user-guide/issues/)\n- [Ignoring the issues](/project-administration/narrowing-the-focus/)\n- Using the `NOSONAR` tag. To switch off an issue, place the `NOSONAR` tag in a comment line located right before the line containing the issue. Example:\n\n```\n* NOSONAR, in such case call to GO TO is tolerated, blabla...\n GO TO MY_PARAGRAPH.\n```\n\n### ACUCOBOL-GT Source Code Control Directives\n\nThe COBOL analyzer supports the ACUCOBOL-GT’s Source Code Control directives. This mechanism allows you to conditionally modify the program at compile time by excluding or including lines. This can be used to maintain different versions of the program, perhaps to support different machine environments.\n\nThe `-Si` (include) flag controls the actions of the source code control system. It must be followed by an argument that specifies a pattern that the compiler will search for in the Identification Area of each source line. If the pattern is found, then the line will be included in the source program, even if it is a comment line. However, if the pattern is immediately preceded by an exclamation point, then the line will be excluded from the source (i.e., commented out).\n\nThe `-Sx` (exclude) flag works the same way except that its meaning is reversed (lines with the pattern will be commented out and lines with a preceding exclamation point will be included).\n\nFor example, suppose a program is being maintained for both the UNIX and VMS environments. The following piece of code is in the program:\n\n```\nMOVE "SYS$HELP:HELPFILE" TO FILE-NAME.  VMS\n*MOVE "/etc/helpfile" TO FILE-NAME.     UNX\nOPEN INPUT HELP-FILE.\n```\n\nThis program fragment is ready to be compiled for the VMS system. If a UNIX version is desired, then the following flags will correct the source during compilation:\n\n```\n-Si UNX -Sx VMS\n```\n\nPlease consult the ACUCOBOL-GT documentation for more on the mechanism.\n\nThere are two ways in SonarQube to specify the list of ACUCOBOL-GT flags to be used in order to preprocess the source code. The first option is to define a list of global flags which will be used to preprocess all source files. This can be done in the **[Administration > General Settings > Cobol](/#sonarqube-admin#/admin/settings?category=cobol) > Preprocessor**.\n\nThe second option is to provide a list of relative paths (with help of the ‘sonar.cobol.acucobol.preprocessor.directives.directories’ property) which contain the list of flags to be used for each COBOL source file. Let’s take a simple example. If a file ‘MY_PROGRAM.CBL’ is going to be processed, the SonarQube ACUCOBOL-GT preprocessor, will try to find a file ‘MY_PROGRAM.CMD’. If this file is found, then the flags contained in this file is going to be used to preprocess the program ‘MY_PROGRAM.CBL’. If the file ‘MY_PROGRAM.CMD’ doesn’t exist, then the preprocess will use the content of the file ‘DEFAULT.CMD’ if exists.\n\n### Microfocus Compiler Constants\n\nIf your code takes advantage of conditional compilation features provided by Microfocus, you may have to configure compiler constants for your analysis. You can define a compiler constant by setting a property named s`onar.cobol.compilationConstant.[constant name here].`\n\nFor example, if your COBOL code looks like this:\n\n```\n       IDENTIFICATION DIVISION.\n      $IF myconstant DEFINED\n       PROGRAM-ID. x.\n      $END\n      $IF otherconstant DEFINED\n       PROGRAM-ID. y.\n      $END\n```\n\nYou can set the value of a compiler constant named "myconstant" by inserting the following line in your sonar-project.properties file:\n\n```\nsonar.cobol.compilationConstant.myconstant=myvalue\n```\n\n## Database Catalog (DB2)\n\nThe COBOL analyzer offers rules which target embedded SQL statements and require the analyzer to have knowledge of the database catalog (E.G. the primary key column(s) of a given table).\nThese rules will raise issues only if the database catalog is provided to the analysis. For the moment, this is available only for IBM DB2 (z/OS) catalogs, and the catalog must be provided via a set of CSV ("Comma Separated Values") files.\n\nThese rules rely on two analysis properties:\n\n| Key                                     | Description                                                                      |\n| --------------------------------------- | -------------------------------------------------------------------------------- |\n| `sonar.cobol.sql.catalog.csv.path`      | relative path of the directory containing CSV files for the database catalog     |\n| `sonar.cobol.sql.catalog.defaultSchema` | comma-separated list of default database schemas used in embedded SQL statements |\n\n`sonar.cobol.sql.catalog.csv.path` should define a directory which contains 8 CSV files. Each of these CSV files contains data for a specific DB2 catalog table and is named after it. The following table lists the required files and their respective mandatory columns. Additional columns may be listed, but will be ignored:\n\n| Table                  | File name           | Required Columns                                                                       |\n| ---------------------- | ------------------- | -------------------------------------------------------------------------------------- |\n| `SYSIBM.SYSCOLUMNS`    | `SYSCOLUMNS.csv`    | `TBNAME`,`TBCREATOR`,`NAME`,`PARTKEY_COLSEQ`,`DEFAULT`,`NULLS`,`DEFAULTVALUE`          |\n| `SYSIBM.SYSINDEXES`    | `SYSINDEXES.csv`    | `NAME`,`CREATOR`,`TBNAME`,`TBCREATOR`,`UNIQUERULE`,`INDEXTYPE`                         |\n| `SYSIBM.SYSINDEXPART`  | `SYSINDEXPART.csv`  | `IXNAME`,`IXCREATOR`,`PARTITION`                                                       |\n| `SYSIBM.SYSKEYS`       | `SYSKEYS.csv`       | `IXNAME`,`IXCREATOR`,`COLNAME`,`COLSEQ`                                                |\n| `SYSIBM.SYSSYNONYMS`   | `SYSSYNONYMS.csv`   | `NAME`,`CREATOR`,`TBNAME`,`TBCREATOR`                                                  |\n| `SYSIBM.SYSTABLES`     | `SYSTABLES.csv`     | `NAME`,`CREATOR`,`TYPE`,`PARTKEYCOLNUM`,`TSNAME`,`DBNAME`,`TBNAME`,`TBCREATOR`,`CARDF` |\n| `SYSIBM.SYSTABLESPACE` | `SYSTABLESPACE.csv` | `NAME`,`DBNAME`,`PARTITIONS`                                                           |\n| `SYSIBM.SYSVIEWS`      | `SYSVIEWS.csv`      | `NAME`,`CREATOR`,`STATEMENT`                                                           |\n\nThe CSV format is the following:\n\n- Each file must be named for the table it represents.\n- First line must contain the exact names of the columns.\n- Order of the columns is not meaningful.\n- Fields are comma-delimited.\n- If a field contains a comma, then its value must be surrounded by double quotes (").\n- If a field which is surrounded by double quotes contains a double quote character ("), then this character must be doubled ("").\n\nExample for `SYSVIEWS.csv`:\n\n```\nCREATOR,NAME,STATEMENT\nUSER1,VIEW1,select x from table1\nUSER1,VIEW2,"select x, y from table1"\nUSER1,VIEW3,"select x, ""y"" from table1"\n```\n\nThe `UNLOAD` DB2 utility with the `DELIMITED` option should produce the required files except for the column names on the first line.\n\n\x3c!-- sonarqube --\x3e\n\n## Custom Rules\n\n### Overview\n\nThe COBOL analyzer parses the source code, creates an Abstract Syntax Tree (AST) and then walks through the entire tree. A coding rule can subscribe to be notified every time a node of a certain type is visited.\n\nAs soon as the coding rule is notified, it can navigate the tree around the node and raise issues if necessary.\n\n### Writing a Plugin\n\nWriting new COBOL coding rules is a six-step process:\n\n- Create a standard SonarQube plugin.\n- Attach this plugin to the SonarQube COBOL plugin (see the `pom.xml` file of the provided sample plugin project).\n- Create as many custom COBOL coding rules as required by extending `com.sonarsource.api.ast.CobolCheck` and add them to the previous repository.\n- Generate the SonarQube plugin (jar file).\n- Place this jar file in the `$SONARQUBE_HOME/extensions/plugins` directory.\n- Restart the SonarQube server.\n\n### Plugin Project Sample\n\nTo get started, clone the sample plugin project and follow the steps below:\n\n- Install Maven\n- Build the plugin by running `mvn install` from the project directory. This will generate a SonarQube plugin jar file in the target directory.\n- Add your newly created jar into the `$SONARQUBE_HOME/extensions/plugins` directory\n- Restart the SonarQube server\n\nIf you now look at the COBOL Quality Profiles, you will find the new coding rule (“Sample check”). Don’t forget to activate it. Run an analysis of a COBOL project, and you will find that an issue was logged at line 5 on every file.\n\n### Subscribing to a NodeType\n\nVery often when writing a coding rule, you will want to subscribe to a NodeType. A NodeType can be either a rule of the grammar or a keyword of the language. As an example, here is the code of the implementation of the “Avoid using Merge statement” coding rule:\n\n```\npublic class MergeStatementUsageCheck extends CobolCheck {\n\n  public void init() {\n    subscribeTo(getCobolGrammar().mergeStatement);\n  }\n\n  public void visitNode(AstNode node) {\n    reportIssue("Avoid using MERGE statement.").on(node);\n  }\n}\n```\n\nNote that CICS and SQL grammars can be accessed using `getCicsGrammar()` and `getSqlGrammar()`.\n\n### Coding Rule Lifecycle\n\nA coding rule can optionally override six methods inherited from the CobolCheck class. Those methods are called sequentially in the following order:\n\n- `public void init() {…}`: This method is called only once and should be used to subscribe to one or more NodeType(s).\n- `public void visitFile(AstNode astNode) {…}`: This method is called on each file before starting the parsing.\n- `public void visitNode(AstNode astNode) {…}`: This method is called when an AstNode matches a subscribed NodeType (see Subscribing to a NodeType) and before analyzing its content.\n- `public void leaveNode(AstNode astNode) {…}`: This method is called when an AstNode matches a desired NodeType (see Subscribing to a NodeType) and after analyzing its content.\n- `public void leaveFile(AstNode astNode) {…}`: This method is called before exiting a file.\n- `public void destroy() {…}`: This method is called before shutting down the coding rule.\n- The `reportIssue(…)` method, used to log an issue, should be called only inside the `visitFile(…)`, `visitNode(…)`, `leaveNode(…)` and `leaveFile(…)` methods. Indeed, the file context isn’t known when the `init()` and `destroy()` methods are called, so the issue can’t be associated to a file.\n\nMore advanced features are documented in the [API Javadoc](http://javadocs.sonarsource.org/cobol/apidocs/).\n\n### Navigating the AST (Abstract Syntax Tree) with the SSLR COBOL Toolkit\n\nWhen starting to write a new COBOL coding rule, the main difficulty is to understand the COBOL AST in order to know which NodeType(s) need to be visited. This can be achieved by using the [SSLR COBOL Toolkit](https://binaries.sonarsource.com/CommercialDistribution/sslr-cobol-toolkit/), a Swing application that enables loading a COBOL file and displaying its representation as an Abstract Syntax Tree.\n\nEach node in the AST is a COBOL grammar rule and each leaf in the AST is a COBOL token. Let’s say you want to visit the node `ifStatement`. In this case, the `init()` method of your COBOL coding rule must contain the following statement: `subscribeTo(getCobolGrammar().ifStatement);`\n\n### API Changes\n\n_Since 4.0_\nA new API is available to write the rules but also to implement the tests.\n\nCustom rules should now extend `CobolCheck` (`CobolAstCheck` is deprecated) and issues should be logged using the `reportIssue(...)` method.  \nTests on custom rules should now use `CobolCheckVerifier`: the assertions about issues should now be added as comments inside COBOL test files.  \nCustom rules should be listed in an implementation of `CobolCheckRepository` (`CobolAstCheckRepository` is now deprecated) and metadata should be loaded by implementing `RulesDefinitionExtension`.  \nYou can now store your custom rules into a dedicated rule repository by implementing SonarQube\'s `RulesDefinition`: in that case, you don\'t need to implement `RulesDefinitionExtension`.  \n![](/images/exclamation.svg) For users who already have custom rules in production: existing issues will be closed and re-opened because the internal keys of the rules are changing.\nIf you wrote a custom plugin against SonarCOBOL 3.x, it should still be compatible at runtime with SonarCOBOL 4.0.\n\nTo migrate to the new API ([full example on github](https://github.com/SonarSource/sonar-custom-rules-examples/pull/14)):\n\n- First, migrate tests without modifying rule classes. That mainly requires moving assertions from java test classes to comments inside test cobol files ([see an example on github](https://github.com/SonarSource/sonar-custom-rules-examples/commit/c95b6a84b6fd1efc832a46cd5e1101ee51e6268e)).\n- Update check classes to replace the calls to deprecated methods with the new methods which create issues ([see an example on github](https://github.com/SonarSource/sonar-custom-rules-examples/commit/d6f6ef7457d99e31990fa64b5ff9cc566775af96)).\n- Implement `CobolRulesDefinitionExtension` and `CobolCheckRepository`, remove the class extending `CobolAstCheckRepository` ([see an example on github](https://github.com/SonarSource/sonar-custom-rules-examples/commit/ea15f07ce79366a08fee5b60e9a93c32a4625918)).\n- Update check classes to extend `CobolCheck` instead of `CobolAstCheck` to stop using deprecated APIs ([see an example on github](https://github.com/SonarSource/sonar-custom-rules-examples/commit/8e1d746900f5411e9700fea04700cd804e45e034)).\n\nTo move your custom rules to a dedicated rule repository, see [an example on github](https://github.com/SonarSource/sonar-custom-rules-examples/commit/16ad89c4172c259f15bce56edcd09dd5b489eacd).\n\n## Related Pages\n\n- [Adding Coding Rules](/extend/adding-coding-rules/)\n  \x3c!-- /sonarqube --\x3e\n'},{path:"analysis/languages/csharp",content:'---\ntitle: C#\nurl: /analysis/languages/csharp/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the C#-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > C#](/#sonarqube-admin#/admin/settings?category=c%23)**.\n\n### Analyze Generated Code\n\nTo analyze tool-generated code (e.g. WCF code generated by `SvcUtil.exe`, protobuf code generated by `protoc`, Swagger client code generated by `NSwag`) for a specific C# project, enable the "Analyze generated code" setting inside **Project > Administration > General Settings > C#**. By default, tool-generated code files are skipped from analysis.\n\n## Related Pages\n* [Excluding External Roslyn Issues](/analysis/external-issues/) (See "Notes on external .NET issues")\n* [Test Coverage & Execution](/analysis/coverage/) (Visual Studio Code Coverage, dotCover, OpenCover, Coverlet, NCover 3)\n* [SonarScanner for MSBuild](/analysis/scan/sonarscanner-for-msbuild/)\n* [SonarScanner for Azure DevOps](/analysis/scan/sonarscanner-for-azure-devops/)\n'},{path:"analysis/languages/css",content:"---\ntitle: CSS\nurl: /analysis/languages/css/\n---\n\n\n\n## Prerequisites\nIn order to analyze CSS code, you need to have Node.js >= 8 installed on the machine running the scan. Set property `sonar.nodejs.executable` to an absolute path to Node.js executable, if standard `node` is not available.\n\nIf you have a community plugin that handles CSS installed on your SonarQube instance it will conflict with SonarCSS, so it should be removed.\n\n## Language-Specific Properties\n\nDiscover and update the CSS-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > CSS](/#sonarqube-admin#/admin/settings?category=css)**\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) (StyleLint.io)\n"},{path:"analysis/languages/flex",content:"---\ntitle: Flex\nurl: /analysis/languages/flex/\n---\n\n\n## Supported Versions\n* ActionScript 2\n* ActionScript 3\n\n## Language-Specific Properties\nDiscover and update the Flex-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e[**Administration > General Settings > Flex**](/#sonarqube-admin#/admin/settings?category=flex)\n\n## Related Pages\n\n* [Test Coverage & Execution](/analysis/coverage/) (Cobertura)\n\x3c!-- sonarqube --\x3e\n* [Adding Coding Rules](/extend/adding-coding-rules/)\n\x3c!-- /sonarqube --\x3e\n"},{path:"analysis/languages/go",content:'---\ntitle: Go\nurl: /analysis/languages/go/\n---\n\n\n\n\n## Prerequisites\n\n* SonarQube Scanner should run on a x86-64 Windows, macOS or Linux 64bits machine\n* You need the [Go](https://golang.org/) installation on the scan machine only if you want to import coverage data\n\n## Language-Specific Properties\n\nYou can discover and update the Go-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > Go](/#sonarqube-admin#/admin/settings?category=go)**\n\n## "sonar-project.properties" Sample\n\nHere is a good first version of a `sonar-project.properties`, correctly excluding "vendor" directories and categorizing files as "main" or "test":\n\n```\n  sonar.projectKey=com.company.projectkey1\n  sonar.projectName=My Project Name\n\n  sonar.sources=.\n  sonar.exclusions=**/*_test.go,**/vendor/**\n\n  sonar.tests=.\n  sonar.test.inclusions=**/*_test.go\n  sonar.test.exclusions=**/vendor/**\n```\n\n## Related Pages\n\n* [Test Coverage & Execution](/analysis/coverage/)\n* [Importing External Issues](/analysis/external-issues/) (GoVet, GoLint, GoMetaLinter)\n'},{path:"analysis/languages/html",content:"---\ntitle: HTML\nurl: /analysis/languages/html/\n---\n\n\n\n## Language-Specific Properties\n\nYou can discover and update HTML-specific [properties](/analysis/analysis-parameters/) in:  \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > HTML](/#sonarqube-admin#/admin/settings?category=html)**.\n\n## PHP Code Analysis\nSonarPHP and SonarHTML both analyze files with extensions: `.php`, `.php3`, `.php4`, `.php5`, `.phtml`.\n\nFile metrics, such as the number of lines of code, can only be measured by one of the languages, PHP or HTML. They are handled by SonarPHP by default, and by SonarHTML if for some reason SonarPHP is not present.\n\nSonarHTML analyzes PHP files even if the PHP file extensions are not included in the list of file extensions to analyze.\n"},{path:"analysis/languages/java",content:'---\ntitle: Java\nurl: /analysis/languages/java/\n---\n\n\n\n## Language-Specific Properties\n\nYou can discover and update the Java-specific [properties](/analysis/analysis-parameters/) in:  \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e[Administration > General Settings > Java](/#sonarqube-admin#/admin/settings?category=java)\n\n## Java Analysis and Bytecode\n\nCompiled `.class` files are required for java projects with more than one java file. If not provided properly, analysis will fail with the message:\n\n    Please provide compiled classes of your project with sonar.java.binaries property.\n\nIf only some `.class` files are missing, you\'ll see warnings like this:\n\n    Class \'XXXXXX\' is not accessible through the ClassLoader.\n\nIf you are not using Maven or Gradle for analysis, you must manually provide bytecode to the analysis.\nYou can also analyze test code, and for that you need to provide tests binaires and test libraries properties.\n\nKey | Value\n---|---|\n`sonar.java.binaries` (required) | Comma-separated paths to directories containing the compiled bytecode files corresponding to your source files. \n`sonar.java.libraries` | Comma-separated paths to files with third-party libraries (JAR or Zip files) used by your project. Wildcards can be used: `sonar.java.libraries=path/to/Library.jar,directory/**/*.jar`\n`sonar.java.test.binaries` | Comma-separated paths to directories containing the compiled bytecode files corresponding to your test files\n`sonar.java.test.libraries` | Comma-separated paths to files with third-party libraries (JAR or Zip files) used by your tests. (For example, this should include the junit jar). Wildcards can be used: `sonar.java.test.libraries=directory/**/*.jar`\n\n[[warning]]\n| Android users, Jack doesn\'t provide the required `.class` files.\n\n\n## Turning issues off\n\nThe best way to deactivate an individual issue you don\'t intend to fix is to mark it "Won\'t Fix" or "False Positive" through the SonarQube UI.\n\nIf you need to deactivate a rule (or all rules) for an entire file, then [issue exclusions](/project-administration/narrowing-the-focus/) are the way to go. But if you only want to deactivate a rule across a subset of a file - all the lines of a method or a class - you can use `@SuppressWarnings("all")` or `@SuppressWarnings` with rule keys: `@SuppressWarnings("squid:S2078")` or `@SuppressWarnings({"squid:S2078", "squid:S2076"})`. \n\n## Handling Java Source Version\n\nThe Java Analyzer is able to react to the java version used for sources. This feature allows the deactivation of rules that target higher versions of Java than the one in use in the project so that false positives aren\'t generated from irrelevant rules.\n\nThe feature relies entirely on the `sonar.java.source` property, which is automatically filled by most of the scanners used for analyses (Maven, Gradle). Java version-specific rules are not disabled when `sonar.java.source` is not provided. Concretely, rules which are designed to target specific java versions (tagged "java7" or "java8") are activated by default in the Sonar Way Java profile. From a user perspective, the feature is fully automatic, but it means that you probably want your projects to be correctly configured.\n\nWhen using SonarScanner to perform analyses of project, the property `sonar.java.source` can to be set manually in `sonar-project.properties`. Accepted formats are:\n* "1.X" (for instance 1.6 for java 6, 1.7 for java 7, 1.8 for java 8, etc.)\n* "X" (for instance 7 for java 7, 8 for java 8, etc. )\n\nExample: `sonar.java.source=1.6`\n\nIf the property is provided, the analysis will take the source version into account, and execute related rules accordingly. At run time, each of these rules will be executed – or not – depending of the Java version used by sources within the project. For instance, on a correctly configured project built with Java 6, rules targeting Java 7 and Java 8 will never raise issues, even though they are enabled in the associated rule profile.\n\n## Related Pages\n\n* [Test Coverage & Execution](/analysis/coverage/) (JaCoCo, Surefire)\n* [Importing External Issues](/analysis/external-issues/) ([SpotBugs](https://spotbugs.github.io/), [FindBugs](http://findbugs.sourceforge.net/), [FindSecBugs](https://github.com/find-sec-bugs/find-sec-bugs/wiki/Maven-configuration), [PMD](http://maven.apache.org/plugins/maven-pmd-plugin/usage.html), [Checkstyle](http://maven.apache.org/plugins/maven-checkstyle-plugin/checkstyle-mojo))\n\x3c!-- sonarqube --\x3e* [Adding Coding Rules](/extend/adding-coding-rules/)\x3c!-- /sonarqube --\x3e\n\n\x3c!-- sonarqube --\x3e\n## Custom Rules\n\nThe tutorial [Writing Custom Java Rules 101](https://redirect.sonarsource.com/doc/java-custom-rules-guide.html) will help to quickly start writing custom rules for Java.\n\n### API changes\n\n#### **6.1**\n\n* The `ExpressionTree` interface, from the AST API, is now enriched by two new methods `Optional<Object> asConstant()` and `<T> Optional<T> asConstant(Class<T> type)`. These methods let you try to retrieve the equivalent constant value of an expression (from a variable, for instance). An example of usage would be:\n\n```\nclass A {\n  public static final String CONSTANT1 = "abc";\n  public static final String CONSTANT2 = CONSTANT1 + "def";\n\n  void foo() {\n    System.out.println(CONSTANT2);\n                    // ^^^^^^^^^ calling \'identifier.asConstant(String.class)\' will return \'Optional.of("abcdef")\'\n  }\n}\n```\n\n#### **6.0**\n\n* Deprecated method `org.sonar.plugins.java.api.JavaFileScannerContext.addIssue(File, JavaCheck, int, String)` has been **removed**. Custom rules relying on it should report issues on a given `Tree` from now on.\n* Deprecated method `org.sonar.plugins.java.api.JavaFileScannerContext.getFile()` has been **removed**. Custom rules relying on it should rely on content of SQ\'s API `InputFile`.\n* Deprecated method `org.sonar.plugins.java.api.tree.TryStatementTree.resources()` has been **removed**, in favor of `org.sonar.plugins.java.api.tree.TryStatementTree.resourceList()`, as Java 9 allows other trees than `VariableTree` to be placed as resources in try-with-resources statements.\n* Method `org.sonar.plugins.java.api.semantic.Symbol.owner()` has been **flagged** with `@Nullable` annotation, to explicitly document the fact that some symbols (package, unknown, recovered) might well return `null`.\n\n* **Semantic engine**\n    * Return type of constructor is now `void type` instead of `null`.\n    * A **raw type** is now explicitly different from an **erasure type**. It is recommended to systematically use type erasure for type comparison when dealing with generics.\n        ```\n        class A<T> {\n        //    ^^^^ Definition of a Generic Type\n          boolean equals(Object o) {\n            if (o instance of A) {\n                           // ^ this is a raw type, not erasure of A<T>\n             return true;\n            }\n            return false;\n          }\n\n          A<String> foo() {\n            return new A<String>();\n                   //  ^^^^^^^^^ Parameterization of a Generic Type\n          }\n        }\n        ```\n    * According to Java Language Specification every array type implements the interface `java.io.Serializable`, calling `isSubtypeOf("java.io.Serializable")` on an array type now consistently returns `true`.\n    * Symbol corresponding to generic method invocations are now correctly parameterized.\n    * In some special cases (mostly missing bytecode dependencies, misconfigured projects), and due to ECJ recovery system, unknown/recovered types can now lead to unknown symbols, even on `ClassTree`/`MethodTree`/`VariableTree`. To illustrate this, the following example now associate the method to an unknown symbol, while previous semantic engine from SonarJava 5.X series was creating a `Symbol.MethodSymbol` with an unknown return type.\n        ```\n        Class A {\n          UnknownType<String> myMethod() { /* ... */ }\n                          //  ^^^^^^^^  symbol corresponding to the MethodTree will be unknown,\n        }\n        ```\n    * Thanks to improved semantic provided by ECJ engine, new semantic is now able to say that an *unknown* symbol is supposed to be type/variable/method (`isTypeSymbol()`, `isVariableSymbol()`, ...). Old semantic was answering `false` for all of them. Consequently, be sure to always use `isUnknown()` to validate symbol resolution. Other `is...Symbol()` methods are only designed to know how to cast the symbols (e.g from `Symbol` to `Symbol.MethodSymbol`).\n\n#### **5.12**\n* **Dropped**\n    * `org.sonar.plugins.java.api.JavaFileScannerContext`: Drop deprecated method used to retrieve trees contributing to the complexity of a method from  (deprecated since SonarJava 4.1). \n        ```\n        //org.sonar.plugins.java.api.JavaFileScannerContext\n        /**\n        * Computes the list of syntax nodes which are contributing to increase the complexity for the given methodTree.\n        * @deprecated use {@link #getComplexityNodes(Tree)} instead\n        * @param enclosingClass not used.\n        * @param methodTree the methodTree to compute the complexity.\n        * @return the list of syntax nodes incrementing the complexity.\n        */\n        @Deprecated\n        List<Tree> getMethodComplexityNodes(ClassTree enclosingClass, MethodTree methodTree);\n        ```\n    * `org.sonar.plugins.java.api.JavaResourceLocator`: The following method has been dropped (deprecated since SonarJava 4.1), without replacement.\n        ```\n        //org.sonar.plugins.java.api.JavaResourceLocator\n        /**\n        * get source file key by class name.\n        * @deprecated since 4.1 : will be dropped with no replacement.\n        * @param className fully qualified name of the analyzed class.\n        * @return key of the source file for the given class.\n        */\n        @Deprecated\n        String findSourceFileKeyByClassName(String className);\n        ```\n    * `org.sonar.plugins.surefire.api.SurefireUtils`: Dropping deprecated field with old property (deprecated since SonarJava 4.11)\n        ```\n        //org.sonar.plugins.surefire.api.SurefireUtils\n        /**\n        * @deprecated since 4.11\n        */\n        @Deprecated\n        public static final String SUREFIRE_REPORTS_PATH_PROPERTY = "sonar.junit.reportsPath";\n        ```\n* **Deprecated**  \n    * `org.sonar.plugins.java.api.JavaFileScannerContext`: Deprecate usage of File-based methods from API, which will be removed in future release. Starting from this version, methods relying on InputFile has to be preferred.\n        ```\n        //org.sonar.plugins.java.api.JavaFileScannerContext\n        /**\n        * Report an issue at a specific line of a given file.\n        * This method is used for one\n        * @param file File on which to report\n        * @param check The check raising the issue.\n        * @param line line on which to report the issue\n        * @param message Message to display to the user\n        * @deprecated since SonarJava 5.12 - File are not supported anymore. Use corresponding \'reportIssue\' methods, or directly at project level\n        */\n        @Deprecated\n        void addIssue(File file, JavaCheck check, int line, String message);\n        /**\n        * FileKey of currently analyzed file.\n        * @return the fileKey of the file currently analyzed.\n        * @deprecated since SonarJava 5.12 - Rely on the InputFile key instead, using {@link #getInputFile()}\n        */\n        @Deprecated\n        String getFileKey();\n\n        /**\n        * File under analysis.\n        * @return the currently analyzed file.\n        * @deprecated since SonarJava 5.12 - File are not supported anymore. Use {@link #getInputFile()} or {@link #getProject()} instead\n        */\n        @Deprecated\n        File getFile();\n        ```\n    * Deprecate methods which are not relevant anymore in switch-related trees from API, following introduction of the new Java 12 `switch` expression:\n        ```\n        //org.sonar.plugins.java.api.tree.CaseLabelTree\n        /**\n        * @deprecated (since 5.12) use the {@link #expressions()} method.\n        */\n        @Deprecated\n        @Nullable\n        ExpressionTree expression();\n\n        /**\n        * @deprecated (since 5.12) use the {@link #colonOrArrowToken()} method.\n        */\n        @Deprecated\n        SyntaxToken colonToken();\n        ```\n* **Added**\n    * `org.sonar.plugins.java.api.JavaFileScannerContext`: Following methods have been added in order to provide help reporting issues at project level, and access data through SonarQube\'s InputFile API, which won\'t be possible anymore through files:\n    ```\n        //JavaFileScannerContext: New methods\n        /**\n        * Report an issue at at the project level.\n        * @param check The check raising the issue.\n        * @param message Message to display to the user\n        */\n        void addIssueOnProject(JavaCheck check, String message);\n    \n        /**\n        * InputFile under analysis.\n        * @return the currently analyzed inputFile.\n        */\n        InputFile getInputFile();\n        \n        /**\n        * InputComponent representing the project being analyzed\n        * @return the project component\n        */\n        InputComponent getProject();\n        ```\n    * In order to cover the Java 12 new switch expression, introduce a new Tree in the SonarJava Syntax Tree API  (Corresponding `Tree.Kind`: `SWITCH_EXPRESSION` ). New methods have also been added to fluently integrate the new switch expression into the SonarJava API.\n        ```\n        //org.sonar.plugins.java.api.tree.SwitchExpressionTree\n        /**\n        * \'switch\' expression.\n        *\n        * JLS 14.11\n        *\n        * <pre>\n        *   switch ( {@link #expression()} ) {\n        *     {@link #cases()}\n        *   }\n        * </pre>\n        *\n        * @since Java 12\n        */\n        @Beta\n        public interface SwitchExpressionTree extends ExpressionTree {\n        \n        SyntaxToken switchKeyword();\n        \n        SyntaxToken openParenToken();\n        \n        ExpressionTree expression();\n        \n        SyntaxToken closeParenToken();\n        \n        SyntaxToken openBraceToken();\n        \n        List<CaseGroupTree> cases();\n        \n        SyntaxToken closeBraceToken();\n        }\n        ```\n        ```\n        //org.sonar.plugins.java.api.tree.SwitchStatementTree\n        /**\n        * Switch expressions introduced with support Java 12\n        * @since SonarJava 5.12\n        */\n        SwitchExpressionTree asSwitchExpression();\n        ```\n        ```\n        //org.sonar.plugins.java.api.tree.CaseLabelTree\n        /**\n        * @return true for case with colon: "case 3:" or "default:"\n        *         false for case with arrow: "case 3 ->" or "default ->"\n        * @since 5.12 (Java 12 new features)\n        */\n        boolean isFallThrough();\n        \n        /**\n        * @since 5.12 (Java 12 new features)\n        */\n        SyntaxToken colonOrArrowToken();\n        ```\n        ```\n        //org.sonar.plugins.java.api.tree.BreakStatementTree\n        /**\n        * @since 5.12 (Java 12 new features)\n        */\n        @Nullable\n        ExpressionTree value();\n        ```\n        ```\n        //org.sonar.plugins.java.api.tree.TreeVisitor\n        void visitSwitchExpression(SwitchExpressionTree tree);\n        ```\n\n#### **5.7**\n* **Breaking**  \n    * This change will impact mostly the custom rules relying on semantic API. The type returned by some symbols will change from raw type to parameterized type with identity substitution and this will change how subtyping will answer.\n\n    It is possible to get the previous behavior back by using type erasure on the newly returned type. Note that not all returned types are impacted by this change.\n\n    Example:\n    ```\n    @Rule(key = "MyFirstCustomRule")\n    public class MyFirstCustomCheck extends IssuableSubscriptionVisitor {\n    \n        @Override\n        public List<Kind> nodesToVisit() {\n            return ImmutableList.of(Kind.METHOD);\n        }\n    \n        @Override\n        public void visitNode(Tree tree) {\n            MethodTree method = (MethodTree) tree;\n            MethodSymbol symbol = method.symbol();\n            \n            Type returnType = symbol.returnType().type();\n            // When analyzing the code "MyClass<Integer> foo() {return null; }"\n            // BEFORE: returnType == ClassJavaType\n            // NOW: returnType == ParametrizedTypeJavaType\n    \n            // Getting back previous type\n            Type erasedType = returnType.erasure();\n            // erasedType == ClassJavaType\n        }\n    }\n    ```\n\x3c!-- /sonarqube --\x3e\n'},{path:"analysis/languages/javascript",content:"---\ntitle: JavaScript\nurl: /analysis/languages/javascript/\n---\n\n\n\n## Prerequisites\n\nIn order to analyze JavaScript code, you need to have Node.js >= 8 installed on the machine running the scan. Set property `sonar.nodejs.executable` to an absolute path to Node.js executable, if standard `node` is not available.\n \n## Language-Specific Properties\n\nDiscover and update the JavaScript-specific properties in: **\x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e[Administration > General Settings > JavaScript](/#sonarqube-admin#/admin/settings?category=javascript)**\n\n## Supported Frameworks and Versions\n* ECMAScript 5 / ECMAScript 2015 (ECMAScript 6) / ECMAScript 2016 / ECMAScript 2017\n* React JSX\n* Vue.js\n* Flow\n\n## Rule Profiles\n\nThere are 2 built-in rule profiles for JavaScript: `Sonar way` (default) and `Sonar way Recommended`.\n* `Sonar way` profile is activated by default. It defines a trimmed list of high-value/low-noise rules useful in almost any JS development context.\n* `Sonar way Recommended` contains all rules from `Sonar way`, plus more rules that mandate high code readability and long-term project evolution.\n\n\x3c!-- sonarqube --\x3e\n## Custom rules\n[[warning]]\n| This feature is deprecated\n### Overview\n\nThe JavaScript Analyzer parses the source code, creates an Abstract Syntax Tree (AST) and then walks through the entire tree. A coding rule is a visitor that is able to visit nodes from this AST.\n\nAs soon as the coding rule visits a node, it can navigate the tree around the node and log issues if necessary.\n\n### Create SonarQube Plugin\nCustom rules for JavaScript can be added by writing a SonarQube Plugin and using JavaScript analyzer APIs.\n\nTo get started a sample plugin can be found here: [javascript-custom-rules](https://github.com/SonarSource/sonar-custom-rules-examples/tree/master/javascript-custom-rules).\nHere are the step to follow:\n\n* Create a standard SonarQube plugin project\n* Attach this plugin to the SonarQube JavaScript analyzer through the `pom.xml`:\n  * Add the dependency to the JavaScript analyzer.\n  * Add the following line in the sonar-packaging-maven-plugin configuration.\n  ```\n  <basePlugin>javascript</basePlugin>\n  ```\n* Implement the following extension points:\n  * [Plugin](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/Plugin.html)\n  * [RulesDefinition](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/server/rule/RulesDefinition.html) \n  * `CustomRuleRepository`, this interface registers rule classes with JavaScript plugin, so they are invoked during analysis of JavaScript files.\n* Declare `RulesDefinition` as an extension in the `Plugin` extension point.\n\nYou can implement both `RulesDefinition` and `CustomRulesRepository` in a single class.\n\n### Implement a Rule\n\n* Create a class that will hold the implementation of the rule. It should:\n  * Extend `DoubleDispatchVisitorCheck` or `SubscriptionVisitorCheck`\n  * Define the rule name, key, tags, etc. with Java annotations.\n* Declare this class in the `RulesDefinition`.\n\n###  Implementation Details\n\n#### Using DoubleDispatchVisitorCheck\n`DoubleDispatchVisitorCheck` extends `DoubleDispatchVisitor` which provide a set of methods to visit specific tree nodes (these methods' names start with `visit`). To explore a part of the AST, override the required method(s). For example, if you want to explore `if` statement nodes, override the `DoubleDispatchVisitor#visitIfStatement` method that will be called each time an `IfStatementTree` node is encountered in the AST.\n\n[[warning]]\n| When overriding a visit method, you must call the `super` method in order to allow the visitor to visit the rest of the tree.\n\n#### Using SubscriptionVisitorCheck\n`SubscriptionVisitorCheck` extends `SubscriptionVisitor`. To explore a part of the AST, override `SubscribtionVisitor#nodesToVisit()` by returning the list of the `Tree#Kind` of node you want to visit. For example, if you want to explore `if` statement nodes the method will return a list containing the element `Tree#Kind#IF_STATEMENT`.\n\n#### Create issues\nUse these methods to log an issue:\n\n* `JavaScriptCheck#addIssue(tree, message)` creates and returns an instance of `PreciseIssue`. In the SonarQube UI this issue will highlight all code corresponding to the tree passed as the first parameter. To add cost (effort to fix) or secondary locations provide these values to your just-created instance of `PreciseIssue`.\n* `JavaScriptCheck#addIssue(issue)` creates and returns the instance of `Issue`. Use this method to create non-standard issues (e.g. for a file-level issue instantiate `FileIssue`).\n\n#### Check context\nCheck context is provided by `DoubleDispatchVisitorCheck` or `SubscriptionVisitorCheck` by calling the `JavaScriptCheck#getContext` method. Check context provides you access to the root tree of the file, the file itself and the symbol model (information about variables).\n\n#### Test rule\nTo test the rule you can use `JavaScriptCheckVerifier#verify()` or `JavaScriptCheckVerifier#issues()`. To be able to use these methods add a dependency to your project:\n```\n<dependency>\n  <groupId>org.sonarsource.javascript</groupId>\n  <artifactId>javascript-checks-testkit</artifactId>\n  <version>XXX</version>\n  <scope>test</scope>\n</dependency>\n```\n\n### API Changes\n#### SonarJS 4.2.1\n* `CustomJavaScriptRulesDefinition` is deprecated. Implement extension `RulesDefinition` and `CustomRuleRepository` instead.\n\n#### SonarJS 4.0\n* Method `TreeVisitorContext#getFile()` is removed.\n\n\x3c!-- /sonarqube --\x3e\n\n## Related Pages\n\n* [Test Coverage & Execution](/analysis/coverage/) (LCOV format)\n* [Importing External Issues](/analysis/external-issues/) (ESLint)\n* [SonarJS Plugin for ESLint](https://github.com/SonarSource/eslint-plugin-sonarjs)\n\x3c!-- sonarqube --\x3e\n* [Adding Coding Rules](/extend/adding-coding-rules/)\n\x3c!-- /sonarqube --\x3e\n"},{path:"analysis/languages/kotlin",content:"---\ntitle: Kotlin\nurl: /analysis/languages/kotlin/\n---\n\n\n\n## Language-Specific Properties\n\nYou can discover and update Kotlin-specific [properties](/analysis/analysis-parameters/) in:  \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > Kotlin](/#sonarqube-admin#/admin/settings?category=kotlin)**.\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) (AndroidLint and Detekt)\n* [Test Coverage & Execution](/analysis/coverage/) (JaCoCo)\n"},{path:"analysis/languages/overview",content:"---\ntitle: Overview\nurl: /analysis/languages/overview/\n---\n\nSonarQube provides analysis of different languages depending on the edition you're running.\n\n| Language                             | Community Edition      | Developer Edition      | Enterprise Edition and Data Center Edtion |\n| ------------------------------------ | ---------------------- | ---------------------- | ----------------------------------------- |\n| [ABAP](/analysis/languages/abap/)             |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Apex](/analysis/languages/apex/)             |                        |                        | ![](/images/check.svg)                    |\n| [C#](/analysis/languages/csharp/)             | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [C](/analysis/languages/cfamily/)             |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [C++](/analysis/languages/cfamily/)           |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [COBOL](/analysis/languages/cobol/)           |                        |                        | ![](/images/check.svg)                    |\n| [CSS](/analysis/languages/css/)               | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Flex](/analysis/languages/flex/)             | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Go](/analysis/languages/go/)                 | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Java](/analysis/languages/java/)             | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [JavaScript](/analysis/languages/javascript/) | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Kotlin](/analysis/languages/kotlin/)         | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Objective-C](/analysis/languages/cfamily/)   |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [PHP](/analysis/languages/php/)               | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [PLI](/analysis/languages/pli/)               |                        |                        | ![](/images/check.svg)                    |\n| [PLSQL](/analysis/languages/plsql/)           |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Python](/analysis/languages/python/)         | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [RPG](/analysis/languages/rpg/)               |                        |                        | ![](/images/check.svg)                    |\n| [Ruby](/analysis/languages/ruby/)             | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Scala](/analysis/languages/scala/)           | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [Swift](/analysis/languages/swift/)           |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [TypeScript](/analysis/languages/javascript/) | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [TSQL](/analysis/languages/tsql/)             |                        | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [VB.NET](/analysis/languages/vbnet/)          | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [VB6](/analysis/languages/vb6/)               |                        |                        | ![](/images/check.svg)                    |\n| [HTML](/analysis/languages/html/)             | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n| [XML](/analysis/languages/xml/)               | ![](/images/check.svg) | ![](/images/check.svg) | ![](/images/check.svg)                    |\n\nIn this section, you'll find documentation related to languages supported by SonarSource.\n"},{path:"analysis/languages/php",content:'---\ntitle: PHP\nurl: /analysis/languages/php/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the PHP-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > PHP](/#sonarqube-admin#/admin/settings?category=php)**\n\n## Analyze php.ini Files\n\nThe PHP analyzer can analyze `php.ini` files with some specific rules (if these rules are activated in your Quality Profile). `php.ini` files must be part of the project you are analyzing, meaning the `php.ini` files have to be inside the directories listed in `sonar.sources`. \nRules targeting `php.ini` files can be quickly identified through the ["php-ini"](https://rules.sonarsource.com/php/tag/php-ini) tag set on them.\n\n\x3c!-- sonarqube --\x3e\n\n## Custom Rules\n\n### Overview\n\nThe PHP analyzer parses the source code, creates an Abstract Syntax Tree (AST) and then walks through the entire tree. A coding rule is a visitor that is able to visit nodes from this AST.\n\nAs soon as the coding rule visits a node, it can navigate its children and log issues if necessary.\n\n### Example Plugin\n\nTo get started a sample plugin can be found here: [php-custom-rules](https://github.com/SonarSource/sonar-custom-rules-examples/tree/master/php-custom-rules).\n\n### Writing a Plugin\n\nCustom rules for PHP can be added by writing a SonarQube Plugin and using PHP analyzer APIs.\nHere are the step to follow:\n\n#### Create SonarQube Plugin\n\n* create a standard SonarQube plugin project\n* attach this plugin to the SonarQube PHP analyzer through the `pom.xml`:\n  * add the dependency to the PHP analyzer.\n  * add the following line in the sonar-packaging-maven-plugin configuration.\n  ```\n  <basePlugin>php</basePlugin>\n  ```\n* implement the following extension points:\n  * [Plugin](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/Plugin.html)\n  * [RulesDefinition](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/server/rule/RulesDefinition.html) and [PHPCustomRuleRepository](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/visitors/PHPCustomRuleRepository.java), which can be implemented by a single class, to declare your custom rules\n* declare the RulesDefinition as an extension in the Plugin extension point.\n\n#### Implement a Rule\n\n* create a class that will hold the implementation of the rule, it should:\n  * extend `PHPVisitorCheck` or `PHPSubscriptionCheck`\n  * define the rule name, key, tags, etc. with Java annotations.\n* declare this class in the `RulesDefinition`.\n\n####  Implementation Details\n\n**Using `PHPVisitorCheck`**\n\nTo explore a part of the AST, override a method from the PHPVisitorCheck. For example, if you want to explore "if statement" nodes, override [PHPVisitorCheck#visitIfStatement](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/visitors/PHPVisitorCheck.java#L265) method that will be called each time an [ifStatementTree](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/tree/statement/IfStatementTree.java) node is encountered in the AST.\n\n[[warning]]\n| When overriding a visit method, you must call the super method in order to allow the visitor to visit the children the node.\n\n**Using `PHPSubscriptionCheck`**\n\nTo explore a part of the AST, override [`PHPSubscriptionCheck#nodesToVisit`](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/visitors/PHPSubscriptionCheck.java#L33) by returning the list of the [`Tree#Kind`](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/tree/Tree.java#L124) of node you want to visit. For example, if you want to explore "if statement" nodes the method will return a list containing the element [`Tree#Kind#IF_STATEMENT`](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/tree/Tree.java#L761).\n\n**Create Issues**\n\nFrom the check, issue can be created by calling [`CheckContext#newIssue`](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/visitors/CheckContext.java#L90) method.\n\n**Testing Checks**\n\nTo test custom checks you can use method [`PHPCheckVerifier#verify`](https://github.com/SonarSource/sonar-php/blob/master/php-frontend/src/main/java/org/sonar/plugins/php/api/tests/PHPCheckVerifier.java#L55). You should end each line with an issue with a comment in the following form:\n\n```\n// Noncompliant {{Message}}\n```\n\nComment syntax is described [here](https://github.com/SonarSource/sonar-analyzer-commons/blob/master/test-commons/README.md).\n\n\x3c!-- /sonarqube --\x3e\n\n## Related Pages\n\n* [Test Coverage & Execution](/analysis/coverage/)\n\x3c!-- sonarqube --\x3e\n* [Adding Coding Rules](/extend/adding-coding-rules/)\n\x3c!-- /sonarqube --\x3e\n'},{path:"analysis/languages/pli",content:"---\ntitle: PLI\nurl: /analysis/languages/pli/\n---\n\n_PL/I analysis is available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n\n\n## Language-Specific Properties\n\nDiscover and update the PL/I-specific properties in: **[Administration > General Settings > PL/I](/#sonarqube-admin#/admin/settings?category=pl%2Fi)**\n\n## Source Code Extraction\n\nIn order to analyze your source code with SonarQube you need to first extract it onto a filesystem. You can use your own tool or an open source tool; SonarSource does not provide any connectors or source code extraction tools.\n\n## Dealing with Includes\n\nThere are two possible ways to tell SonarQube where to retrieve the source code referenced by an %INCLUDE statement.\n\nThe following syntaxes are supported:\n\n```\n%INCLUDE 'C:/temp/myLib.pli'\n%INCLUDE ddname(member);\n%INCLUDE member; /* With member not enclosed within single or double quotes, i.e. a SYSLIB member */\n```\n\nExample:\n\nIf you want to interpret:\n\n```\n%INCLUDE O (XX02511) as %INCLUDE 'C:/temp/o/XX02511.99IPO';\n%INCLUDE lib1 as %INCLUDE 'C:/temp/syslib/lib1.pli';\n```\n\nthe Ddnames are defined as:\n\n```\nsonar.pli.includeDdnames=O,SYSLIB\n\nsonar.pli.includeDdname.O.path=c:/temp/o\nsonar.pli.includeDdname.O.suffix=.99IPO\n\nsonar.pli.includeDdname.SYSLIB.path=c:/temp/syslib\nsonar.pli.includeDdname.SYSLIB.suffix=.pli\n```\n\nNote that the following constructs, involving at least two members, are currently not supported:\n\n```\n%INCLUDE member1, member2;\n%INCLUDE ddname1(member1), member2;\n%INCLUDE member1, ddname1(member2);\n%INCLUDE ddname1(member1), ddname2(member2);\n```\n\n## Related Pages\n\x3c!-- sonarqube --\x3e\n* [Adding Coding Rules](/extend/adding-coding-rules/)\n\x3c!-- /sonarqube --\x3e\n"},{path:"analysis/languages/plsql",content:"---\ntitle: PL/SQL\nurl: /analysis/languages/plsql/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the PL/SQL-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > PL/SQL](/#sonarqube-admin#/admin/settings?category=pl%2Fsql)**\n\n## Advanced parameters\n\n### Default Schema\nParameter | Description\n--- | ---\n`sonar.plsql.defaultSchema` | When a schema object (table, view, index, synonym) is referenced in SQL code without a schema prefix, the analyzer will assume that it belongs to this schema.\n\n\n### Data Dictionary\nSome rules raise issues only when a data dictionary is provided during analysis. To provide a data dictionary, you must define the following properties in the `sonar-project.properties` file or on the scanner command line using the  `-D` prefix:\n\n\n|Parameter|Description|\n| --- | --- | \n|`sonar.plsql.jdbc.url`|URL of the JDBC connection. **Required for data dictionary lookup**. For example: `jdbc:oracle:thin:@my-oracle-server:1521/my-db`\n|`sonar.plsql.jdbc.user`|JDBC user to authenticate the connection.\n|`sonar.plsql.jdbc.password`|JDBC password provided to authenticate the connection.\n|`sonar.plsql.jdbc.driver.path`|Path or URL of the Oracle jdbc driver jar.\n|`sonar.plsql.jdbc.driver.class`|Java class name of the Oracle Driver. For example: `oracle.jdbc.OracleDriver`\n\nProviding this configuration allows SonarPLSQL to query data dictionary views such as `SYS.ALL_TAB_COLUMNS` in order to to better analyze your SQL.\n\n\n\x3c!-- sonarqube --\x3e\n## Related Pages\n* [Adding Coding Rules](/extend/adding-coding-rules/)\n\x3c!-- /sonarqube --\x3e\n\n"},{path:"analysis/languages/python",content:'---\ntitle: Python\nurl: /analysis/languages/python/\n---\n\n\n\n## Supported Versions\n* Python 3.X\n* Python 2.X\n\n## Language-Specific Properties\n\nDiscover and update the Python-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > Python](/#sonarqube-admin#/admin/settings?category=python)**.\n\n## Pylint\n[Pylint](http://www.pylint.org/) is an external static source code analyzer, it can be used in conjunction with SonarPython.\n\nYou can enable Pylint rules directly in your Python Quality Profile. Their rule keys start with "*Pylint:*".\n\nOnce the rules are activated you should run Pylint and import its report:\n```\npylint <module_or_package> -r n --msg-template="{path}:{line}: [{msg_id}({symbol}), {obj}] {msg}" > <report_file>\n```\nThen pass the generated report path to analysis via the `sonar.python.pylint.reportPath` property.\n\n\x3c!-- sonarqube --\x3e\n\n## Custom Rules\n\n### Overview\n\nThe Python analyzer parses the source code, creates an Abstract Syntax Tree (AST) and then walks through the entire tree. A coding rule is a visitor that is able to visit nodes from this AST.\n\nAs soon as the coding rule visits a node, it can navigate its children and log issues if necessary.\n\n### Writing a Plugin\n\nCustom rules for Python can be added by writing a SonarQube Plugin and using Python analyzer APIs.\nHere are the step to follow:\n\n#### Create SonarQube Plugin\n\n* create a standard SonarQube plugin project\n* attach this plugin to the SonarQube Python analyzer through the `pom.xml`:\n  * add the dependency to the Python analyzer.\n  * add the following line in the sonar-packaging-maven-plugin configuration.\n  ```\n  <requirePlugins>python:2.0-SNAPSHOT</requirePlugin>\n  ```\n* implement the following extension points:\n  * [Plugin](http://javadocs.sonarsource.org/latest/apidocs/org/sonar/api/Plugin.html)\n  * [RulesDefinition](http://javadocs.sonarsource.org/latest/apidocs/org/sonar/api/server/rule/RulesDefinition.html) and [PythonCustomRuleRepository](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/PythonCustomRuleRepository.java), which can be implemented by a single class, to declare your custom rules\n* declare the RulesDefinition as an extension in the Plugin extension point.\n\n#### Implement a Rule\n\n* create a class that will hold the implementation of the rule, it should:\n  * extend `PythonCheckTree` or `PythonSubscriptionCheck`\n  * define the rule name, key, tags, etc. with Java annotations.\n* declare this class in the `RulesDefinition`.\n\n### Example Plugin\n\nTo get started a sample plugin can be found here: [python-custom-rules](https://github.com/SonarSource/sonar-custom-rules-examples/tree/master/python-custom-rules).\n\n####  Implementation Details\n\n**Using `PythonCheckTree`**\n\nTo explore a part of the AST, override a method from the PythonCheckTree. For example, if you want to explore "if statement" nodes, override [PythonCheckTree#visitIfStatement](https://github.com/SonarSource/sonar-python/blob/39b6126e9fdef42b93004cf6cc5818e861051334/python-frontend/src/main/java/org/sonar/plugins/python/api/tree/BaseTreeVisitor.java#L56) method that will be called each time an [ifStatement](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/tree/IfStatement.java) node is encountered in the AST.\n\n[[warning]]\n| When overriding a visit method, you must call the super method in order to allow the visitor to visit the children the node.\n\n**Using `PythonSubscriptionCheck`**\n\nTo explore a part of the AST, override [`PythonSubscriptionCheck#initialize`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/SubscriptionCheck.java#L26) and call the [`SubscriptionCheck.Context#registerSyntaxNodeConsumer`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/SubscriptionCheck.java) with the [`Tree#Kind`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/tree/Tree.java#L42) of node you want to visit. For example, if you want to explore "if statement" you should register to the kind [`Tree#Kind#IF_STATEMENT`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/tree/Tree.java#L97) and then provide a lambda that will consume a [`SubscriptionContext`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/SubscriptionContext.java#L27) to act on such ndoes.\n\n**Create Issues**\n\nFrom the check, issue can be created by calling [`SubscriptionContext#addIssue`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/SubscriptionContext.java#L30) method or  [`PythonCheckTree#addIssue`](https://github.com/SonarSource/sonar-python/blob/master/python-frontend/src/main/java/org/sonar/plugins/python/api/PythonCheckTree.java#L36) method.\n\n**Testing Checks**\n\nTo test custom checks you can use method [`PythonCheckVerifier#verify`](https://github.com/SonarSource/sonar-python/blob/master/python-checks-testkit/src/main/java/org/sonar/python/checks/utils/PythonCheckVerifier.java). Don\'t forget to add the testkit dependency to access this class from your project : \n  ```\n    <dependency>\n\t  <groupId>org.sonarsource.python</groupId>\n\t  <artifactId>python-checks-testkit</artifactId>\n\t  <version>${project.version}</version>\n\t  <scope>test</scope>\n    </dependency>\n  ```\n\nYou should end each line with an issue with a comment in the following form:\n\n```\n# Noncompliant {{Message}}\n```\n\nComment syntax is described [here](https://github.com/SonarSource/sonar-analyzer-commons/blob/master/test-commons/README.md).\n\n\x3c!-- /sonarqube --\x3e\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) ([Pylint](http://www.pylint.org/), [Bandit](https://github.com/PyCQA/bandit/blob/master/README.rst))\n* [Test Coverage & Execution](/analysis/coverage/) (the [Coverage Tool](http://nedbatchelder.com/code/coverage/) provided by [Ned Batchelder](http://nedbatchelder.com/), [Nose](https://nose.readthedocs.org/en/latest/), [pytest](https://docs.pytest.org/en/latest/))\n'},{path:"analysis/languages/rpg",content:'---\ntitle: RPG\nurl: /analysis/languages/rpg/\n---\n\n_RPG analysis is available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n\n\n## Language-Specific Properties\n\nDiscover and update the RPG-specific [properties](/analysis/analysis-parameters/) in: **[Administration > General Settings > RPG](/#sonarqube-admin#/admin/settings?category=rpg)**\n\n## Source Code Extraction\n\nIn order to analyze your source code with SonarQube you need to first extract it onto a filesystem. You can use your own tool or an open source tool; SonarSource does not provide any connectors or source code extraction tools.\n\n## RPG Source Format\n\nDepending on your extraction process, your RPG source files may include an extra margin on the left of the 80 columns used for code. This margin is in addition to the standard margin which takes up characters 1-5 in the 80-character source format. The extra margin is controlled through the `sonar.rpg.leftMarginWidth` property. By default, it is set to 12, which is the size of the margin in an IBM “source physical file”. If your RPG source files do not contain such a margin, you should set `sonar.rpg.leftMarginWidth` to `0`.\n\nYou can find an [example file](https://raw.githubusercontent.com/SonarSource/sonar-scanning-examples/master/sonarqube-scanner/src/rpg/MYPROGRAM.rpg) illustrating a 12-character margin in our sample project.\n\nYou should also make sure to set `sonar.sourceEncoding` to the appropriate encoding. Please check the [documentation of this property](/analysis/analysis-parameters/).\n\n## Free-Form Support\n\nFree-form is supported for C-specs and SQL statements. Free-form is not yet supported for H, F, D and P specs (which were [added in IBM i 7.2](http://www-01.ibm.com/support/knowledgecenter/ssw_ibm_i_72/rzasd/rpgrelv7r2.htm)).\n\n## Custom Rules for RPG\n\nTo get started you can [browse](https://github.com/SonarSource/sonar-custom-rules-examples/tree/master/rpg-custom-rules) or [download](https://github.com/SonarSource/sonar-custom-rules-examples/archive/master.zip) a simple plugin.\n\n### Pre-requisites\n\n- JDK 8\n- SonarRPG 2.0+\n\n### Creating a Maven Project\n\nYou should first create a Maven project: re-using the [pom.xml from the RPG example](https://github.com/SonarSource/sonar-custom-rules-examples/blob/master/rpg-custom-rules/pom.xml) is a good start.\n\nThe following dependencies need to be defined in the pom.xml:\n\n- `sonar-plugin-api` to get access to SonarQube APIs\n- `sonar-rpg-plugin` to use the APIs of the RPG plugin\n\n### Writing a Custom Rule\n\nEach rule needs to be defined in a class which:\n\n- Implements [`com.sonarsource.rpg.api.checks.Check`](http://javadocs.sonarsource.org/rpg/apidocs/2.3/index.html?com/sonarsource/rpg/api/checks/Check.html). Instead of implementing this interface directly, the class can also extend [`VisitorBasedCheck`](http://javadocs.sonarsource.org/rpg/apidocs/2.3/index.html?com/sonarsource/rpg/api/checks/Check.html?com/sonarsource/rpg/api/checks/VisitorBasedCheck.html) which makes it easier to target some specific parts of the analyzed source code.\n- Has an `org.sonar.check.Rule` annotation to define the key of the rule.\n\n#### Navigating the Syntax Tree\n\nThe analyzed source code is represented as a tree structure. The top-most tree is an instance of [`ModuleTree`](http://javadocs.sonarsource.org/rpg/apidocs/2.3/index.html?com/sonarsource/rpg/api/checks/Check.html?com/sonarsource/rpg/api/tree/ModuleTree.html) which has references to other trees. Some of the trees represent a group of RPG calculations (for example, an `IF` group is represented as a tree which references the calculations which are executed when the condition is true), some others represent expressions such as `a + b`.\n\nThe instance of [`CheckContext`](http://javadocs.sonarsource.org/rpg/apidocs/2.3/index.html?com/sonarsource/rpg/api/checks/Check.html?com/sonarsource/rpg/api/checks/CheckContext.html) which is passed to the checks gives a reference to the `ModuleTree` of the analyzed source code. The whole tree structure can be navigated from that object.\n\nMost often, it\'s easier to extend `VisitorBasedCheck` and to override one or more methods which name starts with visit, e.g. `visitIfGroup`. That way, it\'s possible to define what should be executed when visiting some specific kinds of trees.\n\n#### Creating Issues\n\n[`CheckContext`](http://javadocs.sonarsource.org/rpg/apidocs/2.3/index.html?com/sonarsource/rpg/api/checks/Check.html?com/sonarsource/rpg/api/checks/CheckContext.html) provides methods to create issues either at file level or at line level.\n\n#### Testing the Rule\n\nIt\'s possible to write unit tests for custom rules using `com.sonarsource.rpg.api.test.RpgCheckVerifier`. This utility class executes a custom rule against a given RPG test file. The RPG test file should contain comments denoting lines where issues should be expected:\n\n- if the line ends with "// Noncompliant", `RpgCheckVerifier` expects an issue on that line.\n- if the line ends with "// Noncompliant {{my message}}", `RpgCheckVerifier` expects an issue on that line and checks that the issue message is "my message".\n\nThe example project contains an [example test class](https://github.com/SonarSource/sonar-custom-rules-examples/blob/master/rpg-custom-rules/src/test/java/com/sonarsource/rpg/example/checks/DataStructureNamingConventionCheckTest.java) and the [associated RPG file](https://github.com/SonarSource/sonar-custom-rules-examples/blob/master/rpg-custom-rules/src/test/resources/data-structure-name.rpg).\n\n### Rules Definition\n\nOne class should extend [`com.sonarsource.rpg.api.CustomRulesDefinition`](http://javadocs.sonarsource.org/rpg/apidocs/2.3/index.html?com/sonarsource/rpg/api/checks/Check.html?com/sonarsource/rpg/api/CustomRulesDefinition.html): it should list the classes of the custom rules and use the SonarQube API to define the metadata of these rules: name, HTML description, default severity...\n\n### Plugin Class\n\nThe entry point of the custom plugin is a class which lists SonarQube extensions. This list should contain the class created at the previous step.\n\n### Packaging the Custom Plugin\n\nTo package your custom plugin, the pom.xml should use `org.sonarsource.sonar-packaging-maven-plugin`, as described in the [documentation explaining how to build a plugin](/extend/developing-plugin/).\n\nIn the configuration for `sonar-packaging-maven-plugin`, basePlugin should be set to "rpg".\n\nBuilding the Maven project will produce a JAR file which can be deployed to a SonarQube server.\n'},{path:"analysis/languages/ruby",content:"---\ntitle: Ruby\nurl: /analysis/languages/ruby/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the Ruby-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > Ruby](/#sonarqube-admin#/admin/settings?category=ruby)**\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) (Rubocop)\n* [Test Coverage & Execution](/analysis/coverage/) (SimpleCov)\n"},{path:"analysis/languages/scala",content:"---\ntitle: Scala\nurl: /analysis/languages/scala/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the Scala-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > Scala](/#sonarqube-admin#/admin/settings?category=scala)**.\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) (Scalastyle or Scapegoat)\n* [Test Coverage & Execution](/analysis/coverage/) (Scoverage)\n"},{path:"analysis/languages/swift",content:"---\ntitle: Swift\nurl: /analysis/languages/swift/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the Swift-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > Swift](/#sonarqube-admin#/admin/settings?category=swift)**.\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) (Xcode A.K.A. ProfData)\n* [Test Coverage & Execution](/analysis/coverage/) (SwiftLint)\n"},{path:"analysis/languages/tsql",content:"---\ntitle: T-SQL\nurl: /analysis/languages/tsql/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the T-SQL-specific [properties](/analysis/analysis-parameters/) in:  \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > T-SQL](/#sonarqube-admin#/admin/settings?category=t-sql)**.\n\n## Important Note\nWith the default configuration, only files with the `.tsql` are analyzed as T-SQL, and files with the `.sql` file extension are analyzed as PL/SQL. This behavior is defined in \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > T-SQL > File Suffixes](/#sonarqube-admin#/admin/settings?category=t-sql)** and \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > PL/SQL > File Suffixes](/#sonarqube-admin#/admin/settings?category=pl%2Fsql)**. You can override these properties \x3c!-- sonarqube --\x3eeither at server level or\x3c!-- /sonarqube --\x3e at project level.\n\n"},{path:"analysis/languages/vb6",content:"---\ntitle: VB6\nurl: /analysis/languages/vb6/\n---\n\n_VB6 analysis is available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html)._\n\n\n## Language-Specific Properties\n\nYou can discover and update VB6-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > Visual Basic](/#sonarqube-admin#/admin/settings?category=visual+basic)**.\n"},{path:"analysis/languages/vbnet",content:"---\ntitle: VB.NET\nurl: /analysis/languages/vbnet/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the VB.NET-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e **[Administration > General Settings > VB.NET](/#sonarqube-admin#/admin/settings?category=vb.net)**\n\n### Analyze Generated Code\n\nTo analyze tool-generated code (e.g. WCF code generated by `SvcUtil.exe`) for a specific VB.NET project, enable the \"Analyze generated code\" setting inside **Project > Administration > General Settings > VB.NET**. By default, tool-generated code files are skipped from analysis.\n\n## Known Limitations\nCurrently an error will be thrown when an issue is raised on a line of code containing the following pattern `\\s+error\\s*:` (i.e. one or more spaces, the string 'error', zero or more spaces and a ':' ) . This is a well known problem on the Microsoft side (see [issue](https://github.com/dotnet/roslyn/issues/5724/)). In order to work around this problem, our analyzer will skip issues reported on any line where the pattern is detected.\n\n\n## Related Pages\n* [Importing External Issues](/analysis/external-issues/) (VSTest, NUnit, MSTest, xUnit)\n* [Test Coverage & Execution](/analysis/coverage/) (Visual Studio Code Coverage, dotCover, OpenCover, Coverlet, NCover 3)\n* [SonarScanner for MSBuild](/analysis/scan/sonarscanner-for-msbuild/)\n* [SonarScanner for Azure DevOps](/analysis/scan/sonarscanner-for-azure-devops/)\n"},{path:"analysis/languages/xml",content:"---\ntitle: XML\nurl: /analysis/languages/xml/\n---\n\n\n\n## Language-Specific Properties\n\nDiscover and update the XML-specific [properties](/analysis/analysis-parameters/) in: \x3c!-- sonarcloud --\x3eProject \x3c!-- /sonarcloud --\x3e**[Administration > General Settings > XML](/#sonarqube-admin#/admin/settings?category=xml)**\n\n\x3c!-- sonarqube --\x3e\n## Related Pages\n* [Adding Coding Rules](/extend/adding-coding-rules/)\n\x3c!-- /sonarqube --\x3e\n"},{path:"analysis/overview",content:"---\ntitle: Overview\nurl: /analysis/overview/\n---\n\nOnce the SonarQube platform has been installed, you're ready to install a scanner and begin creating projects. To do that, you must install and configure the scanner that is most appropriate for your needs. Do you build with:\n\n* Gradle - [SonarScanner for Gradle](/analysis/scan/sonarscanner-for-gradle/)\n* .NET - [SonarScanner for .NET](/analysis/scan/sonarscanner-for-msbuild/)\n* Maven - use the [SonarScanner for Maven](/analysis/scan/sonarscanner-for-maven/)\n* Jenkins - [SonarScanner for Jenkins](/analysis/scan/sonarscanner-for-jenkins/)\n* Azure DevOps - [SonarQube Extension for Azure DevOps](/analysis/scan/sonarscanner-for-azure-devops/)\n* Ant - [SonarScanner for Ant](/analysis/scan/sonarscanner-for-ant/)\n* anything else (CLI) - [SonarScanner](/analysis/scan/sonarscanner/)\n\n[[info]]\n| SonarQube integrations are supported for popular ALMs: GitHub Enterprise and GitHub.com, BitBucket Server, Azure Devops Server and Azure DevOps Services.\n\n[[warning]]\n| We do not recommend running an antivirus scanner on the machine where a SonarQube analysis runs, it could result in unpredictable behavior.\n\n\nA project is created in SonarQube automatically on its first analysis. However, if you need to set some configuration on your project before its first analysis, you have the option of provisioning it via Administration options or the **+** menu item, which is visible to users with project creation rights.\n\n\n## What does analysis produce? \nSonarQube can analyze up to 27 different languages depending on your edition. The outcome of this analysis will be quality measures and issues (instances where coding rules were broken). However, what gets analyzed will vary depending on the language:\n\n* On all languages, \"blame\" data will automatically be imported from supported SCM providers. [Git and SVN are supported automatically](/analysis/scm-integration/). Other providers require additional plugins.\n* On all languages, a static analysis of source code is performed (Java files, COBOL programs, etc.)\n* A static analysis of compiled code can be performed for certain languages (.class files in Java, .dll files in C#, etc.)\n\n\n## Will all files be analyzed?\nBy default, only files that are recognized by your edition of SonarQube are loaded into the project during analysis. \nFor example if you're using SonarQube Community Edition, which includes analysis of Java and JavaScript, but not C++, all `.java` and `.js` files would be loaded, but `.cpp` files would be ignored.\n\n## What about branches and pull requests?\n_Developer Edition_ adds the ability to analyze your project's [branches](/branches/overview/) and [pull requests](/analysis/pull-request/) as well as the ability to automatically decorate pull requests in some ALM interfaces. \n\n## What happens during analysis?\nDuring analysis, data is requested from the server, the files provided to the analysis are analyzed, and the resulting data is sent back to the server at the end in the form of a report, which is then analyzed asynchronously server-side.\n\nAnalysis reports are queued, and processed sequentially, so it is quite possible that for a brief period after your analysis log shows completion, the updated values are not visible in your {instance} project. However, you will be able to tell what's going on because an icon will be added on the project homepage to the right of the project name. Mouse over it for more detail (and links if you're logged in with the proper permissions).\n\n![background task processing in progress.](/images/backgroundTaskProcessingInProgress.jpeg)\n\n\nThe icon goes away once processing is complete, but if analysis report processing fails for some reason, the icon changes:\n\n![background task processing failed.](/images/backgroundTaskProcessingFailedIcon.jpeg)\n\n\n## FAQ\n\n**Q.** Analysis errors out with `java.lang.OutOfMemoryError: GC overhead limit exceeded`. What do I do?  \n**A.** This means your project is too large or too intricate for the scanner to analyze with the default memory allocation. To fix this you'll want to allocate a larger heap (using `-Xmx[numeric value here]`) to the process running the analysis. Some CI engines may give you an input to specify the necessary values, for instance if you're using a Maven Build Step in a Jenkins job to run analysis. Otherwise, use Java Options to set a higher value. Note that details of setting Java Options are omitted here because they vary depending on the environment.\n\n**Q.** Analysis errors out with `PKIX path building failed`. What do I do? \n**A.** This error tells you that your SonarQube server is configured with HTTPS and a custom SSL certificate. However, the certificate is not correctly configured in the scanner machine’s JVM. This configuration is outside of SonarQube scope. The server certificate is unknown and could not be validated with the provided truststore. You need to add the SonarQube server certificate to the Java truststore. See [Oracle's documentation](https://docs.oracle.com/cd/E19830-01/819-4712/ablqw/index.html) for more information."},{path:"analysis/pull-request",content:"---\ntitle: Pull Request Analysis\nurl: /analysis/pull-request/\n---\n\n_Pull Request analysis is available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)._\n\nYou can see your Pull Requests in SonarQube from the Branches and Pull Requests dropdown menu of your project.  \n\nPull Request analysis shows your Pull Request's Quality Gate and analysis in the SonarQube interface. This analysis shows new issues introduced by the Pull Request before merging with the target branch:\n\n![Pull Request Analysis.](/images/pranalysis.png)\n\n## Prerequisites\n\nBefore analyzing your Pull Requests, make sure the Pull Request branch is checked out. Avoid any attempt at previewing the merge or actions involving your main branch.\n\n## Pull request decoration\nYou can also add pull request decoration that shows the Pull Request analysis and Quality Gate directly in your ALM's interface. To set up pull request decoration, see the ALM integration page that corresponds with your ALM:\n- [GitHub Enterprise and GitHub.com](/analysis/github-integration/)\n- [GitLab Self-Managed and GitLab.com](/analysis/gitlab-integration/)\n- [Bitbucket Server](/analysis/bitbucket-integration/)\n- [Azure DevOps](/analysis/azuredevops-integration/)\n\n[[info]]\n| To decorate Pull Requests, a SonarQube analysis needs to be run on your code. You can find the additional parameters required for Pull Request analysis below in the **Analysis parameters** section.\n\n## Pull request Quality Gate\n\nA [Quality Gate](/user-guide/quality-gates/) lets you ensure you are meeting your organization's quality policy and that you can merge your pull request. The pull request uses your project Quality Gate as follows:\n* **Focuses on new code** – The Pull Request quality gate only uses your project's quality gate conditions that apply to \"on New Code\" metrics.\n* **Assigns a status** – Each Pull Request shows a quality gate status reflecting whether it Passed or Failed.\n\nPull request analyses on SonarQube are deleted automatically after 30 days with no analysis. This can be updated in **Administration > Configuration > General Settings > Housekeeping > Number of days before purging inactive branches**. \n\n## Analysis parameters\n\nThe following parameters enable PR analysis.\n\n[[info]]\n| Scanners running on Jenkins with the Branch Source plugin configured, GitLab CI/CD, Bitbucket Pipelines, Azure Pipelines, and Cirrus CI automatically detect these parameters, and you don't need to pass them manually.\n\n| Parameter Name        | Description |\n| --------------------- | ---------------------------------- |\n| `sonar.pullrequest.key` | Unique identifier of your Pull Request. Must correspond to the key of the Pull Request in your ALM.<br/> e.g.: `sonar.pullrequest.key=5` |\n| `sonar.pullrequest.branch` | The name of the branch that contains the changes to be merged.<br/> e.g.: `sonar.pullrequest.branch=feature/my-new-feature` |\n| `sonar.pullrequest.base` | The branch into which the Pull Request will be merged. <br/> Default: master <br/> e.g.: `sonar.pullrequest.base=master` |"},{path:"analysis/scan/sonarscanner-for-ant",content:'---\ntitle: SonarScanner for Ant\nurl: /analysis/scan/sonarscanner-for-ant/\n---\n\n\x3c!-- static --\x3e\n<update-center updatecenterkey="scannerant"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner-ant.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\nThe SonarScanner for Ant provides a `task` to allow integration of SonarQube analysis into an Apache Ant build script.\n\nThe SonarScanner for Ant is an Ant Task that is a wrapper of [SonarScanner](/analysis/scan/sonarscanner/), which works by invoking SonarScanner and passing to it all [properties](/analysis/analysis-parameters/) named following a `sonar.*` convention. This has the downside of not being very Ant-y, but the upside of providing instant availability of any new analysis parameter introduced by a new version of SonarQube. Therefore, successful use of the SonarScanner for Ant requires strict adherence to the property names shown below.\n\n## Using the SonarScanner for Ant\nDefine a new sonar Ant target in your Ant build script:\n```\n\x3c!-- build.xml --\x3e\n<project name="My Project" default="all" basedir="." xmlns:sonar="antlib:org.sonar.ant">\n...\n  \n\x3c!-- Define the SonarQube global properties (the most usual way is to pass these properties via the command line) --\x3e\n<property name="sonar.host.url" value="http://localhost:9000" />\n \n...\n  \n\x3c!-- Define the SonarQube project properties --\x3e\n<property name="sonar.projectKey" value="org.sonarqube:sonarqube-scanner-ant" />\n<property name="sonar.projectName" value="Example of SonarScanner for Ant Usage" />\n<property name="sonar.projectVersion" value="1.0" />\n<property name="sonar.sources" value="src" />\n<property name="sonar.java.binaries" value="build" />\n<property name="sonar.java.libraries" value="lib/*.jar" />\n...\n \n\x3c!-- Define SonarScanner for Ant Target --\x3e\n<target name="sonar">\n    <taskdef uri="antlib:org.sonar.ant" resource="org/sonar/ant/antlib.xml">\n        \x3c!-- Update the following line, or put the "sonarqube-ant-task-*.jar" file in your "$HOME/.ant/lib" folder --\x3e\n        <classpath path="path/to/sonar/ant/task/lib/sonarqube-ant-task-*.jar" />\n    </taskdef>\n \n    \x3c!-- Execute SonarScanner for Ant Analysis --\x3e\n    <sonar:sonar />\n</target>\n```\n\nRun the following command from the project base directory to launch the analysis. You need to pass an [authentication token](/user-guide/user-token/) using the `sonar.login` property in your command line:\n```\nant sonar -Dsonar.login=yourAuthenticationToken\n```\n\n## Sample Project\nTo help you get started, a simple project sample is available here: https://github.com/SonarSource/sonar-scanning-examples/tree/master/sonarqube-scanner-ant\n\n## Troubleshooting\n**Enable Debug Logs**  \nTo enable debug logs, use the regular Ant verbose option: `-v`\n```\nant sonar -v\n```\n'},{path:"analysis/scan/sonarscanner-for-azure-devops",content:'---\ntitle: SonarScanner for Azure DevOps\nurl: /analysis/scan/sonarscanner-for-azure-devops/\n---\n\n\x3c!-- static --\x3e\n<update-center updatecenterkey="scannerazure"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner-azure.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\nThe [SonarScanner for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarqube) makes it easy to integrate analysis into your build pipeline. The extension allows the analysis of all languages supported by SonarQube.\n\n## Compatibility\nThe SonarScanner for Azure DevOps is compatible with:\n* TFS 2017 Update 2+\n* TFS 2018\n* Azure DevOps Server 2019\n* Azure DevOps Server 2020\n* Azure DevOps Services\n\n## Analysis\nFor information on setting up analysis with the SonarScanner for Azure DevOps, see the [Azure DevOps ALM integration](/analysis/azuredevops-integration/) page.\n'},{path:"analysis/scan/sonarscanner-for-gradle",content:'---\ntitle: SonarScanner for Gradle\nurl: /analysis/scan/sonarscanner-for-gradle/\n---\n\n\x3c!-- static --\x3e\n<update-center updatecenterkey="scannergradle"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner-gradle.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\nThe SonarScanner for Gradle provides an easy way to start SonarQube analysis of a Gradle project.\n\nThe ability to execute the SonarQube analysis via a regular Gradle task makes it available anywhere Gradle is available (developer build, CI server, etc.), without the need to manually download, setup, and maintain a SonarQube Runner installation. The Gradle build already has much of the information needed for SonarQube to successfully analyze a project. By preconfiguring the analysis based on that information, the need for manual configuration is reduced significantly. \n\n## Prerequisites\n* Gradle versions 3+\n* At least the minimal version of Java supported by your SonarQube server is in use \n\nBytecode created by javac compilation is required for Java analysis, including Android projects.\n\n## Configure the Scanner\nInstallation is automatic, but certain global properties should still be configured. A good place to configure global properties is `~/.gradle/gradle.properties`. Be aware that the scanner uses system properties so all properties should be prefixed by `systemProp`. \n\n```\n# gradle.properties\nsystemProp.sonar.host.url=http://localhost:9000\n```\n\n## Analyzing\nFirst, include the scanner in your build in `build.gradle`:\n\n```\nplugins {\n  id "org.sonarqube" version "3.2.0"\n}\n```\n\nMore details on https://plugins.gradle.org/plugin/org.sonarqube\n\nAssuming a local SonarQube server with out-of-the-box settings is up and running, no further configuration is required.\n\nYou need to pass an [authentication token](/user-guide/user-token/) using the `sonar.login` property in your command line or you configure it as part of your `gradle.properties` file. Execute `gradle sonarqube -Dsonar.login=yourAuthenticationToken` and wait until the build has completed, then open the web page indicated at the bottom of the console output. You should now be able to browse the analysis results. \n\n## Analyzing Multi-Project Builds\nTo analyze a project hierarchy, apply the SonarQube plugin to the root project of the hierarchy. Typically (but not necessarily) this will be the root project of the Gradle build. Information pertaining to the analysis as a whole has to be configured in the sonarqube block of this project. Any properties set on the command line also apply to this project.\n\n```\n// build.gradle\nsonarqube {\n    properties {\n        property "sonar.sourceEncoding", "UTF-8"\n    }\n}\n```\n\nConfiguration shared between subprojects can be configured in a subprojects block.\n```\n// build.gradle\nsubprojects {\n    sonarqube {\n        properties {\n            property "sonar.sources", "src"\n        }\n    }\n}\n```\n\nProject-specific information is configured in the `sonarqube` block of the corresponding project.\n```\n// build.gradle\nproject(":project1") {\n    sonarqube {\n        properties {\n            property "sonar.branch", "Foo"\n        }\n    }}\n```\n\nTo skip SonarQube analysis for a particular subproject, set sonarqube.skipProject to true.\n```\n// build.gradle\nproject(":project2") {\n    sonarqube {\n        skipProject = true\n    }\n}\n```\n\n## Task dependencies\nAll tasks that produce output that should be included in the SonarQube analysis need to be executed before the `sonarqube` task runs. Typically, these are compile tasks, test tasks, and code coverage tasks. \n\nStarting with v3.0 of the SonarScanner for Gradle, task dependencies are no longer added automatically. Instead, the SonarScanner plugin enforces the correct order of tasks with `mustRunAfter`. You need to be either manually run the tasks that produce output before `sonarqube`, or you can add a dependency to the build script: \n\n```\n// build.gradle\nproject.tasks["sonarqube"].dependsOn "anotherTask"\n```\n\n## Sample project\nA simple working example is available at this URL so you can check everything is correctly configured in your env:  \nhttps://github.com/SonarSource/sonar-scanning-examples/tree/master/sonarqube-scanner-gradle\n\n\n## Analysis property defaults\nThe SonarScanner for Gradle uses information contained in Gradle\'s object model to provide smart defaults for most of the standard [analysis parameters](/analysis/analysis-parameters/), as listed below.\n\nGradle defaults for standard SonarQube properties: \n\nProperty|Gradle default\n---|---\n`sonar.projectKey`|`[${project.group}:]${project.name}` for root module; `<root module key>:<module path>` for submodules \n`sonar.projectName`|`${project.name}`\n`sonar.projectDescription`|`${project.description}`\n`sonar.projectVersion`|`${project.version}`\n`sonar.projectBaseDir`|`${project.projectDir}`\n`sonar.working.directory`|`${project.buildDir}/sonar`\n\nNotice that additional defaults are provided for projects that have the java-base or java plugin applied:\n\nProperty|Gradle default\n---|---\n`sonar.sourceEncoding`|`${project.compileJava.options.encoding}`\n`sonar.java.source`|`${project.sourceCompatibility}`\n`sonar.java.target`|`${project.targetCompatibility}`\n`sonar.sources`|`${sourceSets.main.allJava.srcDirs}` (filtered to only include existing directories)\n`sonar.tests`|`${sourceSets.test.allJava.srcDirs}` (filtered to only include existing directories)\n`sonar.java.binaries`|`${sourceSets.main.output.classesDir}`\n`sonar.java.libraries`|`${sourceSets.main.compileClasspath}` (filtering to only include files; rt.jar and jfxrt.jar added if necessary)\n`sonar.java.test.binaries`|`${sourceSets.test.output.classesDir}`\n`sonar.java.test.libraries`|`${sourceSets.test.compileClasspath}` (filtering to only include files; rt.jar and jfxrt.jar added if necessary)\n`sonar.junit.reportPaths`|`${test.testResultsDir}` (if the directory exists)\n\nGroovy projects get all the Java defaults, plus:\n\nProperty|Gradle default\n---|---\n`sonar.groovy.binaries`|`${sourceSets.main.output.classesDir}`\n\n\nAdditional defaults when JaCoCo plugin is applied\n\nProperty|Gradle default\n---|---\n`sonar.jacoco.reportPaths`|`${jacoco.destinationFile}`\n`sonar.groovy.jacoco.reportPath`|`${jacoco.destinationFile}`\n\nAdditional defaults for Android projects (`com.android.application`, `com.android.library`, or `com.android.test`)\nBy default the first variant of type "debug" will be used to configure the analysis. You can override the name of the variant to be used using the parameter \'androidVariant\':\n \n```\nbuild.gradle\nsonarqube {\n    androidVariant \'fullDebug\'\n}\n```\n\nProperty|\tGradle default\n---|---\n`sonar.sources` (for non test variants)|`${variant.sourcesets.map}` (ManifestFile/CDirectories/AidlDirectories/AssetsDirectories/CppDirectories/JavaDirectories/RenderscriptDirectories/ResDirectories/ResourcesDirectories)\n`sonar.tests` (for test variants)|`${variant.sourcesets.map}` (ManifestFile/CDirectories/AidlDirectories/AssetsDirectories/CppDirectories/JavaDirectories/RenderscriptDirectories/ResDirectories/ResourcesDirectories)\n`sonar.java[.test].binaries`|`${variant.destinationDir}`\n`sonar.java[.test].libraries`|`${variant.javaCompile.classpath} + ${bootclasspath}`\n`sonar.java.source`|`${variant.javaCompile.sourceCompatibility}`\n`sonar.java.target`|`${variant.javaCompile.targetCompatibility}`\n\n\n## Passing manual properties / overriding defaults\nThe SonarScanner for Gradle adds a SonarQubeExtension extension to project and its subprojects, which allows you to configure/override the analysis properties.\n```\n// in build.gradle\nsonarqube {\n    properties {\n        property "sonar.exclusions", "**/*Generated.java"\n    }\n}\n```\nSonarQube properties can also be set from the command line, or by setting a system property named exactly like the SonarQube property in question. This can be useful when dealing with sensitive information (e.g. credentials), environment information, or for ad-hoc configuration.\n \n```\ngradle sonarqube -Dsonar.host.url=http://sonar.mycompany.com -Dsonar.verbose=true\n```\n\nWhile certainly useful at times, we recommend keeping the bulk of the configuration in a (versioned) build script, readily available to everyone.\nA SonarQube property value set via a system property overrides any value set in a build script (for the same property). When analyzing a project hierarchy, values set via system properties apply to the root project of the analyzed hierarchy. Each system property starting with `sonar.` will be taken into account.\n\n\n\n### Analyzing Custom Source Sets\nBy default, the SonarScanner for Gradle passes on the project\'s main source set as production sources, and the project\'s test source set as test sources. This works regardless of the project\'s source directory layout. Additional source sets can be added as needed.\n\n```\n// build.gradle\nsonarqube {\n    properties {\n        properties["sonar.sources"] += sourceSets.custom.allSource.srcDirs\n        properties["sonar.tests"] += sourceSets.integTest.allSource.srcDirs\n    }\n}\n```\n\n## Advanced topics\n### More on configuring SonarQube properties\nLet\'s take a closer look at the `sonarqube.properties` `{}` block. As we have already seen in the examples, the `property()` method allows you to set new properties or override existing ones. Furthermore, all properties that have been configured up to this point, including all properties preconfigured by Gradle, are available via the properties accessor.\n\nEntries in the properties map can be read and written with the usual Groovy syntax. To facilitate their manipulation, values still have their “idiomatic” type (File, List, etc.). After the sonarProperties block has been evaluated, values are converted to Strings as follows: Collection values are (recursively) converted to comma-separated Strings, and all other values are converted by calling their `toString()` methods.\n\nBecause the `sonarProperties` block is evaluated lazily, properties of Gradle\'s object model can be safely referenced from within the block, without having to fear that they have not yet been set.\n\n'},{path:"analysis/scan/sonarscanner-for-jenkins",content:"---\ntitle: SonarScanner for Jenkins\nurl: /analysis/scan/sonarscanner-for-jenkins/\n---\n\n\x3c!-- static --\x3e\n<update-center updatecenterkey=\"scannerjenkins\"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner-jenkins.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\nThis plugin lets you centralize the configuration of SonarQube server connection details in Jenkins global configuration.\n\nThen you can trigger SonarQube analysis from Jenkins using standard Jenkins Build Steps or [Jenkins Pipeline DSL](https://jenkins.io/solutions/pipeline/) to trigger analysis with:\n\n* [SonarScanner](/analysis/scan/sonarscanner/)\n* [SonarScanner for Maven](/analysis/scan/sonarscanner-for-maven/)\n* [SonarScanner for Gradle](/analysis/scan/sonarscanner-for-gradle/)\n* [SonarScanner for .NET](/analysis/scan/sonarscanner-for-msbuild/)\n\nOnce the job is complete, the plugin will detect that a SonarQube analysis was made during the build and display a badge and a widget on the job page with a link to the SonarQube dashboard as well as quality gate status.\n\n## Installation\n1. [Install the SonarScanner for Jenkins via the Jenkins Update Center](https://plugins.jenkins.io/sonar).\n1. Configure your SonarQube server(s):\n   1. Log into Jenkins as an administrator and go to **Manage Jenkins > Configure System**.\n   1. Scroll down to the SonarQube configuration section, click **Add SonarQube**, and add the values you're prompted for.\n   1. The server [authentication token](/user-guide/user-token/) should be created as a 'Secret Text' credential.\n\n## Analyzing a .NET solution\n**Global Configuration**  \nThis step is mandatory if you want to trigger any of your analyses with the SonarScanner for .NET. You can define as many scanner instances as you wish. Then for each Jenkins job, you will be able to choose which launcher to use to run the SonarQube analysis.\n1. Log into Jenkins as an administrator and go to **Manage Jenkins > Global Tool Configuration**\n1. Click on **Add SonarScanner for MSBuild**\n1. Add an installation of the latest available version. Check **Install automatically** to have the SonarScanner for MSBuild automatically provisioned on your Jenkins executors\n\nIf you do not see any available version under Install from GitHub, first go to Manage Jenkins > Manage Plugins > Advanced and click on Check now\n\n**Job Configuration**  \n1. Configure the project, and go to the **Build** section.\n1. Add the SonarQube for MSBuild - Begin Analysis to your build\n1. Configure the SonarQube Project Key, Name, and Version in the SonarScanner for MSBuild - Begin Analysis build step\n1. Add the MSBuild build step or the Execute Windows batch command to execute the build with MSBuild 14 (see compatibility) to your build.\n1. Add the SonarQube for MSBuild - End Analysis build steps to your build\n\n## Analyzing a Java project with Maven or Gradle\n**Global Configuration**  \n1. Log into Jenkins as an administrator and go to Manage Jenkins > Configure System\n1. Scroll to the SonarQube servers section and check Enable injection of SonarQube server configuration as build environment variables\n\n**Job Configuration**  \n1. **Configure** the project, and go to the **Build Environment** section.\n1. Enable **Prepare SonarScanner environment** to allow the injection of SonarQube server values into this particular job. If multiple SonarQube instances are configured, you will be able to choose which one to use.\nOnce the environment variables are available, use them in a standard Maven build step (Invoke top-level Maven targets) by setting the Goals to include, or a standard Gradle build step (Invoke Gradle script) by setting the Tasks to execute.\n\nMaven goal:\n```\n$SONAR_MAVEN_GOAL\n```\nGradle task:\n```\nsonarqube\n```\n\nIn both cases, launching your analysis may require authentication. In that case, make sure that the Global Configuration defines a valid SonarQube token.\n\n## Analyzing other project types\n\n**Global Configuration**  \nThis step is mandatory if you want to trigger any of your SonarQube analyses with the SonarScanner. You can define as many scanner instances as you wish. Then for each Jenkins job, you will be able to choose which launcher to use to run the SonarQube analysis.\n\n1. Log into Jenkins as an administrator and go to **Manage Jenkins > Global Tool Configuration**\n1. Scroll down to the SonarScanner configuration section and click on Add SonarScanner. It is based on the typical Jenkins tool auto-installation. You can either choose to point to an already installed version of SonarScanner (uncheck 'Install automatically') or tell Jenkins to grab the installer from a remote location (check 'Install automatically')\n\nIf you don't see a drop-down list with all available SonarScanner versions but instead see an empty text field then this is because Jenkins still hasn't downloaded the required update center file (default period is 1 day). You may force this refresh by clicking the 'Check Now' button in Manage Plugins > Advanced tab.\n\n**Job Configuration**  \n1. **Configure** the project, and go to the **Build** section. \n1. Add the SonarScanner build step to your build.\n1. Configure the SonarQube analysis properties. You can either point to an existing sonar-project.properties file or set the analysis properties directly in the **Analysis properties** field\n\n\n\n## Using a Jenkins pipeline\nWe provide a `withSonarQubeEnv` block that allows you to select the SonarQube server you want to interact with. Connection details you have configured in Jenkins global configuration will be automatically passed to the scanner.\n\nIf needed you can override the `credentialId` if you don't want to use the one defined in global configuration (for example if you define credentials at folder level).\n\nIf you only need the SonarQube environment variables to be expanded in the build context then you can override the `envOnly` flag.\n```\nwithSonarQubeEnv('My SonarQube Server', envOnly: true) {\n  // This expands the evironment variables SONAR_CONFIG_NAME, SONAR_HOST_URL, SONAR_AUTH_TOKEN that can be used by any script.\n  println ${env.SONAR_HOST_URL} \n}\n```\n\nHere are some examples for every scanner, assuming you run on Unix slaves and you have configured a server named \"My SonarQube Server\" as well as required tools. If you run on Windows slaves, just replace `sh` with `bat`.\n\nSonarScanner:\n```\nnode {\n  stage('SCM') {\n    git 'https://github.com/foo/bar.git'\n  }\n  stage('SonarQube analysis') {\n    def scannerHome = tool 'SonarScanner 4.0';\n    withSonarQubeEnv('My SonarQube Server') { // If you have configured more than one global server connection, you can specify its name\n      sh \"${scannerHome}/bin/sonar-scanner\"\n    }\n  }\n}\n```\nSonarScanner for Gradle:\n```\nnode {\n  stage('SCM') {\n    git 'https://github.com/foo/bar.git'\n  }\n  stage('SonarQube analysis') {\n    withSonarQubeEnv() { // Will pick the global server connection you have configured\n      sh './gradlew sonarqube'\n    }\n  }\n}\n```\nSonarScanner for Maven:\n```\nnode {\n  stage('SCM') {\n    git 'https://github.com/foo/bar.git'\n  }\n  stage('SonarQube analysis') {\n    withSonarQubeEnv(credentialsId: 'f225455e-ea59-40fa-8af7-08176e86507a', installationName: 'My SonarQube Server') { // You can override the credential to be used\n      sh 'mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.7.0.1746:sonar'\n    }\n  }\n}\n```\nSonarScanner for .NET:\n```\nnode {\n  stage('SCM') {\n    git 'https://github.com/foo/bar.git'\n  }\n  stage('Build + SonarQube analysis') {\n    def sqScannerMsBuildHome = tool 'Scanner for MSBuild 4.6'\n    withSonarQubeEnv('My SonarQube Server') {\n      bat \"${sqScannerMsBuildHome}\\\\SonarQube.Scanner.MSBuild.exe begin /k:myKey\"\n      bat 'MSBuild.exe /t:Rebuild'\n      bat \"${sqScannerMsBuildHome}\\\\SonarQube.Scanner.MSBuild.exe end\"\n    }\n  }\n}\n```\n\n## Pause pipeline until the Quality Gate is computed\nThe `waitForQualityGate` step will pause the pipeline until SonarQube analysis is completed and returns Quality Gate status.\n\n### Pre-requisites:\n* Configure a webhook in your SonarQube server pointing to `<your Jenkins instance>/sonarqube-webhook/` \n* Use `withSonarQubeEnv` step in your pipeline (so that SonarQube taskId is correctly attached to the pipeline context).\n\n\nScripted pipeline example:\n```\nnode {\n  stage('SCM') {\n    git 'https://github.com/foo/bar.git'\n  }\n  stage('SonarQube analysis') {\n    withSonarQubeEnv('My SonarQube Server') {\n      sh 'mvn clean package sonar:sonar'\n    } // submitted SonarQube taskId is automatically attached to the pipeline context\n  }\n}\n  \n// No need to occupy a node\nstage(\"Quality Gate\"){\n  timeout(time: 1, unit: 'HOURS') { // Just in case something goes wrong, pipeline will be killed after a timeout\n    def qg = waitForQualityGate() // Reuse taskId previously collected by withSonarQubeEnv\n    if (qg.status != 'OK') {\n      error \"Pipeline aborted due to quality gate failure: ${qg.status}\"\n    }\n  }\n}\n```\nThanks to the webhook, the step is implemented in a very lightweight way: no need to occupy a node doing polling, and it doesn't prevent Jenkins to restart (step will be restored after restart). Note that to prevent race conditions, when the step starts (or is restarted) a direct call is made to the server to check if the task is already completed.\n\nDeclarative pipeline example:\n```\npipeline {\n    agent any\n    stages {\n        stage('SCM') {\n            steps {\n                git url: 'https://github.com/foo/bar.git'\n            }\n        }\n        stage('build && SonarQube analysis') {\n            steps {\n                withSonarQubeEnv('My SonarQube Server') {\n                    // Optionally use a Maven environment you've configured already\n                    withMaven(maven:'Maven 3.5') {\n                        sh 'mvn clean package sonar:sonar'\n                    }\n                }\n            }\n        }\n        stage(\"Quality Gate\") {\n            steps {\n                timeout(time: 1, unit: 'HOURS') {\n                    // Parameter indicates whether to set pipeline to UNSTABLE if Quality Gate fails\n                    // true = set pipeline to UNSTABLE, false = don't\n                    waitForQualityGate abortPipeline: true\n                }\n            }\n        }\n    }\n}\n```\n\nIf you want to run multiple analysis in the same pipeline and use waitForQualityGate you have to do everything in order:\n```\npipeline {\n    agent any\n    stages {\n        stage('SonarQube analysis 1') {\n            steps {\n                sh 'mvn clean package sonar:sonar'\n            }\n        }\n        stage(\"Quality Gate 1\") {\n            steps {\n                waitForQualityGate abortPipeline: true\n            }\n        }\n        stage('SonarQube analysis 2') {\n            steps {\n                sh 'gradle sonarqube'\n            }\n        }\n        stage(\"Quality Gate 2\") {\n            steps {\n                waitForQualityGate abortPipeline: true\n            }\n        }\n    }\n}\n```\n\n### Configuring a webhook secret\n\nIf you want to verify the webhook payload that is sent to Jenkins, you can add a secret to your webhook on SonarQube.\n\nTo set the secret: \n\n1. In Jenkins, navigate to **Manage Jenkins > Configure System > SonarQube Server > Advanced > Webhook Secret** and click the **Add** button.\n1. Select **Secret text** and give the secret an ID.\n1. Select the secret from the dropdown menu.\n\nIf you want to override the webhook secret on a project level, you can add the secret to Jenkins and then reference the secret ID when calling `waitForQualityGate`.\n\n    waitForQualityGate(webhookSecretId: 'yourSecretID')    \nif your pipeline is declarative or\n\n    waitForQualityGate webhookSecretId: 'yourSecretID'\nif your pipeline is scripted.\n"},{path:"analysis/scan/sonarscanner-for-maven",content:'---\ntitle: SonarScanner for Maven\nurl: /analysis/scan/sonarscanner-for-maven/\n---\n\n\x3c!-- static --\x3e\n<update-center updatecenterkey="scannermaven"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner-maven.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\nThe SonarScanner for Maven is recommended as the default scanner for Maven projects.\n\nThe ability to execute the SonarQube analysis via a regular Maven goal makes it available anywhere Maven is available (developer build, CI server, etc.), without the need to manually download, setup, and maintain a SonarQube Runner installation. The Maven build already has much of the information needed for SonarQube to successfully analyze a project. By preconfiguring the analysis based on that information, the need for manual configuration is reduced significantly. \n\n## Prerequisites\n* Maven 3.x\n* At least the minimal version of Java supported by your SonarQube server is in use \n\n## Global Settings \n\nEdit the [settings.xml](http://maven.apache.org/settings.html) file, located in `$MAVEN_HOME/conf` or `~/.m2`, to set the plugin prefix and optionally the SonarQube server URL.\n\nExample:\n```\n<settings>\n    <pluginGroups>\n        <pluginGroup>org.sonarsource.scanner.maven</pluginGroup>\n    </pluginGroups>\n    <profiles>\n        <profile>\n            <id>sonar</id>\n            <activation>\n                <activeByDefault>true</activeByDefault>\n            </activation>\n            <properties>\n                \x3c!-- Optional URL to server. Default value is http://localhost:9000 --\x3e\n                <sonar.host.url>\n                  http://myserver:9000\n                </sonar.host.url>\n            </properties>\n        </profile>\n     </profiles>\n</settings>\n```\n\n## Analyzing\nAnalyzing a Maven project consists of running a Maven goal: `sonar:sonar` from the directory that holds the main project `pom.xml`. You need to pass an [authentication token](/user-guide/user-token/) using the `sonar.login` property in your command line.\n\n```\nmvn clean verify sonar:sonar -Dsonar.login=myAuthenticationToken\n```\n\nIn some situations you may want to run the `sonar:sonar` goal as a dedicated step. Be sure to use `install` as first step for multi-module projects\n```\nmvn clean install\nmvn sonar:sonar -Dsonar.login=myAuthenticationToken\n```\n\nTo specify the version of sonar-maven-plugin instead of using the latest:\n```\nmvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.7.0.1746:sonar\n```\n\nTo get coverage information, you\'ll need to generate the coverage report before the analysis. \n\n## Configuring Analysis\nMost analysis properties will be read from your project. If you would like override the default values of specify additional parameters, configure the parameter names found on the [Analysis Parameters](/analysis/analysis-parameters/) page in the `<properties>` section of your pom.xml like this:\n```\n<properties>\n  <sonar.buildString> [...] </sonar.buildString>\n</properties>\n ```\n\n## Sample Project\nTo help you get started, a simple project sample is available here: https://github.com/SonarSource/sonar-scanning-examples/tree/master/sonarqube-scanner-maven\n\n## Excluding a module from analysis\n* define property `<sonar.skip>true</sonar.skip>` in the `pom.xml` of the module you want to exclude\n* use build profiles to exclude some module (like for integration tests)\n* use Advanced Reactor Options (such as "-pl"). For example `mvn sonar:sonar -pl !module2`\n\n## How to Fix Version of Maven Plugin\nIt is recommended to lock down versions of Maven plugins:\n```\n<build>\n  <pluginManagement>\n    <plugins>\n      <plugin>\n        <groupId>org.sonarsource.scanner.maven</groupId>\n        <artifactId>sonar-maven-plugin</artifactId>\n        <version>3.7.0.1746</version>\n      </plugin>\n    </plugins>\n  </pluginManagement>\n</build>\n```\n\n## Troubleshooting\n**If you get a java.lang.OutOfMemoryError**  \nSet the `MAVEN_OPTS` environment variable, like this in *nix environments:\n```\nexport MAVEN_OPTS="-Xmx512m"\n```\nIn Windows environments, avoid the double-quotes, since they get misinterpreted.\n```\nset MAVEN_OPTS=-Xmx512m\n```\n'},{path:"analysis/scan/sonarscanner-for-msbuild",content:'---\nurl: /analysis/scan/sonarscanner-for-msbuild/\ntitle: SonarScanner for .NET\n---\n\n\x3c!-- sonarqube --\x3e\n\x3c!-- static --\x3e\n<update-center updatecenterkey="scannermsbuild"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner-msbuild.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\x3c!-- /sonarqube --\x3e\n\n\x3c!-- sonarcloud --\x3e\n[[info]]\n| **Download SonarScanner for .NET 5.2.0** - [Issue Tracker](https://github.com/SonarSource/sonar-scanner-msbuild/issues) - [Source](https://github.com/SonarSource/sonar-scanner-msbuild)\n|\n| [Standalone executables](https://github.com/SonarSource/sonar-scanner-msbuild/releases/tag/5.2.0.29862) |\n| [.NET Core Global Tool](https://www.nuget.org/packages/dotnet-sonarscanner)\n\x3c!-- /sonarcloud --\x3e\n\n[[info]]\n| Since version 5.0, the SonarScanner for MSBuild is now the SonarScanner for .NET. \n| Documentation is updated with that new name, artifacts and links will remain with the old name for now.\n\nThe SonarScanner for .NET is the recommended way to launch an analysis for projects/solutions using MSBuild or dotnet command as a build tool. It is the result of a [collaboration between SonarSource and Microsoft](https://www.sonarqube.org/announcing-sonarqube-integration-with-msbuild-and-team-build/).\n\nSonarScanner for .NET is distributed as a standalone command line executable, as an extension for \x3c!-- sonarcloud --\x3e[Azure DevOps](/analysis/scan/sonarscanner-for-azure-devops/)\x3c!-- /sonarcloud --\x3e\x3c!-- sonarqube --\x3e[Azure DevOps Server](/analysis/scan/sonarscanner-for-azure-devops/)\x3c!-- /sonarqube --\x3e, and as a plugin for [Jenkins](/analysis/scan/sonarscanner-for-jenkins/).\n\nIt supports .Net Core on every platform (Windows, macOS, Linux).\n\n## Prerequisites\n\x3c!-- sonarqube --\x3e\n* At least the minimal version of Java supported by your SonarQube server\n\x3c!-- /sonarqube --\x3e\n\x3c!-- sonarcloud --\x3e\n* Java 11 or greater\n\x3c!-- /sonarcloud --\x3e\n* The SDK corresponding to your build system:\n   * [.NET Framework v4.6](https://www.microsoft.com/en-us/download/details.aspx?id=53344) - either [Build Tools for Visual Studio 2015 Update 3](https://go.microsoft.com/fwlink/?LinkId=615458) or the [Build Tools for Visual Studio 2017](https://www.visualstudio.com/downloads/)\n   * [.NET Core SDK 2.0 and above](https://dotnet.microsoft.com/download) (for .NET Core version of the scanner or if you plan to use [.NET Core Global Tool](https://www.nuget.org/packages/dotnet-sonarscanner)\n\n[[info]]\n| The flavor used to compile the Scanner for .NET (either .NET Framework, .NET Core or .NET) is independent of the .NET version the \n| project you want to analyze has been built with. Concretely, you can analyze .NET Core code with the .NET Framework version of \n| the Scanner. It\'s only relevant depending on your OS, and on the versions of .NET SDKs that are installed on your build machine.\n\n\x3c!-- sonarqube --\x3e\n### Compatibility\n\nScanner Version|SonarQube\n---|---\n5.x| LTS 6.7+\n4.x| LTS 6.7+\n\x3c!-- /sonarqube --\x3e\n## Installation\n\n### Standalone executable\n\n* Expand the downloaded file into the directory of your choice. We\'ll refer to it as `$install_directory` in the next steps.\n  * On Windows, you might need to unblock the ZIP file first (right-click **file > Properties > Unblock**).\n  * On Linux/OSX you may need to set execute permissions on the files in `$install_directory/sonar-scanner-(version)/bin`.\n\n* Uncomment, and update the global settings to point to \x3c!-- sonarqube --\x3eyour SonarQube server\x3c!-- /sonarqube --\x3e\x3c!-- sonarcloud --\x3eSonarCloud\x3c!-- /sonarcloud --\x3e by editing `$install_directory/SonarQube.Analysis.xml`. Values set in this file will be applied to all analyses of all projects unless overwritten locally.  \nConsider setting file system permissions to restrict access to this file.:\n\n```xml\n<SonarQubeAnalysisProperties  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns="http://www.sonarsource.com/msbuild/integration/2015/1">\n  <Property Name="sonar.host.url">\x3c!-- sonarqube --\x3ehttp://localhost:9000\x3c!-- /sonarqube --\x3e\x3c!-- sonarcloud --\x3ehttps://sonarcloud.io\x3c!-- /sonarcloud --\x3e</Property>\n  <Property Name="sonar.login">[my-user-token]</Property>\n</SonarQubeAnalysisProperties>\n```\n\n* Add `$install_directory` to your PATH environment variable.\n\n### .NET Core Global Tool\n\n```bash\ndotnet tool install --global dotnet-sonarscanner --version x.x.x\n```\n\nThe _--version_ argument is optional. If it is omitted the latest version will be installed. Full list of releases is available on the [NuGet page](https://www.nuget.org/packages/dotnet-sonarscanner)\n\n.NET Core Global Tool is available from .NET Core 2.1+\n\n\x3c!-- sonarqube --\x3e\n### On Linux/OSX, if your SonarQube server is secured\n\n1. Copy the server\'s CA certs to `/usr/local/share/ca-certificates`\n2. Run `sudo update-ca-certificates`\n\x3c!-- /sonarqube --\x3e\n\n## Use\n\n[[info]]\n| You can invoke the Scanner using arguments with both dash (-) or forward-slash (/) separators.\n| Example : SonarScanner.MSBuild.exe begin /k:"project-key" or SonarScanner.MSBuild.exe begin -k:"project-key" will work.\n\nThere are two versions of the SonarScanner for .NET. In the following commands, you need to pass an [authentication token](/user-guide/user-token/) using the `sonar.login` property.\n\n### "Classic" .NET Framework Invocation\n\nThe first version is based on the "classic" .NET Framework. To use it, execute the following commands from the root folder of your project:\n\n```\nSonarScanner.MSBuild.exe begin /k:"project-key" \x3c!-- sonarcloud --\x3e/o:"<organization>" \x3c!-- /sonarcloud --\x3e/d:sonar.login="<token>"\nMSBuild.exe <path to solution.sln> /t:Rebuild\nSonarScanner.MSBuild.exe end /d:sonar.login="<token>"\n```\n\nNote: On macOS or Linux, you can also use `mono <path to SonarScanner.MSBuild.exe>`.\n\n### .NET Core and .NET Core Global Tool Invocation\n\nThe second version is based on .NET Core which has a very similar usage:\n\n```bash\ndotnet <path to SonarScanner.MSBuild.dll> begin /k:"project-key" \x3c!-- sonarcloud --\x3e/o:"<organization>" \x3c!-- /sonarcloud --\x3e/d:sonar.login="<token>"\ndotnet build <path to solution.sln>\ndotnet <path to SonarScanner.MSBuild.dll> end /d:sonar.login="<token>" \n```\n\nThe .NET Core version can also be used as a .NET Core Global Tool.\nAfter installing the Scanner as a global tool as described above it can be invoked as follows:\n\n```bash\ndotnet tool install --global dotnet-sonarscanner\ndotnet sonarscanner begin /k:"project-key" \x3c!-- sonarcloud --\x3e/o:"<organization>" \x3c!-- /sonarcloud --\x3e/d:sonar.login="<token>"\ndotnet build <path to solution.sln>\ndotnet sonarscanner end /d:sonar.login="<token>"\n```\n\nIn summary, the invocation of the SonarScanner for .NET will depend on the scanner flavor:\n\n Scanner Flavor | Invocation\n --- | ---\n .NET 5 | `dotnet <path to SonarScanner.MSBuild.dll>` etc.\n .NET Core Global Tool | `dotnet sonarscanner begin` etc.\n .NET Core 2.0+ | `dotnet <path to SonarScanner.MSBuild.dll>` etc.\n .NET Framework 4.6+|`SonarScanner.MSBuild.exe begin` etc.\n\nNotes:\n\n* The .NET Core version of the scanner does not support TFS XAML builds and automatic finding/conversion of Code Coverage files. Apart from that, all versions of the Scanner have the same capabilities and command line arguments.\n\n## Analysis steps\n### Begin\nThe begin step is executed when you add the `begin` command line argument. It hooks into the build pipeline, downloads {instance} quality profiles and settings and prepares your project for the analysis.\n\nCommand Line Parameters:\n\nParameter|Description\n---|---\n`/k:<project-key>`|[required] Specifies the key of the analyzed project in {instance}\n`/n:<project name>`|[optional] Specifies the name of the analyzed project in {instance}. Adding this argument will overwrite the project name in {instance} if it already exists.\n`/v:<version>`|[recommended] Specifies the version of your project.\n`/d:sonar.login=<token> or <username>`| [recommended] Specifies the [authentication token](/user-guide/user-token/) or username used to authenticate with to {instance}. If this argument is added to the begin step, it must also be added to the end step.\n`/d:sonar.password=<password>`|[optional] Specifies the password for the {instance} username in the `sonar.login` argument. This argument is not needed if you use authentication token. If this argument is added to the begin step, it must also be added on the end step.\n`/d:sonar.verbose=true`|[optional] Sets the logging verbosity to detailed. Add this argument before sending logs for troubleshooting.\n`/d:sonar.dotnet.excludeTestProjects=true`|[optional] Excludes Test Projects from analysis. Add this argument to improve build performance when issues should not be detected in Test Projects.\n`/d:<analysis-parameter>=<value>`|[optional] Specifies an additional {instance} [analysis parameter](/analysis/analysis-parameters/), you can add this argument multiple times.\n\x3c!-- sonarcloud --\x3e `/o:<organization>`|[required] Specifies the name of the target organization in SonarCloud. \x3c!-- /sonarcloud --\x3e\nFor detailed information about all available parameters, see [Analysis Parameters](/analysis/analysis-parameters/).\n\n[[warning]]\n| ![](/images/exclamation.svg) The "begin" step will modify your build like this:\n| * the active `CodeAnalysisRuleSet` will be updated to match the {instance} quality profile\n| * `WarningsAsErrors` will be turned off\n|\n| If your build process cannot tolerate these changes we recommend creating a second build job for {instance} analysis.\n\n### Build\nBetween the `begin` and `end` steps, you need to build your project, execute tests and generate code coverage data. This part is specific to your needs and it is not detailed here.\n\n### End\nThe end step is executed when you add the "end" command line argument. It cleans the MSBuild/dotnet build hooks, collects the analysis data generated by the build, the test results, the code coverage and then uploads everything to {instance}\n\nThere are only two additional arguments that are allowed for the end step:\n\nParameter|Description\n---|---\n`/d:sonar.login=<token> or <username>`| This argument is required if it was added to the begin step.\n`/d:sonar.password=<password>`| This argument is required if it was added to the begin step and you are not using an authentication token.\n\n### Known Limitations\n\n* MSBuild versions older than 14 are not supported.\n* Web Application projects are supported. Legacy Web Site projects are not.\n* Projects targeting multiple frameworks and using preprocessor directives could have slightly inaccurate metrics (lines of code, complexity, etc.) because the metrics are calculated only from the first of the built targets.\n\n## Code Coverage\n\nIn a Azure DevOps / TFS environment, test files are automatically retrieved following this search\n* Search for .trx files in any TestResults folder located under the $Build.SourcesDirectory path\n* If not found, then a fallback search is made against $Agent.TempDirectory\n\nOnce trx files have been found, their `.coverage` counterpart are searched as well and the scanner tries to convert them to `.coveragexml` files that will be uploaded to {instance}.\nCodeCoverage.exe tool is used for that, and the scanner also needs to find a path to that tool, following this search path\n* Search for the presence of `VsTestToolsInstallerInstalledToolLocation` environment variable, set by the VsTestToolsPlatformInstaller task or by the user\n* If not found, search for either the presence of that tool in well-known installation path, or via the registry.\n\nAs stated above, this will work only with the .NET 4.6 flavor of the Scanner.\n\n## Excluding projects from analysis\n\nSome project types, such as [Microsoft Fakes](https://msdn.microsoft.com/en-us/library/hh549175.aspx), are automatically excluded from analysis. To manually exclude a different type of project from the analysis, place the following in its .xxproj file.\n\n```xml\n\x3c!-- in .csproj --\x3e\n<PropertyGroup>\n  \x3c!-- Exclude the project from analysis --\x3e\n  <SonarQubeExclude>true</SonarQubeExclude>\n</PropertyGroup>\n```\n\n## Advanced topics\n\n**Analyzing MSBuild 12 projects with MSBuild 14**  \nThe Sonar Scanner for .NET requires your project to be built with MSBuild 14.0. We recommend installing Visual Studio 2015 update 3 or later on the analysis machine in order to benefit from the integration and features provided with the Visual Studio ecosystem (VSTest, MSTest unit tests, etc.).\n\nProjects targeting older versions of the .NET Framework can be built using MSBuild 14.0 by setting the "TargetFrameworkVersion" MSBuild property as documented by Microsoft:\n\n* [How to: Target a Version of the .NET Framework](https://msdn.microsoft.com/en-us/library/bb398202.aspx)\n* [MSBuild Target Framework and Target Platform](https://msdn.microsoft.com/en-us/library/hh264221.aspx)\n\nIf you do not want to switch your production build to MSBuild 14.0, you can set up a separate build dedicated to the {instance} analysis.\n\n**Detection of test projects**\n\nYou can read a full description on that subject on our wiki [here](https://github.com/SonarSource/sonar-scanner-msbuild/wiki/Analysis-of-product-projects-vs.-test-projects).\n\n**Per-project analysis parameters**\nSome analysis parameters can be set for a single MSBuild project by adding them to its .csproj file.\n\n```xml\n\x3c!-- in .csproj --\x3e\n<ItemGroup>\n  <SonarQubeSetting Include="sonar.stylecop.projectFilePath">\n    <Value>$(MSBuildProjectFullPath)</Value>\n  </SonarQubeSetting>\n</ItemGroup>\n```\n\n**Analyzing languages other than C# and VB**\n\nBy default, SonarScanner for .NET will only analyze C# and VB files in your project. To enable the analysis of other types of files, these files must be listed in the MSBuild project file (the `.csproj` or `.vbproj` file).\n\nMore specifically, any files included by an element of one of the `ItemTypes` in\n[this list](https://github.com/SonarSource/sonar-scanner-msbuild/blob/master/src/SonarScanner.MSBuild.Tasks/Targets/SonarQube.Integration.targets#L112)\nwill be analyzed automatically. For example, the following line in your `.csproj` or `.vbproj` file\n\n```\n<Content Include="foo\\bar\\*.js" />\n```\n\nwill enable the analysis of all JS files in the directory `foo\\bar` because `Content` is one of the `ItemTypes` whose includes are automatically analyzed.\n\nYou can also add `ItemTypes` to the default list by following the directions [here](https://github.com/SonarSource/sonar-scanner-msbuild/blob/master/src/SonarScanner.MSBuild.Tasks/Targets/SonarQube.Integration.targets#L75).\n\nYou can check which files the scanner will analyze by looking in the file .sonarqube\\out\\sonar-project.properties after MSBuild has finished.\n\n**Using SonarScanner for .NET with a Proxy**  \nOn build machines that connect to the Internet through a proxy server you might experience difficulties connecting to {instance}. To instruct the Java VM to use the system proxy settings, you need to set the following environment variable before running the SonarScanner for .NET:\n\n```bash\nSONAR_SCANNER_OPTS = "-Djava.net.useSystemProxies=true"\n```\n\nTo instruct the Java VM to use specific proxy settings or when there is no system-wide configuration use the following value:\n\n```bash\nSONAR_SCANNER_OPTS = "-Dhttp.proxyHost=yourProxyHost -Dhttp.proxyPort=yourProxyPort"\n```\nWhere _yourProxyHost_ and _yourProxyPort_ are the hostname and the port of your proxy server. There are additional proxy settings for HTTPS, authentication and exclusions that could be passed to the Java VM. For more information see the following article: https://docs.oracle.com/javase/8/docs/technotes/guides/net/proxies.html.\n\n```HTTP_PROXY```, ```HTTPS_PROXY```, ```ALL_PROXY``` and ```NO_PROXY``` will be automatically recognized and used to make calls against {instance}. The Scanner for .NET makes HTTP calls, independant from the settings above concerning the Java VM, to fetch the Quality Profile and other useful settings for the "end" step.\n\n## Known issues\n\n**I have multiple builds in the same pipeline, each of them getting analyzed even if the Run Code Analysis has already been executed**\n\nWe don\'t uninstall the global `ImportBefore` targets to support concurrent analyses on the same machine. Main effect is that if you build a solution where a .sonarqube folder is located nearby, then the sonar-dotnet analyzer will be executed along your build task.\n\nTo avoid that, you can disable the targets file by adding a build parameter:\n```\nmsbuild /p:SonarQubeTargetsImported=true\ndotnet build -p:SonarQubeTargetsImported=true\n```\n'},{path:"analysis/scan/sonarscanner",content:'---\ntitle: SonarScanner\nurl: /analysis/scan/sonarscanner/\n---\n\n\x3c!-- static --\x3e\n<update-center updatecenterkey="scannercli"></update-center>\n\x3c!-- /static --\x3e\n\x3c!-- embedded --\x3e\n[[info]]\n| See the [online documentation](https://redirect.sonarsource.com/doc/download-scanner.html) to get more details on the latest version of the scanner and how to download it.\n\x3c!-- /embedded --\x3e\n\nThe SonarScanner is the scanner to use when there is no specific scanner for your build system.\n\n## Configuring your project\nCreate a configuration file in your project\'s root directory called `sonar-project.properties`\n\n```\n# must be unique in a given SonarQube instance\nsonar.projectKey=my:project\n\n# --- optional properties ---\n\n# defaults to project key\n#sonar.projectName=My project\n# defaults to \'not provided\'\n#sonar.projectVersion=1.0\n \n# Path is relative to the sonar-project.properties file. Defaults to .\n#sonar.sources=.\n \n# Encoding of the source code. Default is default system encoding\n#sonar.sourceEncoding=UTF-8\n```\n\n## Running SonarScanner from the zip file\nTo run SonarScanner from the zip file, follow these steps:\n\n1. Expand the downloaded file into the directory of your choice. We\'ll refer to it as `$install_directory` in the next steps.\n1. Update the global settings to point to your SonarQube server by editing `$install_directory/conf/sonar-scanner.properties`:\n```\n#----- Default SonarQube server\n#sonar.host.url=http://localhost:9000\n```\n1. Add the `$install_directory/bin` directory to your path.\n1. Verify your installation by opening a new shell and executing the command `sonar-scanner -h` (`sonar-scanner.bat -h` on Windows). You should get output like this:\n\n   ```\n   usage: sonar-scanner [options]\n  \n   Options:\n     -D,--define <arg>     Define property\n     -h,--help             Display help information\n     -v,--version          Display version information\n     -X,--debug            Produce execution debug output\n   ```\nIf you need more debug information, you can add one of the following to your command line: `-X`, `--verbose`, or `-Dsonar.verbose=true`.\n\n1. Run the following command from the project base directory to launch analysis and pass your [authentication token](/user-guide/user-token/):  \n`sonar-scanner -Dsonar.login=myAuthenticationToken`\n\n## Running SonarScanner from the Docker image\nTo scan using the SonarScanner Docker image, use the following command:\n\n```\ndocker run \\\n    --rm \\\n    -e SONAR_HOST_URL="http://${SONARQUBE_URL}" \\\n    -e SONAR_LOGIN="myAuthenticationToken" \\\n    -v "${YOUR_REPO}:/usr/src" \\\n    sonarsource/sonar-scanner-cli\n```\n\n## Scanning C, C++, or ObjectiveC Projects\nScanning projects that contain C, C++, or ObjectiveC code requires some additional analysis steps. You can find full details on the [C/C++/Objective-C](/analysis/languages/cfamily/) language page.\n\n## Sample Projects\nTo help you get started, simple project samples are available for most languages on GitHub. They can be [browsed](https://github.com/SonarSource/sonar-scanning-examples) or [downloaded](https://github.com/SonarSource/sonar-scanning-examples/archive/master.zip). You\'ll find them filed under sonarqube-scanner/src.\n\n## Alternatives to sonar-project.properties\nIf a sonar-project.properties file cannot be created in the root directory of the project, there are several alternatives:\n\n* The properties can be specified directly through the command line. Ex:\n```\nsonar-scanner -Dsonar.projectKey=myproject -Dsonar.sources=src1\n```\n* The property project.settings can be used to specify the path to the project configuration file (this option is incompatible with the `sonar.projectBaseDir` property). Ex:\n```\nsonar-scanner -Dproject.settings=../myproject.properties\n```\n* The root folder of the project to analyze can be set through the `sonar.projectBaseDir` property since SonarScanner 2.4. This folder must contain a `sonar-project.properties` file if `sonar.projectKey` is not specified on the command line.\nAdditional analysis parameters can be defined in this project configuration file or through command-line parameters. \n\n## Alternate Analysis Directory\nIf the files to be analyzed are not in the directory where the analysis starts from, use the `sonar.projectBaseDir` property to move analysis to a different directory. E.G. analysis begins from `jenkins/jobs/myjob/workspace` but the files to be analyzed are in `ftpdrop/cobol/project1`.\nThis is configured in `sonar-project.properties` as follows:\n```\nsonar.projectBaseDir=/home/ftpdrop/cobol/project1\nsonar.sources=src\nsonar.cobol.copy.directories=/copy\n```\n\n[[info]]\n| You can configure more parameters. See [Analysis Parameters](/analysis/analysis-parameters/) for details.\n\n## Advanced Docker Configuration\n\nThe following sections offer advanced configuration options when running the SonarScanner with Docker. Click the headings to expand the instructions.\n\n[[collapse]]\n| ## Running as a non-root user\n| You can run the Docker image as a non-root user using the `--user` option. For example, to run as the current user:\n| ```\n| docker run \\\n|     --rm \\\n|     --user="$(id -u):$(id -g)" \\\n|     -e SONAR_HOST_URL="http://${SONARQUBE_URL}"  \\\n|     -v "${YOUR_REPO}:/usr/src" \\\n|     sonarsource/sonar-scanner-cli\n| ```\n| [[warning]]\n| |When running the container as a non-root user you have to make sure the user has read and write access to the directories you are mounting (like your source code or scanner cache directory), otherwise you may encounter permission-related problems.  \n\n[[collapse]]\n| ## Caching scanner files\n| To prevent SonarScanner from re-downloading language analyzers each time you run a scan, you can mount a directory where the scanner stores the downloads so that the downloads are reused between scanner runs. On some CI systems, you also need to add this directory to your CI cache configuration. \n|\n| The following command will store and use cache between runs:\n|\n| ```\n| docker run \\\n|     --rm \\\n|     -v ${YOUR_CACHE_DIR}:/opt/sonar-scanner/.sonar/cache \\\n|     -v ${YOUR_REPO}:/usr/src \\\n|     -e SONAR_HOST_URL="http://${SONARQUBE_URL}" \\\n|     sonarsource/sonar-scanner-cli\n| ```\n|\n| You can also change the location of where the scanner puts the downloads with the `SONAR_USER_HOME` environment variable.\n\n[[collapse]]\n| ## Using self-signed certificates\n| If you need to configure a self-signed certificate for the scanner to communicate with your SonarQube instance, we recommend using the OpenJDK provided with the `sonarsource/sonar-scanner-cli` image. To do this, follow these steps: \n|\n| 1. Extract the `cacerts` file from OpenJDK from the `sonarsource/sonar-scanner-cli` image:\n|\n| ```\n| docker pull sonarsource/sonar-scanner-cli\n| docker run \\\n|     --rm \\\n|     --entrypoint cat sonarsource/sonar-scanner-cli /opt/java/openjdk/lib/security/cacerts > cacerts\n| ```\n|\n| 2. Add your certificate to the exported `cacerts` file. Assuming your certificate file is named `mycert.cer` and it\'s in your current local directory:\n|\n| ```\n| docker run \\\n|     --rm \\\n|     -v `pwd`:/tmp/certs \\\n|     sonarsource/sonar-scanner-cli \\\n|     bash -c \'cd /tmp/certs && keytool -keystore cacerts -storepass changeit -noprompt -trustcacerts -importcert -alias mycert -file mycert.cer\'\n| ```\n|\n| 3. Mount the `cacerts` file that you\'ve prepared in your target container:\n| \n| ```\n| docker run \\\n|     --rm \\\n|     -e SONAR_HOST_URL="http://${SONARQUBE_URL}" \\\n|     -v `pwd`/cacerts:/opt/java/openjdk/lib/security/cacerts \\\n|     sonarsource/sonar-scanner-cli\n| ```\n|\n| Alternatively, you can create your own container that includes the modified `cacerts` file. Create a `Dockerfile` with the following contents:\n|\n| ```\n| FROM sonarsource/sonar-scanner-cli\n| COPY cacerts /opt/java/openjdk/lib/security/cacerts\n| ```\n|\n| Then, assuming both the `cacerts` and `Dockerfile` are in the current directory, create the new image with a command such as:\n| ```\n| docker build --tag our-custom/sonar-scanner-cli .\n| ```\n|\n\n## Troubleshooting\n**Java heap space error or java.lang.OutOfMemoryError**  \nIncrease the memory via the `SONAR_SCANNER_OPTS` environment variable when running the scanner from a zip file:\n```\nexport SONAR_SCANNER_OPTS="-Xmx512m"\n```\nIn Windows environments, avoid the double-quotes, since they get misinterpreted and combine the two parameters into a single one.\n```\nset SONAR_SCANNER_OPTS=-Xmx512m\n```\n\n**Unsupported major.minor version**  \nUpgrade the version of Java being used for analysis or use one of the native package (that embed its own Java runtime).\n\n**Property missing: `sonar.cs.analyzer.projectOutPaths\'. No protobuf files will be loaded for this project.**  \nScanner CLI is not able to analyze .NET projects. Please, use the SonarScanner for .NET. If you are running the SonarScanner for .NET, ensure that you are not hitting a known limitation.\n'},{path:"analysis/scm-integration",content:"---\ntitle: SCM Integration\nurl: /analysis/scm-integration/\n---\n\nCollecting SCM data during code analysis can unlock a number of SonarQube features:\n\n* Automatic Issue Assignment\n* code annotation (blame data) in the Code Viewer\n* SCM-driven detection of new code (to help with [Clean as You Code](/user-guide/clean-as-you-code/)). Without SCM data, SonarQube determines new code using analysis dates (to timestamp modification of lines).\n\nSCM integration requires support for your individual SCM provider. Git and SVN are supported by default. For other SCM providers, see the Marketplace.\n\nIf need be, you can toggle it off at global level via administration settings and at a project level via project settings.\n\n## Git\n[Git](http://www.git-scm.com/) integration is supported out of the box with a pure Java implementation so there's no need to have Git command line tool installed on the machine where analysis is performed.\n\nAuto-detection of Git during analysis will happen if there is a .git folder in the project root directory or in one of its parent folders. Otherwise you can force the provider using `-Dsonar.scm.provider=git`. A full clone is required for this integration to be able to collect the required blame information (see Known Issues). If a shallow clone is detected, a warning will be logged and no attempt will be made to retrieve blame information.\n\nGit integration uses [JGit](https://www.eclipse.org/jgit/). JGit is a pure Java implementation of the Git client.\n\n### Known Issues\n\n* Git doesn't consider old \"Mac\" line ends (CR) as new lines. As a result the blame operation will contain fewer lines than expected by SonarQube and analysis will fail. The solution is to fix line ends to use either Windows (CR/LF) or Unix (LF) line ends.\n* JGit doesn't support .mailmap file to \"clean\" email adress during the blame\n* \"Missing blame information...\" and \"Could not find ref...\" can be caused by checking out with a partial / shallow clone, or using Git submodules.\n\n### How to investigate error during blame (only possible on Unix/Linux)?\n\nIf you get an error when blame is executed on a file, it may be a limitation or a bug in JGit. To confirm please follow these steps:\n\n1. Download the standalone JGit command line distribution\n\n2. Try to execute the blame command on the offending file:  \n    `chmod +x /path/to/org.eclipse.jgit.pgm-4.9.0.201710071750-r.sh /path/to/org.eclipse.jgit.pgm-4.9.0.201710071750-r.sh blame -w /path/to/offending/file`\n\n3. If you get the same error as during analysis, then this really looks like a bug in JGit (especially if you don't have an issue with the native git command line tool). Please try to do the previous steps with latest version of JGit and report all information to the [SonarQube Community Forum](https://community.sonarsource.com/).\n\n## Subversion\n[Subversion](https://subversion.apache.org/) integration is supported out of the box for Subversion 1.6 to 1.9.x.\n\nAuto-detection of SVN during analysis will happen if there is a `.svn` folder somewhere in the parent hierarchy of the project root. Otherwise you can force the provider using `-Dsonar.scm.provider=svn` on the analysis command line.\n\n### Known issues\nIf you get errors like:\n\n`Caused by: org.tmatesoft.svn.core.SVNException: svn: E200007: Retrieval of mergeinfo unsupported by 'https://pmd.svn.sourceforge.net/svnroot/pmd/trunk/pmd/src/main/java/net/sourceforge/pmd/AbstractConfiguration.java';`\nIt means the SVN server is not advertising the 'mergeinfo' capability. You can check the advertised capabilities by simply connecting to it:\n\n`telnet <svn_server> 3690`\nOften this is because your SVN server is not >= 1.5 or your project was not properly migrated after a server upgrade. It could also be a misconfiguration of the server.\n\nYou should try to run svnadmin upgrade **on the server**. For more information, please read https://subversion.apache.org/docs/release-notes/1.5.html#repos-upgrades.\n\n"},{path:"analysis/security_configuration",content:'---\ntitle: Security Engine Custom Configuration\nurl: /analysis/security_configuration/\n---\n*Security Engine Custom Configuration is available as part of the [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html) and [above](https://www.sonarsource.com/plans-and-pricing/).*\n\nThe security engine tracks the path that data follows through your code. It detects when data that\'s potentially manipulated by a malicious user reaches a sensitive piece of code where an attack can occur.\n\nThose potentially malicious data are also called tainted data because they are tainted by user inputs. \n\nSonarQube\'s security engine already knows a lot of APIs that are potential sources or targets of attack. While we do our best to identify publicly available APIs, we can\'t know everything about your homemade frameworks particularly when it comes to sanitizing your data. Because of this, SonarQube allows you to customize the security engine to add your own sources, sanitizers, passthroughs, and sinks (see the **Elements** section below for more on these elements).\n\nFor example, you may want to:\n\n* add a source to add support for a framework that SonarQube doesn\'t cover out of the box\n* use a custom sanitizer to tell the security engine that all data going through sanitizers should be considered safe. This allows you to remove false positives and tailor the security engine to your company.\n\n## Rules\nYou can customize elements for Java, PHP, C#, and Python rules in the security engine. Click the languages below to expand a list of customizable rules for that language:\n\n[[collapse]]\n| ## Java\n| * [S3649](https://rules.sonarsource.com/java/RSPEC-3649): SQL Injection\n| * [S5131](https://rules.sonarsource.com/java/RSPEC-5131): XSS\n| * [S5146](https://rules.sonarsource.com/java/RSPEC-5146): Open Redirect\n| * [S5167](https://rules.sonarsource.com/java/RSPEC-5167): HTTP Response Splitting\n| * [S2083](https://rules.sonarsource.com/java/RSPEC-2083): Path Traversal Injection\n| * [S2078](https://rules.sonarsource.com/java/RSPEC-2078): LDAP Injection\n| * [S5145](https://rules.sonarsource.com/java/RSPEC-5145): Log Injection\n| * [S2076](https://rules.sonarsource.com/java/RSPEC-2076): OS Command Injection\n| * [S2631](https://rules.sonarsource.com/java/RSPEC-2631): RegExp Injection\n| * [S5144](https://rules.sonarsource.com/java/RSPEC-5144): Server-Side Request Forgery (SSRF)\n| * [S2091](https://rules.sonarsource.com/java/RSPEC-2091): XPath Injection\n| * [S5135](https://rules.sonarsource.com/java/RSPEC-5135): Deserialization Injection\n| * [S5334](https://rules.sonarsource.com/java/RSPEC-5334): Code Injection\n| * [S6096](https://rules.sonarsource.com/java/RSPEC-6096): Zip Slip\n\n[[collapse]]\n| ## PHP\n| * [S3649](https://rules.sonarsource.com/php/RSPEC-3649): SQL Injection\n| * [S5131](https://rules.sonarsource.com/php/RSPEC-5131): XSS\n| * [S5146](https://rules.sonarsource.com/php/RSPEC-5146): Open Redirect\n| * [S5167](https://rules.sonarsource.com/php/RSPEC-5167): HTTP Response Splitting\n| * [S2083](https://rules.sonarsource.com/php/RSPEC-2083): Path Traversal Injection\n| * [S2078](https://rules.sonarsource.com/php/RSPEC-2078): LDAP Injection\n| * [S5145](https://rules.sonarsource.com/php/RSPEC-5145): Log Injection\n| * [S2076](https://rules.sonarsource.com/php/RSPEC-2076): OS Command Injection\n| * [S2631](https://rules.sonarsource.com/php/RSPEC-2631): RegExp Injection\n| * [S5144](https://rules.sonarsource.com/php/RSPEC-5144): Server-Side Request Forgery (SSRF)\n| * [S2091](https://rules.sonarsource.com/php/RSPEC-2091): XPath Injection\n| * [S5135](https://rules.sonarsource.com/php/RSPEC-5135): Deserialization Injection\n| * [S5334](https://rules.sonarsource.com/php/RSPEC-5334): Code Injection\n| * [S5335](https://rules.sonarsource.com/php/RSPEC-5335): Include Injection\n\n[[collapse]]\n| ## C&#35;\n| * [S3649](https://rules.sonarsource.com/csharp/RSPEC-3649): SQL Injection\n| * [S5131](https://rules.sonarsource.com/csharp/RSPEC-5131): XSS\n| * [S5146](https://rules.sonarsource.com/csharp/RSPEC-5146): Open Redirect\n| * [S5167](https://rules.sonarsource.com/csharp/RSPEC-5167): HTTP Response Splitting\n| * [S2083](https://rules.sonarsource.com/csharp/RSPEC-2083): Path Traversal Injection\n| * [S2078](https://rules.sonarsource.com/csharp/RSPEC-2078): LDAP Injection\n| * [S5145](https://rules.sonarsource.com/csharp/RSPEC-5145): Log Injection\n| * [S2076](https://rules.sonarsource.com/csharp/RSPEC-2076): OS Command Injection\n| * [S2631](https://rules.sonarsource.com/csharp/RSPEC-2631): RegExp Injection\n| * [S5144](https://rules.sonarsource.com/csharp/RSPEC-5144): Server-Side Request Forgery (SSRF)\n| * [S2091](https://rules.sonarsource.com/csharp/RSPEC-2091): XPath Injection\n| * [S5334](https://rules.sonarsource.com/csharp/RSPEC-5334): Code Injection\n| * [S6096](https://rules.sonarsource.com/csharp/RSPEC-6096): Zip Slip\n\n[[collapse]]\n| ## Python\n| * [S3649](https://rules.sonarsource.com/python/RSPEC-3649): SQL Injection\n| * [S5131](https://rules.sonarsource.com/python/RSPEC-5131): XSS\n| * [S5146](https://rules.sonarsource.com/python/RSPEC-5146): Open Redirect\n| * [S5167](https://rules.sonarsource.com/python/RSPEC-5167): HTTP Response Splitting\n| * [S2083](https://rules.sonarsource.com/python/RSPEC-2083): Path Traversal Injection\n| * [S2078](https://rules.sonarsource.com/python/RSPEC-2078): LDAP Injection\n| * [S5145](https://rules.sonarsource.com/python/RSPEC-5145): Log Injection\n| * [S2076](https://rules.sonarsource.com/python/RSPEC-2076): OS Command Injection\n| * [S2631](https://rules.sonarsource.com/python/RSPEC-2631): RegExp Injection\n| * [S5144](https://rules.sonarsource.com/python/RSPEC-5144): Server-Side Request Forgery (SSRF)\n| * [S2091](https://rules.sonarsource.com/python/RSPEC-2091): XPath Injection\n| * [S5135](https://rules.sonarsource.com/python/RSPEC-5135): Object Injection\n| * [S5334](https://rules.sonarsource.com/python/RSPEC-5334): Code Injection\n\n## Elements\n\nYou can add the following elements to your custom configuration:\n\n* **Source** – Where you get user data. You should always consider user data tainted and vulnerable to injection attacks.\n  Example: Calling `HttpServletRequest#getParam("foo")` will return tainted content\n* **Sanitizer** – Finds and removes malicious content from tainted data.\n* **Passthrough** – Allows you to keep track of tainted data sent to a library outside the current function. When you pass a tainted value to a library function outside the current function, SonarQube automatically assumes it\'s being passed to a sanitizer. If the tainted data isn\'t being passed to a sanitizer, you can set up a passthrough to keep track of the data.\n* **Sink** – A piece of code that can perform a security-sensitive task. Data should not contain any malicious content once it reaches a sink.\n  Example: Running an SQL query with `java.sql.Statement#execute`\n\n## MethodId\n\nAll custom configurations rely on the accuracy of the `methodIds` provided. The `methodId` format differs for each language. Click the language you\'re using below for more information on the format for that language.\n\n[[collapse]]\n| ## Java methodId\n|\n| The `methodId` format is inspired by the bytecode. The easiest way to get a `methodId` is to write a simple piece of Java code, compile it, and then look at the bytecode generated using the `javap -c path_to.class` file, and transform it a little. Looking at the following real-life example will help you understand the format.\n| \n| Let\'s imagine you want to declare `org.rapidoid.jdbc.JdbcClient.execute(String sql, Object... args)` as a new sink (you don\'t need to do this because Rapidoid is part of what is covered out of the box).\n| \n| Write a simple piece of code calling the JdbcClient.execute(...) method. The code doesn\'t need to actually do anything.\n| \n| ```\n| import org.rapidoid.http.Req;\n| import org.rapidoid.jdbc.JdbcClient;\n|\n| public static void callJDBCMethods(Req req) {\n|   String tainted = req.param("TAINTED");\n|   JdbcClient jdbc = JDBC.api();\n|   jdbc.execute(tainted, req); // Noncompliant\n| }      \n| ```\n| \n| Run the `javap -c` and locate the piece of bytecode corresponding to the call to `JdbcClient.execute`\n| \n| ```\n| [...]\n| org/rapidoid/jdbc/JdbcClient.execute:(Ljava/lang/String;[Ljava/lang/Object;)I\n| [...]\n| ````\n| \n| * Replace the `/` in the package name with  `.`\n| * Remove the `:`\n| * Replace the `.` separating the Class name and the Method name with a `#`\n| \n| The resulting `methodId` is:\n| ```\n| org.rapidoid.jdbc.JdbcClient#execute(Ljava/lang/String;[Ljava/lang/Object;)I\n| ```\n\n[[collapse]]\n| ## PHP methodId\n| \n| The `methodId` can be:\n| * the name of a PHP function \n| * the fully qualified name of a method following this format: `namespace\\\\ClassName::methodName`\n| \n| Example: `Symfony\\\\Component\\\\HttpFoundation\\\\Request::getUser` for the `getUser()` method of the `Request` object provided by `Symfony`\n| \n| Note: the `methodId` should be related to methods or functions that are part of the analysis scope. Because we recommended to not analyze the code of frameworks at the same time that you scan your own source code, defining methods or functions from frameworks will have no effect.\n| This is linked to the fact that the SonarQube security engine needs to know the runtime type of each variable. The type can\'t be guessed when objects are created by frameworks\' factories. Out of the box, the SonarQube security engine supports the main Symfony and Laravel types.\n\n[[collapse]]\n| ## C&#35; methodId \n| \n| If you want to declare the constructor `SqlCommand` belonging to the namespace `System.Data.SqlClient` as a sink, the `methodId` should be:\n| \n| ```\n| System.Data.SqlClient.SqlCommand.SqlCommand(string, System.Data.SqlClient.SqlConnection)\n| ```\n| \n| You simply need to provide the fully qualified name of the method or constructor plus the types of the arguments.\n\n[[collapse]]\n| ## Python methodId\n| \n| Python `methodIds` can be defined as either of the following:\n| * the name of a global Python function.\n| * the fully qualified name of a method following this format: `namespace.ClassName.methodName`. Ex: `ldap.ldapobject.SimpleLDAPObject.search`, `str.isidentifier`.\n  \n## Creating your custom configuration JSON file\n\nYou need to add your custom configurations to SonarQube using a JSON file. You can apply your custom configuration to a specific project or to all of your projects at the global level in SonarQube: \n\n* **Project level** – go to **Project Settings > General Settings > SAST Engine** and add your JSON file to the **JAVA/PHP/C#/Python custom configuration** field.\n\n* **Global level** – go to **Administration > General Settings > SAST Engine** and add your JSON file to the **JAVA/PHP/C#/Python custom configuration** field.  \n\nSee the following section for more information on formatting your JSON file.\n\n### Configuration file format\nYour JSON file should include the rule you\'re adding a custom element to, the element you are customizing, and the `methodId` for each element. Each language needs a separate JSON file but can contain multiple rules. Click your language below to expand an example of a JSON file to help you understand the expected format.\n\n[[collapse]]\n| ## Java JSON file example\n|\n| ```\n| {\n|   "S3649": {\n|     "sources": [\n|       {\n|         "methodId": "my.package.ServerRequest#getQuery()Ljava/lang/String;"\n|       }\n|     ],\n|     "sanitizers": [\n|       {\n|         "methodId": "my.package.StringUtils#stringReplace(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;"\n|       }\n|     ],\n|     "passthroughs": [\n|       {\n|         "methodId": "my.package.RawUrl#<init>(Ljava/lang/String;)V",\n|         "isWhitelist": true,\n|         "args": [\n|           1\n|         ]\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "my.package.MySql#query(Ljava/lang/String;)V",\n|         "args": [\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "my.package.SqlStatement#execute",\n|         "isMethodPrefix": true,\n|         "args": [\n|           0,\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "my.package.SqlStatement#run(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V",\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   },\n|   "S5131": {\n|     "sources": [\n|       {\n|         "methodId": "my.package.ServerRequest#getQueryString()Ljava/lang/String;"\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "my.package.Server#write(",\n|         "isMethodPrefix": true,\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   }\n| }\n|```\n|\n| The `args` is the index of the parameter that can receive a tainted variable. Index starts:\n| * `1` for a function call. \n| * `0` for a method call, index `0` being the current instance (`this`)\n\n[[collapse]]\n| ## PHP JSON file example\n|\n| ```\n| {\n|   "S3649": {\n|     "sources": [\n|       {\n|         "methodId": "My\\\\Namespace\\\\ClassName\\\\ServerRequest::getQuery"\n|       }\n|     ],\n|     "sanitizers": [\n|       {\n|         "methodId": "str_replace"\n|       }\n|     ],\n|     "passthroughs": [\n|       {\n|         "methodId": "My\\\\Namespace\\\\RawUrl::RawUrl",\n|         "isWhitelist": true,\n|         "args": [\n|           1\n|         ]\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "mysql_query",\n|         "args": [\n|           1\n|         ]\n|       },\n|      {\n|         "methodId": "My\\\\Namespace\\\\SqlStatement::execute",\n|         "isMethodPrefix": true,\n|         "args": [\n|           0,\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "My\\\\Namespace\\\\SqlStatement::run",\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   },\n|   "S5131": {\n|     "sources": [\n|       {\n|         "methodId": "My\\\\Namespace\\\\ClassName\\\\ServerRequest::getQueryString"\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "My\\\\Namespace\\\\ClassName\\\\Server::write",\n|         "isMethodPrefix": true,\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   }\n| }\n|```\n|\n| The `args` is the index of the parameter that can receive a tainted variable. Index starts:\n| * `1` for a function call. \n| * `0` for a method call, index `0` being the current instance (`this`)\n\n[[collapse]]\n| ## C&#35; JSON file example\n|\n| ```\n| {\n|   "S3649": {\n|     "sources": [\n|       {\n|         "methodId": "My.Namespace.ServerRequest.GetQuery()"\n|       }\n|     ],\n|     "sanitizers": [\n|       {\n|         "methodId": "My.Namespace.StringUtils.StringReplace(string, string)"\n|       }\n|     ],\n|     "passthroughs": [\n|       {\n|         "methodId": "My.Namespace.RawUrl.RawUrl(string)",\n|         "isWhitelist": true,\n|         "args": [\n|           1\n|         ]\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "My.Namespace.MySql.Query(string)",\n|         "args": [\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "My.Namespace.SqlStatement.Execute",\n|         "isMethodPrefix": true,\n|         "args": [\n|           0,\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "My.Namespace.SqlStatement.Run(string, string, string)",\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   },\n|   "S5131": {\n|     "sources": [\n|       {\n|         "$comment": "The following method id is a getter on the \'QueryString\' property",\n|         "methodId": "My.Namespace.ServerRequest.QueryString.get"\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "My.Namespace.Server.Write(",\n|         "isMethodPrefix": true,\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   }\n| }\n|```\n|\n| The `args` is the index of the parameter that can receive a tainted variable. Index starts:\n| * `1` for a function call. \n| * `0` for a method call, index `0` being the current instance (`this`)\n\n[[collapse]]\n| ## Python JSON file example\n|\n|```\n| {\n|   "S3649": {\n|     "sources": [\n|       {\n|         "methodId": "my.namespace.ServerRequest.get_query"\n|       }\n|     ],\n|     "sanitizers": [\n|       {\n|         "methodId": "str_replace"\n|       }\n|     ],\n|     "passthroughs": [\n|       {\n|         "methodId": "my.namespace.RawUrl",\n|         "isWhitelist": true,\n|         "args": [\n|           1\n|         ]\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "mysql_query",\n|         "args": [\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "my.namespace.SqlStatement.execute",\n|         "isMethodPrefix": true,\n|         "args": [\n|           0,\n|           1\n|         ]\n|       },\n|       {\n|         "methodId": "my.namespace.SqlStatement.run",\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   },\n|   "S5131": {\n|     "sources": [\n|       {\n|         "methodId": "my.namespace.ServerRequest.get_query_string"\n|       }\n|     ],\n|     "sinks": [\n|       {\n|         "methodId": "my.namespace.Server.write(",\n|         "isMethodPrefix": true,\n|         "interval": {\n|           "fromIndex": 1\n|         }\n|       }\n|     ]\n|   }\n| }\n|\n|```\n|\n| The `args` is the index of the parameter that can receive a tainted variable. Index starts:\n| * `1` for a function call. \n| * `0` for a method call, index `0` being the current instance (`this`)\n\n### (Deprecated) Customizing through analysis parameters\n\n[[warning]]\n| Customizing the security engine through analysis parameters is deprecated. We recommend adding your custom configuration in SonarQube as shown above. This allows you to create a single configuration file for each language and to easily apply it to multiple projects or globally.\n\nTo customize the SonarQube security engine, you can feed security configuration data through parameters given to the SonarScanners. To do this, you should provide JSON files with the value of the new analysis parameters. \n\n[[info]]\n|The configuration works per rule. You can\'t share a configuration between rules.\n\nThe parameters should use the following syntax:\n\n```\nsonar.security.[ConfigType].[RuleRepository].[RuleKey]=[FileName]\n```\nThe `ConfigType` value can be one of the following:\n\n* `sources`\n* `sanitizers`\n* `passthroughs`\n* `sinks`\n\nThe `RuleRepository` value can be one of the following:\n\n* `javasecurity`: if you want to customize the Java Security Engine\n* `phpsecurity`: if you want to customize the PHP Security Engine\n* `roslyn.sonaranalyzer.security.cs`: if you want to customize the C# Security Engine\n* `pythonsecurity`: if you want to customize the Python Security Engine\n\nThe `RuleKey` value should be one of the values shown in the **Rules** section above.\n  \n#### **JSON formatting example**\n\nConfiguration is provided using JSON files. Click the heading below to expand an example PHP JSON file to help you understand the expected format.\n\n[[collapse]]\n| ## JSON File Format Example for PHP\n|\n| [[info]]\n| | You need to create a configuration for each rule. There is no way to share a configuration between rules.\n|\n| ```\n| {\n|   "sources": [\n|     {\n|       "methodId": "My\\\\Namespace\\\\ClassName\\\\ServerRequest::getQuery"\n|     }\n|   ],\n|   "sanitizers": [\n|     {\n|       "methodId": "str_replace"\n|     }\n|   ],\n|  "passthroughs": [\n|     {\n|       "methodId": "rawurldecode",\n|       "args": [\n|         1\n|       ]\n|     }\n|   ],\n|   "sinks": [\n|     {\n|       "methodId": "mysql_query",\n|       "args": [\n|         1\n|       ]\n|     },\n|     {\n|       "methodId": "My\\\\Namespace\\\\SqlStatement::execute",\n|       "isMethodPrefix": true, // this is to say that all the methods starting with execute on the SqlStatement object will be considered\n|       "args": [\n|         0,\n|         1\n|       ]\n|     },\n|     {\n|       "methodId": "My\\\\Namespace\\\\SqlStatement::run",\n|       "interval": {\n|         "fromIndex": 1 // every parameter from the number 1 will be considered\n|       }\n|     }\n|   ]  \n| }\n| ```\n|\n| The `args` is the index of the parameter that can receive a tainted variable. Index starts:\n| * `1` for a function call. \n| * `0` for a method call, index `0` being the current instance (`this`)  \n\n## Deactivating the core configuration\n\nYou can disable the core configuration per language or per rule using the following:\n\n```\nsonar.security.[ConfigType].[RuleRepository].noDefaultConfig=[true|false]\nsonar.security.[ConfigType].[RuleRepository].[RuleKey].noDefaultConfig=[true|false]\n```\n'},{path:"architecture/architecture-integration",content:"---\ntitle: Architecture and Integration\nurl: /architecture/architecture-integration/\n---\n## Overview\nThe SonarQube Platform is made of 4 components:  \n![SonarQube Platform.](/images/architecture-scanning.png)\n\n1. One SonarQube Server starting 3 main processes:\n    * Web Server for developers, managers to browse quality snapshots and configure the SonarQube instance\n    * Search Server based on Elasticsearch to back searches from the UI\n    * Compute Engine Server in charge of processing code analysis reports and saving them in the SonarQube Database\n2. One SonarQube Database to store:\n    * the configuration of the SonarQube instance (security, plugins settings, etc.)\n    * the quality snapshots of projects, views, etc.\n3. Multiple SonarQube Plugins installed on the server, possibly including language, SCM, integration, authentication, and governance plugins\n4. One or more SonarScanners running on your Build / Continuous Integration Servers to analyze projects\n\n## Integration\nThe following schema shows how SonarQube integrates with other ALM tools and where the various components of SonarQube are used.  \n![SonarQube Integration.](/images/architecture-integrate.png)\n\n1. Developers code in their IDEs and use [SonarLint](https://sonarlint.org) to run local analysis.\n2. Developers push their code into their favourite SCM : git, SVN, TFVC, ...\n3. The Continuous Integration Server triggers an automatic build, and the execution of the SonarScanner required to run the SonarQube analysis.\n4. The analysis report is sent to the SonarQube Server for processing.\n5. SonarQube Server processes and stores the analysis report results in the SonarQube Database, and displays the results in the UI.\n6. Developers review, comment, challenge their Issues to manage and reduce their Technical Debt through the SonarQube UI.\n7. Managers receive Reports from the analysis.\nOps use APIs to automate configuration and extract data from SonarQube.\nOps use JMX to monitor SonarQube Server.\n\n## About Machines and Locations\n* The SonarQube Platform cannot have more than one SonarQube Server (although the Server can be installed [as a cluster](/setup/install-cluster/)) and one SonarQube Database.\n* For optimal performance, each component (server, database, scanners) should be installed on a separate machine, and the server machine(s) should be dedicated.\n* SonarScanners scale by adding machines.\n* All machines must be time synchronized.\n* The SonarQube Server and the SonarQube Database must be located in the same network\n* SonarScanners don't need to be on the same network as the SonarQube Server.\n* There is **no communication** between **SonarScanners** and the **SonarQube Database**.\n"},{path:"branches/branches-faq",content:'---\ntitle: Branch FAQ\nurl: /branches/branches-faq/\n---\n\n_Branch analysis is available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)._\n\n## How long are branches retained?  \nBranches will be deleted automatically when they are inactive according to your settings at [Administration > Configuration > General Settings > Housekeeping > Number of days before deleting inactive branches](/#sonarqube-admin#/admin/settings?category=housekeeping) except for branches you have set to be kept when inactive. These branches are kept until you delete them manually at the project level at **Project Settings > Branches & Pull Requests**. See the [Branches Analysis](/branches/overview/) for more information on keeping inactive branches.\n\n## Does my project need to be stored in an SCM like Git or SVN?  \nNo, you don\'t need to be connected to a SCM. However, SCM data still enhances the SonarQube experience (including issue auto-assignment and issue backdating), and you will be well prepared to take advantage of [Pull Request Analysis](/analysis/pull-request/)!\n\n## What if I mark an Issue "Won\'t Fix" or "False-Positive" in a branch?\nIt will be replicated as such when creating a pull request and merging the pull request into the master branch.\n\nIf you\'re using the **Reference Branch** [New Code](/project-administration/new-code-period/) definition, issues in the reference branch that come from a feature branch automatically inherit their attributes (including "Won\'t Fix" and "False Positive" resolutions) from the feature branch.\n## Can I manually delete a branch?  \nYou can delete a branch in the **Branches** tab at **Project Settings > Branches and Pull Requests**.\n\n## Does the payload of the Webhook include branch information?  \nYes, an extra node called "branch" is added to the payload.\n\n## When are Webhooks called?  \nWhen the computation of the background task is done for a given branch.\n\n## What is the impact on my LOCs consumption vs my license?  \nThe LOC of your largest branch are counted toward your license limit. All other branches are ignored.  \n'},{path:"branches/overview",content:"---\ntitle: Branch Analysis\nurl: /branches/overview/\n---\n\n_Branch analysis is available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)._\n\n## Overview\n\nWith Branch Analysis, you can ensure that you're maintaining consistent code quality all the way down to the branch level of your projects. \n\n### Master / Main Branch\n\nThis is the default branch and typically corresponds to what's being developed for your next release. This branch is usually known within a development team as \"master\" or \"head\" and is analyzed when no specific branch parameters are provided. SonarQube labels this branch as **Main Branch**, and, with Community Edition, this is the only branch you can analyze. \n\nAdding projects by ALM copies the main branch name in SonarQube from the main branch name in your repository. See **ALM Integrations** in the documentation navigation for more information on adding your project from an ALM.\n\nIf you add your project manually, your main branch defaults to the name \"master\".\n\nStarting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), your main branch can be renamed from the project settings at **Project Settings > Branches and Pull Requests**. \n\n### Settings and Quality Profiles on Branches\n\nBranch settings and Quality Profiles are the same as those set for the master branch, and by design, it's not possible to configure other values. The New Code Period is the only exception to this as it can be set on a branch-by-branch basis. \n\n### New Code\n\nYou can set a New Code definition for each branch. This is especially helpful if you are likely to develop and release multiple versions from the branch. See the [Defining New Code](/project-administration/new-code-period/) documentation for more information.\n\n### Quality Gate\n\nThe branch Quality Gate lets you know if your branch is ready to be merged. Each branch has a quality gate that:\n\n* Applies on conditions on New Code and overall code.\n* Assigns a status (Passed or Failed).\n\n## Setting up Branch analysis\n\nA branch is created when the `sonar.branch.name` parameter is passed during analysis.\n\n| Parameter Name        | Description |\n| --------------------- | ------------------------------------------------- |\n| `sonar.branch.name`   | Name of the branch (visible in the UI)\n\n### Limiting analysis to relevant branches  \n\nYou need to add a condition to your pipeline script to ensure only relevant branches are analyzed. For example, you wouldn't want to run analysis on feature branches that won't need analysis until they have pull requests . \n\nIn the following example, analysis would be limited to branches named `master` or `release/*`.\n\n```\nif [[ \"$CI_BRANCH_NAME\" == master ]] || [[ \"$CI_BRANCH_NAME\" == release/* ]]; then\n  ./gradlew sonarqube\nfi\n``` \n\n### Issue Creation and Synchronization\n\nDuring the first analysis, issues (type, severity, status, assignee, change log, comments) are synchronized with the Main Branch. In each synchronized issue, a comment is added to the change log of the issue on the branch: \"The issue has been copied from branch 'master' to branch 'yyy'\".\n\nAt each subsequent analysis of the branch, any new issue in the Main Branch that comes from a pull request automatically inherits its attributes (type, severity, ...) from the pull request. A comment is added to the change log of the issue on the branch: \"The issue has been merged from 'xxx' into 'yyy'\"\n\nIssues can be synchronized between branches if you're using the **Reference Branch** [New Code](/project-administration/new-code-period/) definition. When using this New Code definition, any new issue in the reference branch that comes from a feature branch automatically inherits its attributes (type, severity, ...) from the feature branch. A comment is added to the change log of the issue on the branch: \"The issue has been merged from 'xxx' into 'yyy'\".\n\n### Fetching full Git history\n\nBy default, some CIs don't fetch your full Git history. For example, TravisCI only fetches the last 50 git commits. You must use `git fetch --unshallow` to get the full history. If you don't, new issues may not be assigned to the correct developer.\n\n## Managing inactive branches\nInactive branches are branches that are no longer being analyzed. You can use Housekeeping to automatically delete branches that are inactive (i.e. old feature branches) or to keep inactive branches that you want to continue maintaining (i.e. release branches). \n\n### Deleting inactive branches\n\nYou can set the number of days a branch can be inactive before it's deleted in the global settings at **Administration > General Settings > Housekeeping > Number of days before deleting inactive branches**. Branches that are inactive for the number of days that you set will be automatically deleted.\n\n### Using patterns to keep inactive branches\n\nYou can use naming patterns to protect specific branches, such as release branches, from automatic deletion. To do this, add a pattern using Java regular expressions under **Administration > General Settings > Housekeeping > Branches > Branches to keep when inactive** at either the global or project level. When a branch is created with a name that follows one of these patterns, it will be kept indefinitely. \n\nFor example, adding the pattern `release/.*` would keep any branches named release/6.0, release/7, and so on.\n\n**Note:** Patterns aren't retroactive and won't apply to branches that have already been created. They only apply to branches created after the pattern is set. You can protect an existing branch at the project level. See the following section.\n\n### Managing inactive branches at a project level\n\nYou can set a branch to **Keep when inactive** at the project level from from the **Branches** tab at **Project Settings > Branches and Pull Requests**. Here, you can also turn off protection for a branch so it will be deleted when it's inactive for the number of days that has been specified in the global settings at **Administration > General Settings > Housekeeping > Number of days before deleting inactive branches**. \n\n**Note:** The main branch is always protected from automatic deletion, even if it's inactive. This can't be changed.\n\n## Keeping your \"master\" branch history when upgrading from Community Edition to a commercial edition\n[[info]]\n| If you added a SonarQube project from an ALM instead of manually, the name of the main branch in SonarQube is copied from the name of the main branch in your repository, and you shouldn't have any branch history issues when upgrading to a commercial edition.\n\nIn Community Edition, if you create a project manually, your analyzed branch is named \"master\" by default. \n\nWhen upgrading to a current commercial edition version, automatic branch and pull request configuration creates branches based on their names in your code repository. If the name of your Main Branch (master) in SonarQube doesn't match the branch's name in your code repository, the history of your Main Branch won't be taken on by the branch you analyze. \n\n**Before running analysis**, you can keep your branch history by renaming the Main Branch in SonarQube with the name of the branch in your code repository at **Project Settings > Branches and Pull Requests**. \n\nFor example, if your Main Branch is named \"master\" in SonarQube but \"develop\" in your code repository, rename your Main Branch \"develop\" in SonarQube.\n"},{path:"extend/adding-coding-rules",content:'---\ntitle: Adding Coding Rules\nurl: /extend/adding-coding-rules/\n---\n\nThere are three ways to add coding rules to SonarQube:\n\n* Writing a SonarQube plugin in Java that uses SonarQube APIs to add new rules\n* Adding XPath rules directly through the SonarQube web interface\n* Importing [Generic Issue Reports](/analysis/generic-issue/) generated by an independently run tool\n\nThe Java API will be more fully-featured than what\'s available for XPath, and is generally preferable. However, this comes with the overhead of maintaining a SonarQube plugin (including keeping it up-to-date as APIs change, upgrading the plugin after releasing a new version).\n\nImporting [Generic Issue Reports](/analysis/generic-issue/) is a good solution when there\'s a very specific need for a subset of projects on your SonarQube instance. They are the most flexible option, but lack some features (such as being able to control their execution by inclusion in a Quality Profile).\n\n[[info]]\n| Before implementing a new coding rule, you should consider whether it is specific to your own context or might benefit others. If it might benefit others, you can propose it on the [Community Forum](https://community.sonarsource.com/). If there is shared interest, then it might be implemented for you directly in the related language plugin. It means less maintenance for you, and benefit to others.\n\n## Custom rule support by language\n\n|  | XPath 1.0 | Java | Generic Issue Reports | Other |\n|-|-|-|-|-|\n| ABAP | - | - | ![](/images/check.svg) |  |\n| Apex | - | - | ![](/images/check.svg) |  |\n| C# | - | - | ![](/images/check.svg) | ![](/images/check.svg)[Importing Issues from Third-Party Roslyn Analyzers (C#, VB.NET)](/analysis/external-issues/) |\n| C/C++/Objective-C | - | - | ![](/images/check.svg) |  |\n| COBOL | - | ![](/images/check.svg) | ![](/images/check.svg) |  |\n| CSS | - | - | ![](/images/check.svg) |  |\n| Flex | ![](/images/check.svg) | - | ![](/images/check.svg) |  |\n| Go | - | - | ![](/images/check.svg) |  |\n| HTML | - | - | ![](/images/check.svg) |  |\n| Java | - | ![](/images/check.svg) | ![](/images/check.svg) |  |\n| JavaScript / Typescript | - | - | ![](/images/check.svg) |  |\n| PHP | - | ![](/images/check.svg) | ![](/images/check.svg) |  |\n| PL/SQL | ![](/images/check.svg) | - | ![](/images/check.svg) |  |\n| PL/I | ![](/images/check.svg) | - | ![](/images/check.svg) |  |\n| Python | - | ![](/images/check.svg) | ![](/images/check.svg) |  |\n| RPG | - | ![](/images/check.svg) | ![](/images/check.svg) |  |\n| Ruby | - | - | ![](/images/check.svg) |  |\n| Scala | - | - | ![](/images/check.svg) |  |\n| Swift | - | - | ![](/images/check.svg) |  |\n| T-SQL | - | - | ![](/images/check.svg) |  |\n| VB.NET | - | - | ![](/images/check.svg) | ![](/images/check.svg)[Importing Issues from Third-Party Roslyn Analyzers (C#, VB.NET)](/analysis/external-issues/) |\n| VB6 | - | - | ![](/images/check.svg) |  |\n| XML | ![](/images/check.svg) | - | ![](/images/check.svg) |  |\n\n\n## Adding coding rules using Java\nWriting coding rules in Java is a six-step process:\n\n* Create a SonarQube plugin.\n* Put a dependency on the API of the language plugin for which you are writing coding rules.\n* Create as many custom rules as required.\n* Generate the SonarQube plugin (jar file).\n* Place this jar file in the SONARQUBE_HOME/extensions/plugins directory.\n* Restart SonarQube server.\n\nSee the following pages to see samples and details about how to create coding rules \n\n* [for COBOL](/analysis/languages/cobol/)\n* [for Java](/analysis/languages/java/)\n* [for PHP](/analysis/languages/php/)\n* [for Python](/analysis/languages/python/)\n* [for RPG](/analysis/languages/rpg/)\n\n\n## Adding coding rules using XPATH\n\nSonarQube provides a quick and easy way to add new coding rules directly via the web interface for certain languages using XPath 1.0 expressions. For XML, which is already immediately accessible to XPath, you can simply write your rules and check them using any of the [freely available tools](http://codebeautify.org/Xpath-Tester) for examining XPath on XML. If you\'re writing rules for XML, skip down to the Adding your rule to the server section once you\'ve got your rules written.\n\nFor other languages how to access a variable, for example, in XPath is less obvious, so we\'ve provided tools.\n\n### Writing an XPath Rule using SSLR Toolkit\nThe rules must be written in XPath (version 1.0) to navigate the language\'s [Abstract Syntax Tree](http://en.wikipedia.org/wiki/Abstract_syntax_tree) (AST). For most languages, an SSLR Toolkit is provided to help you navigate the AST. You need to download the `sslr-{language}-toolkit-{version}.jar` file corresponding to the version of your language plugin you have on your SonarQube instance.\n\nEach language\'s SSLR Toolkit is a standalone application that displays the AST for a piece of code source that you feed into it, allowing you to read the node names and attributes from your code sample and write your XPath expression. Knowing the XPath language is the only prerequisite, and there are a lot of tutorials on XPath online.\n\nThe latest version of SSLR Toolkit can be downloaded from following locations:\n\n* [Flex](https://binaries.sonarsource.com/Distribution/sonar-flex-plugin/)\n* [PL/SQL](https://binaries.sonarsource.com/CommercialDistribution/sslr-plsql-toolkit/)\n* [PL/I](https://binaries.sonarsource.com/CommercialDistribution/sslr-pli-toolkit/)\n\nFor an SSLR preview, consider the following source code sample:\n```\nfunction HelloWorld(hour) {\n  if (hour) {\n    this.hour = hour;\n  } else {\n    var date = new Date();\n    this.hour = date.getHours();\n  }\n  this.displayGreeting = function() {\n    if (this.hour >= 22 || this.hour <= 5)\n      document.write("Good night, World!");\n    else\n      document.write("Hello, World!");\n  } \n}\n```\nWhile parsing source code, SonarQube builds an Abstract Syntax Tree (AST) for it, and the SSLR Toolkit provided for each language will show you SonarQube\'s AST for a given piece of code. Here\'s the AST for our sample:\n\n![AST example](/images/astSample.png)\n\nThe [XPath](http://en.wikipedia.org/wiki/XPath) language provides a way to write coding rules by navigating this AST, and the SSLR Toolkit for the language will give you the ability to test your new rules against your sample code.\n\n### Adding your Rule to the Server\nOnce your new rule is written, you can add it SonarQube:\n\n1. Login as an Quality Profile Administrator\n1. Go to the Rules page\n1. Select the Language for which you want to create the XPath rule\n1. Tick the Template criterion and select "Show Templates Only" \n1. Look for the XPath rule template\n1. Click on it to select it, then use the interface controls to create a new instance\n1. Fill in the form that pops up\n1. Once you\'ve created your rule, you\'ll need to add it to a Quality Profile and run analysis to see it in action.\n\n\n## Coding rule guidelines\nThese are the guidelines that SonarSource uses internally to specify new rules. Rules in community plugins are not required to adhere to these guidelines. They are provided here only in case they are useful.\n\nNote that fields "title", "description" and "message" have a different format when the rule type is "Hotspot".\n\n### Guidelines applicable to all rules\n#### Code examples\nDo not give examples that make references to real companies or organizations:\n```\n$fp = file_get_contents("https://www.real-company.com"); \n```\n\nShould be replaced by a neutral website:\n```\n$fp = file_get_contents("https//www.example.com");\n// or even better:\n$fp = file_get_contents("https://localhost");\n```\n\n#### See/References\nWhen a reference is made to a standards specification, e.g. MISRA, the following steps must also be taken:\n\n* add any related tags such as security, bug, etc.\n* add the relevant standard-related tag/label such as cwe, misra, etc. (If you forget, the overnight automation will remember for you.) \n* update the appropriate field on the References tab with the cited id. (If you forget, the overnight automation will remember for you.) \n\nIf needed, references to other rules should be listed under a "See also" heading. If a "See" heading exists in the rule, then the "See also" title should be at the h3 level. Otherwise, use an h2 for it.\n\nOther rules should be linked to only if they are related or contradictory (such as a pair of rules about where `{` should go).\n\nWhy list references to other rules under "see also" instead of "see"? The see section is used to support the current rule, and one rule cannot be used as justification for another rule. \n\n#### Rule Type\nNow that you\'ve fleshed out the description, you should have a fairly clear idea of what type of rule this is, but to be explicit:\n\n**Bug** - Something that\'s wrong or potentially wrong. \n\n**Code Smell** - Something that will confuse a maintainer or cause her to stumble in her reading of the code.\n\n**Vulnerability** - Something that\'s wrong which impacts the application\'s security and therefore needs a fix.\n\n**Hotspot** - An optional protection is missing and the developer needs to do a review before deciding whether to apply a fix.\n\nSometimes the line between Bug and Code Smell is fuzzy. When in doubt, ask yourself: "Is code that breaks this rule doing what the programmer probably intended?" If the answer is "probably not" then it\'s a Bug. Everything else is a Code Smell. \n\nThe main differences between vulnerabilities and hotspots are explained on the [security-hotspots](/user-guide/security-hotspots/) page. During the specification of a rule, the following guidelines might also help:\n* The difficulty of exploiting a weakness should not be a criterion for specifying a hotspot or a vulnerability.\n* Vulnerabilities and hotspots should not overlap but can be related to the same subject. For example, with the hotspot [RSPEC-2077](https://jira.sonarsource.com/browse/RSPEC-2077), formatted SQL queries are highlighted and we recommend the use of *prepare statements* as an additional protection to prevent SQL-injection vulnerabilities ([RSPEC-3649](https://jira.sonarsource.com/browse/RSPEC-3649)).\n\n\n#### Default severities\nWhen assessing the default severity of a rule, the first thing to do is ask yourself "what\'s the worst thing that could happen?" In answering, you should factor in Murphy\'s Law without predicting Armageddon.\n\nOnce you have your answer, it\'s time to assess whether the Impact and Likelihood of the Worst Thing are High or Low. To do that, ask yourself these specific questions:\n\nVulnerability\n* Impact: Could the exploitation of the vulnerability result in significant damage to your assets or your users? (Yes = High)\n* Likelihood: What is the probability a hacker will be able to exploit it? what is the time to fix the issue?\n\nBug\n* Impact: Could the bug cause the application to crash or corrupt stored data?\n(Languages where an error can cause program termination: COBOL, Python, PL/SQL, RPG.) \n* Likelihood: What is the probability the worst will happen?\n\nCode Smell\n* Impact: Could the Code Smell lead a maintainer to introduce a bug?\n* Likelihood: What is the probability the worst will happen?\n\nOnce you have your Impact and Likelihood assessments, the rest is easy:\n\n&nbsp;| impact|likelihood\n---|---|---\nBlocker|![](/images/check.svg)|![](/images/check.svg)\nCritical|![](/images/check.svg)|![](/images/cross.svg)\nMajor|![](/images/cross.svg)|![](/images/check.svg)\nMinor|![](/images/cross.svg)|![](/images/cross.svg)\n\n#### Tags\nRules can have 0-n tags, although most rules should have at least one. Many of the common-across-languages tags are described in [the issues docs](/user-guide/issues/).\n\n#### Evaluation of the remediation cost\nFor most rules, the SQALE remediation cost is constant per issue. The goal of this section is to help define the value of this constant and to unify the way those estimations are done to prevent having some big discrepancies among language plugins. \n\nFirst, classify the effort to do the remediation:\n\n1. TRIVIAL\nNo need to understand the logic and no potential impact. \nExamples: remove unused imports, replace tabulations by spaces, remove call to System.out.println() used for debugging purpose, ...\n1. EASY\nNo need to understand the logic but potential impacts. \nExamples: rename a method, rename a parameter, remove unused private method, ...\n1. MEDIUM\nUnderstanding the logic of a piece of code is required before doing a little and easy refactoring (1 or 2 lines of code), but understanding the big picture is not required.\nExamples : CURSORs should not be declared inside a loop, EXAMINE statement should not be used, IF should be closed with END-IF, ...\n1. MAJOR\nUnderstanding the logic of a piece of code is required and it\'s up to the developer to define the remediation action.\nExamples: Too many nested IF statements, Methods should not have too many parameters, UNION should not be used in SQL SELECT statements, Public java method should have a javadoc, Avoid using deprecated methods, ...\n1. HIGH\nThe remediation action might lead to locally impact the design of the application.\nExamples: Classes should not have too many responsibilities, Cobol programs should not have too many lines of code, Architectural constraint, ...\n1. COMPLEX\nThe remediation action might lead to an impact on the overall design of the application.\nExamples: Avoid cycles between packages, ...\n\nThen use the following table to get the remediation cost according to the required remediation effort and to the language:\n\n&nbsp;|Trivial|Easy|Medium|Major|High|Complex\n---|---|---|---|---|---|---\nABAP, COBOL, ...| 10min | 20min | 30min | 1h | 3h | 1d \nOther languages| 5min |10min|20min|1h|3h|1d\n\nFor rules using either the "linear" or "linear with offset" remediation functions, the "Effort To Fix" field must be fed on each issue and this field is used to compute the remediation cost.  \n\n#### Issue location(s) and highlighting\nFor any given rule, highlighting behavior should be consistent across languages within the bounds of what\'s relevant for each language.\n\nWhen possible, each issue should be raised on the line of code that needs correction, with highlighting limited to the portion of the line to be corrected. For example:\n\n* an issue for a misnamed method should be raised on the line with the method name, and the method name itself should be highlighted.\n\nWhen correcting an issue requires action across multiple lines, the issue should be raised on the lowest block that encloses all relevant lines. For example an issue for:\n\n* method complexity should be raised on the method signature\n* method count in a class should be raised on the class declaration\n\nWhen an issue could be made clearer by highlighting multiple code segments, such as a method complexity issue, additional issue locations may be highlighted, and additional messages may optionally be logged for those locations. In general, these guidelines should be followed for secondary issue locations:\n\n* highlight the minimum code to show the line\'s contribution to the issue. \n* avoid using an additional message if the secondary location is likely to be on the same issue as the issue itself. For example: the rule "Parameters should be final" will raise an issue on the method name, and highlight each non-final parameter. Since all locations are likely to be on the same line, additional messages would only confuse the issue.\n* don\'t write a novel. The message for a secondary location is meant to be a hint to push the user in the right direction. Don\'t take over the interface with a narrative.\n\n\n### Guidelines for Bug, Vulnerability, and Code Smell rules\n#### Titles\n\n* The title of the rule should match the pattern "X should [ not ] Y" for most rules. Note that the "should [ not ]" pattern is too strong for Finding rules, which are about observations on the code. Finding titles should be neutral, such as "Track x".\n* All other things being equal, the positive form is preferred. E.G.\n   * "X should Y" is preferred to \n   * "X should not Z"\n* Titles should be written in plural form if at all possible. E.G.\n   * ![](/images/check.svg)Flibbers should gibbet\n   * ![](/images/cross.svg)A Flibber should gibbet\n* Any piece of code in the rule title should be double-quoted (and not single-quoted).\n* There should be no category/tag prefixed to the rule title, such as "Accessibility - Image tags should have an alternate text attribute"\n* Titles should be as concise as possible. Somewhere around 70 or 80 characters is an ideal maximum, although this is not always achievable.\n\nNoncompliant Title Examples:\n\n* File should not have too many lines of code  // Noncompliant; singular form used\n* Avoid file with too many lines of code  // Noncompliant; doesn\'t follow "x should [not] y" pattern\n* Too many lines of code  // Noncompliant\n* Don\'t use "System.(out/err)"  // Noncompliant\n* Parameters in an overriding virtual function should either use the same default arguments as the function they override, or not specify any default arguments  // Noncompliant; waaaay too long\n\nCompliant Solutions:\n\n* Files should not have too many lines of code  \n* "System.(out/err)" should not be used to log messages\n* Overriding virtual functions should not change parameter defaults\n\nStarting with the subject, such as "Files", will ensure that all rules applying to files will be grouped together.\n\n#### Descriptions\nRule descriptions should contain the following sections in the listed order:\n\n* **Rationale** (unlabeled) - explaining why this rule makes sense. \nIf it\'s not absolutely clear from the rationale what circumstances will cause an issue to be raised, then this section should end with "This rule raises an issue when \\[ insert circumstances here ]".\n* **Noncompliant Code Example** - providing some examples of issues\n   * Ideally, the examples should depend upon the default values of any parameters the rule has, and these default values should be mentioned before the code block. This is for the benefit of users whose rule parameters are tuned to something other than the default values. E.G.\nWith a parameter of: <code>*:.*log4j.*</code>\n   * The lines in these code samples where issues are expected should be marked with a "Noncompliant" comment\n   * "Compliant" comments may be used to help demonstrate the difference between what is and is not allowed by the rule\n   * It is acceptable to omit this section when demonstrating noncompliance would take too long, e.g. "Classes should not have too many lines of code"\n* **Compliant Solution** - demonstrating how to fix the previous issues. Good to have but not required for rules that detect bugs. \n   * There is no need to mark anything "Compliant" in the Compliant Solution; everything here is compliant by definition\n   * It is acceptable to omit this section when there are too many equally viable solutions.\n* **Exceptions** (optional) - listing and explaining some specific use cases where no issues are logged even though some might be expected. Note that this is sometimes incorporated into the rationale, instead.\n* **See** (optional) - listing references and/or links to external standards like MISRA, SEI, CERT, etc.\nDeprecated (optional): listing replacement rules with links\n\nCode samples for COBOL should be in upper case. \n\nWhen displayed in SonarQube, any code or keywords in the description should be enclosed in <code> tags. For descriptions written in JIRA, this means using double curly braces (`{{` and `}}`) to enclose such text. They will be translated in the final output.\n\n#### Messages\nIssue messages should contain the remediation message for bug and quality rules. For potential-bug rules, it should make it explicit that a manual review is required. It should be in the imperative mood ("Do x"), and therefore start with a verb.\n\nAn issue message should always end with a period (\'.\') since it is an actual sentence, unless it ends with a regular expression, in which case the regular expression should be preceded by a colon and should end the message.\n\nAny piece of code in the rule message should be double-quoted (and not single-quoted). Moreover, if an issue is triggered because a number was above a threshold value, then both the number and the threshold value should be mentioned in the issue message. \n\nSample messages:\n\n* Remove or refactor this useless "switch" statement. // Compliant\n* This "switch" statement is useless and should be refactored or removed. // Noncompliant\n* Every "switch" statement shall have at least one case-clause. // Noncompliant\n* Rename this variable to comply with the regular expression: [a-z]+  // Compliant\n\n[[collapse]]\n| ## Sample Specification\n| ### Generic exceptions should not be thrown\n|\n| Using generic exceptions such as `Error`, `RuntimeException`, `Throwable`, and `Exception` prevents calling methods from handling true, system-generated exceptions differently than application-generated errors.\n| \n| **Noncompliant Code Example**  \n| ```\n| With the default regular expression [a-z][a-zA-Z0-9]+:\n| \n| try { /* ... */ } catch (Exception e) { LOGGER.info("context"); } // Noncompliant; exception is lost\n| try { /* ... */ } catch (Exception e) { LOGGER.info(e); } // Noncompliant; context is required\n| try { /* ... */ } catch (Exception e) { LOGGER.info(e.getMessage()); } // Noncompliant; exception is lost (only message is preserved)\n| try {\n| /* ... */\n| } catch (Exception e) { // Noncompliant - exception is lost\n| throw new RuntimeException("context");\n| }\n| ```\n|\n| **Compliant Solution**  \n| ```\n| try { /* ... */ } catch (Exception e) { LOGGER.info("context", e); }\n| try {\n| /* ... */\n| } catch (Exception e) {\n| throw new RuntimeException("context", e);\n| }\n| ```\n| **Exceptions**  \n| Generic exceptions in the signatures of overriding methods are ignored.\n| ```\n| @Override\n| public void myMethod() throws Exception {...}\n| ```\n| **See**  \n| * MISRA C:2004, 4.5.2\n| * MITRE, [CWE-580](http://cwe.mitre.org/data/definitions/580.html) - clone() Method Without super.clone()\n|\n| **See also**  \n| S4567 - Rule title here\n\n### Guidelines for Hotspot rules\n\nSee [RSPEC-2092](https://jira.sonarsource.com/browse/RSPEC-2092) for an example of Hotspot rule.\n\n#### Titles\n* The title should start with a verb in the present participle form (-ing)\n* The title should end with "is security-sensitive"\n\nNoncompliant Title Examples:\n\n* Avoid creation of cookies without the "secure" flag\n\nCompliant Solution:\n\n* Creating cookies without the "secure" flag is security-sensitive\n\n#### Descriptions\nRule descriptions should contain the following sections in the listed order:\n\n* **Rationale** (unlabeled) - explaining why this rule makes sense.\n   * It starts with a copy of the title. The "is security sensitive" part can be replaced with "can lead to ...<DESCRIBE RISK>" when there is one risk and it is easy to describe in a short manner.\n* **Ask Yourself Whether** - set of questions that the developer should ask herself/himself.\n   * Those questions should help the developer to decide whether or not a missing protection has to be implemented based on the context of the application.\nFor example, if the highlighted missing protection (such as secure cookie flag) helps protect a bit against MITM attacks, list all mandatory protections that, at the contrary, greatly lower this risk (such as encryption). At the end of the review, the developer should be sure that in its context the implementation of this protection improves the overall application\'s security.  \n   * The hotspot-review should be done by developers by themselves without external help:\n      * It is not recommended to drive the review with **data sensitivity** (eg: "*if this data/feature/component is sensitive there is risk*") because this concept is too generic and the use of the application (with ou without sensitive data) may vary over time and cannot be controlled by developers.\n      * It is not recommended to highlight a widely-used technology (weak in some contexts) when its replacement can only be done with such significant changes (eg: a new authentication system or a different database engine) that it would block developers who may not be responsible for the architecture of the application.\n   * This section ends with "There is a risk if you answered yes to any of those questions.".\n* **Recommended Secure Coding Practices** - describing all the ways to mitigate the risk.\n   * This part can be easily translated by a developer into examples of implementation/source code, if the recommendations are too abstract the developer will not be able to imagine the fix and decide whether to implement it.\n* The following parts are mandatory in RSPEC language-specification:\n   * **Sensitive Code Example** - Same as "Noncompliant code example" for Bug, Vulnerability, and Code Smell rules.\n   * **Compliant Solution** - same as for Bug, Vulnerability, and Code Smell rules.\n\n* **See** (optional) -  same as for Bug, Vulnerability and Code Smell rules.\n* **Deprecated** (optional) -  listing replacement rules with links.\n\nGuidelines regarding COBOL, keywords and code are the same as for other rules.\n\n#### Messages\nMost of the time you can paraphrase the title:\n* start the sentence with "Make sure that"\n* replace "is security-sensitive" with "is safe here"\n\nExamples:\n   * Make sure creating this cookie without the "secure" flag is safe. \n'},{path:"extend/adding-scm",content:'---\ntitle: Supporting SCM Providers\nurl: /extend/adding-scm/\n---\nSonarQube Scanner uses information from the project\'s SCM, if available, to:\n\n* Assign a new issue to the person who introduced it. The last committer on the related line of code is considered to be the author of the issue. \n* Estimate the coverage on New Code, including added and changed code since in your New Code.\n* Display the most recent commit on each line the code viewer.\n![Commit info is available from the margin of the code viewer](/images/commit-info-in-code-viewer.png)\n\nThe only required SCM command is "blame", which gets the last committer of each line for a given file. This command is executed by a SonarQube plugin through the extension point  org.sonar.api.batch.scm.ScmProvider. See the multiple existing plugins, for instance [Git](https://docs.sonarqube.org/8.9/analysis/scm-integration/), for more details.\n'},{path:"extend/contributing",content:"---\ntitle: Contributing\nurl: /extend/contributing/\n---\n\nPlease be aware that we are not actively looking for feature contributions to SonarQube itself because it's extremely difficult for someone outside SonarSource to comply with our roadmap and expectations. Therefore, we typically only accept minor cosmetic changes and typo fixes for SonarQube, but we do happily welcome contributions to the other open source projects under the SonarSource umbrella. \n\n\n## General guidelines\n* Choose an open ticket in [JIRA](https://jira.sonarsource.com/secure/Dashboard.jspa) or propose your change on the [SonarQube Community Forum](https://community.sonarsource.com) - the discussion there is likely to result in an open JIRA ticket. ;-)\n* Use the SonarSource conventions, which you'll find neatly packaged here: https://github.com/SonarSource/sonar-developer-toolset#the-almost-unbreakable-build\n* Use pull requests to submit your work\n\n## New rule implementations in existing plugins\n* Start from an existing [RSpec](https://jira.sonarsource.com/browse/RSPEC-1973?filter=10375) (Rule Specification) that lists your language of interest in the \"Targeted languages\" field. \n   * If the RSpec you're interested in doesn't target the language where you want to implement it, raise the question on the Community Forums .\n   * If no RSpec exists for the rule you want to implement, raise the question on the [Community Forum](https://community.sonarsource.com/).\n* Put your rule implementation class in the [language]-checks (e.g. java-checks, javascript-checks, &etc.) module, in the checks sub-package\n* The naming convention for implementation classes is [A-Z][A-Za-z]+Check.java. (Yes, put \"Check\" in the name too.) The class name should be descriptive and not reflect the rule key. E.G. FindBadCodeCheck.java, not S007.java.\n* A good way to get started on a rule implementation is to look at the implementations of rules that do similar things.\n* During development there's no need to load the plugin in a server to test your implementation, use the rule's unit test for that.\n* For a complete implementation, make sure all of the following are done:\n   * create HTML description file and metadata file\n   * write test class\n   * register the rule in CheckList.java\n   * add the rule to the profile used for the integration test in `profile.xml`\n   * run the integration test and add any new issues to the set of expected issues \n"},{path:"extend/developing-plugin",content:'---\ntitle: Plugin basics\nurl: /extend/developing-plugin/\n---\n\n## Building your plugin\n\n### Prerequisites\nTo build a plugin, you need Java 8 and Maven 3.1 (or greater). Gradle can also be used thanks to https://github.com/iwarapter/gradle-sonar-packaging-plugin. Note that this Gradle plugin is not officially supported by SonarSource.\n\n### Create a Maven Project\nThe recommended way to start is by duplicating the plugin example project: https://github.com/SonarSource/sonar-custom-plugin-example.\n\nIf you want to start the project from scratch, use the following Maven pom.xml template:\n\n[[collapse]]\n| ## pom.xml\n| ```\n| <?xml version="1.0" encoding="UTF-8"?>\n| <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n|   <modelVersion>4.0.0</modelVersion>\n|   <groupId>YOUR_GROUP_ID</groupId>\n|   \x3c!-- it\'s recommended to follow the pattern "sonar-{key}-plugin", for example "sonar-myphp-plugin" --\x3e\n|   <artifactId>YOUR_ARTIFACT_ID</artifactId>\n|   <version>YOUR_VERSION</version>\n|   \n|   \x3c!-- this is important for sonar-packaging-maven-plugin --\x3e\n|   <packaging>sonar-plugin</packaging>\n|  \n|   <dependencies>\n|     <dependency>\n|       <groupId>org.sonarsource.sonarqube</groupId>\n|       <artifactId>sonar-plugin-api</artifactId>\n|       \x3c!-- minimal version of SonarQube to support. --\x3e\n|       <version>6.7</version>\n|       \x3c!-- mandatory scope --\x3e\n|       <scope>provided</scope>\n|     </dependency>\n|   </dependencies>\n|  \n|   <build>\n|     <plugins>\n|       <plugin>\n|         <groupId>org.sonarsource.sonar-packaging-maven-plugin</groupId>\n|         <artifactId>sonar-packaging-maven-plugin</artifactId>\n|         <version>1.18.0.372</version>\n|         <extensions>true</extensions>\n|         <configuration>\n|           \x3c!-- the entry-point class that extends org.sonar.api.SonarPlugin --\x3e\n|           <pluginClass>com.mycompany.sonar.reference.ExamplePlugin</pluginClass>\n|            \n|           \x3c!-- advanced properties can be set here. See paragraph "Advanced Build Properties". --\x3e\n|         </configuration>\n|       </plugin>\n|     </plugins>\n|   </build>\n| </project>\n| ```\n\n### Build\nTo build your plugin project, execute this command from the project root directory:  \n`mvn clean package`  \nThe plugin jar file is generated in the project\'s `target/` directory.\n\n### Deploy\n**"Cold" Deploy**  \nThe standard way to install the plugin for regular users is to copy the JAR artifact, from the `target/` directory  to the `extensions/plugins/` directory of your SonarQube installation then start the server. The file `logs/web.log` will then contain a log line similar to:  \n`Deploy plugin Example Plugin / 0.1-SNAPSHOT`  \nScanner extensions such as sensors are immediately retrieved and loaded when scanning source code. \n\n### Debug\n**Debugging web server extensions**  \n\n1. Edit conf/sonar.properties and set: `sonar.web.javaAdditionalOpts=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000`\n1. Install your plugin by copying its JAR file to extensions/plugins\n1. Start the server. The line `Listening for transport dt_socket at address: 5005` is logged in  `logs/sonar.log`.\n1. Attach your IDE to the debug process (listening on port 8000 in the example)\n\n**Debugging compute engine extensions**  \nSame procedure as for web server extensions (see previous paragraph), but with the property: `sonar.ce.javaAdditionalOpts=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000`\n\n**Debugging scanner extensions**  \n```\nexport SONAR_SCANNER_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000"\ncd /path/to/project\nsonar-scanner \n```\nWhen using the Scanner for Maven, then simply execute:\n```\ncd /path/to/project\nmvnDebug sonar:sonar\n# debug port is 8000\n```\n\n### Advanced Build Properties\nPlugin properties are defined in the file `META-INF/MANIFEST.MF` of the plugin .jar file.\n\nMost of them are defined through the `<configuration>` section of the [sonar-packaging-maven-plugin](https://jira.sonarsource.com/browse/PACKMP). Some are taken from standard pom nodes Effective values are listed at the end of the build log:\n```\n[INFO] --- sonar-packaging-maven-plugin:1.15:sonar-plugin (default-sonar-plugin) @ sonar-widget-lab-plugin ---\n[INFO] -------------------------------------------------------\n[INFO] Plugin definition in Marketplace\n[INFO]     Key: widgetlab\n[INFO]     Name: Widget Lab\n[INFO]     Description: Additional widgets\n[INFO]     Version: 1.9-SNAPSHOT\n[INFO]     Entry-point Class: org.codehaus.sonar.plugins.widgetlab.WidgetLabPlugin\n[INFO]     Required Plugins:\n[INFO]     Use Child-first ClassLoader: false\n[INFO]     Base Plugin:\n[INFO]     Homepage URL: https://redirect.sonarsource.com/plugins/widgetlab.html\n[INFO]     Minimal SonarQube Version: 4.5.1\n[INFO]     Licensing: GNU LGPL 3\n[INFO]     Organization: Shaw Industries\n[INFO]     Organization URL: http://shawfloors.com\n[INFO]     Terms and Conditions:\n[INFO]     Issue Tracker URL: http://jira.codehaus.org/browse/SONARWIDLB\n[INFO]     Build date: 2015-12-15T18:28:54+0100\n[INFO]     Sources URL: https://github.com/SonarCommunity/sonar-widget-lab\n[INFO]     Developers: G. Ann Campbell,Patroklos Papapetrou\n[INFO] -------------------------------------------------------\n[INFO] Building jar: /dev/sonar-widget-lab/target/sonar-widget-lab-plugin-1.9-SNAPSHOT.jar \n```\n\nSupported standard pom node properties:\n\nMaven Property|Manifest Key|Notes\n---|---|---\n`version` | Plugin-Version | (required) Plugin version as displayed in page "Marketplace". Default: ${project.version}\n- | Sonar-Version | (required) Minimal version of supported SonarQube at runtime. For example if value is 5.2, then deploying the plugin on versions 5.1 and lower will fail. Default value is given by the version of sonar-plugin-api dependency. It can be overridden with the Maven property sonarQubeMinVersion (since sonar-packaging-maven-plugin 1.16). That allows in some cases to use new features of recent API and to still be compatible at runtime with older versions of SonarQube. Default: version of dependency sonar-plugin-api\n`license` | Plugin-License | Plugin license as displayed in page "Marketplace". Default `${project.licenses}`\n`developers` | Plugin-Developers | List of developers displayed in page "Marketplace". Default: `${project.developers}`\n\nSupported `<configuration>` properties:\n\nMaven Property|Manifest Key|Notes\n---|---|---\n`pluginKey` | Plugin-Key | (required) Contains only letters/digits and is unique among all plugins. Examples: groovy, widgetlab. Constructed from `${project.artifactId}.` Given an artifactId of: `sonar-widget-lab-plugin`, your pluginKey will be: `widgetlab`\n`pluginClass` | Plugin-Class | (required) Name of the entry-point class that extends `org.sonar.api.SonarPlugin`. Example: `org.codehaus.sonar.plugins.widgetlab.WidgetLabPlugin` \n`pluginName` | Plugin-Name | (required) Displayed in the page "Marketplace". Default: `${project.name}`\n`pluginDescription` | Plugin-Description | Displayed in the page "Marketplace". Default: `${project.description}`\n`pluginUrl` |  Plugin-Homepage | Homepage of website, for example https://github.com/SonarQubeCommunity/sonar-widget-lab `${project.url}`\n`pluginIssueTrackerUrl` |  Plugin-IssueTrackerUrl | Example: https://github.com/SonarQubeCommunity/sonar-widget-lab/issues. Default: `${project.issueManagement.url}`\n`pluginTermsConditionsUrl`  |  Plugin-TermsConditionsUrl | Users must read this document when installing the plugin from Marketplace. Default: `${sonar.pluginTermsConditionsUrl}`\n`useChildFirstClassLoader` | Plugin-ChildFirstClassLoader | Each plugin is executed in an isolated classloader, which inherits a shared classloader that contains API and some other classes. By default the loading strategy of classes is parent-first (look up in shared classloader then in plugin classloader). If the property is true, then the strategy is child-first. This property is mainly used when building plugin against API < 5.2, as the shared classloader contained many 3rd party libraries (guava 10, commons-lang, ...) false\n`basePlugin` | Plugin-Base | If specified, then the plugin is executed in the same classloader as basePlugin.\n`pluginSourcesUrl` | Plugin-SourcesUrl | URL of SCM repository for open-source plugins. Displayed in page "Marketplace". Default: `${project.scm.url}`\n`pluginOrganizationName` | Plugin-Organization | Organization which develops the plugin, displayed in the page "Marketplace". Default: `${project.organization.name}`\n`pluginOrganizationUrl` | Plugin-OrganizationUrl | URL of the organization, displayed in the page "Marketplace". Default: `${project.organization.url}`\n`sonarLintSupported` | SonarLint-Supported | Whether the language plugin supports SonarLint or not. Only SonarSource analyzers and custom rules plugins for SonarSource analyzers should set this to true. \n`pluginDisplayVersion` | Plugin-Display-Version | The version as displayed in SonarQube administration console. By default it\'s the raw version, for example "1.2", but can be overridden to "1.2 (build 12345)" for instance. Supported in sonar-packaging-maven-plugin 1.18.0.372. Default: `${project.version}`\n\n\nThe Maven sonar-packaging-maven-plugin supports also these properties:\n\nMaven Property|Manifest Key|Notes\n---|---|---\n`addMavenDescriptor` |Copy pom file inside the directory META-INF of generated JAR file? | Boolean. Default: `${sonar.addMavenDescriptor}` / `true`.\n`skipDependenciesPackaging` | Do not copy Maven dependencies into JAR file. | Default: `${sonar.skipDependenciesPackaging} / `false`.\n\nOther Manifest fields:  \n\n* `Implementation-Build` - Identifier of build or commit, for example the Git sha1 "94638028f0099de59f769cdca776e506684235d6". It is displayed for debugging purpose in logs when SonarQube server starts.\n\n## API basics\n\n### Extension points\nSonarQube provides extension points for its three technical stacks:\n\n* Scanner, which runs the source code analysis\n* Compute Engine, which consolidates the output of scanners, for example by \n   * computing 2nd-level measures such as ratings\n   * aggregating measures (for example number of lines of code of project = sum of lines of code of all files)\n   * assigning new issues to developers\n   * persisting everything in data stores\n* Web application\n\nExtension points are not designed to add new features but to complete existing features. Technically they are contracts defined by a Java interface or an abstract class annotated with @ExtensionPoint. The exhaustive list of extension points is available in the javadoc.\n\nThe implementations of extension points (named "extensions") provided by a plugin must be declared in its entry point class, which implements org.sonar.api.Plugin and which is referenced in pom.xml:\n\nExamplePlugin.java\n```\npackage org.sonarqube.plugins.example;\nimport org.sonar.api.Plugin;\n \npublic class ExamplePlugin implements Plugin {\n  @Override\n  public void define(Context context) {\n    // implementations of extension points\n    context.addExtensions(FooLanguage.class, ExampleProperties.class);\n  }\n}\n```\npom.xml\n```\n<?xml version="1.0" encoding="UTF-8"?>\n<project>\n  ...\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.sonarsource.sonar-packaging-maven-plugin</groupId>\n        <artifactId>sonar-packaging-maven-plugin</artifactId>\n        <extensions>true</extensions>\n        <configuration>\n          <pluginClass>org.sonarqube.plugins.example.ExamplePlugin</pluginClass>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n</project>\n```\n### Lifecycle\nA plugin extension exists only in its associated technical stacks. A scanner sensor is for example instantiated and executed only in a scanner runtime, but not in the web server nor in Compute Engine. The stack is defined by the annotations [@ScannerSide](http://javadocs.sonarsource.org/latest/apidocs/org/sonar/api/batch/ScannerSide.html), [@ServerSide](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/server/ServerSide.html) (for web server) and [@ComputeEngineSide](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/ce/ComputeEngineSide.html). \n\nAn extension can call core components or another extension of the same stack. These dependencies are defined by constructor injection:\n\n```\n@ScannerSide\npublic class Foo {\n  public void call() {}\n}\n \n// Sensor is a scanner extension point \npublic class MySensor implements Sensor {\n  private final Foo foo;\n  private final Languages languages;\n  \n  // Languages is core component which lists all the supported programming languages.\n  public MySensor(Foo foo, Languages languages) {   \n    this.foo = foo;\n    this.languages = languages;\n  }\n  \n  @Override\n  public void execute(SensorContext context) {\n    System.out.println(this.languages.all());\n    foo.call();\n  }\n}\n \n  \npublic class ExamplePlugin implements Plugin {\n  @Override\n  public void define(Context context) {\n    // Languages is a core component. It must not be declared by plugins.\n    context.addExtensions(Foo.class, MySensor.class);\n  }\n}\n```\n\nIt is recommended not to call other components in constructors. Indeed, they may not be initialized at that time. Constructors should only be used for dependency injection.\n\n[[warning]]\n| Compilation does not fail if incorrect dependencies are defined, such as a scanner extension trying to call a web server extension. Still it will fail at runtime when plugin is loaded.\n\n### Third-party Libraries\nPlugins are executed in their own isolated classloaders. That allows the packaging and use of 3rd-party libraries without runtime conflicts with core internal libraries or other plugins. Note that since version 5.2, the SonarQube API does not bring transitive dependencies, except SLF4J. The libraries just have to be declared in the pom.xml with default scope "compile":\n\npom.xml\n```\n<?xml version="1.0" encoding="UTF-8"?>\n<project>\n  ...\n  <dependencies>\n    ...\n    <dependency>\n      <groupId>commons-codec</groupId>\n      <artifactId>commons-codec</artifactId>\n      <version>1.10</version>\n    </dependency>\n </dependencies>\n</project>\n```\nTechnically the libraries are packaged in the directory META-INF/lib of the generated JAR file. An alternative is to shade libraries, for example with maven-shade-plugin. That minimizes the size of the plugin .jar file by copying only the effective used classes.\n\n[[info]]\n| The command `mvn dependency:tree` gives the list of all dependencies, including transitive ones.\n\n### Configuration\nThe core component [`org.sonar.api.config.Configuration`](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/config/Configuration.html) provides access to configuration. It deals with default values and decryption of values. It is available in all stacks (scanner, web server, Compute Engine). As recommended earlier, it must not be called from constructors.\n\nMyExtension.java\n```\npublic class MyRules implements RulesDefinition {\n  private final Configuration config;\n  \n  public MyRules(Configuration config) {   \n    this.config = config; \n  }\n  \n  @Override\n  public void define(Context context) {\n    int value = config.getInt("sonar.property").orElse(0);\n  }\n}\n```\nScanner sensors can get config directly from SensorContext, without using constructor injection:\n\nMySensor.java\n```\npublic class MySensor extends Sensor {\n  @Override\n  public void execute(SensorContext context) {\n    int value = context.config().getInt("sonar.property").orElse(0);\n  }\n}\n```\n\nIn the scanner stack, properties are checked in the following order, and the first non-blank value is the one that is used:\n\n1. System property\n1. Scanner command-line (-Dsonar.property=foo for instance)\n1. Scanner tool (<properties> of scanner for Maven for instance) \n1. Project configuration defined in the web UI \n1. Global configuration defined in the web UI \n1. Default value\n\nPlugins can define their own properties so that they can be configured from web administration console. The extension point org.sonar.api.config.PropertyDefinition must be used :\n```\npublic class ExamplePlugin implements Plugin {\n  @Override\n  public void define(Context context) {\n    context.addExtension(\n      PropertyDefinition.builder("sonar.my.property")\n       .name("My Property")\n       .description("This is the description displayed in web admin console")\n       .defaultValue("42")\n       .build()\n    );\n  }\n}\n```\n\n[[info]]\n| Values of the properties suffixed with `.secured` are not available to non-authorized users (anonymous and users without project or global administration rights). `.secured` is needed for passwords, for instance.\n\nThe annotation [`@org.sonar.api.Property`](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/Property.html) can also be used on an extension to declare a property, but org.sonar.api.config.PropertyDefinition is preferred.\n```\n@Properties(\n    @Property(key="sonar.my.property", name="My Property", defaultValue="42")\n)\npublic class MySensor implements Sensor {\n  // ...\n}\n  \npublic class ExamplePlugin implements Plugin {\n  @Override\n  public void define(Context context) {\n    context.addExtension(MySensor.class);\n  }\n}\n```\n\n### Logging\nThe class [`org.sonar.api.utils.log.Logger`](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/utils/log/Logger.html) is used to log messages to scanner output, web server logs/sonar.log, or Compute Engine logs (available from administration web console). It\'s convenient for unit testing (see class [`LogTester`](http://javadocs.sonarsource.org/latest/apidocs/index.html?org/sonar/api/utils/log/LogTester.html)).\n```\nimport org.sonar.api.utils.log.*;\npublic class MyClass {\n  private static final Logger LOGGER = Loggers.get(MyClass.class);\n \n  public void doSomething() {\n    LOGGER.info("foo");\n  }\n}\n```\nInternally [SLF4J](http://www.slf4j.org/) is used as a facade of various logging frameworks (log4j, commons-log, logback, java.util.logging). That allows all these frameworks to work at runtime, such as when they are required for a 3rd party library. SLF4J loggers can also be used instead of org.sonar.api.utils.log.Logger. Read the [SLF4J manual](http://www.slf4j.org/manual.html) for more details.\n\nAs an exception, plugins must not package logging libraries. Dependencies like SLF4J or log4j must be declared with scope "provided".\n\n### Exposing APIs to Other Plugins\nThe common use case is to write a language plugin that will allow some other plugins to contribute additional rules (see for example how it is done for [Java](https://github.com/SonarSource/sonar-java) analysis). The main plugin will expose some APIs that will be implemented/used by the "rule" plugins.\n\nPlugins are loaded in isolated classloaders. It means a plugin can\'t access another plugin\'s classes. There is an exception for package names following pattern `org.sonar.plugins.<pluginKey>.api`. For example all classes in a plugin with the key myplugin that are located in `org.sonar.plugins.myplugin.api` are visible to other plugins.\n\n### Serving Static Resources\nIf you need to serve static resources from your plugin such as images or JavaScript files, place them in a directory under `resources` named `static` (`myplugin/src/main/resources/static`). At runtime they\'ll be available from `http://{server}/static/{pluginKey}/{file}`. \n\n\n## Versioning and API Deprecation\n### Versioning Strategy\nThe goal of this versioning strategy is both to:\n\n* Release often, release early in order to get quick feedback from the SonarQube community\n* Release stable versions of the SonarQube platform for companies whose main priority is to set up a very stable environment. Even if the price for such stable environments is missing out on the latest, sexy SonarQube features\n* Support the API deprecation strategy (see next section)\n\nThe rules are:\n\n* Each ~two months a new version of SonarQube is released. This version should increment the minor digit of the previous version (ex: 4.2 -> 4.3)\n* After three (or more) releases, a bug-fix version is released, and becomes the new LTS. The major digit of the subsequent version is incremented to start a new cycle (ex: 5.6 -> 6.0)\n\nAnd here is the strategy in action:\n```\n4.4 -> 4.5 -> 5.0 -> 5.1 -> 5.2 -> ... -> 5.5 -> 6.0 -> ...     <- New release every ~2 months\n        |                                  |\n      4.5.1 -> 4.5.2 -> ...              5.5.1 -> 5.5.2 -> ...  <- New LTS\n```\n\n### API Deprecation Strategy\nThe goal of this deprecation strategy is to make sure that deprecated APIs will be dropped without side-effects at a given planned date. The expected consequence of such strategy is to ease the evolution of the SonarQube API by making such refactoring painless.\n\nThe rules are:\n\n* An API must be deprecated before being dropped\n* A deprecated API must be fully supported until its drop (For instance the implementation of a deprecated method can\'t be replaced by `throw new UnsupportedOperationException())`\n* If an API is deprecated in version X.Y, this API will be dropped in version (X+2).0. Example: an API deprecated in 4.1 is supported in 4.2, 4.3, 5.0, 5.1, 5.2, 5.3 and is dropped in version 6.0.\n* According to the versioning strategy, that means that an API can remain deprecated before being dropped during 6 to 12 months.\n* Any release of a SonarQube plugin must at least depend on the latest LTS version of the SonarQube API\n* For each SonarQube plugin there must at least one release on each LTS version of SonarQube, which means at least one release each 6 months.\n* No use of deprecated APIs is accepted when releasing a plugin. It raises a critical issue in SonarQube analysis. This issue can\'t be postponed.\n* No deprecated API introduced 2 major versions ago is accepted when releasing SonarQube. It raises a critical issue in SonarQube analysis. This issue can\'t be postponed.\n* An API is marked as deprecated with both:\n   * the annotation @Deprecated\n   * the javadoc tag @deprecated whose message must start with "in x.y", for example:\n   \n    ```\n    /**\n     * @deprecated in 4.2. Replaced by {@link #newMethod()}.\n     */\n    @Deprecated\n    public void foo() {\n    ```\n\n## API Changes\n\n### Release 8.4\n![](/images/check.svg) Added\n* `org.sonar.api.batch.scm.ScmProvider#forkDate`\n\n![](/images/exclamation.svg) Deprecated\n* `org.sonar.api.rules.Rule#getId()` is deprecated and will always throw UnsupportedOperationException.\n\n### Release 8.3\n![](/images/exclamation.svg) Deprecated\n* `org.sonar.api.utils.text.JsonWriter`\n\n### Release 8.2\nNo changes\n\n### Release 8.1\nNo changes\n\n### Release 8.0\nNo changes\n \n### Release 7.9\nNo changes\n\n### Release 7.8\n\n![](/images/check.svg) Added\n* `org.sonar.api.web.WebAnalytics`\n\n![](/images/exclamation.svg) Deprecated\n* `org.sonar.api.i18n.I18`\n* `org.sonar.api.SonarQubeVersion` use `org.sonar.api.SonarRuntime` instead\n* `org.sonar.api.profiles.XMLProfileParser`\n* `org.sonar.api.notifications.NotificationChannel`\n\n![](/images/cross.svg) Removed\n* Pico components relying on reflection to have their `start` or `stop` method called. Make your component implements `org.sonar.api.Startable` instead.\n\n### Release 7.7\n\n![](/images/check.svg) Added\n* ` org.sonar.api.batch.scm.ScmProvider#ignoreCommand`\n\n![](/images/exclamation.svg) Deprecated\n* `org.sonar.api.batch.fs.InputFile::status`\n* `org.sonar.api.resources.Qualifiers#BRC`\n\n![](/images/cross.svg) Removed\n* The preview/issues mode of scanner has been removed\n\n### Release 7.6\n\n![](/images/info.svg) Changed\n\n* `PostJob` moved to project level IoC container\n* `InputFileFilter` moved to project level IoC container\n\n![](/images/check.svg) Added\n\n* New annotation `org.sonar.api.scanner.ScannerSide` to mark (project level) scanner components\n* `org.sonar.api.batch.fs.InputProject` to create issues on project\n* `org.sonar.api.scanner.ProjectSensor` to declare Sensors that only run at project level\n\n![](/images/exclamation.svg) Deprecated\n\n* `org.sonar.scanner.issue.IssueFilter` deprecated\n* `org.sonar.api.batch.InstantiationStrategy` deprecated\n* `org.sonar.api.batch.ScannerSide` deprecated\n* `org.sonar.api.batch.fs.InputModule` deprecated\n* Concept of global Sensor is deprecated (use `ProjectSensor` instead)\n\n![](/images/cross.svg) Removed\n\n* Support of scanner tasks was removed\n* `RulesProfile` is no longer available for scanner side components (use `ActiveRules` instead)\n\n### Release 7.5\nNo changes\n\n### Release 7.4\n![](/images/info.svg) Changed\n\n* Allow identity provider to not provide login\n\n![](/images/check.svg) Added\n\n* Allow sensors to report adhoc rules metadata\n\n![](/images/cross.svg) Removed\n\n* `org.sonar.api.rules.RuleFinder` removed from scanner side\n* `sonar-channel` removed from plugin classloader\n* stop support of plugins compiled with API < 5.2\n\n### Release 7.3\n\n![](/images/check.svg) Added\n\n* `RulesDefinitions` supports HotSpots and security standards\n\n![](/images/exclamation.svg) Deprecated\n* `org.sonar.api.batch.AnalysisMode` and `org.sonar.api.issue.ProjectIssues` since preview mode is already deprecated for a while\n\n### Release 7.2\n![](/images/check.svg) Added\n* `org.sonar.api.batch.sensor.SensorContext#newExternalIssue` to report external issues\n* `org.sonar.api.batch.sensor.SensorContext#newSignificantCode` to report part of the source file that should be used for issue tracking\n* `org.sonar.api.scan.issue.filter.FilterableIssue#textRange`\n\n![](/images/exclamation.svg) Deprecated\n* org.sonar.api.scan.issue.filter.FilterableIssue#line\n\n### Release 7.1\n![](/images/check.svg) Added\n* `org.sonar.api.Plugin.Context#getBootConfiguration`\n* `org.sonar.api.server.rule.RulesDefinition.NewRule#addDeprecatedRuleKey` to support deprecated rule keys\n\n### Release 7.0\n![](/images/check.svg) Added\n* `org.sonar.api.batch.scm.ScmProvider#relativePathFromScmRoot`, `org.sonar.api.batch.scm.ScmProvider#branchChangedFiles` and `org.sonar.api.batch.scm.ScmProvider#revisionId` to improve branch and PR support\n\n### Release 6.7\nNo changes\n'},{path:"extend/executable-lines",content:'---\ntitle: Executable Lines\nurl: /extend/executable-lines/\n---\n \nThese are the guidelines that SonarSource uses internally when defining executable lines for a language. Community plugins are not required to adhere to these guidelines. They are provided here only in case they are useful.\n\n## Things that are executable\nExecutable lines data is used to calculate missing test coverage for files that are not included in coverage reports. Ideally, executable line counts will be at or just under what coverage engines would calculate.\n\nGenerally, each line containing a statement should count as an executable line, with the exception that compound statements ({}) are ignored, although their contents are not\n\nSo:\n```\nvoid doTheThing ()        // +0\n{                         // +0\n  String fname="Finn";    // +1\n  etc();                  // +1\n}                         // +0\n```\n\n## Things that are ignored\n### !Statement: +0 \nSince some coverage engines mark these things as executable, it\'s worth stating explicitly that we will ignore them:\n\n* lines containing only punctuation: }, });, ;\n* the method signature of a method definition\n\n### Imports, Declarations: +0\nImports, package and namespace statements, declarations, and a few other things demonstrated below are ignored, \n```\npackage foo;     // +0\nnamespace bar {  // +0\n  ...\n}\n  \nimport java.util.ArrayList;  // +0\n#include <stdio>             // +0\n  \npublic interface FooFace {  // +0\n  void doFoo();             // +0\n}\npublic class Foo1 implements FooFace {  // +0\n  private String name;                  // +0\n}\nstruct PairWithOperator { // +0\n  int x;                  // +0\n  int y;                  // +0\n  \n  bool operator==(PairWithOperator rhs) const {  // +0\n    return x == rhs.x && y == rhs.y;             // +1\n  }\n}\n  \nclass C {\n  C(const C&) =default;  // +0 (explicit inheritance of parent method)\n}\n \nusing Vec = std::vector<T,MyAllocator<T>>;       // +0\n  \nstatic {                 // +0\n  ...\n}\n \n01  ERROR-MESSAGE.                                      *> +0\n        02  ERROR-TEXT  PIC X(132) OCCURS 10 TIMES      *> +0\n                                   INDEXED BY ERROR-INDEX.\n77  ERROR-TEXT-LEN      PIC S9(9)  COMP VALUE +132.     *> +0\n```\n\n### Location\nThe presence of executable code on a line makes the entire line executable.\n\nIf a statement is split over multiple lines, the line to be marked executable is the first one with executable code. \nGiven that a for loop is considered executable:\n```\nfor         // +1\n  (         // +0\n   int i=0; // +0\n   i < 10;  // +0\n   i++      // +0\n  )         // +0\n{           // +0\n}\n```\nRegardless of the number of lines across which nested statements are spread, the executable line count should only be incremented by one, since typically the execution of one naturally follows from the other. \n\n```\nfoo(1, bar());  // +1\n  \nfoo(1,          // +1\n    bar());     // +0\n```\nWe ignore here the possibility that `bar()` could throw an exception, preventing `foo` from being executed.\n\n## Exceptions\n### Python\nBased on observations from code on SonarCloud, `# pragma: no cover` exempts a block from coverage\n\n![# pragma: no cover example](/images/executable-lines-python-exception.png)\n\n### JavaScript\nIt seems to be accepted practice in JavaScript to mark variable declarations executable, so we will too. E.G.\n```\nvar a;  // +1\n```\n'},{path:"extend/extend-web-app",content:'---\ntitle: Adding pages to the webapp\nurl: /extend/extend-web-app/\n---\nSonarQube\'s UI is built as a Single Page Application using [React](https://reactjs.org/). It provides the ability to add a new pages to the UI using JavaScript. A page (or page extension) is a self-contained JavaScript application that runs in the SonarQube environment. You can find the example of page extensions in the [SonarQube](https://github.com/SonarSource/sonarqube) or [sonar-custom-plugin-example](https://github.com/SonarSource/sonar-custom-plugin-example/tree/7.x/) repositories on GitHub.\n\nBefore reading this guide, make sure you know how to [build, deploy, and debug a plugin](/extend/developing-plugin/).\n\n## Step 1. Create a Java class implementing PageDefinition\n\nFor each page, you\'ll need to set a key and a name. The page key should have the format `plugin_key/page_id` (e.g.: `governance/project_dump`). The `plugin_key` is computed from the `<artifactId>` in your `pom.xml`, or can be set explicitly in the pom using the `<pluginKey>` parameter in the `sonar-packaging-maven-plugin` configuration. All the pages should be declared in this class.\n\nExample:\n\n```\nimport org.sonar.api.web.page.Page;\nimport org.sonar.api.web.page.PageDefinition;\nimport org.sonar.api.web.page.Context;\n\nimport static org.sonar.api.web.page.Page.Scope.COMPONENT;\nimport static org.sonar.api.web.page.Page.Qualifier.VIEW;\nimport static org.sonar.api.web.page.Page.Qualifier.SUB_VIEW;\n \npublic class MyPluginPageDefinition implements PageDefinition {\n  @Override\n  public void define(Context context) {\n    context\n      .addPage(Page.builder("my_plugin/global_page")\n        .setName("Global Page")\n        .build())\n      .addPage(Page.builder("my_plugin/project_page")\n        .setName("Project Page")\n        .setScope(COMPONENT)\n        .build())\n      .addPage(Page.builder("my_plugin/portfolio_page")\n        .setName("Portfolio Page")\n        .setScope(COMPONENT)\n        .setComponentQualifiers(VIEW, SUB_VIEW)\n        .build())\n      .addPage(Page.builder("my_plugin/admin_page")\n        .setName("Admin Page")\n        .setAdmin(true)\n        .build());\n  }\n}\n```\n\n### Configuring each page\n\nThere are 3 settings available when you define the page extensions using the `PageDefinition` class:\n\n* `setAdmin(boolean admin)`: flag this page as restricted to users with "administer" permission. Defaults to `false`.\n* `setScope(org.sonar.api.web.page.Page.Scope scope)`: set the scope of this page. Available scopes are `GLOBAL` (default), which will add this page to the main menu, and `COMPONENT`, which will add the page to a project, application, or portfolio menu (applications and portfolios only apply to Enterprise Edition and above).\n* `setComponentQualifiers(org.sonar.api.web.page.Qualifier... qualifiers)`: if `setScope()` is set to `COMPONENT`, this sets to what kind of component the page applies to. Available qualifiers are `PROJECT`, `APP`, `VIEW` (portfolio), and `SUB_VIEW` (`APP`, `VIEW`, and `SUB_VIEW` only apply to Enterprise Edition and above). You can pass multiple qualifiers. If no qualifier is set, it will apply to all types.\n\n## Step 2. Create a JavaScript file per page\n\nThe `PageDefinition` will register each key as an available route in SonarQube. Whenever this route is visited, SonarQube will asynchronously fetch a single JavaScript file from your plugin\'s `/static/` directory, and boot up your page\'s application. This file should have the same name as the `page_id` you defined in your `PageDefinition` class. In the example in Step 1, you would need 4 different JavaScript files:\n\n* `/static/global_page.js`\n* `/static/project_page.js`\n* `/static/portfolio_page.js`\n* `/static/admin_page.js`\n\nEach file *must* call the global `window.registerExtension()` function, and pass its *full key* as a first argument (`plugin_key/page_id`, e.g.: `governance/project_dump`). The second argument is the *start* callback. This function will be called once your page is started, and receive information about the current page as an argument (see below). The return value of the start callback depends on how you want to implement your page:\n\n* If you want to use [React](https://reactjs.org/), you should return a React Component:\n  ```\n  // static/global_page.js\n  import React from "react";\n  import App from "./components/App";\n  \n  window.registerExtension(\'my_plugin/global_page\', function (options) {\n    return <App options={options} />\n  });\n  ```\n* If you want to use any other framework, you should perform any start logic directly inside the start function body, and **return a shutdown callback**:\n  ```\n  // static/global_page.js\n  const init = require("./my-app/init");\n  \n  window.registerExtension(\'my_plugin/global_page\', function (options) {\n    // Start up my custom application, passing the DOM element which will serve as\n    // the container.\n    init.boot(options.el, options.currentUser, options.component);\n  \n    // Whenever the user leaves the page, cleanly shut everything down\n    // (i.e., remove event listeners, stop running timers, etc).\n    return function () {\n      init.removeEventListeners();\n      init.clearState();\n      init.shutdown();\n    };\n  });\n  ```\n\nThe `options` object will contain the following:\n* `options.el`: a DOM node you must use to inject your content.\n* `options.currentUser`: information about the current user.\n* (optional) `options.component`: contains the information of the current project, application, or portfolio.\n* (optional) `options.branchLike`: contains the information of the current branch or pull request.\n\n[[info]]\n| SonarQube doesn\'t guarantee any JavaScript library availability at runtime (except React). If you need a library, include it in the final file.\n\n## Examples\n\nIt is highly recommended you check out [sonar-custom-plugin-example](https://github.com/SonarSource/sonar-custom-plugin-example/tree/7.x/). It contains detailed examples using several front-end frameworks, and its code is thoroughly documented. It also describes how to run a local development server to speed up the front-end development, without requiring a full rebuild and re-deploy to test your changes.\n'},{path:"extend/i18n",content:'---\ntitle: Internationalization\nurl: /extend/i18n/\n---\n\nThis page gives guidelines to I18n for:\n\n* Plugin developers who would like to apply the i18n mechanism in their own plugins, so that these plugins can be available in several languages.\n* People who would like to help the community by making the platform available in a new language.\n\n## Principles\nAlthough the basics of the i18n mechanism are the same for every part of the ecosystem, the packaging differs depending on what you are developing:\n\n* Translations for SonarQube: making SonarQube available in a new language requires you to develop and publish a new Language Pack plugin. \n   * By default SonarQube embeds the English Pack.\n   * All other Language Pack plugins, like the French Pack plugin, are maintained by the community, and are available through Marketplace (category "Localization").\n* Translations for the SonarQube Community Plugins: open-source plugins from the SonarQube Community must embed only the bundles for the default locale (en). Translations will be done in the Language Pack plugins.\n\n* Translations for other Plugins: closed-source/commercial/independent plugins must embed the bundles for the default locale and the translations for every language they want to support.\n\n## Translation Bundles\nLocalized messages are stored in properties files:\n\n* These are regular properties files with key/value pairs where you put most translations\n* These files must be stored in the org.sonar.l10n package (usually in the `src/main/resources/org/sonar/l10n` directory)\n* The names of these files must follow the convention `<key of the plugin to translate>_<language>.properties`, for example `widgetlabs_fr.properties` or `core_fr.properties` for the core bundle. See `sonar-packaging-maven-plugin` for details on plugin key derivation.\n* Messages can accept arguments. Such entries would look like:\n   * `myplugin.foo=This is a message with 2 params: the first "{0}" and the second "{1}".`\n* Messages can accept pluralization. Such entries would look like:\n   * `myplugin.foo={x, number} {x, plural, one {thing} other {things}}`\n   * We use it for example with a combination of 2 labels: `component_navigation.last_analysis_had_warnings=Last analysis had {warnings}` and `component_navigation.x_warnings={warningsCount, number} {warningsCount, plural, one {warning} other {warnings}}`. This renders `Last analysis had 1 warning` if `warningsCount` equals 1 and `Last analysis had 2 warnings` otherwise, in this case 2.\n   * Learn more about this syntax [here](https://formatjs.io/guides/message-syntax/#plural-format).\n   \n[[warning]]\n| **UTF-8 encoding**  \n| In the Java API, properties files are supposed to be encoded in ISO-8859 charset. Without good tooling, it can be quite annoying to write translations for languages that do not fit in this charset.\n| This is why we decided to encode the properties files in UTF-8, and let Maven turn them into ASCII at build time thanks to native2ascii-maven-plugin (check the French plugin pom.xml). This makes the process of writing translations with a standard editor far easier.\n\n### How to read localized messages from a plugin extension?\nThe component `org.sonar.api.i18n.I18n` is available for web server extensions. Scanner extensions cannot load bundles.\n\n## Writing a Language Pack\nA Language Pack defines bundles for SonarQube and/or plugins.\n\n### Creating a Language Pack\nThe easiest way to create a new pack is to copy the [Chinese Pack](https://github.com/SonarQubeCommunity/sonar-l10n-zh) and adapt it to your language.\n\n### Maintaining a Language Pack\nIn the pom file, set the versions of SonarQube and of the plugins you want to translate. When it\'s time to update your language pack for a new version of SonarQube or a plugin, the easiest way to see what keys are missing is to run:\n```\nmvn test\n```\nIf the build fails, it means that some keys are missing. Go to `target/l10n` to check the reports for each bundle. Missing keys are listed under \'Missing translations are:\'\n```\nMissing translations are:\ncode_viewer.no_info_displayed_due_to_security=Due to security settings, no information can be displayed.\ncomparison.version.latest=LATEST\n...\n```\n\nEach time you add a new bundle or update an existing one, please create a JIRA ticket on the corresponding L10n component in order to track changes.\n\n## Localizing a Plugin\nThis section applies if you are developing a closed-source plugin. If your plugin falls in this category, it must embed its own bundles. Bundle must be defined in `src/main/resources/org/sonar/l10n/<plugin key>_<language>.properties`\n\nThe default bundle is mandatory, and must be English. For example the plugin with key "mysonarplugin" must define the following files in order to enable the French translation:\n\n* `org/sonar/l10n/mysonarplugin.properties`\n* `org/sonar/l10n/mysonarplugin_fr.properties`\n'},{path:"extend/new-languages",content:"---\ntitle: Supporting New Languages\nurl: /extend/new-languages/\n---\n\n\nThe steps to cover a new programming language are:\n\n1. Write the grammar. This is the hardest part.\n1. Write a parser (a parser simply parses an input based on your grammar to yield a parse tree).\n1. Test your grammar, to ensure it is able to parse real-life language files.\n1. Write a few parse tree visitors. Some visitors will compute metrics such as [executable lines](/extend/executable-lines/), while others will enforce [coding rules](/extend/adding-coding-rules/). A dozen or so visitors is sufficient for an initial release.\n1. Write a scanner Sensor, in a SonarQube plugin, to launch the visitors. \n1. Compute\n   1. issues\n   1. raw measures\n   1. code duplications\n   1. syntax highlighting\n   1. symbol table\n   1. coverage information (lines/branches to cover, line/branch hits)\n   \nIn fulfilling these steps, the [SonarSource Language Recognizer (SSLR)](https://github.com/SonarSource/sslr) can be an important resource.\n   \n\n \n\n"},{path:"extend/web-api",content:"---\ntitle: Web API\nurl: /extend/web-api/\n---\n## Documentation\n\nSonarQube provides web API to access its functionalities from applications. The web services composing the web API are documented within SonarQube, through the URL [/web_api](/#sonarqube#/web_api). You can also access the web API documentation from the top bar in SonarQube:\n\n ![web API documentation](/images/webapi.png)\n\n## Authentication\n\nAdministrative web services are secured and require the user to have specific permissions. In order to be authenticated, the user must provide credentials as described below.\n\n### User Token\n\nThis is the recommended way. Benefits are described in the page [User Token](/user-guide/user-token/). The token is sent via the login field of HTTP basic authentication, without any password.\n```\n# note that the colon after the token is required in curl to set an empty password \ncurl -u THIS_IS_MY_TOKEN: https://sonarqube.com/api/user_tokens/search\n```\n\n### HTTP Basic Access\n\nLogin and password are sent via the standard HTTP Basic fields:\n```\ncurl -u MY_LOGIN:MY_PASSWORD https://sonarqube.com/api/user_tokens/search\n```\nUsers who authenticate in web application through an OAuth provider, for instance GitHub or Bitbucket, don't have credentials and can't use HTTP Basic mode. They must generate and use tokens.\n"},{path:"faq",content:"---\ntitle: Frequently Asked Questions\nurl: /faq/\n---\n\n## How do I get rid of issues that are False-Positives?\n**False-Positive and Won't Fix**  \nYou can mark individual issues False Positive or Won't Fix through the issues interface. If you're using PR analysis provided by the Developer Edition, issues marked False Positive or Won't Fix will retain that status after merge. This is the preferred approach.\n\n**//NOSONAR**  \nFor most languages, SonarQube supports the use of the generic mechanism: `//NOSONAR` at the end of the line of the issue. This will suppress all issues - now and in the future - that might be raised on the line.\n\n## How do I find and remove projects that haven't been analyzed in a while?\nIn **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management)** you can search for **Last analysis before** to filter projects not analyzed since a specific date, and then use bulk **Delete** to remove the projects that match your filter.\n\nThis can be automated by using the corresponding Web API: `api/projects/bulk_delete?analyzedBefore=YYYY-MM-DD`.\n\n\x3c!-- sonarqube --\x3e\n## How do I trigger a full ElasticSearch reindex?\nCurrently, the only way to force a reindex is to:\n\n* Stop your server\n* Remove the contents of the $SQ_HOME/data/es7 directory\n* Start your server\n\nBefore doing this, you should be aware first that processes are in place on the SonarQube side that out-of-sync indices are detected and corrected, and second that a full re-index can be quite lengthy depending on the size of your instance.\n\n## Why can't I use my HTTP Proxy since I upgraded to Java8u111?\n\nIf you are getting this error in the logs when trying to use the Marketplace:\n```\njava.io.IOException: Unable to tunnel through proxy. Proxy returns \"HTTP/1.1 407 Proxy Authentication Required\n```\n... you probably upgraded your Java8 installation with an update greater than 111. To fix that, update _$SONARQUBE_HOME/conf/sonar.properties` like this:\n```\nsonar.web.javaOpts=-Xmx512m -Xms128m -XX:+HeapDumpOnOutOfMemoryError -Djdk.http.auth.tunneling.disabledSchemes=\"\"\n```\nReference: http://www.oracle.com/technetwork/java/javase/8u111-relnotes-3124969.html\n\x3c!-- /sonarqube --\x3e\n\n"},{path:"index",content:"---\ntitle: SonarQube Documentation\nurl: /\n---\n\nWelcome to the SonarQube documentation! \n\n[SonarQube](http://www.sonarqube.org/)® is an automatic code review tool to detect bugs, vulnerabilities, and code smells in your code. It can integrate with your existing workflow to enable continuous code inspection across your project branches and pull requests.\n\nIf you want to try out SonarQube, check out the [Try out SonarQube](/setup/get-started-2-minutes/) page for instructions on installing a local instance and analyzing a project.\n\nIf you're ready to set up a production instance, check out the [Install the Server](/setup/install-server/) documentation.\n\nOtherwise, you can also find an overview and common scenarios below or navigate through and search the full documentation in the left pane.\n\n## Overview\n\n![SonarQube Instance Components](/images/dev-cycle.png)\n\nIn a typical development process:  \n\n1. Developers develop and merge code in an IDE (preferably using [SonarLint](https://www.sonarlint.org/) to receive immediate feedback in the editor) and check-in their code to their ALM.\n1. An organization’s continuous integration (CI) tool checks out, builds, and runs unit tests, and an integrated SonarQube scanner analyzes the results.\n1. The scanner posts the results to the SonarQube server which provides feedback to developers through the SonarQube interface, email, in-IDE notifications (through SonarLint), and decoration on pull or merge requests (when using [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) and above).\n\n## Installing, monitoring, and upgrading\n\nSee the [installing](/setup/install-server/) and [upgrading](/setup/upgrading/) pages for setting up your production instance.\n\nWhen your instance is up and running, see the [Monitoring](/instance-administration/monitoring/) documentation for information on keeping your instance running smoothly.\n\nIf you're using SonarQube Data Center Edition, see the [Configure & Operate a Cluster](/setup/operate-cluster/) documentation for more information on running your instance as a cluster.\n\n## Setting up analysis\n\nAnalyzing your code starts with installing and configuring a SonarQube scanner. The scanner can either run on your build or as part of your continuous integration (CI) pipeline performing a scan whenever your build process is triggered. For more information, see [Analyzing Source Code](/analysis/overview/). \n\n### Analyzing branches\n\nStarting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can analyze your branches in SonarQube, and ensure that your code quality is consistent all the way down to the branch level in your projects. For more information, see [Branch Analysis](/branches/overview/).\n\n### Analyzing pull requests\n\nStarting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can integrate SonarQube to be part of your pull or merge request process. Issuing a pull request can trigger a branch analysis and add pull request decoration to see your branch analysis directly in your ALM's interface in addition to the SonarQube interface. For more information, see the [Pull Request Analysis Overview](/analysis/pull-request/).\n\n## Writing Clean and Safe Code\n\nSonarQube gives you the tools you need to write clean and safe code:\n\n- [SonarLint](https://www.sonarlint.org/) – SonarLint is a companion product that works in your editor giving immediate feedback so you can catch and fix issues before they get to the repository.\n- [Quality Gate](/user-guide/quality-gates/) – The Quality Gate lets you know if your project is ready for production. \n- [Clean as You Code](/user-guide/clean-as-you-code/) – Clean as You Code is an approach to code quality that eliminates a lot of the challenges that come with traditional approaches. As a developer, you focus on maintaining high standards and taking responsibility specifically in the New Code you're working on.\n- [Issues](/user-guide/issues/) – SonarQube raises issues whenever a piece of your code breaks a coding rule, whether it's an error that will break your code (bug), a point in your code open to attack (vulnerability), or a maintainability issue (code smell).\n- [Security Hotspots](/user-guide/security-hotspots/) – SonarQube highlights security-sensitive pieces of code that need to be reviewed. Upon review, you'll either find there is no threat or you need to apply a fix to secure the code.\n \n## Administering a Project\n\nIf you have the **Create Projects** permission (a global administrator can set permissions at **Administration > Security > Global Permissions**), you can create and administer projects. See [Project Settings](/project-administration/project-settings/) for general information on setting up projects. \n\nA project is automatically added on the first analysis. However, you can provision projects (set up permissions, Quality Profiles, etc.) before running the first analysis. See [Project Existence](/project-administration/project-existence/) for more information on provisioning a project and handling provisioned projects.\n\nYou also want to make sure SonarQube's results are relevant. To do this you need to [Narrowing the Focus](/project-administration/narrowing-the-focus/) or configure what to analyze for each project.\n\nYou can also set up [Webhooks](/project-administration/webhooks/) to notify external services when a project analysis is complete.\n\n## Administering an Instance\n\nIf you're a global administrator, you can set up authentication, administrator access, and authorization. See [Security](/instance-administration/security/) for more information.\n\nYou can also set up email [notifications](/instance-administration/notifications/) that developers can subscribe to that are sent at the end of each analysis. \n\nWhen you run new analyses on your projects, some data is cleaned out of the database to save space and improve performance. See [Housekeeping](/instance-administration/housekeeping/) for information on what data is cleaned and how to change these settings.\n\nStarting in [Enterprise Edition](https://www.sonarqube.org/enterprise-edition/), you can set up [Portfolios](/user-guide/portfolios/) to get a high-level overview on the releasability of a group of projects.  \n\n## Staying Connected\n\nUse the following links to get help and keep up with SonarQube:\n\n- [Get help in the community](https://www.sonarqube.org/community/)\n- [Source code](https://github.com/SonarSource)\n- [Issue tracker](https://jira.sonarsource.com/)"},{path:"instance-administration/backup-restore",content:"---\ntitle: Backup and Restore\nurl: /instance-administration/backup-restore/\n---\n\n## Backing Up Data\nMost databases come with backup tools. We recommend using these tools to back up your data.\n\n## Restoring Data\nTo restore data from backup, follow these steps:\n\n1. Stop the server.\n1. Restore the backup.\n1. Drop the Elasticsearch indexes by deleting the contents of `$SQ_HOME/data/es6 directory`.\n1. Restart the server."},{path:"instance-administration/compute-engine-performance",content:"---\ntitle: Compute Engine Performance\nurl: /instance-administration/compute-engine-performance/\n---\n\n_The ability to manage Compute Engine performance is available as part of [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html) and [above](https://www.sonarsource.com/plans-and-pricing/)._\n\n\n### How can I get analyses through the Compute Engine Queue faster?\nIf analyses are taking too long to process, it may be that you need to increase the number of Compute Engine (CE) workers (**[Administration > Projects > Background Tasks > Number of Workers](/#sonarqube-admin#/admin/background_tasks)**). \n\nThere are two cases to consider:\n\n1. slowness comes from the fact that the queue is often full of pending tasks\n1. individual tasks take a long time to process\n\nIn the first case, increasing the number of workers could help. The second case should be carefully evaluated. In either case, when considering increasing the number of CE workers, two questions should be answered.\n\n* does my infrastructure allow me to increase the number of workers?\n* to what extent should I increase the number of workers? I.E. What number should I configure?\n\nIncreasing the number of workers will increase the stress on the resources consumed by the Compute Engine. Those resources are:\n\n* the DB\n* disk I/O\n* network\n* heap\n* CPU\n\nOf those, only the last two are internal to the CE.\n\nIf slowness comes from any of the external resources (DB, disk I/O, network), then increasing the number of workers could actually slow the processing of individual reports (think of two people trying to go through a door at  the same time). However, if your slowness is caused by large individual analysis reports hogging the CE worker for extended periods of time, then enabling parallel processing by adding another worker could help. But if you do, you need to take a look at the internal resources.\n\nCE workers are not CPU-intensive and memory use depends entirely on the project that was analyzed. Some need a lot of memory, others don't. But with multiple CE workers, you should increase CE heap size by a multiple of the number of workers. The same logic applies to CPU: if running with one worker consumes up to Y% of CPU, then you should plan for Z workers requiring Y*Z% of CPU.\n\nTo accurately diagnose your situation, monitor network latency, the I/O of the SonarQube instance, and the database CPU and memory usage to evaluate whether slowness is mainly/mostly/only related to external resources. \n"},{path:"instance-administration/custom-measures",content:'---\ntitle: Custom Measures\nurl: /instance-administration/custom-measures/\n---\n\nSonarQube collects a maximum of measures in an automated manner but there are some measures for which this is not possible, such as when: the information is not available for collection, the measure is computed by a human, and so on. Whatever the reason, SonarQube provides a service to inject those measures manually and allow you to benefit from other services: the Manual Measures service. The manual measures entered will be picked during the next analysis of the project and thereafter treated as "normal" measures.\n\n## Managing Custom Metrics\nAs with measures that are collected automatically, manual measures are the values collected in each analsis for manual metrics. Therefore, the first thing to do is create the metric you want to save your measure against. In order to do so, log in as a system administrator and go to **[Administration > Configuration > Custom Metrics](/#sonarqube-admin#/admin/custom_metrics)**, where the interface will guide you in creating the Metric you need. \n\n## Managing Custom Measures\nCustom measures can be entered at project level. To add a measure, sign in as a project administrator, navigate to the desired project and choose **Project Settings > Custom Measures**, where you will find a table with the latest measure value entered for each metric. \n\nValues entered in this interface are "Pending", and will not be visible outside this administrative interface until the next analysis. \n\n'},{path:"instance-administration/db-copy",content:"---\ntitle: SonarQube DB Copy Tool\nurl: /instance-administration/db-copy/\n---\n\n_The SonarQube DB Copy Tool is available to customers with [SonarSource support](https://www.sonarsource.com/support/)._\n\nThis tool is provided to help you migrate your SonarQube database from one DB vendor to another. If, for instance, you've been using your SonarQube instance with Oracle and you want to migrate to PostgreSQL without loosing your analysis history, the SonarQube DB Copy Tool is what you need. \n\nIn the following lines we will talk about \"source\" and \"target\" SonarQube database instances. The source instance is the database you want to discard and the target is the one you want to move to.\n\nThe procedure is basically as follows:\n\n* connect to both the source and target databases\n* read the data from the source database table by table\n* save the data into the target database table by table\n* recreate the sequences, index, ... on the target database\n\n## Installation\nThe SonarQube DB Copy Tool is provided as a standalone JAR file. **It must not be installed in your source or target SonarQube instances**. Put the JAR wherever your want on your machine, the only prerequisite is that this machine must be authorized to access your source and target SonarQube databases.\n\nThe version of the JAR to use must be at least **1.3.3.627**\n\n## DB Copy Preparation Phase\nIn the preparation phase, you ready the target database by setting up SonarQube schema and populating it with the necessary tables so that you end up with the same  database schema in the source and the target.\n\n1. Make sure your target database is up and running\n1. On your target database, create the `sonar` schema. \n1. Download and expand a copy of SonarQube that exactly matches the version you're running. \n1. Configure your SonarQube copy to connect to the target database. (If you've placed your SonarQube copy on the same server that runs your primary SonarQube instance, you'll also need to configure non-default ports for your copy SonarQube instance.)\n1. Start your copy SonarQube instance. It will connect to your empty target and populate the schema.\n1. Once your copy instance is up and running (this indicates that the schema is fully populated), you can stop and delete it.\n1. Refresh the Database Statistics on the target database before restarting SonarQube\n\nAt this point, you have in your source and target databases the exact same lists of tables.\n\n## DB Copy Run Phase\nThere are only four steps in this phase:\n\n1. **Stop your primary SonarQube instance.**\n1. Execute the base command jar with the correct parameters. \n1. Update your primary SonarQube instance's configuration to point to the target DB\n1. Restart your primary SonarQube instance.\n\n### Base command\n```\njava -jar sonar-db-copy-1.3.3.627-jar-with-dependencies.jar\n```\n\n### Parameters\nName | Description | Required\n---|---|---|---\n`-help`|Print this parameters help| no  \n`-urlSrc`|JDBC URL of the source database|yes\n`-userSrc`|Username of the source database|yes\n`-pwdSrc`|Password of the source database|yes\n`-urlDest`|JDBC URL of the target database|yes\n`-userDest`|Username of the target database|yes\n`-pwdDest`|Password of the target database|yes\n`-driverDest`|JDBC Driver of the target database|no\n`-driverSrc`|JDBC Driver of the source database|no\n`-T`|Comma separated list of tables to migrate|no\n\n## Execution Examples\nFirst sonar-db-copy verifies if URLs can be reached and the database versions:  \n![verify urls](/images/db-copy/verify-urls.png)\n\nWhen the versions are different, the application stops.  \n![stop for different versions](/images/db-copy/verify-versions.png)\n\nSometime when you have restarted the copy, the destination database version is 0. This is not a problem, the copy will continue.  \n![version 0 in target is okay](/images/db-copy/version0-ok.png)\n\nThen it searches tables in source and destination database:  \n![search tables](/images/db-copy/search-tables.png)\n\nIf there are missing tables, you will read this log:  \n![missing table warning](/images/db-copy/missing-table-warning.png)\n\nSecond sonar-db-copy truncates tables in target database and indicates the number of tables purged:  \n![truncate tables in target](/images/db-copy/truncate-tables.png)\n\nOf course, the tables missing can not be purged:  \n![missing tables aren't purged](/images/db-copy/missing-table-not-purged.png)\n\nThird, sonar-db-copy reproduces data from source to destination and adjusts the sequence of destination database after the copy:  \n![copy data](/images/db-copy/copy-data.png)\n\nIf there are some missing tables:  \n![missing tables not copied](/images/db-copy/missing-table-not-copied.png)\n\nIf errors appear during the copy, the process does NOT stop but the errors are displayed:  \n![copy errors displayed](/images/db-copy/copy-errors-shown.png)\n\nAt the end sonar-db-copy reiterates the difference between source and destination database. An error message is displayed if the databases are different. \n![final warning of remaining differences](/images/db-copy/summary-of-differences.png)\n"},{path:"instance-administration/delegated-auth",content:'---\ntitle: Delegating Authentication\nurl: /instance-administration/delegated-auth/\n---\n\n\nSonarQube comes with an onboard user database, as well as the ability to delegate authentication via HTTP Headers, GitHub Authentication, GitLab Authentication, SAML, or LDAP. Each method offers user identity management, group synchronization/mapping, and authentication.\n\n## Group Mapping\nWhen using group mapping, the following caveats apply regardless of which delegated authentication method is used:\n* membership in synchronized groups will override any membership locally configured in SonarQube _at each login_\n* membership in a group is synched only if a group with the same name exists in SonarQube\n* membership in the default group `sonar-users` remains (this is a built-in group) even if the group does not exist in the identity provider\n\n[[warning]]\n|When group mapping is configured, the delegated authentication source becomes the one and only place to manage group membership, and the user\'s groups are re-fetched with each log in.\n\n\n## HTTP Header Authentication\nYou can delegate user authentication to third-party systems (proxies/servers) using HTTP Header Authentication.\n\nWhen this feature is activated, SonarQube expects that the authentication is handled prior any query reaching the server. \nThe tool that handles the authentication should:\n\n* intercept calls to the SonarQube server\n* take care of the authentication\n* update the HTTP request header with the relevant SonarQube user information\n* re-route the request to SonarQube with the appropriate header information\n\n![HTTP Header Authentication flow](/images/http-header-authentication.png)\n\nAll the parameters required to activate and configure this feature are available in SonarQube server configuration file (in _$SONARQUBE-HOME/conf/sonar.properties_).\n\nUsing Http header authentication is an easy way integrate your SonarQube deployment with an in-house SSO implementation.\n\n## GitHub and GitLab Authentication\nYou can delegate authentication to GitHub Enterprise and GitHub.com or GitLab Self-Managed and GitLab.com. See the corresponding ALM integration page for more information:\n- [GitHub Enterprise and GitHub.com](/analysis/github-integration/)\n- [GitLab Self-Managed and GitLab.com](/analysis/gitlab-integration/)\n\n## SAML Authentication  \nYou can delegate authentication to a SAML 2.0 Identity Provider using SAML Authentication.\n\n### Limitations\n* SAML requests are not signed. Client signature validation should be disabled in the Identity Provider.\n* SAML encrypted responses are not supported. SAML encryption should be disabled in the Identity Provider.\n\n### Example: Using Keycloak as a SAML Identity Provider\nThe following example may be useful if you\'re using Keycloak as a SAML Identity Provider. If you\'re not using Keycloak, your settings are likely to be different.\n\n[[collapse]]\n| ## In the Keycloak server, create a new SAML client\n| Create a new client\n|\n| 1. "Client ID" is something like "sonarqube" \n| 1. "Client Protocol" must be set to "saml"\n| 1. "Client SAML Endpoint" can be left empty\n|\n| Configure the new client\n|\n| 1. in Settings\n|    1. Set"Client Signature Required" to OFF\n|    1. Set "Valid Redirect URIs" to "<Your SonarQube URL>/oauth2/callback/*, E.G https://sonarqube.mycompany.com/oauth2/callback/saml\n| 1. in Client Scopes > Default Client Scopes , remove "role_list" from "Assigned Default Client Scopes" (to prevent the error `com.onelogin.saml2.exception.ValidationError: Found an Attribute element with duplicated Name` during authentication)\n| 1. In Mappers create a mapper for each user attribute (Note that values provided below for Name, SAML Attribute Name, Role Attribute Name are only example values): \n|    1. Create a mapper for the login: \n|       * Name: Login\n|       * Mapper Type: User Property\n|       * Property: Username (Note that the login should not contain any special characters other than `.-_@` to meet SonarQube restrictions.)\n|       * SAML Attribute Name: login\n|    1. Create a mapper for the name: \n|       * Name: Name\n|       * Mapper Type: User Property\n|       * User Attribute: Username (It can also be another attribute you would previously have specified for the users)\n|       * SAML Attribute Name: name\n|    1. (Optional) Create a mapper for the email: \n|       * Name: Email\n|       * Mapper Type: User Property\n|       * Property: Email\n|       * SAML Attribute Name: email\n|    1. (Optional) Create a mapper for the groups (If you rely on a list of roles defined in "Roles" of the Realm (not in "Roles" of the client)):\n|       * Name: Groups\n|       * Mapper Type: Role list\n|       * Role Attribute Name: groups\n|       * Single Role Attribute: ON\n|    1. If you rely on a list of groups defined in "Groups":\n|       * Name: Groups\n|       * Mapper Type: Group list\n|       * Role Attribute Name: groups\n|       * Single Role Attribute: ON\n|       * Full Group Path: OFF\n|\n| Download the XML configuration file from Keycloak.\n\n[[collapse]]\n| ## In SonarQube, Configure SAML authentication\n| Go to **[Administration > Configuration > General Settings > Security > SAML](/#sonarqube-admin#/admin/settings?category=security)**\n| * **Enabled** should be set to true\n| * **Application ID** is the value of the "Client ID" you set in Keycloak (for example "sonarqube")\n| * **Provider ID** is the value of the "EntityDescriptor" > "entityID" attribute in the XML configuration file (for example "http://keycloak:8080/auth/realms/sonarqube" where sonarqube is the name of the realm)\n| * **SAML login url** is the value of "SingleSignOnService" > "Location" attribute in the XML configuration file (for example "http://keycloak:8080/auth/realms/sonarqube/protocol/saml")\n| * **Provider certificate** is the value you get from *Reaml Settings* -> *Keys* -> click on the *Certificate* button\n| * **SAML user login attribute** is the value set in the login mapper in "SAML Attribute Name"\n| * **SAML user name attribute** is the value set in the name mapper in "SAML Attribute Name"\n| * (Optional) **SAML user email attribute** is the value set in the email mapper in "SAML Attribute Name"\n| * (Optional) **SAML group attribute** is the value set in the groups mapper in "Role/Group Attribute Name"\n|\n| In the login form, the new button "Log in with SAML" allows users to connect with their SAML account.\n\n### SAML and reverse proxy configuration\nWhen using SAML, make sure your reverse proxy is properly configured. See [Operating the Server](/setup/operate-server/) for more information.\n\n## LDAP Authentication\nYou can configure SonarQube authentication and authorization to an LDAP server (including LDAP Service of Active Directory) by configuring the correct values in _$SONARQUBE-HOME/conf/sonar.properties_.\n\nThe main features are:\n\n* Password checking against the external authentication engine.\n* Automatic synchronization of usernames and emails.\n* Automatic synchronization of relationships between users and groups (authorization).\n* Ability to authenticate against both the external and the internal authentication systems. There is an automatic fallback on SonarQube internal system if the LDAP server is down.\n* During the first authentication trial, if the user\'s password is correct, the SonarQube database is automatically populated with the new user. Each time a user logs into SonarQube, the username, the email and the groups this user belongs to that are refreshed in the SonarQube database. You can choose to have group membership synchronized as well, but this is not the default.\n\n\n&nbsp;| Apache DS | OpenLDAP | Open DS | Active Directory\n----|-----------|----------|---------|-----------------\nAnonymous | ![](/images/check.svg) |![](/images/check.svg) |![](/images/check.svg) |  &nbsp;\nSimple|![](/images/check.svg)|![](/images/check.svg)|![](/images/check.svg)|![](/images/check.svg)\nLDAPS|![](/images/check.svg)|![](/images/check.svg)|  |![](/images/check.svg)\nDIGEST-MD5|![](/images/check.svg)|  |![](/images/check.svg)|![](/images/check.svg)\nCRAM-MD5|![](/images/check.svg)|  |![](/images/check.svg)|![](/images/check.svg)\nGSSAPI|![](/images/check.svg)|  |  |  \n![](/images/check.svg) = successfully tested\n\n### Setup\n1. Configure LDAP by editing _$SONARQUBE-HOME/conf/sonar.properties_ (see table below)\n2. Restart the SonarQube server and check the log file for:\n```\nINFO org.sonar.INFO Security realm: LDAP ...\nINFO o.s.p.l.LdapContextFactory Test LDAP connection: OK\n```\n1. Log into SonarQube\n1. On logout users will be presented a login page (_/sessions/login_), where they can choose to login as technical user or a domain user by passing appropriate credentials\n\nFrom SonarScanners, we recommend using [local technical users](/instance-administration/security/) for authentication against SonarQube Server.\n\n**General Configuration**\n\nProperty|Description|Default value|Required|Example\n---|---|---|---|---\n`sonar.security.realm`|Set this to `LDAP` authenticate first against the external sytem. If the external system is not reachable or if the user is not defined in the external system, authentication will be performed against SonarQube\'s internal database.| none |Yes|`LDAP` (only possible value)\n`sonar.authenticator.downcase`|Set to true when connecting to a LDAP server using a case-insensitive setup.|`false`|No\n`ldap.url`|URL of the LDAP server. If you are using ldaps, you should install the server certificate into the Java truststore.| none |Yes|`ldap://localhost:10389`\n`ldap.bindDn`|The username of an LDAP user to connect (or bind) with. Leave this blank for anonymous access to the LDAP directory.|none|No|`cn=sonar,ou=users,o=mycompany`\n`ldap.bindPassword`|The password of the user to connect with. Leave this blank for anonymous access to the LDAP directory.|none|No|`secret`\n`ldap.authentication`|Possible values: `simple`, `CRAM-MD5`, `DIGEST-MD5`, `GSSAPI`. See [the tutorial on authentication mechanisms](http://java.sun.com/products/jndi/tutorial/ldap/security/auth.html)|`simple`|No\n`ldap.realm`|See [Digest-MD5 Authentication](http://java.sun.com/products/jndi/tutorial/ldap/security/digest.html), [CRAM-MD5 Authentication](http://java.sun.com/products/jndi/tutorial/ldap/security/crammd5.html)| none|No|example.org\n`ldap.contextFactoryClass`|Context factory class.|`com.sun.jndi.ldap.LdapCtxFactory`|No\n`ldap.StartTLS`|Enable use of `StartTLS`|`false`|No\n`ldap.followReferrals`|Follow referrals or not. See [Referrals in the JNDI](http://docs.oracle.com/javase/jndi/tutorial/ldap/referral/jndi.html)|`true`\n\n**User Mapping**\n\nProperty|Description|Default value|Required|Example for Active Directory\n---|---|---|---|---\n`ldap.user.baseDn`|Distinguished Name (DN) of the root node in LDAP from which to search for users.|None|Yes|`cn=users,dc=example,dc=org`\n`ldap.user.request`|LDAP user request.|`(&(objectClass=inetOrgPerson)(uid={login}))`|No|`(&(objectClass=user)(sAMAccountName={login}))`\n`ldap.user.realNameAttribute`|Attribute in LDAP defining the user’s real name.|`cn`|No|  \n`ldap.user.emailAttribute`|Attribute in LDAP defining the user’s email.|`mail`|No| \n\n**Group Mapping**\nOnly groups (not roles) and static groups (not dynamic groups) are supported. Click [here](http://identitycontrol.blogspot.fr/2007/07/static-vs-dynamic-ldap-groups.html) for more information.\n\nFor the delegation of authorization, [groups must be first defined in SonarQube](/instance-administration/security/). Then, the following properties must be defined to allow SonarQube to automatically synchronize the relationships between users and groups.\n\nProperty|Description|Default value|Required|Example for Active Directory\n---|---|---|---|---\n`ldap.group.baseDn`|Distinguished Name (DN) of the root node in LDAP from which to search for groups.|none|No|`cn=groups,dc=example,dc=org`\n`ldap.group.request`|LDAP group request.|`(&(objectClass=groupOfUniqueNames)(uniqueMember={dn}))`|No|`(&(objectClass=group)(member={dn}))`\n`ldap.group.idAttribute`|Property used to specifiy the attribute to be used for returning the list of user groups in the compatibility mode.|`cn`|No|`sAMAccountName`\n\n### Sample Configuration\n```\n# LDAP configuration\n# General Configuration\nsonar.security.realm=LDAP\nldap.url=ldap://myserver.mycompany.com\nldap.bindDn=my_bind_dn\nldap.bindPassword=my_bind_password\n  \n# User Configuration\nldap.user.baseDn=ou=Users,dc=mycompany,dc=com\nldap.user.request=(&(objectClass=inetOrgPerson)(uid={login}))\nldap.user.realNameAttribute=cn\nldap.user.emailAttribute=mail\n \n# Group Configuration\nldap.group.baseDn=ou=Groups,dc=sonarsource,dc=com\nldap.group.request=(&(objectClass=posixGroup)(memberUid={uid}))\n```\n\n## Advanced LDAP Topics\n### Authentication Methods\n* **`Anonymous`** -  Used when only read-only access to non-protected entries and attributes is needed when binding to the LDAP server.\n* **`Simple`** Simple authentication is not recommended for production deployments not using the ldaps secure protocol since it sends a cleartext password over the network.\n* **`CRAM-MD5`** - The Challenge-Response Authentication Method (CRAM) based on the HMAC-MD5 MAC algorithm ([RFC 2195](http://tools.ietf.org/html/rfc2195)).\n* **`DIGEST-MD5`** - This is an improvement on the CRAM-MD5 authentication method ([RFC 2831](http://www.ietf.org/rfc/rfc2831.txt)).\n* **`GSSAPI`** - GSS-API is Generic Security Service API ([RFC 2744](http://www.ietf.org/rfc/rfc2744.txt)). One of the most popular security services available for GSS-API is the Kerberos v5, used in Microsoft\'s Windows 2000 platform.\n\nFor a full discussion of LDAP authentication approaches, see [RFC 2829](http://www.ietf.org/rfc/rfc2829.txt) and [RFC 2251](http://www.ietf.org/rfc/rfc2251.txt).\n\n### Multiple Servers\nTo configure multiple servers:\n```\n# List the different servers\nldap.servers=server1,server2\n  \n# Configure server1\nldap.server1.url=ldap://server1:1389\nldap.server1.user.baseDn=dc=dept1,dc=com\n...\n \n# Configure server2\nldap.server2.url=ldap://server2:1389\nldap.server2.user.baseDn=dc=dept2,dc=com\n...\n```\n\nAuthentication will be tried on each server, in the order they are listed in the configurations, until one succeeds. User/Group mapping will be performed against the first server on which the user is found.\n\nNote that all the LDAP servers must be available while (re)starting the SonarQube server.\n\n### Migrate users to a new authentication method\nIf you are changing your delegated authentication method and migrating existing users from your previous authentication method, you can use the `api/users/update_identity_provider` web API to update your users\' identity provider.\n\n### Troubleshooting\n* Detailed connection logs (and potential error codes received from LDAP server) are output to SonarQube\'s _$SONARQUBE_HOME/logs/web.log_, when logging is in `DEBUG` mode.\n\n* Time out when running SonarQube analysis using LDAP\nJava parameters are documented here: http://docs.oracle.com/javase/jndi/tutorial/ldap/connect/config.html. Such parameters can be set in `sonar.web.javaAdditionalOpts` in _$SONARQUBE-HOME/conf/sonar.properties_.\n'},{path:"instance-administration/housekeeping",content:"---\ntitle: Housekeeping\nurl: /instance-administration/housekeeping/\n---\n\nWhen you run a new analysis of your project or its branches or pull requests(PRs), some data that was previously available is cleaned out of the database. For example the source code of the previous analysis, measures at directory and file levels, and so on are automatically removed at the end of a new analysis. Additionally, some old analysis snapshots, PR analyses, and branches are also removed.\n\nWhy? Well, it's useful to analyze a project frequently to see how its quality evolves. It is also useful to be able to see the trends over weeks, months, years. But when you look back in time, you don't really need the same level of detail as you do for the project's current state. To save space and to improve overall performance, the Database Cleaner deletes some rows in the database. Here is its default configuration:\n\n* For each project:\n  * only one snapshot per day is kept after 1 day. Snapshots marked by an event are not deleted.\n  * only one snapshot per week is kept after 1 month. Snapshots marked by an event are not deleted.\n  * only one snapshot per month is kept after 1 year. Snapshots marked by an event are not deleted.\n  * only snapshots with version events are kept after 2 years. Snapshots without events or with only other event types are deleted.\n  * **all snapshots** older than 5 years are deleted, including snapshots marked by an event. \n* All closed issues more than 30 days old are deleted\n* History at package/directory level is removed\n\nThese settings can be changed at [Administration > General > Database Cleaner](/#sonarqube-admin#/admin/settings).\n"},{path:"instance-administration/license-manager",content:"---\ntitle: License Administration\nurl: /instance-administration/license-manager/\n---\n\n## License Manager\n_Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can access the License Manager at **Administration > Configuration> License Manager**._\n\nYou can use the License Manager to retrieve your server ID (required for obtaining a License Key) and configure your SonarSource-provided License key.\n\n### Retrieving the server ID\nThe server ID is always available on the License Manager page, as well as in the **System Info** section at **Administration > System**.\n\n[[info]]\n|If the database connection string is updated, the server ID will be re-generated and you'll need a new license. When it is generated, the server ID is unique. The same server ID will never be generated twice, even on the same SonarQube instance.\n\n### Setting a license\nBy clicking the **Set new license** button, you can set a new license to enable or disable features in SonarQube or to update your license.\n\n### Lines of Code consumption\nUnder **Lines of Code**, the gauge shows how many lines of code (LOC) you are currently scanning and how close you are to your limit. If you're near your limit, you may need to purchase additional LOCs.\n\n### Global Administrator notifications\nThe License Manager has two built-in notification mechanisms (notifications are sent to Global Administrators). Global administrators will get notifications when:\n\n- **the license is about to expire** – a reminder is sent two months and again one month before your license expires.\n- **the configurable LOC threshold is exceeded** – you can change this threshold using the indicator on the LOC gauge. \n\t- A background job runs at server startup and then every 24 hours to check the LOC threshold and decide if a notification should be sent. \n\t- The background job does not check the validity of SMTP server settings and whether the global administrator email addresses are set up. For global administrators to receive notifications, these settings need to be correctly configured before the LOC threshold is reached or exceeded.\n\n### Features Included\n\nThis section of the License Manager page lists the commercial features that are enabled by the current license.\n\n## Staging licenses\n_Staging licenses are only available in Enterprise Editions, Data Center Edition, or with commercial support_\n\nYour commercial license may include one or more staging licenses. You can use these licenses for non-production instances to test new features, upgrades, new integrations, etc.\n\nOur license mechanism supports a regular synchronization between your production instance and staging instances. To set up synchronization:\n\n- First Staging setup:\n  1. Create a staging database and copy the production database in it.\n  1. Connect your SonarQube staging instance to it.\n  1. Start SonarQube and retrieve the generated server ID.\n  1. Request your Staging license key for this server ID.\n  1. Set it up in the Administration panel.\n  \n- Synchronization on a regular basis:\n  1. Empty the staging database and copy the production database in it\n  1. Start SonarQube\n  1. The server ID will be the same as generated the first time, so you can reuse the same license key\n\n## Actions that will invalidate your license key\n\nCertain actions will regenerate your server ID and invalidate your license key. The following are some of the most common of these actions:\n\n- Moving, upgrading, or changing your database server to another host, available with a different IP or DNS name.\n- Changing the existing database server IP or DNS name.\n- Changing the database/schema name on the database server.\n- Restoring the database content from another SonarQube instance (except for production/staging synchronization).\n- Reinstalling SonarQube on an empty database.\n- Using DBCopy or MySQL Migrator to copy your old database into a new one.\n\nIf you plan on going through one of these scenarios and you have commercial support, please open a support ticket beforehand to confirm the plan or to explore alternatives.\n\nIn all cases, follow the steps below in **Requesting a new license** if your license key had been invalidated.\n\n## Requesting a new license\nIf your license key isn't working:\n1. Send an email to contact@sonarsource.com that includes the following information:\n\t- Server ID - Found under **System Info** at **Administration > System**\n\t- SonarQube version - Found under **System Info** at **Administration > System**\n\t- SonarQube edition\n1. Clarify what current license (production/staging) and server ID this is replacing.\n1. Confirm the status of the existing license.\n\nA new license key will be issued within 1 business day once we receive an email with the needed information at contact@sonarsource.com.\n\n## Support\n\n### Access to SonarSource Support\nIf your license entitles you to SonarSource Support, A **Support** tab will appear at **[Administration > Support](/#sonarqube-admin#/admin/extension/license/support)** to guide you through interactions with SonarSource Support.\n\nThis page also allows you to collect the Support Information File of your instance. Make sure to provide this file for any interaction with SonarSource Support.\n\n![Support Information File.](/images/support-information-file.png)\n\n"},{path:"instance-administration/look-and-feel",content:'---\ntitle: Look and Feel\nurl: /instance-administration/look-and-feel/\n---\n\n## Home logo\nYou can set your own "home" logo in **[Administration > General > Look & Feel](/#sonarqube-admin#/admin/settings)**. Simply provide an image URL and width. Ideally, the width will scale the height to 30 pixels. This logo will be used in both the menu bar and on the About page.\n\n## Content of the "About" page\nYou also have the ability to add content to the About page, which anonymous users land on by default: **[Administration > General > Look & Feel](/#sonarqube-admin#/admin/settings)**.\n\n## Gravatar\nGravatar support is enabled by default, using gravatar.com. You can configure a different server or disable the feature altogether. When enabled, gravatars show up next to most uses of the user name.\n'},{path:"instance-administration/marketplace",content:"---\ntitle: Marketplace\nurl: /instance-administration/marketplace/\n---\n\n[[info]]\n| You can only install and update plugins from the Marketplace in SonarQube Community Edition. With commercial editions, you need manually install and update your plugins. See [Install a Plugin](/setup/install-plugin/) for more information.\n\nAdministrators can access the Marketplace via **[Administration > Marketplace](/#sonarqube-admin#/admin/marketplace)**. The Marketplace is the place for keeping the pieces of the SonarQube platform up to date. It lets you:\n\nSee\n\n* The currently installed SonarQube Edition\n* Which plugins are installed\n* Whether plugin updates are available\n* Which other plugins are compatible with your version of SonarQube\n\nDiscover\n\n* Which other Editions are available, to enable more features\n\nInstall\n\n* New plugins\n* Plugin updates\n\nTo view/install plugin updates, your SonarQube server needs internet access. Installations require the platform to be restarted before they take effect.\n\n## Pending Operations\n\nWhen you perform an action in the Marketplace (install, update, or uninstall a plugin), a yellow banner appears at the top of the page showing pending operations that will be executed once SonarQube is restarted. Pending operations can be canceled until the server is restarted.\n\n## Restart SonarQube\nRestarting SonarQube can be done manually from the command line by running `sonar.sh restart` or directly from the UI:\n\n* in the Update Center when you have Pending Changes, the restart button will be displayed in the yellow banner (see Pending Operations)\n* in the System Info page at any time\n\n## Manual Updates\nIf you're using a commercial edition or your server doesn't have internet access, you won't be able to rely on the Marketplace for plugins, and you will have to handle plugin installations and upgrades manually.\n\nTo see what plugins are available and which version of a plugin is appropriate for your server, use the [plugin version matrix](/instance-administration/plugin-version-matrix/), which is kept up to date with current plugin availability and compatibility.\n\nTo install a plugin, simply download it using the manual download link on the plugin documentation page, place it in `$SONARQUBE-HOME/extensions/plugins`, and restart the server.\n\n### Stopping the Marketplace from searching for plugin updates\nYour SonarQube server needs internet access for the Marketplace to search for plugin updates. If your server doesn't have internet access, you may get errors in your logs when the Marketplace tries to search for new plugins. You can stop this by updating `sonar.updatecenter.activate` in `$SONARQUBE-HOME/conf/sonar.properties`.\n\n## Which URLs does the Marketplace connect to?\nThe SonarQube Marketplace connects to https://update.sonarsource.org/ to get the list of plugins. Most of the referenced plugins are downloaded from:\n* https://binaries.sonarsource.com/\n* https://github.com/\n\n## Using the Marketplace behind a Proxy\nMarketplace uses HTTP(S) connections to external servers to provide these services. If SonarQube is located behind a proxy, additional information must be provided in the _$SONARQUBE-HOME/conf/sonar.properties_ configuration file:\n```\nhttp.proxyHost=<your.proxy.host>\nhttp.proxyPort=<yout.proxy.port>\n\n#If proxy authentication is required\nhttp.proxyUser=<your.proxy.user>\nhttp.proxyPassword=<your.proxy.password> \n```\nNote: the same properties can be used in the 'https.' form for HTTPS connections."},{path:"instance-administration/monitoring",content:"---\ntitle: Monitoring\nurl: /instance-administration/monitoring/\n---\n\nMonitoring your SonarQube instance is key to keeping it healthy and having happy users.\n\nAs a start, you can use this Web API to get an overview of the health of your SonarQube installation:\n\n* [api/system/health](/#sonarqube-admin#/api/system/health)\n\n## Java Process Memory\n\nThe SonarQube application server consists of three main Java processes:\n\n* Compute Engine\n* Elasticsearch\n* Web (including embedded web server)\n\nEach of these Java processes has its own memory settings that can be configured in the _$SONARQUBE-HOME/conf/sonar.properties_ file. The default memory settings that ship with SonarQube are fine for most instances. If you are supporting a large SonarQube instance (more than 100 users or more than 5,000,000 lines of code) or an instance that is part of your Continuous Integration pipeline, you should monitor the memory and CPU usage of all three key Java processes on your instance, along with overall disk space. Monitoring will allow you to see if any of the processes is running short of resources and take action ahead of resource shortages. There are numerous monitoring tools available, both open source and commercial, to help you with this task. SonarSource does not recommend or endorse any particular tool.\n\n## Memory settings\n\nYou may need to increase your memory settings if you see the following symptoms:\n\n* Your monitoring tools show one or more of the SonarQube processes is reaching its memory limit\n* Any of the SonarQube processes crashes and/or generates an out-of-memory error in the sonar.log file\n* A SonarQube background task fails with an out-of-memory error in the background task log\n* The store size of the Issues index of your Elasticsearch instance (visible in the System Info) is greater than or equal to the memory allocated to the Elasticsearch Java process\n\nYou can increase the maximum memory allocated to the appropriate process by increasing the  -Xmx memory setting for the corresponding Java process in your _$SONARQUBE-HOME/conf/sonar.properties_ file:\n\nJava Process | SonarQube Property | Notes\n--- | --- | ---\nCompute Engine | sonar.ce.javaOpts\nElasticsearch | sonar.search.javaOpts | It is recommended to set the min and max memory to the same value to prevent the heap from resizing at runtime, which diverts JVM resources and can greatly increase response times of in-flight requests.\nWeb | sonar.web.javaOpts\n\nThe -Xmx parameter accepts numbers in both megabytes (e.g. -Xmx2048m) and gigabytes (e.g. -Xmx2G). The metric suffix is case-insensitive.\n\n## Exposed JMX MBeans\n\nThe SonarQube Server offers visibility about what happens internally through the exposure of JMX MBeans.\n\nIn addition to the classical Java MBeans providing information about the ClassLoader, OS, Memory, and Threads you have access to three more MBeans in the SonarQube Server:\n\n* ComputeEngine\n* Database\n* SonarQube\n\nAll these MBeans are read-only. It's not possible to modify or reset their values in real time.\n\n[[collapse]]\n| ## ComputeEngineTasks MBean\n| Attribute Name | Description\n| ---|---\n| ProcessingTime | Measure the time (in ms) spent to process Background Tasks since the last restart of SonarQube. Its value will always increase and will be reset by a restart of SonarQube.  This measure is very powerful when combined with SuccessCount and ErrorCount measures to get the average time to handle a Background Task, or when used to understand how much time the SonarQube Server is spending during a day to handle Background Tasks. It gives you an indication of the load on your server.\n| ErrorCount | Number of Background Tasks which failed since the last restart of SonarQube\n| PendingCount | Number of Background Tasks waiting to be processed since the last restart of SonarQube\n| InProgressCount | Number of Background Tasks currently under processing. Its value is either 1 or 0, since SonarQube can process only one task at a time.\n| SuccessCount | Number of Background Tasks successfully processed since the last restart of SonarQube\n| WorkerCount | Number of Background Tasks that can be processed at the same time\n| PendingTime | Pending time (in ms) of the oldest Background Task waiting to be processed. This measure, together with PendingCount, helps you know if analyses are stacking and taking too long to start processing. This helps you evaluate if it might be worth configuring additional Compute Engine workers (Enterprise Edition) or additional nodes (Data Center Edition) to improve SonarQube performance.\n|\n| Note:\n| * the total number of Background Tasks handled since the last restart of SonarQube is equal to SuccessCount + ErrorCount\n| * all values reset to their default values after restarting SonarQube\n\n[[collapse]]\n| ## Database MBean\n| ### Same attributes are available for both ComputeEngineServer and WebServer.\n| Attribute Name | Description\n| ---|---\n| MigrationStatus | Possible values are: UP_TO_DATE, REQUIRES_UPGRADE, REQUIRES_DOWNGRADE, FRESH_INSTALL (only available for WebServer).\n| PoolActiveConnections\t| Number of active database connections\n| PoolIdleConnections | Number of database connections waiting to be used\n| PoolInitialSize | Initial size of the database connections pool.\n| PoolMaxActiveConnections | Maximum number of active database connections\n| PoolMaxIdleConnections | Maximum number of database connections waiting to be used\n| PoolMaxWaitMillis | In milliseconds\n| PoolRemoveAbandoned | Possible values : true, false\n| PoolRemoveAbandonedTimeoutSeconds | In Seconds\n\n[[collapse]]\n| ## SonarQube MBean\n| Attribute Name | Description\n| ---|---\n| LogLevel | Log Level: INFO, DEBUG, TRACE\n| ServerId | SonarQube Server ID\n| Version | SonarQube Version\n\n## How do I Activate JMX?\n\n### Local Access\n\nThere is nothing to activate to view SonarQube MBeans if your tool is running on the same server as the SonarQube Server.\n\n### Remote Access\n\nHere are examples of configuration to activate remote access to JMX MBeans.\n\n* For the WebServer:\n```\n# JMX WEB - 10443/10444\nsonar.web.javaAdditionalOpts=-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.port=10443 -Dcom.sun.management.jmxremote.rmi.port=10444 -Dcom.sun.management.jmxremote.password.file=/opt/sonarsource/sonar/conf/jmxremote.password -Dcom.sun.management.jmxremote.access.file=/opt/sonarsource/sonar/conf/jmxremote.access\n```\n\n* For the ComputeEngine:\n\nThere is no specific javaAdditionalOpts entry, simply amend sonar.ce.javaOpts.\n\nExample of `jmxremote.access`:\n\n```\n#\n# JMX Access Control file\n#\nreader readonly\nadmin  readwrite \\\n    create javax.management.monitor.*,javax.management.timer.*,com.sun.management.*,com.oracle.jrockit.* \\\n    unregister\n```\n\nExample of `jmxremote.password`:\n\n```\n#\n# JMX Access Password file\n#\nreader readerpassword\nadmin  adminpassword\n```\n\nNote: on `jmxremote.password`, you should apply `chmod 600` or `400` for security reasons.\n"},{path:"instance-administration/notifications",content:"---\ntitle: Notifications\nurl: /instance-administration/notifications/\n---\nAt the end of each analysis, notifications are computed for each subscribed user. Then, asynchronously, these notifications are sent via email.\n\nTo set the frequency with which the notification queue is processed, set `the sonar.notifications.delay` property (in seconds) in _$SONARQUBE-HOME/conf/sonar.properties_. The server must be restarted for the new value to be taken into account.\n\n## Who gets notifications\nOnly users who subscribe themselves will get notifications. With only one exception, there is no admin functionality to proactively subscribe another user. If you believe a user should be receiving notifications, then it's time to practice the gentle art of persuasion.\n\n### The exception\n\nNotifications will automatically (without user opt-in) be sent to users with Quality Profile Administration rights when built-in quality profiles are updated. These updates can only happen through updating SonarQube or updating a third-party analyzer. This type of notification is on by default, and can be toggled globally in **[Administration > General Settings > General](/#sonarqube-admin#/admin/settings/)**.\n\n## Email Configuration\nTo configure the email server, go to **[Administration > General Settings > Email](/#sonarqube-admin#/admin/settings)**.\n\nCheck also the Server base URL property at Administration > General Settings > General to make sure that links in those notification emails will redirect to the right SonarQube server URL.\n"},{path:"instance-administration/plugin-version-matrix",content:'---\ntitle: Plugin Version Matrix\nurl: /instance-administration/plugin-version-matrix/\n---\n\n\n![(Supported by SonarSource)](https://update.sonarsource.org/plugins/onde-sonar-16.png) = Supported by SonarSource  \n![(not compatible)](https://update.sonarsource.org/plugins/error.png) = Not compatible  \n\n<iframe src="https://update.sonarsource.org/plugins/compatibility-matrix.html" height="3100">Your browser does not support iframes.</iframe>\n\n'},{path:"instance-administration/project-move",content:'---\ntitle: Project Move\nurl: /instance-administration/project-move/\n---\n\n_Project Move is available as part of [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html) and [above](https://www.sonarsource.com/plans-and-pricing/)._\n\nProject Move allows you to export a project from one SonarQube instance and import it into another, identically configured SonarQube instance. To use Project Move, you must have the Administer permission on the project in the source instance, and access to the file systems of both instances.\n\n## When to Use "Project Move"\nIn the following cases:\n\n* you want to create a central SonarQube instance at enterprise level and you want to keep the history created on N instances used previously at the team level\n* your company is acquiring another company that already has a central SonarQube instance\n* an application is transferred from one team to another in a large company and that company has several SonarQube instances\n\n## Prerequisites\nIn order to be able to export and then load your Project\'s data, the two SonarQube instances must have:\n\n* the exact same version\n* the same plugins with the same versions\n* the same custom metrics\n* the same custom rules\n\n## How To Export\nOn the source instance:\n* reanalyze the project one last time to make sure it is populated with data corresponding to your current SonarQube installation\n* navigate to the project and at the project level, choose **Project Settings > Import / Export**\n* click on the **Export** button to generate a zip file containing the settings and history of your Project (but not the source code). Note that if you need to change the Project\'s key, you must to do it before performing the export.\n\nA zip file containing all project data ex is generated in _$SONAR_SOURCE_HOME/data/governance/project_dumps/export/_ named _<project_key>.zip_\n\n## How To Import\nOn the target instance:\n\n* With a user having the "Administer System" and "Create Projects" permissions, go to [**Administration > Projects > Management**](/#sonarqube-admin#/admin/projects_management/) and [provision the project](/project-administration/project-existence/) using the same key the project had in the source instance.\n* Configure the Project\'s permissions, and the Quality Profiles and Quality Gate associated to the Project\n* Put the generated zip file into the directory *$SONAR\\_TARGET\\_HOME/data/governance/project_dumps/import*\n* Go to the Project\'s Home Page and choose **Project Settings > Import / Export**\n* Click on the Import button to start importing your data\n* Source code is not included in the zip file. Once the import is finished, trigger an analysis to import source files into the new instance.\n\nNotes:\n\n* If the import is successful, the zip file will automatically be deleted.\n* It is not possible to import a Project that has been already analyzed on the target instance.\n* Security reports in an imported project will be empty until analysis has run.\n'},{path:"instance-administration/quality-profiles",content:"---\ntitle: Quality Profiles\nurl: /instance-administration/quality-profiles/\n---\n\n## Overview\n\n**Quality Profiles** are a core component of SonarQube, since they are where you define sets of [**Rules**](/user-guide/rules/) that when violated should raise issues on your codebase (example: Methods should not have a Cognitive Complexity higher than 15). Quality Profiles are defined for individual languages.\n\nTo manage Quality Profiles, browse to the the [**Quality Profiles**](/#sonarqube#/profiles) page where you'll find Quality Profiles grouped by language.\n\nIdeally all of your projects will be measured with the same Quality Profiles, but that is not _always_ practical. In some cases, you may find that:\n\n- You have different technical requirements from one project to another (different rules might apply to a threaded/non-threaded Java application)\n- You want to ensure stronger requirements for some of your projects (internal frameworks, for example)\n\nWhile it's recommended to have as few Quality Profiles as possible to ensure consistency across projects, you can define as many Quality Profiles as are necessary to fit your specific needs.\n\nEach language must have a default Quality Profile (marked with the Default tag). Projects that are not explicitly assigned to specific Quality Profiles will be analyzed using the default Quality Profiles. There is also at least one built-in Quality Profile (the **Sonar way**) per language. These Quality Profiles are designed by SonarSource with rules that are generally applicable for most projects. \n\nThe Sonar way Quality Profiles are a good starting-point as you begin analyzing code, and they start out as the default Quality Profiles for each language. That being said, we recommend that you **Copy** this profile and begin to fine-tune the contents. Why?\n\n- Default Quality Profiles are not editable, so you won't be able to customize the Sonar way to your needs\n- The Sonar way becomes a baseline against which you can track your own Quality Profiles\n- The Sonar way may be updated over time to adjust which rules are included and adjust rule severities.\n\n## How do I...\n\n### Delegate the management of Quality Profiles to someone else?\n\nBy default, only users with the \"Administer Quality Profiles\" permission can edit Quality Profiles. But in large organizations, it may not be desirable to grant permissions to change all the Quality Profiles without distinction. That's why you can also grant users/groups the permission to edit an individual Quality Profile so that, for instance, the management of the Swift profile can be delegated to a group of Swift experts, and the same for COBOL, ...\n\nThis delegation of permission can only be performed by someone who already has the \"Administer Quality Profiles\" permission or individual edit rights on the profile to which additional permissions should be granted. The interface to grant individual permissions is available on the profile detail page.\n\n### Copy the rules from one profile to another?\n\nMany times people want to work from a profile that's based on a built-in profile without actually using the built-in profile. The easiest thing to do in this case is to go to the original profile, we'll call it _Source_, in **Quality Profiles**. From there, click through on the total number of rules in _Source_ to land on the **Rules** page at a pre-narrowed search of _Source_'s rules. Use **Bulk Activate** to turn Source's rules on in your target profile.\n\n### Know what's changed in a profile?\n\nWhen {instance} notices that an analysis was performed with a profile that is different in some way from the previous analysis, a Quality Profile event is added to the project's event log. To see the changes in a profile, navigate to the profile (**Quality Profiles > [ Profile Name ]**), and choose **Changelog**. This may help you understand how profile changes impact the issues raised in an analysis.\n\nAdditionally, users with Quality Profile administration privileges are notified by email each time a built-in profile is updated. These updates can be caused by updating SonarQube or updating third-party analyzers.\n\n### Copy a profile from one SonarQube instance to another?\n\nUse the **Back up** feature on the source instance to export the profile to an XML file. Use the **Restore Profile** feature on the target instance to import the file.\n\n### Apply a core set of rules plus additional rules to a project?\n\nLet's say your company has a minimum set of coding rules that all teams must follow, but you want to add rules that are specific to the in use technology in your project. Those rules are good for your team, but irrelevant or even misleading for others. This situation calls for inheritance. Set up a base profile, we'll call it _Root_ with your core set of rules. Then create a child profile, we'll call it _Sprout_. Once it's created, you can **Change parent** to inherit from _Root_, then add your missing rules.\n\nAny profile that inherits from another Quality Profile will be updated when the parent Quality Profile is updated.\n\n### Make sure my non-default profile is used on a project?\n\nOne profile for each language is marked the default. Barring any other intervention, all projects that use that language will be analyzed with that profile. To have a project analyzed by a non-default profile instead, start from **Quality Profiles**, and click through on your target profile, then use the Projects part of the interface to manage which projects are explicitly assigned to the profile.\n\n### Make sure I've got all the relevant new rules in my profile?\n\nEach time a new SonarQube version is released, new rules are added, but they won't appear automatically in your profile unless you're using a built-in profile such as _Sonar way_.\n\nIf you're not using a built-in profile, you can compare your profile to the built-in profile to see what new on-by-default rules you're missing.\n\nAnother option is to go to the **Rules** space, and use the **Available Since** search facet to see what rules have been added to the platform since the day you upgraded the relevant plugin.\n\nAnd finally, the profile interface itself will help you be aware of rules added in a new plugin version in the **Latest New Rules** section on the right of the interface.\n\n### Compare two profiles?\n\nStarting from the **Quality Profiles** page, click through on one of the profiles you'd like to compare, then use the **Actions > Compare** interface to select the second profile and see the differences.\n\n### Make sure I don't have any deprecated rules in my profile?\n\nThe **Deprecated Rules** section of the rules interface itself is your first warning that a profile contains deprecated rules. This pink-background section gives the total number of instances of deprecated rules that are currently active in profiles, and a breakdown of deprecated count per profile. A click-through here takes you to the **Rules** page to edit the profile in question.\n\nAlternately, you can perform a **Rules** search for the rules in a profile (either manually or by clicking-through from **Quality Profiles** page) and use the **Status** rule search facet to narrow the list to the ones that need attention.\n\n## Security\n\nThe Quality Profiles service can be accessed by any user (even anonymous users). All users can view every aspect of a profile. That means anyone can see which rules are included in a profile, and which ones have been left out, see how a profile has changed over time, and compare the rules in any two profiles.\n\nTo make rule profile changes (create, edit or delete) users must be granted the **Administer Quality Profiles and Gates** permission.\n\nA **project administrator** can choose which profiles his project is associated with. See Project Settings for more.\n"},{path:"instance-administration/security",content:"---\ntitle: Security\nurl: /instance-administration/security/\n---\n\n## Overview\n\nSonarQube comes with a number of global security features:\n\n* on-board authentication and authorization mechanisms\n* the ability to force users to authenticate before they can see any part of a SonarQube instance\n* the ability to delegate to authentication (for more see [Delegating Authentication](/instance-administration/delegated-auth/))\n\nAdditionally, you can configure at a group or user level who can:\n* see that a project even exists\n* access a project's source code \n* administer a project (set exclusion patterns, tune plugin configuration for that project, etc.)\n* administer Quality Profiles, Quality Gates, and the SonarQube instance itself.\n\nAnother aspect of security is the encryption of settings such as passwords. SonarQube provides a built-in mechanism to encrypt settings.\n\n## Authentication\n\nBy default, SonarQube forces user authentication. You can disable forced user authentication, and allow anonymous users to browse projects and run analyses in your instance. To do this, log in as a system administrator, go to **[Administration > Configuration > General Settings > Security](/#sonarqube-admin#/admin/settings?category=security)**, and disable the **Force user authentication** property. \n\n[[warning]]\n| Disabling the **Force user authentication** can expose your SonarQube instance to security risks. We strongly recommend forcing user authentication on production instances or carefully configuring the security (user permissions, project visibility, etc.) on your instance.  \n\n### API Endpoints Authentication\n\nIf the **Force user authentication** property is set to false, the following API endpoints are accessible **without authentication** (click **API endpoints** below to expand the list):\n\n[[collapse]]\n| ## API endpoints\n|\n| * api/components/search\n| * api/issues/tags\n| * api/languages/list\n| * api/metrics/domains\n| * api/metrics/search\n| * api/metrics/types\n| * api/plugins/installed\n| * api/project_tags/search\n| * api/qualitygates/list\n| * api/qualitygates/search\n| * api/qualitygates/show\n| * api/qualityprofiles/backup\n| * api/qualityprofiles/changelog\n| * api/qualityprofiles/export\n| * api/qualityprofiles/exporters\n| * api/qualityprofiles/importers\n| * api/qualityprofiles/inheritance\n| * api/qualityprofiles/projects\n| * api/qualityprofiles/search\n| * api/rules/repositories\n| * api/rules/search\n| * api/rules/show\n| * api/rules/tags\n| * api/server/version\n| * api/sources/scm (for public repositories)\n| * api/sources/show (for public repositories)\n| * api/system/db_migration_status\n| * api/system/migrate_db\n| * api/system/ping\n| * api/system/status\n| * api/system/upgrades\n| * api/users/search\n| * api/views/run\n| * api/webservices/list\n| * api/webservices/response_example\n\nWe advise keeping **Force user authentication** enabled if you have your SonarQube instance publicly accessible.\n\n### Authentication Mechanisms\nAuthentication can be managed through a number of mechanisms:\n\n* Via the SonarQube built-in users/groups database\n* Via external identity providers such as an LDAP server (including LDAP Service of Active Directory), GitHub etc. See the Authentication & Authorization section of the Plugin Library.\n* Via HTTP headers\n\n### Technical Users\nWhen you create a user in SonarQube's own database, it is considered local and will only be authenticated against SonarQube's own user/group database rather than against any external tool (LDAP, Active Directory, Crowd, etc.). By default `admin` is a local account.\n\nSimilarly, all non-local accounts will be authenticated only against the external tool. \n\nAn Administrator can manage tokens on a user's behalf via **[Administration > Security > Users](/#sonarqube-admin#/admin/users)**. From here, click in the user's **Tokens** column to see the user's existing tokens, and either revoke existing tokens or generate new ones. Once established, a token is the only credential needed to run an analysis. Tokens should be passed as the value of the `sonar.login` property.\n\n### Default Admin Credentials\nWhen installing SonarQube, a default user with Administer System permission is created automatically:\n\n* Login: admin\n* Password: admin\n\n## Reinstating Admin Access\n\nIf you've deleted `admin` and subsequently locked out the other users with global administrative permissions, you'll need to re-grant `admin` to a user with the following query:\n```\nINSERT INTO user_roles(uuid, user_uuid, role) \nVALUES ('random-uuid',\n(select uuid from users where login='mylogin'), \n'admin');\n```\n\nIf you changed and then lost the `admin` password, you can reset it using the following query, depending on the database engine:\n\n### PostgreSQL and Microsoft SQL Server\n```\nupdate users set crypted_password='100000$t2h8AtNs1AlCHuLobDjHQTn9XppwTIx88UjqUm4s8RsfTuXQHSd/fpFexAnewwPsO6jGFQUv/24DnO55hY6Xew==', salt='k9x9eN127/3e/hf38iNiKwVfaVk=', hash_method='PBKDF2', reset_password='true', user_local='true' where login='admin';\n```\n### Oracle\n```\nupdate users set crypted_password='100000$t2h8AtNs1AlCHuLobDjHQTn9XppwTIx88UjqUm4s8RsfTuXQHSd/fpFexAnewwPsO6jGFQUv/24DnO55hY6Xew==', salt='k9x9eN127/3e/hf38iNiKwVfaVk=', hash_method='PBKDF2', reset_password=1, user_local=1 where login='admin';\n```\n\n## Authorization\nThe way authorization is implemented in SonarQube is pretty standard. It is possible to create as many users and groups of users as needed. The users can then be attached (or not) to (multiple) groups. Groups and/or users are then given (multiple) permissions. The permissions grant access to projects, services, and functionalities.\n\nTo administer groups and users, choose **Administration > Security**, and use the sub-menu items.\n\n### User\nMultiple integrations that allow the delegation of authentication are available (see the [Plugin Library](https://docs.sonarqube.org/8.9/instance-administration/plugin-version-matrix/) but you can manually create and edit users at **[Settings > Security > Users](/#sonarqube-admin#/admin/users)**. For manually-created users, login and password can be set at creation. Manually-created users can edit their passwords.\n\nDuring both user creation and edit, you can set an account's screen name, email address. User login and email address will be implicitly recognized by the Issue Assignment feature as SCM accounts if applicable, but you can set additional SCM accounts explicitly. \n\n### Group\nA group is a set of users.\n\nTo administer groups, go to **[Administration > Security > Groups](/#sonarqube-admin#/admin/groups)**.\n\nTo edit the membership of a group, click the icon next to the membership total.\n\nTwo groups have a special meaning:\n\n* **Anyone** is a group that exists in the system, but that cannot be managed. Every user belongs to this group, including anonymous users.\n* **sonar-users** is the default group to which users are automatically added.\n\n### Global Permissions\nTo set global permissions, log in as a System administrator and go to **[Administration > Security > Global Permissions](/#sonarqube-admin#/admin/permissions)**. \n\n* **Administer System**: All administration functions for the instance: global configuration.\n* **Administer Quality Profiles**: Any action on Quality Profiles.\n* **Administer Quality Gates**: Any action on quality gates\n* **Execute Analysis**:  Access to all settings required to perform analysis and the ability to push analysis results to the SonarQube server. This includes private project settings and secured settings like passwords. \n* **Create Projects**: Initialize the structure of a new project before its first analysis. This permission is also required when doing the very first analysis of a project that has not already been created via the GUI. * **\n* **Create Applications**: Create a new Application. * **\n* **Create Portfolios**: Create a new Portfolio. * **\n\n\\* Users with any explicit create permission will see a \"+\" item in the top menu giving access to these functions. If these permissions are removed from global administrators, they will lose quick access to them via the \"+\" menu, **but retain access to creation** via the **Administration** menu.\n\n** Creating an item does not automatically grant rights to administer it. For that, see _Creators permission_ below.\n\n### Project Permissions\nProject permissions are available from the project-level Administration menu: **Project Settings > Permissions**.\n\nProject visibility may be toggled between public or private. Making a project private hides its source code and measures from the `Anyone` group. For both public and private projects, four different permissions can be set:\n\n* **Administer Issues**: Change the type and severity of issues, resolve issues as being \"Won't Fix\" or \"False Positive\" (users also need \"Browse\" permission).\n* **Administer Security Hotspots**: Change the status of a Security Hotspot.\n* **Administer**: Access project settings and perform administration tasks (users also need \"Browse\" permission).  \n  By default, a user with this **Administer** permission can manage both configuration and permissions for the current project. To only allow project administrators to update the project configuration, go to **[Administration > Configuration > General Settings > Security](/#sonarqube-admin#/admin/settings?category=security)** and disable the **Enable permission management for project administrators** property.\n* **Execute Analysis**: Access to all settings required to perform analysis and the ability to push analysis results to the SonarQube server. This includes private project settings and secured settings like passwords\n\nPrivate projects have two additional permissions:\n* **Browse**: Access a project; browse its measures, issues, and Security Hotspots; perform some issue edits (confirm/resolve/reopen, assignment, comment); comment on or change the user assigned to a Security Hotspot.\n* **See Source Code**: View the project's source code.\n\nNote that permissions _are not_ cumulative. For instance, if you want to be able to administer the project, you also have to be granted the Browse permission to be able to access the project (which is the default for public projects).\n\nYou can either manually grant permissions for each project to some users and groups or apply permission templates to projects. \n\n## Permission Templates for Default Permissions\nSonarQube ships with a default permissions template, which automatically grants specific permissions to certain groups when a project, portfolio, or application is created. It is possible to edit this template and to create additional templates. A separate template can be set for each type of resource. Further, for projects, you can have a template apply only to a subset of new projects using a project key regular expression (the template's **Project Key Pattern**). By default, every new project with a key that matches the supplied pattern will have the template's permissions applied.\n\nTemplates are empty immediately after creation. Clicking on the template name will take you to its permission editing interface.\n\nTemplates are administered through **[Administration > Security > Permission Templates](/#sonarqube-admin#/admin/permission_templates)**.\n\n### Creators permissions\n**Creators** is a special group that appears only in the permission template editing interface. Any permissions assigned to this group will at the time of project/portfolio/application creation be granted to the single user account used to create the project. This allows SonarQube administrators to let users autonomously create and administer their own projects.\n\nWhile templates can be applied after project creation, applying a template that includes \"Creators\" permissions to an existing project/portfolio/application will not grant the relevant permissions to the project's original creator because that association is not stored.\n\n### Reset project permissions to a template\nTo apply permission templates to projects go to **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management)**. You can either apply a template to a specific project using the project-specific **Actions > Apply Permission Template** option or use the Bulk Apply Permission Template to apply a template to all selected projects.\n\nNote that there is no relation between a project and a permission template, meaning that:\n* the permissions of a project can be modified after a permission template has been applied to this project\n* none of the project permissions is changed when a permission template is modified\n\n## Settings Encryption\nEncryption is mostly used to remove clear passwords from settings (database or SCM credentials for instance). The implemented solution is based on a symmetric key algorithm. The key point is that the secret key is stored in a secured file on disk. This file must be owned by and readable only by the system account that runs the SonarQube server.\n\nThe encryption algorithm used is AES with 256 bit keys.\n\n1. **Generate the secret key**  \nA unique secret key must be shared between all parts of the SonarQube infrastructure. To generate it, go to **[Administration > Configuration > Encryption](/#sonarqube-admin#/admin/settings/encryption)** and click on Generate Secret Key.\n1. **Store the secret key on the SonarQube server**  \n   * Copy the generated secret key to a file on the machine hosting the SonarQube server. The default location is _~/.sonar/sonar-secret.txt_. If you want to store it somewhere else, set its path through the `sonar.secretKeyPath` property in _$SONARQUBE-HOME/conf/sonar.properties_\n   * Restrict file permissions to the account running the SonarQube server (ownership and read-access only).\n   * Restart your SonarQube server\n1. **Generate the encrypted values of your settings**  \nGo back to **[Administration > Configuration > Encryption](/#sonarqube-admin#/admin/settings/encryption)** and use the form that has been added to the interface to generated encrypted versions of your values.\n![Encrypt values through the admin interface](/images/encrypt-value.png)\n1. **Use the encrypted values in your SonarQube server configuration**  \nSimply copy these encrypted values into _$SONARQUBE-HOME/conf/sonar.properties_\n```\nsonar.jdbc.password={aes-gcm}CCGCFg4Xpm6r+PiJb1Swfg==  # Encrypted DB password\n...\nsonar.secretKeyPath=C:/path/to/my/secure/location/my_secret_key.txt\n```\n"},{path:"instance-administration/system-info",content:'---\ntitle: Server Logs & System Info\nurl: /instance-administration/system-info/\n---\n\nThe System Info page is found at **[Administration > System](/#sonarqube-admin#/admin/system)**. It gives you access to detailed information on the state of your SonarQube instance. \n\n## System Info\n\nYou can browse details about your running instance on this page. \n\n### Download\n\nAdditionally, if you have a Support contract, you might be asked by a Support representative to send in your System Info, which can be downloaded from the page **[Administration > System](/#sonarqube-admin#/admin/system)** using the **"Download System Info"** button at the top.\n\n### Server Id\nYour server id can be obtained from this page by expanding the **System** section. If you\'re running a commercial instance, you can also find this value on the License page (**[Administration > Configuration > License Manager](/#sonarqube-admin#/admin/extension/license/app)**)\n\n## Logs\nServer-side logging is controlled by properties set in _$SONARQUBE-HOME/conf/sonar.properties_.\n\n4 logs files are created: one per SonarQube process.\n\n### Log Level\nThe server-side log level can be customized via the `sonar.log.level` property. Supported values are:\n\n* **`INFO`** - the default\n* **`DEBUG`** - for advanced logs.\n* **`TRACE`** - show advanced logs and all SQL and Elasticsearch requests. `TRACE` level logging slows down the server environment, and should be used only for tracking web request performance problems.\n\n### Log Level by Process\nThe server-side log level can be adjusted more precisely for the 4 processes of SonarQube Server via the following property:\n\n* **`sonar.log.level.app`** - for the Main process of SonarQube (aka WrapperSimpleApp, the bootstrapper process starting the 3 others) \n* **`sonar.log.level.web`** - for the WebServer\n* **`sonar.log.level.ce`** - for the ComputeEngineServer\n* **`sonar.log.level.es`** - for the SearchServer\n\n### Log Rotation\nTo control log rolling, use the `sonar.log.rollingPolicy`\n\n* **`time:[value]`** - for time-based rotation. For example, use `time:yyyy-MM-dd` for daily rotation, and * `time:yyyy-MM` for monthly rotation.\n* **`size:[value]`** - for size-based rotation. For example, `size:10MB`.\n* **`none`** - for no rotation. Typically this would be used when logs are handled by an external system like logrotate.\n\n`sonar.log.maxFiles` is the maximum number of files to keep. This property is ignored if `sonar.log.rollingPolicy=none`.\n\n#### **Wrapper Config**\n\nIf Sonarqube was started using the SonarQube wrapper (for example, by using the provided start and stop scripts), the log rotation of the main Process (sonar.log) needs to be defined in the `wrapper.conf`.  \nBy Default, the wrapper will rotate the `sonar.log` file each day if there is new content to be logged.  \n\nThe log rotation in the wrapper can be fine-tuned with the following properties:\n\n* **`wrapper.logfile.maxsize=value[m for mb, k for kb]`**\n* **`wrapper.logfile.maxfiles=value`**\n* **`wrapper.logfile.rollmode=DATE|SIZE`**\n\n`wrapper.logfile.maxsize` and `wrapper.logfile.maxfiles` are only considered if `wrapper.logfile.rollmode` is set to `SIZE`.  \nFor `wrapper.logfile.rollmode=DATE` to work properly, the file defined with the property `wrapper.logfile` needs to include a "YYYYMMDD" Token.\n\n### UI Access to Logs and Log Levels\n\nThe System Info page gives you the ability to download your instance\'s current log files (log files rotate on a regular basis), and to tune the log level via controls at the top of the page. Changes made here are temporary, and last only until the next time the instance is restarted, at which point the level will be reset to the more permanent value set in _$SONARQUBE-HOME/conf/sonar.properties_. Regardless, if you change your log level _from_ `INFO`, but sure to change it back as soon as is practical; log files can get very large very quickly at lower log levels.\n\n## Total Lines of Code\nThe number of Lines of Code (for licensing purposes) in an instance can be found in the **System** section of the System Info page on, and on the License page (**[Administration > Configuration > License Manager](/#sonarqube-admin#/admin/extension/license/app)** in commercial editions. \n\nIf you\'re on a commercial edition and using Branch or PR analysis, rest assured that only lines from the single largest branch in a project are considered for licensing purposes. The Lines of Code in the rest of the branches are ignored.\n'},{path:"project-administration/managing-application",content:'---\ntitle: Managing Applications\nurl: /project-administration/managing-applications/\n---\n\n*Applications are available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html).*\n\n## Permissions\nThere are two levels of users with permissions for adding and editing Applications: users with the Create Applications permission and Global Administrators.  \n\n### Create Applications Permission\nUsers with the Create Applications permission (granted at the global level at [Administration > Security > Global Permissions](/#sonarqube-admin#/admin/permissions)) can create Applications by clicking the **Create Application** button in the upper-right corner of the **Projects** homepage. \n\nUsers with the Create Applications permission can edit an individual Application definition from the Application-level **Portfolio Settings > Edit Definition** interface.\n\n### Global Administrators\nStarting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), Global Administrators have access to the overall Portfolio and Application administration interface at **[Administration > Configuration > Portfolios](/#sonarqube-admin#/admin/extension/governance/views_console)**. From this page, they can create and edit Applications. \n\nGlobal Administrators also have access to the Projects Management page at **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management)**. Changing the selection mechanism on this page to “Portfolios” or “Applications” lets you manage the Portfolios or Applications of your SonarQube instance. The dropdown menu to the right of each item lets you edit permissions, apply Permission Templates, or restore access to a Portfolio or Application.\n\n## Populating Applications\nOnce your Application exists, you can populate it with manually-selected projects. By default, the configuration interface shows the list of projects currently selected for the application. To add additional projects, choose the "Unselected" or "All" filter.\n\n## Creating Application Branches\nOnce your Application is populated with projects, you can create application branches by choosing branches from the Application\'s component projects. This option is available in the Application\'s **Application Settings > Edit Definition** interface, or from the global administration interface.\n\n## Calculation\nBy default, Applications are queued to be recalculated after each analysis of an included project. For each relevant Application, a “Background Task” is created, and you can follow the progress on each in the **[Administration > Projects > Background Tasks](/#sonarqube-admin#/admin/background_tasks)** by looking at the logs available for each item.\n\n## Reindexing\nDuring Elasticsearch reindexing due to disaster recovery or upgrading, Applications become available as they are indexed.'},{path:"project-administration/managing-portfolios",content:"---\ntitle: Managing Portfolios\nurl: /project-administration/managing-portfolios/\n---\n\n*Portfolios are available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html).*\n\n## Permissions\nThere are two levels of users with permissions for adding and editing Portfolios: users with the Create Portfolios permission and Global Administrators.  \n\n### Create Portfolios Permission\n\nUsers with the Create Portfolios permission (granted at the global level at [Administration > Security > Global Permissions](/#sonarqube-admin#/admin/permissions)) can create Portfolios by clicking the **Create Portfolio** button in the upper-right corner of the **Portfolios** homepage.\n\nUsers with the Create Portfolios permission can edit an individual Portfolio definition from the Portfolio-level **Portfolio Settings > Edit Definition** interface.\n\n### Global Administrators\n\nIn addition to the access granted to users with the Create Portfolios permission, Global Administrators have access to the overall Portfolio and Application administration interface at **[Administration > Configuration > Portfolios](/#sonarqube-admin#/admin/extension/governance/views_console)**. From this page, they can create and edit Portfolios. \n\nGlobal Administrators also have access to the Projects Management page at **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management)**. Changing the selection mechanism on this page to “Portfolios” or “Applications” lets you manage the Portfolios or Applications of your SonarQube instance. The dropdown menu to the right of each item lets you edit permissions, apply Permission Templates or restore access to a Portfolio or Application.\n\n## Populating Portfolios\nOnce your Portfolio exists, you can populate it with any mix of projects, Applications, and sub-portfolios.\n\n### Adding a Sub-portfolio\nTo add a sub-portfolio, click on “Add Portfolio” at the top of the third column, and choose:\n\n* **Standard** - This option allows you to create a new sub-Portfolio from scratch. Once created, you can add projects, applications, and more layers of sub-portfolios.\n* **Local Reference** - This option allows you to reference an existing Portfolio/Application as a sub-portfolio. Once added, it is not editable here, but must be chosen in the left-most column to be edited.\n\n### Adding Projects to a Portfolio\nTo add projects directly to a Portfolio or standard sub-Portfolio first make sure the correct item is selected, then choose the **Project selection mode**:\n\n* **Manual** – choose the projects individually.\n* **Tags** - select one or more project tags. Projects with those tags will automatically be included.\n* **Regular Expression** – specify a regular expression and projects with a matching name OR key will be included.\n* **All Remaining Projects** – choose this option to add all projects not already included in this Portfolio (directly or via sub-Portfolio).\n\n### Adding Applications to a Portfolio\nTo add an Application to a Portfolio, first make sure your Application is [already created](/user-guide/applications/). Then:\n\n1. Navigate to the Portfolios configuration page by going to **[Administration > Configuration > Portfolios](/#sonarqube-admint#/admin/extension/governance/views_console/)**.\n2. Select the Portfolio where you want to add your Application\n3. Click **Add Portfolio**\n4. Select **Local Reference**\n5. Choose your Application from the drop-down list and click **Add**.\n\n[[info]]\n|**Project unicity under a portfolio**<br/><br/>\n|Projects, applications and sub-portfolios can only appear once in any given hierarchy in order to avoid magnifying their impacts on aggregated ratings. The portfolio configuration interface has some logic to prevent obvious duplications (e.g. manually adding the same project), however in case of more subtle duplications (e.g. due to regex, or other bulk definition), then the calculation of that portfolio will fail with a helpful error message.\n\n## Calculation\nBy default, Portfolios are queued to be recalculated after each analysis of an included project. For each relevant Portfolio, a “Background Task” is created, and you can follow the progress on each in the **[Administration > Projects > Background Tasks](/#sonarqube-admin#/admin/background_tasks)** by looking at the logs available for each item.\n\nIf you're having performance issues related to automatic recalculation of large portfolios, you can specify the hour(s) at which you want them to be recalculated at **[Administration > Portfolios > Recalculation](/#sonarqube-admin#/admin/settings?category=portfolios)**. Portfolios are queued to be recalculated at the beginning of the hour(s) that you specify.\n\n## Reindexing\nDuring Elasticsearch reindexing due to disaster recovery or an upgrade, you won't have access to Portfolios until all projects are indexed.\n"},{path:"project-administration/managing-project-history",content:"---\ntitle: Managing Project History\nurl: /project-administration/managing-project-history/\n---\n\nOne of the most powerful features of {instance} is that it shows you not just your project health today, but how it has changed over time. It does that by selectively keeping data from previous analyses (see [Housekeeping](/instance-administration/housekeeping/)). It doesn't keep all previous analyses - that would bloat the database. Similarly, for the analyses it does keep, {instance} doesn't keep all the data. Once a project snapshot moves from the \"Last analysis\" (i.e. the most recent) to being part of the project's history, data below the project level is purged - again to keep from bloating the database.\n\nTypically these aren't things you need to even think about; {instance} just handles them for you. But occasionally you may need to remove a bad snapshot from a project's history or change the housekeeping algorithms.\n\n## Managing History\nOccasionally, you may need to manually delete a project snapshot, whether because the wrong Quality Profile was used, or because there was a problem with analysis, and so on. Note that the most recent snapshot (labeled \"Last snapshot\") can never be deleted.\n\n[[warning]]\n|**About deleting snapshots**<br/><br/>\n|Deleting a snapshot is a 2-step process:<br/><br/>\n|* The snapshot must first be removed from the project history by clicking on Delete snapshot. It won't be displayed anymore on this History page but will still be present in the database.\n|* The snapshot is actually deleted during the next project analysis.\n\nAt project level, from the front page **Activity** list, choose **Show More** to see the full activity list.\n\nFor every snapshot, it is possible to manually:\n\n* Add, rename or remove a version\n* Add, rename or remove an event\n* Delete the snapshot\n"},{path:"project-administration/narrowing-the-focus",content:'---\ntitle: Narrowing the Focus\nurl: /project-administration/narrowing-the-focus/\n---\n\nIf SonarQube\'s results aren\'t relevant, no one will want to use it. That\'s why precisely configuring what to analyze for each project is a very important step. Doing so allows you to remove noise, like the issues and duplications marked on generated code, or the issues from rules that aren\'t relevant for certain types of files.\n\nSonarQube gives you several options for configuring exactly what will be analyzed. You can\n\n* completely ignore some files or directories\n* exclude files/directories from Issues detection (specific rules or all of them) but analyze all other aspects\n* exclude files/directories from Duplications detection but analyze all other aspects\n* exclude files/directories from Coverage calculations but analyze all other aspects\n\nYou can make these changes globally or at a project level. At the global level, the navigation path is  **Administration > General Settings > Analysis Scope**. At the project level, the navigation path is **Project Settings > General Settings > Analysis Scope**\n\n## Patterns\n\nPaths are relative to the project base directory. The following wildcards can be used:\n\n* `*`\t- Match zero or more characters  \n* `**` - Match zero or more directories  \n* `?` - Match a single character  \n\nRelative paths are based on the fully qualified name of the component.\n\nExample|Matches|Does not match\n----|----|----\n`**/*Bean.java`|org/sonar.api/MyBean.java <br/> org/sonar/util/MyOtherBean.java|org/sonar/util/MyDTO.java\n`**/*Bean?.java`|org/sonar/util/MyOtherBean1.java|org/sonar/util/MyOtherBean.java <br/> org/sonar.api/MyBean.java <br/> org/sonar/util/MyDTO.java\n`org/sonar/*`|org/sonar/MyClass.java <br/> org/sonar/MyOtherClass.java|org/sonar/util/MyClassUtil.java\n`org/sonar/**/*`|org/sonar/MyClass.java <br/> org/sonar/MyOtherClass.java <br/> org/sonar/util/MyClassUtil.java|\n\n## Ignore Files\nWe recommend that you exclude generated code, source code from libraries, etc. There are four different ways to narrow your analysis to the source code that will be relevant to the development team. You can combine them all together to tune your analysis scope. Additionally, we automatically exclude from analysis the files described in your projects\' `.gitignore` files. This behavior can be disabled. See `sonar.scm.exclusions.disabled` in the [Analysis Parameters](/analysis/analysis-parameters/) page for details.\n\n### Source Directories\nSet the [sonar.sources](/analysis/analysis-parameters/) property to limit the scope of the analysis to certain directories.\n\n### File Suffixes\nFor most languages, you can restrict the scope of analysis to files matching a set of extensions. Go to **Project Settings > General Settings > [Language]** to set the File suffixes property.\n\n### Choosing Files\nYour first line of defence having a well-defined set of files in your analysis is your `sonar.sources` value. For projects built and analyzed with Maven, Gradle, or MSBuild, this value is defined automatically with a generally thorough, yet sane value. For other projects, you want to make sure `sonar.sources` is set to your project _sub-directory_ that actually contains your source files. Setting it to `.` will cast a wider net than most people intend.\n\n![Set sonar.sources to the project sub-directory that contains your source files](/images/sources.jpg)\n\nOnce you\'ve got all the files _in_ your analysis that you want, it\'s time to look at whether you have any files you\'d rather leave _out_ of your analysis, such as JavaScript libraries, and generated files. Those can be handled with Exclusions. Specifying an exclusion means that everything under your `sonar.sources` directory will be included in analysis _except_ the files with paths that match your exclusion pattern.\n\n![Use exclusions to keep libraries and generated files out of analysis](/images/exclusions.jpg)\n\nTo use exclusions to analyze everything but the specified files, go to **Project Settings > General Settings > Analysis Scope > Files**.\n\n* **Source File Exclusions** - to exclude source code files\n* **Test File Exclusions** - to exclude test files\n\nThe vast majority of needs are met simply by setting `sonar.sources` carefully. Most other needs are met with the addition of a few simple exclusions. In a few corner cases, it is necessary to be explicit about what\'s _included_ in analysis and leave out everything else, but that is not the normal case, and setting inclusions should not be the first thing you try when configuring a new project.\n\n![Use inclusions in the rare case that you want to analyze only a subset of files](/images/inclusions.jpg)\n\nTo use exclusions to analyze _only_ the specified subset(s) of files in `sonar.sources`, go to **Project Settings > General Settings > Analysis Scope > Files**.\n\n* **Source File Inclusions** \n* **Test File Inclusions** \n\nYou can set these properties at both the project and global levels.\n\nSee the Patterns section below for more details on the syntax to use in these inputs.\n\n## Ignore Issues\nYou can have SonarQube ignore issues on certain components and against certain coding rules. Go to **Project Settings > General Settings > Analysis Scope > Issues**.\n\nNote that the properties below can only be set through the web interface because they are multi-valued.\n\n### Ignore Issues on Files\nYou can ignore all issues on files that contain a block of code matching a given regular expression.\n\nExample:\n* *Ignore all issues in files containing "@javax.annotation.Generated"*  \n`@javax\\.annotation\\.Generated`\n\n### Ignore Issues in Blocks\nYou can ignore all issues on specific blocks of code, while continuing to scan and mark issues on the remainder of the file. Blocks to be ignored are delimited by start and end strings which can be specified by regular expressions (or plain strings).\n\nNotes:\n\n* If the first regular expression is found but not the second one, the end of the file is considered to be the end of the block.\n* Regular expressions are not matched on a multi-line basis.\n\n### Ignore Issues on Multiple Criteria\nYou can ignore issues on certain components and for certain coding rules. To list a specific rule, use the fully qualified rule ID.\n\n[[info]]\n| You can find the fully qualified rule ID on the Rule definition.\n\nExamples:\n\n* *Ignore all issues on all files*  \nKEY = `*`  \nPATH = `**/*`\n* *Ignore all issues on COBOL program "bank/ZTR00021.cbl"*  \nKEY = `*`  \nPATH = `bank/ZTR00021.cbl`  \n* *Ignore all issues on classes located directly in the Java package "com.foo", but not in its sub-packages*  \nKEY = `*`  \nPATH = `com/foo/*`\n* *Ignore all issues against coding rule "cpp:Union" on files in the directory "object" and its sub-directories*  \nKEY = `cpp:Union`  \nPATH = `object/**/*`  \n\n### Restrict Scope of Coding Rules\n\nYou can restrict the application of a rule to only certain components, ignoring all others.\n\nExamples:\n\n* *Only check the rule "Magic Number" on "Bean" objects and not on anything else*  \nKEY = `checkstyle:com.puppycrawl.tools.checkstyle.checks.coding.MagicNumberCheck`  \nPATH = `**/*Bean.java`\n* *Only check the rule "Prevent GO TO statement from transferring control outside current module on COBOL programs" located in the directories "bank/creditcard" and "bank/bankcard". This requires two criteria to define it:*  \nKEY #1 = `cobol:COBOL.GotoTransferControlOutsideCurrentModuleCheck`  \nPATH #1 = `bank/creditcard/**/*`  \nKEY #2 = `cobol:COBOL.GotoTransferControlOutsideCurrentModuleCheck`  \nPATH #2 = `bank/bankcard/**/*`\n\n## Ignore Duplications\n\nYou can prevent some files from being checked for duplications.\n\nTo do so, go to **Project Settings > General Settings > Analysis Scope > Duplications** and set the *Duplication Exclusions* property. See the Patterns section for more details on the syntax.\n\n## Ignore Code Coverage\n\nYou can prevent some files from being taken into account for code coverage by unit tests.\n\nTo do so, go to **Project Settings > General Settings > Analysis Scope > Code Coverage** and set the *Coverage Exclusions* property. See the Patterns section for more details on the syntax.'},{path:"project-administration/new-code-period",content:"---\ntitle: Defining New Code\nurl: /project-administration/new-code-period/\n---\n\nDefining what is considered New Code is an important part of SonarQube's Clean as You Code approach to code quality and safety. By focusing on code that's been added or changed since your New Code definition, you can set consistent quality requirements and expectations. Your New Code will be issue free and you'll clean up the code you encounter along the way. For more information on New Code and why it's important, check out [Clean as You Code](/user-guide/clean-as-you-code/).\n\n## Setting your New Code definition\n\nYou can define New Code at the global, project, or branch level.\n\n- **Global level**  \n   You can set a global New Code definition at [**Administration > Configuration > General Settings > New Code**](/#sonarqube-admin#/admin/settings?category=new_code_period/). What you define as New Code at the global level will be the default for your projects.\n\n- **Project level**  \n   You can set a New Code definition for your project at **Project Settings > New Code**. What you define as New Code at the project level will be the default for the project's branches if you're using an edition that supports multiple branches (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)).\n\n- **Branch level**  \n   You can define New Code for each branch from the **Actions** column of the branches table on the project's **New Code** settings page if you're using an edition that supports multiple branches (starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)).\n\n## New Code definitions\n\nYou can define New Code as changes from a previous version, a specific analysis, a reference branch, or within a specific period (number of days):\n\n- **Previous Version** – Define New Code as any changes made in your project's current version. This works well for projects with regular versions or releases.\n\n   Available at the global, project, and branch level.\n\n- **Specific analysis** – Choose a previous analysis as your New Code definition. Any changes made since that analysis are considered New Code.\n\n   Available at the branch level starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) and the project level for community edition.\n\n[[info]]\n| For Community Edition, past analysis is available at the project-level because Community Edition doesn't support multiple branches. Starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html), you can do this at the branch level, and each branch can be set to one of the branch's specific past analyses.\n\n- **Reference Branch** – Choose a specific branch to define your New Code. Any changes made from your reference branch are considered New Code.\n\n   Available at the project and branch level.\n\n- **Number of days** – Specify a number of days for a floating New Code period. For example, setting **Number of Days** to 30 creates a floating New Code period beginning 30 days from the current date.\n  Available at the global, project, and branch level.\n"},{path:"project-administration/portfolio-pdf-configuration",content:'---\ntitle: Portfolio PDF Configuration\nurl: /project-administration/portfolio-pdf-configuration/\n---\n\n*Portfolio PDFs are available as part of the [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html) and [above](https://www.sonarsource.com/plans-and-pricing/).*\n\nA user with administrative rights on a portfolio can configure email distribution of the PDF. From a Portfolio Home Page go to **Administration > Executive Report**.\n\n### Frequency\nYou can tune the email frequency of the PDF Report. The possible values are:\n\n* Daily: report is sent during the first portfolio calculation of the day (if any)\n* Weekly: report is sent during the first portfolio calculation of the week (if any) from Monday\n* Monthly (default): report is sent during the first portfolio calculation of the month (if any), starting from the first day of the current month\n\n### Other Recipients\nIf people without SonarQube accounts want to receive the PDF, you can feed the administrative "Other Recipients" field with their email addresses.\n'},{path:"project-administration/project-existence",content:"---\ntitle: Project Existence\nurl: /project-administration/project-existence/\n---\n\nTypically, projects are created during their first analysis and never deleted (because old software never dies). For atypical situations, there is the page at **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management/)**, which allows you to manage project existence.\n\n## How do I provision a project before its first analysis?\nProvisioning a project allows you to declare and configure it (define permissions, set Quality Profiles, etc.) before running the first analysis. To be able to provision projects, you have to be logged in and be granted the Provision Projects permission.\n\nTo provision a new project either use the '+' menu in the top menu or if you have global administration privileges, go to **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management/)** and click on **Create Project**. The only required information is the key and the name of your project.\n\nOnce the project is provisioned, you can configure it (define permissions, set Quality Profiles, etc.), and when you're finished with the configuration, you can simply run the project's first analysis.\n\nYou can also provision and configure projects using the Web API.\n\n## How do I find provisioned projects (that haven't been analyzed yet)?\nThe **[Projects Management](/#sonarqube-admin#/admin/projects_management/)** search interface includes a toggle to allow you to narrow your results on this page to only projects that have never been analyzed. From there you can deal with them on this page as a set, or click through to the individual project homepages for individual attention and administration.\n\n## How do I lock down permissions on a project? (Private vs Public)\nBy default, any newly created project will be considered \"Public\". It means every SonarQube user, authenticated or not, will be able to:\n\n* **Browse**: Access a project, browse its measures, issues and perform some issue edits (confirm/resolve/reopen, assignment, comment).\n* **See Source Code**: View the project's source code.\n\nIf you want to be sure only a limited list of Groups and Users can see the project, you need to mark it Private. Once a project is private you will be able to define which Groups and Users can **Browse** the project or **See Source Code**.\n\nIf you want all newly created projects to be considered \"Private\", you can change the default visibility in **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management/)**.\n\n## How do I delete projects?\nA project may be deleted individually from the Administration page of the project. See Project Settings for more details. To delete projects in bulk, use **[Administration > Projects > Management](/#sonarqube-admin#/admin/projects_management/)**. Here you can select the projects to delete. A deleted project is gone for good, there is no way to undo this action.\n\n## How do I find projects that are no longer analyzed?\nThe **[Projects Management](/#sonarqube-admin#/admin/projects_management/)** search interface includes a date picker to help you find all projects last analyzed before your specified date. From there you can deal with them on this page as a set, or click through to the individual project homepages for individual attention and administration.\n"},{path:"project-administration/project-settings",content:"---\ntitle: Project Settings\nurl: /project-administration/project-settings/\n---\n\n## Tags\n\nProject tags allow you to categorize and group projects for easier selection on the **Projects** page. Project tags can be administered from the project home page. Administrators will see a dropdown menu indicator next to the project's list of current tags (or next to the \"No tags\" indicator). If the tag you want isn't visible in the dropdown, use the built in \"search\" input to find what you're looking for or create it on the fly.\n\n## Administration Items\n\nProject administration is accessible through the **Project Settings** menu of each project.  \n\nOnly project administrators can access project's settings (see [Authorization](/instance-administration/security/)).\n\n### Adding a Project\n\nA project is automatically added at its first analysis. Note that you can also [provision projects](/project-administration/project-existence/).\n\n### Analysis Report Processing\n\nA project-level Background Tasks page is available at **Project Settings > Background Tasks** to allow project administrators to check their projects' processing. It offers analysis report details and logs.\n\n### Deleting a Project\n\n#### **Deleting a Single Project**\n\nYou can delete a project through **Project Settings > Deletion**.\n\n#### **Deleting Multiple Projects**\nYou can also delete multiple projects simultaneously from the global **Project Settings > Projects > Management**.\n\n### Updating the Project Key  \n\nThe project key can be updated (without losing the history on the project) at **Project Settings > Update Key**.\n\nThe new key must contain at least one non-digit character. Allowed characters are: 'a' through 'z', 'A' through 'Z', '-' (dash), '\\_' (underscore), '.' (dot), ':' (colon) and digits '0' to '9'.\n\n### Default Issue Assignee\n\nWhen new issues are created during an analysis, they are assigned to the last committer where the issue was raised. When it is not possible to identify the last committer, issues can be assigned to a default assignee, at [Administration  > General Settings > Issues](/#sonarqube-admin#/admin/settings).\n\n### Setting Quality Gate and Quality Profiles  \n\nProject administrators can select which ...\n\n* Quality profiles (go to **Project Settings  > Quality Profiles**)\n* Quality gate (go to **Project Settings  > Quality Gate**)\n\n... to use on their project.\n\n### Setting Exclusions  \n\nSee [Narrowing the Focus](/project-administration/narrowing-the-focus/).\n\n### Customizing Links\n\nOn top of standard links which may only be set as [Analysis Parameters](/analysis/analysis-parameters/), additional custom links can be added through the web interface (under **Project Settings > Links**). Those links will then be displayed in the [Project Page](/user-guide/project-page/).\n"},{path:"project-administration/webhooks",content:'---\ntitle: Webhooks\nurl: /project-administration/webhooks/\n---\n\nWebhooks notify external services when a project analysis is complete. An HTTP POST request including a JSON payload is sent to each URL. URLs may be specified at both the project and global levels. Project-level specification does not replace global-level webhooks. All hooks at both levels are called.\n\nThe HTTP(S) call:\n\n* is made regardless of the status of the Background Task\n* includes a JSON document as payload, using the POST method\n* has a content type of "application/json", with UTF-8 encoding\n\n## Configuration\n\nYou can configure up to 10 webhooks at the project level in **Project Settings > Webhooks**.\n\nAn additional set of 10 webhooks can be configured at the global level in **Administration > Configuration > Webhooks**.\n\nIf configured, all 20 will be executed.\n\n## Delivery and Payload\n\n### Delivery\n\nThe Webhook administration console shows the result and timestamp of the most recent delivery of each webhook with the payload available via the list icon. Results and payloads of earlier deliveries are available from the tools menu to the right of each webhook.\n\nResponse records are purged after 30 days.\n\nThe URL must respond within 10 seconds or the delivery is marked as failed.\n\n### Payload\n\nAn HTTP header "X-SonarQube-Project" with the project key is sent to allow quick identification of the project involved.\n\nThe Payload is a JSON document which includes:\n\n* when the analysis was performed: see "analysedAt"\n* the identification of the project analyzed: see "project"\n* each Quality Gate criterion checked and its status: see "qualityGate"\n* the Quality Gate status of the project: see "qualityGate.status"\n* the status and the identifier of the Background Task : see "status" and "taskId"\n* user-specified properties: see "properties"\n\n#### Example\n\n```\n{\n    "serverUrl": "http://localhost:9000",\n    "taskId": "AVh21JS2JepAEhwQ-b3u",\n    "status": "SUCCESS",\n    "analysedAt": "2016-11-18T10:46:28+0100",\n    "revision": "c739069ec7105e01303e8b3065a81141aad9f129",\n    "project": {\n        "key": "myproject",\n        "name": "My Project",\n        "url": "https://mycompany.com/sonarqube/dashboard?id=myproject"\n    },\n    "properties": {\n    },\n    "qualityGate": {\n        "conditions": [\n            {\n                "errorThreshold": "1",\n                "metric": "new_security_rating",\n                "onLeakPeriod": true,\n                "operator": "GREATER_THAN",\n                "status": "OK",\n                "value": "1"\n            },\n            {\n                "errorThreshold": "1",\n                "metric": "new_reliability_rating",\n                "onLeakPeriod": true,\n                "operator": "GREATER_THAN",\n                "status": "OK",\n                "value": "1"\n            },\n            {\n                "errorThreshold": "1",\n                "metric": "new_maintainability_rating",\n                "onLeakPeriod": true,\n                "operator": "GREATER_THAN",\n                "status": "OK",\n                "value": "1"\n            },\n            {\n                "errorThreshold": "80",\n                "metric": "new_coverage",\n                "onLeakPeriod": true,\n                "operator": "LESS_THAN",\n                "status": "NO_VALUE"\n            }\n        ],\n        "name": "SonarQube way",\n        "status": "OK"\n    }\n}\n```\n\n## Securing your webhooks\n\nAfter you\'ve configured your server to receive payloads, you want to be sure that the payloads you receive are initiated by {instance} and not by hackers. You can do this by validating a hash signature that ensures that requests originate from {instance}. \n\n### Setting your secret\n\nTo set your secret in {instance}:\n\n1. From the project or organization where you\'re securing your webhooks, navigate to the webhooks settings at **Project Settings > Webhooks**\n1. You can either click **Create** to create a new webhook or click an existing webhook\'s settings drop-down and click **Update**.\n1. Enter a random string in the **Secret** text box. This is used as the key to generate the HMAC hex digest value in the `X-Sonar-Webhook-HMAC-SHA256` header.\n1. Click **Update**. \n\n### Validating {instance} Payloads\n\nAfter setting your secret, it\'s used by {instance} to create a hash signature with each payload that\'s passed using the `X-Sonar-Webhook-HMAC-SHA256` HTTP header. The header value needs to match the signature you are expecting to receive. {instance} uses a HMAC lower-case SHA256 digest to compute the signature of the request body. Here\'s some sample Java code for your server:\n\n```\nprivate static boolean isValidSignature(YourHttpRequest request) {\n  String receivedSignature = request.getHeader("X-Sonar-Webhook-HMAC-SHA256");\n  // See Apache commons-codec\n  String expectedSignature = new HmacUtils(HmacAlgorithms.HMAC_SHA_256, "your_secret").hmacHex(request.getBody())\n  return Objects.equals(expectedSignature, receivedSignature);  \n}\n```\n\nIf the signatures don\'t match, then the payload should be ignored.\n\n## Additional parameters\n\nA basic authentication mechanism is supported by providing user/password in the URL of the Webhook such as `https://myLogin:myPassword@my_server/foo`.\n\nIf you provide additional properties to your SonarScanner using the pattern `sonar.analysis.*`, these properties will be automatically added to the section "properties" of the payload.\n\nFor example these additional parameters:\n\n```\nsonar-scanner -Dsonar.analysis.buildNumber=12345\n```\n\nWould add this to the payload:\n\n```\n"properties": {\n  "sonar.analysis.buildNumber": "12345"\n}\n```\n'},{path:"requirements/hardware-recommendations",content:"---\ntitle: Hardware Recommendations\nurl: /requirements/hardware-recommendations/\n---\n## Database\nWe recommend that for large instances, the database used by SonarQube is hosted on a machine which is physically separate from SonarQube Server but close to it on the network.\n\n### Oracle\nIn case your SonarQube Server is running on Linux and you are using Oracle, the Oracle JDBC Driver may be blocked due to /dev/random. See [this Oracle article](http://www.usn-it.de/index.php/2009/02/20/oracle-11g-jdbc-driver-hangs-blocked-by-devrandom-entropy-pool-empty/) for more details about this problem.\n\n To avoid it, you may want to add this JVM parameter to your SonarQube Web Server (`sonar.web.javaOpts`) configuration :\n ```\n -Djava.security.egd=file:///dev/urandom\n ```\n\n ## Elasticsearch (ES)\n* [Elasticsearch](https://www.elastic.co/) is used by SonarQube in the background in the SearchServer process. To ensure good performance of your SonarQube, you need to follow these recommendations that are linked to ES usage.\n\n### Disk\n* Free disk space is an absolute requirement. ES implements a safety mechanism to prevent the disk from being flooded with index data that locks all indices in read-only mode when a 95% disk usage watermark is reached. For information on recovering from ES read-only indices, see the [Troubleshooting](/setup/troubleshooting/) page.\n* Disk can easily  become the bottleneck of ES. If you can afford SSDs, they are by far superior to any spinning media. SSD-backed nodes see boosts in both query and indexing performance. If you use spinning media, try to obtain the fastest disks possible (high performance server disks 15k RPM drives).\n* Using RAID 0 is an effective way to increase disk speed, for both spinning disks and SSD. There is no need to use mirroring or parity variants of RAID because of Elasticsearch replicas and database primary storage.\n* Do not use remote-mounted storage, such as NFS, SMB/CIFS or network-attached storages (NAS). They are often slower, display larger latencies with a wider deviation in average latency, and are a single point of failure.\n\n**Advanced**\n* If you are using SSD, make sure your OS I/O Scheduler is configured correctly. When you write data to disk, the I/O Scheduler decides when that data is actually sent to the disk. The default under most *nix distributions is a scheduler called cfq (Completely Fair Queuing). This scheduler allocates \"time slices\" to each process, and then optimizes the delivery of these various queues to the disk. It is optimized for spinning media: the nature of rotating platters means it is more efficient to write data to disk based on physical layout. This is very inefficient for SSD, however, since there are no spinning platters involved. Instead, deadline or noop should be used instead. The deadline scheduler optimizes based on how long writes have been pending, while noop is just a simple FIFO queue. This simple change can have dramatic impacts.\n* If SQ home directory is located on a slow disk, then the property `sonar.path.data` can be used to move data to a faster disk (RAID 0 local SSD for instance).\n\n### Memory\n* Machine available memory for OS must be at least the Elasticsearch heap size. The reason is that Lucene (used by ES) is designed to leverage the underlying OS for caching in-memory data structures. That means that by default OS must have at least 1Gb of available memory.\n* Don't allocate more than 32Gb. See [this ElasticSearch article](http://www.elasticsearch.org/guide/en/elasticsearch/guide/current/heap-sizing.html) for more details.\n\n### CPU\n* If you need to choose between faster CPUs or more cores, then choose more cores. The extra concurrency that multiple cores offers will far outweigh a slightly faster clock-speed.\n* By nature data are distributed on multiples nodes, so execution time depends on the slowest node. It's better to have multiple medium boxes than one fast + one slow.\n"},{path:"requirements/requirements",content:'---\ntitle: Prerequisites and Overview\nurl: /requirements/requirements/\n---\n## Prerequisite\nThe only prerequisite for running SonarQube is to have Java (Oracle JRE 11 or OpenJDK 11) installed on your machine.\n\n## Hardware Requirements\n1. A small-scale (individual or small team) instance of the SonarQube server requires at least 2GB of RAM to run efficiently and 1GB of free RAM for the OS. If you are installing an instance for a large teams or Enterprise, please consider the additional recommendations below.\n2. The amount of disk space you need will depend on how much code you analyze with SonarQube.\n3. SonarQube must be installed on hard drives that have excellent read & write performance. Most importantly, the "data" folder houses the Elasticsearch indices on which a huge amount of I/O will be done when the server is up and running. Great read & write hard drive performance will therefore have a great impact on the overall SonarQube server performance.\n4. SonarQube does not support 32-bit systems on the server side. SonarQube does, however, support 32-bit systems on the scanner side.\n\n### Enterprise Hardware Recommendations\nFor large teams or Enterprise-scale installations of SonarQube, additional hardware is required. At the Enterprise level, [monitoring your SonarQube instance](/instance-administration/monitoring/) is essential and should guide further hardware upgrades as your instance grows. A starting configuration should include at least:\n\n* 8 cores, to allow the main SonarQube platform to run with multiple Compute Engine workers\n* 16GB of RAM\nFor additional requirements and recommendations relating to database and ElasticSearch, see [Hardware Recommendations](/requirements/hardware-recommendations/).\n\n## Supported Platforms\n### Java\nSonarQube scanners require version 8 or 11 of the JVM and the SonarQube server requires version 11. Versions beyond Java 11 are not officially supported. \n\nSonarQube is able to analyze any kind of Java source files regardless of the version of Java they comply to. \n\nWe recommend using the Critical Patch Update (CPU) releases.\n\n| Java           | Server                    | Scanners                  |\n| -------------- | ------------------------- | ------------------------- |\n| Oracle JRE     | ![](/images/check.svg) 11 | ![](/images/check.svg) 11 |\n|                | ![](/images/cross.svg) 8  | ![](/images/check.svg) 8  |\n| OpenJDK        | ![](/images/check.svg) 11 | ![](/images/check.svg) 11 |\n|                | ![](/images/cross.svg) 8  | ![](/images/check.svg) 8  |\n\n| Database                                                    |                                                                                                                                                                                                                                                                   |\n| ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [PostgreSQL](http://www.postgresql.org/)                    | ![](/images/check.svg) 13                                                                                                                                                                                                                                         |\n|                                                             | ![](/images/check.svg) 12                                                                                                                                                                                                                                         |\n|                                                             | ![](/images/check.svg) 11                                                                                                                                                                                                                                         |\n|                                                             | ![](/images/check.svg) 10                                                                                                                                                                                                                                         |\n|                                                             | ![](/images/check.svg) 9.6                                                                                                                                                                                                                                        |\n|                                                             | ![](/images/exclamation.svg) Must be configured to use UTF-8 charset                                                                                                                                                                                              |\n| [Microsoft SQL Server](http://www.microsoft.com/sqlserver/) | ![](/images/check.svg) 2019 (MSSQL Server 15.0) with bundled Microsoft JDBC driver. Express Edition is supported.                                                                                                                                                 |\n|                                                             | ![](/images/check.svg) 2017 (MSSQL Server 14.0) with bundled Microsoft JDBC driver. Express Edition is supported.                                                                                                                                                 |\n|                                                             | ![](/images/check.svg) 2016 (MSSQL Server 13.0) with bundled Microsoft JDBC driver. Express Edition is supported.                                                                                                                                                 |\n|                                                             | ![](/images/check.svg) 2014 (MSSQL Server 12.0) with bundled Microsoft JDBC driver. Express Edition is supported.                                                                                                                                                 |\n|                                                             | ![](/images/exclamation.svg) Collation must be case-sensitive (CS) and accent-sensitive (AS) (example: `Latin1_General_CS_AS`)                                                                                                                                    |\n|                                                             | ![](/images/exclamation.svg) `READ_COMMITTED_SNAPSHOT` must be set on the SonarQube database to avoid potential deadlocks under heavy load                                                                                                                        |\n|                                                             | ![](/images/info.svg) Both Windows authentication (“Integrated Security”) and SQL Server authentication are supported. See the Microsoft SQL Server section in Installing/installation/installing-the-server page for instructions on configuring authentication. |\n| [Oracle](http://www.oracle.com/database/)                   | ![](/images/check.svg) 19C                                                                                                                                                                                                                                        |\n|                                                             | ![](/images/check.svg) 18C                                                                                                                                                                                                                                        |\n|                                                             | ![](/images/check.svg) 12C                                                                                                                                                                                                                                        |\n|                                                             | ![](/images/check.svg) XE Editions                                                                                                                                                                                                                                |\n|                                                             | ![](/images/exclamation.svg) Must be configured to use a UTF8-family charset (see `NLS_CHARACTERSET`)                                                                                                                                                             |\n|                                                             | ![](/images/exclamation.svg) The driver ojdbc14.jar is not supported                                                                                                                                                                                              |\n|                                                             | ![](/images/info.svg) We recommend using the latest Oracle JDBC driver                                                                                                                                                                                            |\n|                                                             | ![](/images/exclamation.svg) Only the thin mode is supported, not OCI                                                                                                                                                                                             |\n|                                                             | ![](/images/exclamation.svg) Only `MAX_STRING_SIZE=STANDARD` parameter is supported, not `EXTENDED`                                                                                                                                                               |\n\n### Web Browser\nTo get the full experience SonarQube has to offer, you must enable JavaScript in your browser.\n\n| Browser                     |                                         |\n| --------------------------- | --------------------------------------- |\n| Microsoft Internet Explorer | ![](/images/check.svg) IE 11            |\n| Microsoft Edge              | ![](/images/check.svg) Latest           |\n| Mozilla Firefox             | ![](/images/check.svg) Latest           |\n| Google Chrome               | ![](/images/check.svg) Latest           |\n| Opera                       | ![](/images/exclamation.svg) Not tested |\n| Safari                      | ![](/images/check.svg) Latest           |\n\n## Platform notes\n### Linux\nIf you\'re running on Linux, you must ensure that:\n\n* `vm.max_map_count` is greater than or equal to 524288\n* `fs.file-max` is greater than or equal to 131072\n* the user running SonarQube can open at least 131072 file descriptors\n* the user running SonarQube can open at least 8192 threads\n\nYou can see the values with the following commands:\n```\nsysctl vm.max_map_count\nsysctl fs.file-max\nulimit -n\nulimit -u\n```\n\nYou can set them dynamically for the current session by running  the following commands as `root`:\n```\nsysctl -w vm.max_map_count=524288\nsysctl -w fs.file-max=131072\nulimit -n 131072\nulimit -u 8192\n```\n\nTo set these values more permanently, you must update either _/etc/sysctl.d/99-sonarqube.conf_ (or _/etc/sysctl.conf_ as you wish) to reflect these values.\n\nIf the user running SonarQube (`sonarqube` in this example) does not have the permission to have at least 131072 open descriptors, you must insert this line in _/etc/security/limits.d/99-sonarqube.conf_ (or _/etc/security/limits.conf_ as you wish):\n```\nsonarqube   -   nofile   131072\nsonarqube   -   nproc    8192\n```\n\nIf you are using `systemd` to start SonarQube, you must specify those limits inside your unit file in the section \\[service\\] :\n```\n[Service]\n...\nLimitNOFILE=131072\nLimitNPROC=8192\n...\n```\n\n### seccomp filter\nBy default, Elasticsearch uses [seccomp filter](https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt). On most distribution this feature is activated in the kernel, however on distributions like Red Hat Linux 6 this feature is deactivated. If you are using a distribution without this feature and you cannot upgrade to a newer version with seccomp activated, you have to explicitly deactivate this security layer by updating `sonar.search.javaAdditionalOpts` in _$SONARQUBE_HOME/conf/sonar.properties_:\n```\nsonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false\n```\n\nYou can check if seccomp is available on your kernel with:\n```\n$ grep SECCOMP /boot/config-$(uname -r)\n```\n\nIf your kernel has seccomp, you will see:\n```\nCONFIG_HAVE_ARCH_SECCOMP_FILTER=y\nCONFIG_SECCOMP_FILTER=y\nCONFIG_SECCOMP=y\n```\nFor more detail, see the [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/breaking-changes-5.6.html).\n\n### Fonts\nGenerating [Executive Reports](/project-administration/portfolio-pdf-configuration/) requires that fonts be installed on the server hosting SonarQube. On Windows servers, this is a given. However, this is not always the case for Linux servers.\n\nThe following should be ensured:\n\n* [Fontconfig](https://en.wikipedia.org/wiki/Fontconfig) is installed on the server hosting SonarQube\n* A package of [FreeType](https://www.freetype.org/) fonts is installed on the SonarQube server. The exact packages available will vary by distribution, but a commonly used package is `libfreetype6`\n'},{path:"setup/analysis-with-java-11",content:"---\ntitle: Moving Analysis to Java 11\nurl: /analysis/analysis-with-java-11/\n---\n\nUse of Java 8 is deprecated for SonarQube scanners, and scanners will require Java 11 in the near future. If you're using a previous version of the Java, see the section below that aligns with your build for information on moving your analysis to Java 11.\n\n## Maven or Gradle\n\nWe suggest basing your whole build on Java 11. If that's not compatible, you can have a dedicated script for the analysis that overrides the `JAVA_HOME` environment variable just before running it. See the following examples:\n\n### Maven\n\n```\nmvn verify ...\nexport JAVA_HOME=/path/to/java11\nmvn sonar:sonar ...\n```\n\n### Gradle \n\n```\ngradle build ...\nexport JAVA_HOME=/path/to/java11\ngradle sonarqube ...\n```\n\n## Azure DevOps\n\nIf you are running your build with a Microsoft-hosted agent, this is already automatically done, and you're all set. \n\nIf you're using a self-hosted agent, you can either modify your build pipeline to ensure that it runs with Java 11 by default or override the `JAVA_HOME` environment variable just before running the analysis.\n\n### Xamarin\nIn the specific case of Xamarin only allowing Java 8, you will need to specify a Java 8 path while invoking MSBuild, allowing the JAVA_HOME environment variable for the scanner only.\n\n```\n$env:XAMARIN_JAVA_HOME=/path/to/java8\nmsbuild.exe  /p:JavaSdkDirectory=$env:XAMARIN_JAVA_HOME\n```\n\n## Dockerfile\n\nYou can use several base images to run your build with Java 11. Here are some examples:\n\n- openjdk:11-jre-slim\n- debian:buster and above\n- gradle:jre11-slim\n\nIf your build is not compatible with Java 11, you can override `JAVA_HOME` environment variable before running scanners.\n\n## Jenkins\n\nYou can easily define a new JDK version by navigating to **Manage Jenkins > Global Tool Configuration** if you have the [JDK Tool Plugin](https://plugins.jenkins.io/jdk-tool/) installed.\n\n### Declaritive Pipelines\n\nIf you are using a declarative pipeline with different stages you can add a 'tools' section to the stage in which the code scan occurs. This makes the scanner use the specificed JDK version.\n\n```\nstage('SonarQube analysis') {\n    tools {\n        jdk \"jdk11\" // the name you have given the JDK installation in Global Tool Configuration\n    }\n    environment {\n        scannerHome = tool 'SonarQube Scanner' // the name you have given the Sonar Scanner (in Global Tool Configuration)\n    }\n    steps {\n        withSonarQubeEnv(installationName: 'SonarQube') {\n            sh \"${scannerHome}/bin/sonar-scanner -X\"\n        }\n    }\n}\n```\n\nIf you are analyzing a Java 8 project you probably want to continue using Java 8 to build your project. The following example allows you to continue building in Java 8 but will use Java 11 to scan the code:\n\n```\nstage('Build') {\n    tools {\n        jdk \"jdk8\" // the name you have given the JDK installation using the JDK manager (Global Tool Configuration)\n    }\n    steps {\n        sh 'mvn compile'\n    }\n}\nstage('SonarQube analysis') {\n    tools {\n        jdk \"jdk11\" // the name you have given the JDK installation using the JDK manager (Global Tool Configuration)\n    }\n    environment {\n        scannerHome = tool 'SonarQube Scanner' // the name you have given the Sonar Scanner (Global Tool Configuration)\n    }\n    steps {\n        withSonarQubeEnv(installationName: 'SonarQube') {\n            sh 'mvn sonar:sonar'\n        }\n    }\n}\n```\n\nThe previous example is for Maven, but you can easily modify it for Gradle.\n\n### Classical Pipelines\n\n#### **Set Job JDK version**  \nYou can set the JDK version that a job should use in the **General** section of your configuration. This option is only visible if you have configured multiple JDK versions under **Manage Jenkins > Global Tool Configuration**.\n\n#### **Set Execute SonarQube Scanner JDK version**  \nIf you're using the **Execute SonarQube Scanner** step in your configuration, you can set the JDK for this step in the configuration dialog. This allows you to use JDK 11 for the code scanning performed by SonarQube and the globally configured JDK for all other steps in the job.\n\n#### **Java 8 projects**  \nJenkins doesn't let you switch JDKs when using a 'Freestyle project' or 'Maven project' configuration,  so when you want to build your project using Java 8 you have to manually set the `JAVA_HOME` variable to Java 11 when executing the scanner.\n\nYou can do this with the [Tool Environment Plugin](https://plugins.jenkins.io/toolenv/). When this plugin is installed, you can expose the location of the JDK you added under **Manage Jenkins > Global Tool Configuration**.\n\nThe location of the JDK can then be used to set the `JAVA_HOME` environment variable. The build and post steps sections can be configured as following\n\n"},{path:"setup/get-started-2-minutes",content:"---\ntitle: Try Out SonarQube\nurl: /setup/get-started-2-minutes/\n---\nYou've heard about how [SonarQube](https://www.sonarqube.org/) can help you write cleaner and safer code, and now you're ready to try it out for yourself. This guide shows you how to install a local instance of SonarQube and analyze a project. Installing a local instance gets you up and running quickly, so you can experience SonarQube first hand.\n\nOnce you're ready to set up a production instance, take a look at the [Install SonarQube](/setup/install-server/) documentation.\n\n## Installing a local instance of SonarQube\nYou can evaluate SonarQube using a traditional installation with the [zip file](https://www.sonarqube.org/downloads/) or you can spin up a Docker container using one of our [Docker images](https://hub.docker.com/_/sonarqube/). Click the method you prefer below to expand the installation instructions: \n\n[[collapse]]\n| ## From the zip file\n|\n| 1. [Download](https://www.sonarqube.org/downloads/) the SonarQube Community Edition zip file.\n|\n| 2. As a **non-`root` user**, unzip it, let's say in _C:\\sonarqube_ or _/opt/sonarqube_.\n|\n| 3. As a **non-`root` user**, start the SonarQube Server:\n|\n|    ```\n|    # On Windows, execute:\n|    C:\\sonarqube\\bin\\windows-x86-64\\StartSonar.bat\n|\n|    # On other operating systems, as a non-root user execute:\n|    /opt/sonarqube/bin/[OS]/sonar.sh console\n|    ```\n|\n|   ![](/images/info.svg) If your instance fails to start, check your [logs](/setup/troubleshooting/) to find the cause.\n\n[[collapse]]\n| ## From the Docker image\n| Find the Community Edition Docker image on [Docker Hub](https://hub.docker.com/_/sonarqube/).\n|\n| 1. Start the server by running:\n|\n| ```console\n| $ docker run -d --name sonarqube -e SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true -p 9000:9000 sonarqube:latest\n| ```\n\nOnce your instance is up and running, Log in to [http://localhost:9000](http://localhost:9000) using System Administrator credentials:\n- login: admin \n- password: admin\n\n## Analyzing a Project\nNow that you're logged in to your local SonarQube instance, let's analyze a project: \n\n1. Click the **Create new project** button.\n\n1. Give your project a **Project key** and a **Display name** and click the **Set Up** button.\n\n1. Under **Provide a token**, select **Generate a token**. Give your token a name, click the **Generate** button, and click **Continue**.\n\n1. Select your project's main language under **Run analysis on your project**, and follow the instructions to analyze your project. Here you'll download and execute a Scanner on your code (if you're using Maven or Gradle, the Scanner is automatically downloaded).\n\nAfter successfully analyzing your code, you'll see your first analysis on SonarQube:\n\n![successful analysis](/images/successfulproject.png)\n\n\n"},{path:"setup/install-cluster",content:'---\ntitle: Install the Server as a Cluster\nurl: /setup/install-cluster/\n---\n\n_Running SonarQube as a Cluster is only possible with a [Data Center Edition](https://www.sonarsource.com/plans-and-pricing/data-center/)_.\n\nThe Data Center Edition allows SonarQube to run in a clustered configuration to make it resilient to failures.\n\n## Overview\n\nThe default configuration for the Data Center Edition comprises five servers, a load balancer, and a database server:\n\n- Two application nodes responsible for handling web requests from users (WebServer process) and handling analysis reports (ComputeEngine process). You can add application nodes to increase computing capabilities.\n- Three search nodes that host the Elasticsearch process that will store data indices. SSDs perform significantly better than HDDs for these nodes.\n- A reverse proxy / load balancer to load balance traffic between the two application nodes. The installing organization must supply this hardware or software component.\n- PostgreSQL, Oracle, or Microsoft SQL Server database server. This software must be supplied by the installing organization.\n\n\nWith this configuration, one application node and one search node can be lost without impacting users.  Here is a diagram of the default topology:\n\n![DCE Cluster Machines Topology.](/images/cluster-dce.png)\n\n## Requirements\n\n### Network\n\nAll servers, including the database server, must be located within the same region. \n\nAll application and search nodes should have static IP addresses (reference via hostname is not supported). Network traffic should not be restricted between application and search nodes.\n\n### Servers\n\nYou need a minimum of five servers (two application nodes and three search nodes) to form a SonarQube application cluster. Servers can be virtual machines; it is not necessary to use physical machines. You can also add application nodes to increase computing capabilities. \n\nThe operating system requirements for servers are available on the [Requirements](/requirements/requirements/) page. \n\nAll application nodes should be identical in terms of hardware and software. Similarly, all search nodes should be identical to each other. Application and search nodes, however, can differ from one another. Generally, search nodes are configured with more CPU and RAM than application nodes.\n\nSearch nodes can be located in different availability zones, but they must be in the same region. In this case, each search node should be located in a separate availability zone to maintain availability in the event of a failure in one zone.\n\n#### **Example Machines**\nHere are the machines we used to perform our validation with a 200M issues database. You can use this as a minimum recommendation to build your cluster.\n\n- App Node made of [Amazon EC2 m4.xlarge](https://aws.amazon.com/ec2/instance-types/): 4 vCPUs, 16GB RAM\n- Search Node made of [Amazon EC2 m4.2xlarge](https://aws.amazon.com/ec2/instance-types/): 8 vCPUs, 32GB RAM - 16GB allocated to Elasticsearch. SSDs perform significantly better than HDDs for these nodes.\n\n### Database Server\n\nSupported database systems are available on the [Requirements](/requirements/requirements/) page.\n\n### Load Balancer\n\nSonarSource does not provide specific recommendations for reverse proxy / load balancer or solution-specific configuration. The general requirements for SonarQube Data Center Edition are:\n\n- Ability to balance HTTP requests (load) between the application nodes configured in the SonarQube cluster.\n- If terminating HTTPS, meets the requirements set out in [Securing SonarQube Behind a Proxy](/setup/operate-server/).\n- No requirement to preserve or sticky sessions; this is handled by the built-in JWT mechanism.\n- Ability to check for node health for routing\n\n#### Example with HAProxy\n\n```\nfrontend http-in\n    bind *:80\n    bind *:443 ssl crt /etc/ssl/private/<server_certificate>\n    http-request redirect scheme https unless { ssl_fc }\n    default_backend sonarqube_server\nbackend sonarqube_server\n    balance roundrobin\n    http-request set-header X-Forwarded-Proto https\n    option httpchk GET /api/system/status\n    http-check expect rstring UP|DB_MIGRATION_NEEDED|DB_MIGRATION_RUNNING\n    default-server check maxconn 200\n    server node1 <server_endpoint_1>\n    server node2 <server_endpoint_2> \n```\n\n### License\n\nYou need a dedicated license to activate the Data Center Edition. If you don\'t have one yet, please contact the SonarSource Sales Team.\n\n### Support\n\nDon\'t start this journey alone!  As a Data Center Edition subscriber, SonarSource will assist with the setup and configuration of your cluster. Get in touch with [SonarSource Support](https://support.sonarsource.com) for help.\n\n## Installing SonarQube from the ZIP file\n\nAdditional parameters are required to activate clustering capabilities and specialize each node. These parameters are in addition to standard configuration properties used in a single-node configuration.\n\nThe **sonar.properties** file on each node will be edited to configure the node\'s specialization. A list of all cluster-specific configuration parameters is available in the [Operate the Cluster](/setup/operate-cluster/) documentation.\n\nPrior to configuration, you will need to generate a value for the `sonar.auth.jwtBase64Hs256Secret` property for the application nodes.  The value is a HS256 key encoded with base64 and will be the same for both nodes.  The following is an example on how to generate this value on a Unix system:\n\n```\necho -n "your_secret" | openssl dgst -sha256 -hmac "your_key" -binary | base64\n```\n\n### Sample Configuration\n\nThe following example represents a sample configuration of a SonarQube cluster.  The example assumes:\n\n- The VMs having IP addresses ip1 and ip2 (server1, server2) are application nodes\n- The VMs having IP addresses ip3, ip4, and ip5 (server3, server4 and server5) are search nodes\n\nThe configuration to be added to sonar.properties for each node is the following:\n\n#### Application Nodes\n\n**server1**\n```\n...\nsonar.cluster.enabled=true\nsonar.cluster.node.type=application\nsonar.cluster.node.host=ip1\nsonar.cluster.node.port=9003\nsonar.cluster.hosts=ip1,ip2\nsonar.cluster.search.hosts=ip3:9001,ip4:9001,ip5:9001\nsonar.auth.jwtBase64Hs256Secret=YOURGENERATEDSECRET\n...\n```\n\n**server2**\n```\n...\nsonar.cluster.enabled=true\nsonar.cluster.node.type=application\nsonar.cluster.node.host=ip2\nsonar.cluster.node.port=9003\nsonar.cluster.hosts=ip1,ip2\nsonar.cluster.search.hosts=ip3:9001,ip4:9001,ip5:9001\nsonar.auth.jwtBase64Hs256Secret=YOURGENERATEDSECRET\n...\n```\n\n#### Search Nodes\n\n**server3**\n```\n...\nsonar.cluster.enabled=true\nsonar.cluster.node.type=search\nsonar.cluster.node.search.host=ip3\nsonar.cluster.node.search.port=9001\nsonar.cluster.node.es.host=ip3\nsonar.cluster.node.es.port=9002\nsonar.cluster.es.hosts=ip3:9002,ip4:9002,ip5:9002\n...\n```\n\n**server4**\n```\n...\nsonar.cluster.enabled=true\nsonar.cluster.node.type=search\nsonar.cluster.node.search.host=ip4\nsonar.cluster.node.search.port=9001\nsonar.cluster.node.es.host=ip4\nsonar.cluster.node.es.port=9002\nsonar.cluster.es.hosts=ip3:9002,ip4:9002,ip5:9002\n...\n```\n\n**server5**\n```\n...\nsonar.cluster.enabled=true\nsonar.cluster.node.type=search\nsonar.cluster.node.search.host=ip5\nsonar.cluster.node.search.port=9001\nsonar.cluster.node.es.host=ip5\nsonar.cluster.node.es.port=9002\nsonar.cluster.es.hosts=ip3:9002,ip4:9002,ip5:9002\n...\n```\n\n### Sample Installation Process\n\nThe following is an example of the default SonarQube cluster installation process. You need to tailor your installation to the specifics of the target installation environment and the operational requirements of the hosting organization.\n\n**Prepare the cluster environment:**\n\n1. Prepare the cluster environment by setting up the network and provisioning the nodes and load balancer. \n2. Follow the [Installing the Server](/setup/install-server/) documentation to configure the database server.\n\n**Prepare a personalized SonarQube package:**\n\n1. On a single application node of the cluster, download and install SonarQube Data Center Edition, following the usual [Installing the Server](/setup/install-server/) documentation.\n2. Add cluster-related parameters to `$SONARQUBE_HOME/conf/sonar.properties`.\n3. This is also a good opportunity to install plugins. Download and place a copy of each plugin JAR in `$SONARQUBE_HOME/extensions/plugins`.  Be sure to check compatibility with your SonarQube version using the [Plugin Version Matrix](https://docs.sonarqube.org/8.9/instance-administration/plugin-version-matrix/).\n4. Zip the directory `$SONARQUBE_HOME`. This archive is a customized SonarQube Data Center Edition package that can be copied to other nodes.\n\n**Test configuration on a single node:**\n\n1. On the application node where you created your Zip package, comment out all cluster-related parameters in `$SONARQUBE_HOME/conf/sonar.properties`.\n2. Configure the load balancer to proxy with single application node.\n3. Start server and test access through load balancer.\n4. Request license from SonarSource Sales Team.\n5. After applying license, you will have a full-featured SonarQube system operating on a single node.\n\n**Deploy SonarQube package on other nodes:**\n\n1. Unzip SonarQube package on the other four nodes.\n2. Configure node-specific parameters on all five nodes in `$SONARQUBE_HOME/conf/sonar.properties` and ensure application node-specific and search node-specific parameters are properly set.\n3. Start all search nodes.\n4. After all search nodes are running, start all application nodes.\n5. Configure the load balancer to proxy with both application nodes.\n\n## Installing SonarQube from the Docker Image\n\nYou can also install a cluster using our docker images. The general setup is the same but is shifted to a docker specific terminology.\n\n## Requirements\n\n### Network\n\nAll containers should be in the same network. This includes search and application nodes.\nFor the best performance, it is advised to check for low latency between the database and the cluster nodes.\n\n### Limits\n\nThe limits of each container depend on the workload that each container has. A good starting point would be:\n\n* cpus: 0.5  \n* mem_limit: 4096M  \n* mem_reservation: 1024M  \n\nThe 4Gb mem_limit should not be lower as this is the minimal value for Elasticsearch.\n\n### Scalability\n\nApplication nodes can be scaled using replicas. This is not the case for the Search nodes as Elasticsearch will not become ready. See the [Configure and Operate a Cluster](/setup/operate-cluster/) for more information.\n\n### Volumes\nYou\'ll use the following volumes in your configuration:\n\n- `sonarqube_data` – In the Docker Compose configuration example in the following section, volumes are shared between replicas in the application nodes, so you don\'t need a `sonarqube_data` volume on your application nodes. In the search nodes, the `sonarqube_data` volume contains the Elasticsearch data and helps reduce startup time, so we recommend having a `sonarqube_data` volume on each search node.\n- `sonarqube_extensions` – For application nodes, we recommend sharing a common `sonarqube_extensions` volume which contains any plugins you install and the Oracle JDBC driver if necessary.\n- `sonarqube_logs` – For both application and search nodes, we recommend sharing a common `sonarqube_logs` volume which contains SonarQube logs. The volume will be populated with a new folder depending on the container\'s hostname and all logs of this container will be put into this folder. This behavior also happens when a custom log path is specified via the [Docker Environment Variables](/setup/environment-variables/).\n\n## Example Docker Compose configuration\n\nClick the heading below to expand the docker-compose.yml file example. \n\n[[info]]\n| The example below will use the latest version of the SonarQube Docker image. If want to use the LTS version of SonarQube, you need to update the example with the `sonarqube:lts-datacenter-app` and `sonarqube:lts-datacenter-search` image tags.\n\n[[collapse]]\n| ## docker-compose.yml file example\n|\n| ```yaml\n|version: "3"\n|\n|services:\n|  sonarqube:\n|    image: sonarqube:datacenter-app\n|    depends_on:\n|      - db\n|      - search-1\n|      - search-2\n|      - search-3\n|    networks:\n|      - sonar-network\n|    deploy:\n|      replicas: 2\n|    environment:\n|      SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar\n|      SONAR_JDBC_USERNAME: sonar\n|      SONAR_JDBC_PASSWORD: sonar\n|      SONAR_WEB_PORT: 9000\n|      SONAR_CLUSTER_SEARCH_HOSTS: "search-1,search-2,search-3"\n|      SONAR_CLUSTER_HOSTS: "sonarqube"\n|      SONAR_AUTH_JWTBASE64HS256SECRET: "dZ0EB0KxnF++nr5+4vfTCaun/eWbv6gOoXodiAMqcFo="\n|      VIRTUAL_HOST: sonarqube.dev.local\n|      VIRTUAL_PORT: 9000\n|    volumes:\n|      - sonarqube_extensions:/opt/sonarqube/extensions\n|      - sonarqube_logs:/opt/sonarqube/logs\n|  search-1:\n|    image: sonarqube:datacenter-search\n|    hostname: "search-1"\n|    depends_on:\n|      - db\n|    networks:\n|      - sonar-network\n|    environment:\n|      SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar\n|      SONAR_JDBC_USERNAME: sonar\n|      SONAR_JDBC_PASSWORD: sonar\n|      SONAR_CLUSTER_ES_HOSTS: "search-1,search-2,search-3"\n|      SONAR_CLUSTER_NODE_NAME: "search-1"\n|    volumes:\n|      - search-data-1:/opt/sonarqube/data\n|  search-2:\n|    image: sonarqube:8.6-datacenter-search\n|    hostname: "search-2"\n|    depends_on:\n|      - db\n|    networks:\n|      - sonar-network\n|    environment:\n|      SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar\n|      SONAR_JDBC_USERNAME: sonar\n|      SONAR_JDBC_PASSWORD: sonar\n|      SONAR_CLUSTER_ES_HOSTS: "search-1,search-2,search-3"\n|      SONAR_CLUSTER_NODE_NAME: "search-2"\n|    volumes:\n|      - search-data-2:/opt/sonarqube/data\n|  search-3:\n|    image: sonarqube:8.6-datacenter-search\n|    hostname: "search-3"\n|    depends_on:\n|      - db\n|    networks:\n|      - sonar-network\n|    environment:\n|      SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar\n|      SONAR_JDBC_USERNAME: sonar\n|      SONAR_JDBC_PASSWORD: sonar\n|      SONAR_CLUSTER_ES_HOSTS: "search-1,search-2,search-3"\n|      SONAR_CLUSTER_NODE_NAME: "search-3"\n|    volumes:\n|      - search-data-3:/opt/sonarqube/data\n|  db:\n|    image: postgres:12\n|    networks:\n|      - sonar-network\n|    environment:\n|      POSTGRES_USER: sonar\n|      POSTGRES_PASSWORD: sonar\n|    volumes:\n|      - postgresql:/var/lib/postgresql\n|      - postgresql_data:/var/lib/postgresql/data\n|  proxy:\n|    image: jwilder/nginx-proxy\n|    ports:\n|      - "80:80"\n|    volumes:\n|      - /var/run/docker.sock:/tmp/docker.sock:ro\n|    networks:\n|      - sonar-network\n|      - sonar-public\n|\n|networks:\n|  sonar-network:\n|    ipam:\n|      driver: default\n|      config:\n|        - subnet: 172.28.2.0/24\n|  sonar-public:\n|    driver: bridge\n|\n|volumes:\n|  sonarqube_extensions:\n|  sonarqube_logs:\n|  search-data-1:\n|  search-data-2:\n|  search-data-3:\n|  postgresql:\n|  postgresql_data:\n| ```\n\n## Next Steps\nOnce you\'ve complete these steps, check out the [Operate your Cluster](/setup/operate-cluster/) documentation.\n'},{path:"setup/install-plugin",content:"---\ntitle: Install a Plugin\nurl: /setup/install-plugin/\n---\n\nThere are two ways to install plugins in SonarQube:\n\n- **Marketplace** - With Community Edition, you can use Marketplace to automatically install plugins from the SonarQube. With commercial editions, you can browse plugins in the Marketplace, but you need to manually install and update your plugins.\n- **Manual Installation** - You need to manually install plugins when using commercial editions of SonarQube. You can also manually install plugins if your SonarQube instance doesn't have internet access or the plugin you're installing isn't in the Marketplace.\n\n[[warning]]\n| Plugins are not provided by SonarSource, and you therefore install them at your own risk. A SonarQube administrator needs to acknowledge this risk in the Marketplace before installing plugins or when prompted in SonarQube after installing a plugin manually.\n\n## Installing plugins from the Marketplace\n\n[[info]]\n|You can only install and update plugins from the Marketplace in SonarQube Community Edition. With commercial editions, you need manually install and update plugins.\n\nIf your instance has internet access and you're connected with a SonarQube user with the **Administer System** global permission, you can find the Marketplace at **Administration > Marketplace**. From here:\n\n- Find the plugin you want to install\n- Click **Install** and wait for the download to be processed\n\nOnce the download is complete, a **Restart** button will be available to restart your instance.\n\nSee [Marketplace](/instance-administration/marketplace/) for more details on how to configure your SonarQube Server to connect to the internet.\n\n## Manual installing plugins\n\nTo manually install a plugin:\n\n1. Download the plugin you want to install. The version needs to be compatible with your SonarQube version.\n2. Put the downloaded jar in `$SONARQUBE_HOME/extensions/plugins`, and remove any previous versions of the same plugins.\n3. Restart your SonarQube server.\n\n## Uninstalling plugins\n\nTo uninstall a plugin from the Marketplace (**Administration > Marketplace**):\n1. Sort the **Plugins** list by installed plugins by selecting **Installed** above the list.\n2. Find the plugin you want to uninstall.\n3. Click the **Uninstall** button to the right of the plugin information.\n4. Restart your SonarQube server.\n\nTo uninstall a plugin manually:\n1. Delete the plugin from the `$SONARQUBE-HOME/extensions/plugins` folder.\n2. Restart your SonarQube server.\n"},{path:"setup/install-server",content:'---\ntitle: Install the Server\nurl: /setup/install-server/\n---\n\n## Overview\n\nThis section describes a single-node SonarQube instance. For details on clustered setup, see [Install the Server as a Cluster](/setup/install-cluster/).\n\n### Instance components\n\nA SonarQube instance comprises three components:\n\n![SonarQube Instance Components](/images/SQ-instance-components.png)\n\n1. The SonarQube server running the following processes:\n\t- a web server that serves the SonarQube user interface.\n\t- a search server based on Elasticsearch.\n\t- the compute engine in charge of processing code analysis reports and saving them in the SonarQube database.\n\n2. The database to store the following:\n\t- Metrics and issues for code quality and security generated during code scans.\n\t- The SonarQube instance configuration.\n\n3. One or more scanners running on your build or continuous integration servers to analyze projects.\n\n### Hosts and locations\n\nFor optimal performance, the SonarQube server and database should be installed on separate hosts, and the server host should be dedicated. The server and database hosts should be located in the same network.\n\nAll hosts must be time-synchronized.\n\n## Installing the database\n\nSeveral [database engines](/requirements/requirements/) are supported. Be sure to follow the requirements listed for your database. They are real requirements not recommendations.\n\nCreate an empty schema and a `sonarqube` user. Grant this `sonarqube` user permissions to `create`, `update`, and `delete` objects for this schema.\n\n[[collapse]]\n| ## Microsoft SQL Server\n|\n|[[warning]]\n|| Collation **MUST** be case-sensitive (CS) and accent-sensitive (AS).  \n|| `READ_COMMITED_SNAPSHOT` **MUST** be set on the SonarQube database.\n|\n|MS SQL database\'s shared lock strategy may impact SonarQube runtime. Making sure that `is_read_committed_snapshot_on` is set to `true` to prevent SonarQube from facing potential deadlocks under heavy loads. \n|\n|Example of query to check `is_read_committed_snapshot_on`:\n|```\n|SELECT is_read_committed_snapshot_on FROM sys.databases WHERE name=\'YourSonarQubeDatabase\';\n|```\n|Example of query to update `is_read_committed_snapshot_on`:\n|```\n|ALTER DATABASE YourSonarQubeDatabase SET READ_COMMITTED_SNAPSHOT ON WITH ROLLBACK IMMEDIATE;\n|```\n|### Integrated Security\n|\n|To use integrated security: \n|\n|1. Download the [Microsoft SQL JDBC Driver 9.2.0 package](https://docs.microsoft.com/en-us/sql/connect/jdbc/release-notes-for-the-jdbc-driver?view=sql-server-ver15#92) and copy `mssql-jdbc_auth-9.2.0.x64.dll` to any folder in your path. \n|\n|2. **If you\'re running SonarQube as a Windows service,** make sure the Windows account under which the service is running has permission to connect your SQL server. The account should have `db_owner` database role membership. \n|\n|\t**If you\'re running the SonarQube server from a command prompt,** the user under which the command prompt is running should have `db_owner` database role membership. \n|\n|3. Ensure that `sonar.jdbc.username` or `sonar.jdbc.password` properties are commented out or SonarQube will use SQL authentication.\n|\n|```\n|sonar.jdbc.url=jdbc:sqlserver://localhost;databaseName=sonar;integratedSecurity=true\n|```\n|\n|### SQL Authentication\n|\n|To use SQL Authentication, use the following connection string. Also ensure that `sonar.jdbc.username` and `sonar.jdbc.password` are set appropriately:\n|\n|```\n|sonar.jdbc.url=jdbc:sqlserver://localhost;databaseName=sonar\n|sonar.jdbc.username=sonarqube\n|sonar.jdbc.password=mypassword\n|```\n\n[[collapse]]\n| ## Oracle\n|\n|If there are two SonarQube schemas on the same Oracle instance, especially if they are for two different versions, SonarQube gets confused and picks the first it finds. To avoid this issue:\n|\n|- Either privileges associated to the SonarQube Oracle user should be decreased\n|- Or a trigger should be defined on the Oracle side to automatically alter the SonarQube Oracle user session when establishing a new connection:\n|\n|[[warning]]\n|| Oracle JDBC driver versions 12.1.0.1 and 12.1.0.2 have major bugs, and are not recommended for use with the SonarQube ([see more details](https://groups.google.com/forum/#!msg/sonarqube/Ahqt1iarqJg/u0BVRJZnBQAJ)).\n\n[[collapse]]\n| ## PostgreSQL\n|\n|If you want to use a custom schema and not the default "public" one, the PostgreSQL `search_path` property must be set:\n|\n|```\n|ALTER USER mySonarUser SET search_path to mySonarQubeSchema\n|```\n\n## Installing SonarQube from the ZIP file\n\nFirst, check the [requirements](/requirements/requirements/). Then download and unzip the [distribution](http://www.sonarqube.org/downloads/) (do not unzip into a directory starting with a digit). \n\nSonarQube cannot be run as `root` on Unix-based systems, so create a dedicated user account for SonarQube if necessary.\n\n_$SONARQUBE-HOME_ (below) refers to the path to the directory where the SonarQube distribution has been unzipped.\n\n### Setting the Access to the Database\n\nEdit _$SONARQUBE-HOME/conf/sonar.properties_ to configure the database settings. Templates are available for every supported database. Just uncomment and configure the template you need and comment out the lines dedicated to H2:\n\n```\nExample for PostgreSQL\nsonar.jdbc.username=sonarqube\nsonar.jdbc.password=mypassword\nsonar.jdbc.url=jdbc:postgresql://localhost/sonarqube\n```\n\n### Adding the JDBC Driver\n\nDrivers for the supported databases (except Oracle) are already provided. Do not replace the provided drivers; they are the only ones supported.\n\nFor Oracle, copy the JDBC driver into _$SONARQUBE-HOME/extensions/jdbc-driver/oracle_.\n\n### Configuring the Elasticsearch storage path\n\nBy default, Elasticsearch data is stored in _$SONARQUBE-HOME/data_, but this is not recommended for production instances. Instead, you should store this data elsewhere, ideally in a dedicated volume with fast I/O. Beyond maintaining acceptable performance, doing so will also ease the upgrade of SonarQube.\n\nEdit _$SONARQUBE-HOME/conf/sonar.properties_ to configure the following settings:\n\n```\nsonar.path.data=/var/sonarqube/data\nsonar.path.temp=/var/sonarqube/temp\n```\n\nThe user used to launch SonarQube must have read and write access to those directories.\n\n### Starting the Web Server\n\nThe default port is "9000" and the context path is "/". These values can be changed in _$SONARQUBE-HOME/conf/sonar.properties_:\n\n```\nsonar.web.host=192.168.0.1\nsonar.web.port=80\nsonar.web.context=/sonarqube\n```\n\nExecute the following script to start the server:\n\n- On Linux: bin/linux-x86-64/sonar.sh start\n- On macOS: bin/macosx-universal-64/sonar.sh start\n- On Windows: bin/windows-x86-64/StartSonar.bat\n\nYou can now browse SonarQube at _http://localhost:9000_ (the default System administrator credentials are `admin`/`admin`).\n\n### Adjusting the Java Installation\n\nIf there are multiple versions of Java installed on your server, you may need to explicitly define which version of Java is used.\n\nTo change the Java JVM used by SonarQube, edit _$SONARQUBE-HOME/conf/wrapper.conf_ and update the following line:\n\n```\nwrapper.java.command=/path/to/my/jdk/bin/java\n```\n\n### Advanced Installation Features\n\n- Running SonarQube as a Service on [Windows](/setup/operate-server/) or [Linux](/setup/operate-server/)\n- Running SonarQube [behind a Proxy](/setup/operate-server/)\n- Monitoring and adjusting [Java Process Memory](/instance-administration/monitoring/)\n\n## Installing SonarQube from the Docker Image\n\nFollow these steps for your first installation:\n\n1.\tCreating the following volumes helps prevent the loss of information when updating to a new version or upgrading to a higher edition:\n\t- `sonarqube_data` – contains data files, such as the embedded H2 database and Elasticsearch indexes\n\t- `sonarqube_logs` – contains SonarQube logs about access, web process, CE process, and Elasticsearch\n\t- `sonarqube_extensions` – will contain any plugins you install and the Oracle JDBC driver if necessary.\n\t\n\tCreate the volumes with the following commands:\n\t```bash\n\t$> docker volume create --name sonarqube_data\n\t$> docker volume create --name sonarqube_logs\n\t$> docker volume create --name sonarqube_extensions\n\t``` \n\t[[warning]]\n    | Make sure you\'re using [volumes](https://docs.docker.com/storage/volumes/) as shown with the above commands, and not [bind mounts](https://docs.docker.com/storage/bind-mounts/). Using bind mounts prevents plugins from populating correctly.\n\n2. Drivers for supported databases (except Oracle) are already provided. If you\'re using an Oracle database, you need to add the JDBC driver to the `sonar_extensions` volume. To do this:\n\n\ta. Start the SonarQube container with the embedded H2 database:\n   \n    ```\n\t$ docker run --rm \\\n\t\t-p 9000:9000 \\\n\t\t-v sonarqube_extensions:/opt/sonarqube/extensions \\\n\t\t<image_name>\n\t```\n\t\n\tb. Exit once SonarQube has started properly. \n   \n\tc. Copy the Oracle JDBC driver into `sonarqube_extensions/jdbc-driver/oracle`.\n   \n3. Run the image with your database properties defined using the -e environment variable flag:\n\n\t```bash\n\t$> docker run -d --name sonarqube \\\n\t\t-p 9000:9000 \\\n\t\t-e SONAR_JDBC_URL=... \\\n\t\t-e SONAR_JDBC_USERNAME=... \\\n\t\t-e SONAR_JDBC_PASSWORD=... \\\n\t\t-v sonarqube_data:/opt/sonarqube/data \\\n\t\t-v sonarqube_extensions:/opt/sonarqube/extensions \\\n\t\t-v sonarqube_logs:/opt/sonarqube/logs \\\n\t\t<image_name>\n\t```\n\t\n\tFor more configuration environment variables, see the [Docker Environment Variables](/setup/environment-variables/).\n\t\n\t[[warning]]\n    | Use of the environment variables `SONARQUBE_JDBC_USERNAME`, `SONARQUBE_JDBC_PASSWORD`, and `SONARQUBE_JDBC_URL` is deprecated and will stop working in future releases.\n\n####**Example Docker Compose configuration**\nIf you\'re using [Docker Compose](https://docs.docker.com/compose/), use the following example as a reference when configuring your `.yml` file. Click the heading below to expand the `.yml` file.\n\n[[info]]\n| The example below will use the latest version of the SonarQube Docker image. If want to use the LTS version of SonarQube, you need to update the example with the `sonarqube:lts-community` image tag.\n\n[[collapse]]\n| ## Docker Compose .yml file example\n|\n| ```\n| version: "3"\n| \n| services:\n|   sonarqube:\n|     image: sonarqube:community\n|     depends_on:\n|       - db\n|     environment:\n|       SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar\n|       SONAR_JDBC_USERNAME: sonar\n|       SONAR_JDBC_PASSWORD: sonar\n|     volumes:\n|       - sonarqube_data:/opt/sonarqube/data\n|       - sonarqube_extensions:/opt/sonarqube/extensions\n|       - sonarqube_logs:/opt/sonarqube/logs\n|     ports:\n|       - "9000:9000"\n|   db:\n|     image: postgres:12\n|     environment:\n|       POSTGRES_USER: sonar\n|       POSTGRES_PASSWORD: sonar\n|     volumes:\n|       - postgresql:/var/lib/postgresql\n|       - postgresql_data:/var/lib/postgresql/data\n| \n| volumes:\n|   sonarqube_data:\n|   sonarqube_extensions:\n|   sonarqube_logs:\n|   postgresql:\n|   postgresql_data:\n| ```\n\n## Next Steps\n\nOnce your server is installed and running, you may also want to [Install Plugins](/setup/install-plugin/). Then you\'re ready to begin [Analyzing Source Code](/analysis/overview/).\n\n## Troubleshooting/FAQ\n\n### Failed to connect to the Marketplace via proxy\n\nDouble check that settings for proxy are correctly set in `$SONARQUBE_HOME/conf/sonar.properties`.\nNote that if your proxy username contains a backslash, then it should be escaped - for example username "domain\\user" in file should look like:\n\n```\nhttp.proxyUser=domain\\\\user\n```\n\nFor some proxies, the exception "java.net.ProtocolException: Server redirected too many times" might mean an incorrect username or password has been configured.\n\n### Exception java.lang.RuntimeException: can not run elasticsearch as root\n\nSonarQube starts an Elasticsearch process, and the same account that is running SonarQube itself will be used for the Elasticsearch process. Since Elasticsearch cannot be run as `root`, that means SonarQube can\'t be either. You must choose some other, non-`root` account with which to run SonarQube, preferably an account dedicated to the purpose.\n\n### Sonarqube fails to decorate merge requests when DNS entry to ALM changes\n\nIf you run SonarQube in an environment with a lot of DNS friction, you should define a DNS cache time to live policy as, by default, SonarQube will hold the DNS cache until it is restarted. You can set this policy to five seconds by doing the following: \n\n```bash\necho "networkaddress.cache.ttl=5" >> "${JAVA_HOME}/conf/security/java.security" \n```\n\nPlease be aware that this increases the risk of DNS spoofing attacks.\n'},{path:"setup/lts-to-lts-upgrade-notes",content:'---\ntitle: LTS to LTS Release Upgrade Notes\nurl: /setup/lts-to-lts-upgrade-notes/\n---\n\nThese Upgrade Notes are intended for users who are directly upgrading from SonarQube _v7.9 LTS_. Just upgrading a few minor versions? Refer to the regular [Upgrade Notes](/setup/upgrade-notes/).\n\n## Authentication\n**Default Authentication and Administrator credentials (8.6)**  \nOn a fresh install to avoid misconfiguration and related security risks, authentication is now required by default, and you need to change the default password for the administrator account. \n\nWhen upgrading, if you were still using default credentials, you\'ll be asked to change the password the next time you authenticate with the admin account. ([MMF-1352](https://jira.sonarsource.com/browse/MMF-1352), [MMF-2146](https://jira.sonarsource.com/browse/MMF-2146)).\n\n**Additional SAML checks (8.4)**  \nSAML authentication adds additional checks for validating SAML responses from the identity provider. This could reveal a non-standard configuration that needs to be updated. Information will appear in the logs upon a failed login attempt in the event that the configuration needs to be tweaked.\n\n**GitLab Authentication now available (8.0)**  \nGitLab OAuth2 authentication is now available in all editions. If you were using the community plugin, you need to remove it from SonarQube before upgrading. The configured variable of the plugin will be migrated, so the authentication will work without having to rewrite the configuration. Due to changes in group mapping, GitLab subgroups mapped using the community plugin will need to be renamed in SonarQube for the mapping to work. ([SONAR-12460](https://jira.sonarsource.com/browse/SONAR-12460)).\n\n## Analysis\n**Updated built-in Quality Profiles (8.0-8.9)**  \nThe built-in Quality Profiles for each language have been updated, meaning rules may have been added, changed, deprecated or dropped. If you are using or extending any of the “Sonar way” built-in Quality Profiles, make sure to check their Changelog to see what has changed. \n\n**JavaScript security analysis can take longer (8.8)**  \nThe JavaScript security analysis in commercial editions has been overhauled for far better accuracy. This overhaul results in an expected increase in memory requirement for analysis. \n\n**JavaScript, TypeScript, and CSS analysis now requires Node.js 10+ (8.7, 8.8)**  \nIn order to analyze Javascript, Typescript, and CSS code, you now need to have Node.js 10+ installed on the machine running the scan.\n\n**SonarScanner for MSBuild compatibility (and renaming) (8.5)**  \nAnalyzing a C# / VB.NET solution in SonarQube 8.5 requires SonarScanner for MSBuild 4.0+.\n\nThe SonarScanner for MSBuild has been renamed to the [SonarScanner for .NET](/analysis/scan/sonarscanner-for-msbuild/)\n\n**New Code Period values simplified (8.0, 8.4)**  \nIt\'s now easier to set your New Code Period in the UI. With the new settings, specific analysis has replaced setting the New Code Period to a specific date or version. If you were using a specific date or version for your New Code Period, now you\'ll need to use a specific analysis. \n\nIt is now also possible to set the New Code Period to be defined against an already analyzed branch, mimicking the New Code Period of what were previously short-lived branches.\n\nSee the [Setting Your New Code Period](/project-administration/new-code-period/) for more info. ([MMF-1579](https://jira.sonarsource.com/browse/MMF-1579)).\n\n**Security Hotspots in the built-in Quality Gate (8.3)**   \nWe\'ve added a new condition to the built-in "Sonar way" Quality Gate to make sure all Security Hotspots on New Code are reviewed. The Quality Gate fails if the percentage of new Hotspots reviewed is less than 100%. ([MMF-1907](https://jira.sonarsource.com/browse/MMF-1907)).\n\n**Jenkins automatic branch and Pull Request detection (8.3)**  \nWith [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) and [above](https://www.sonarsource.com/plans-and-pricing/), Scanners now automatically detect branches and Pull Requests in Jenkins Multibranch Pipelines. You no longer need to pass branch and Pull Request parameters. When upgrading from Community Edition or an old commercial edition version, the branch name in your SonarQube project needs to match the branch name in your code repository to continue writing history to the branch. Because SonarQube names the Main Branch "master" by default, you may have to rename it before running analysis again. See the [Jenkins CI Integration](/analysis/jenkins/) page for more information. ([MMF-1676](https://jira.sonarsource.com/browse/MMF-1676)).\n\n**Updated .NET code coverage (8.3)**  \nThe code coverage for .NET projects now takes into account the branch/condition coverage in addition to the line coverage. The coverage of your projects may decrease to be closer to reality, and it can impact your Quality Gate. (See more details [here](https://community.sonarsource.com/t/c-vb-net-sonarqube-and-sonarcloud-support-branch-condition-coverage-data/22384)).\n\n**Support for `.exec` format JaCoCo Coverage Reports dropped (8.2)**  \nThe `.exec` format for JaCoCo coverage reports is no longer supported.\n\nOnce upgraded, you will only be able to import `.xml` style reports. You should ensure that you are now [Importing JaCoCo coverage reports in XML format](https://community.sonarsource.com/t/coverage-test-data-importing-jacoco-coverage-report-in-xml-format/12151).\n\n**Short-lived and Long-lived branches are now just branches (8.1, 8.4)**  \nThe concept for branches is now simplified, with a single way to handle all of them. ([MMF-1786](https://jira.sonarsource.com/browse/MMF-1786)).\n* Analysis is the same for all branches. The parameter `sonar.branch.target` is no longer used and can be removed.\n* All branches behave as previous Long-lived branches: all measures are available. The New Code period is configurable and starts by default after the first analysis. The Quality Gate check applies on all conditions.\n* As a consequence, branches that were previously Short-Lived branches may display incomplete measures before they are analyzed again. With the first analysis, measures on New Code and the Quality Gate status may change.\n* New housekeeping settings replace the Long-lived branch pattern and allow you to choose the branches which should be kept when inactive.\n* Detection of new issues in branches and PRs is simplified. The list of issues reported as new may change slightly. ([SONAR-12627](https://jira.sonarsource.com/browse/SONAR-12627)).\n\n## Integration\n**GitHub Enterprise compatibility (8.9)**  \nSonarQube 8.9 only supports GitHub Enterprise 2.21+ for pull request decoration (the previous minimum version was 2.15).\n\n**Azure DevOps Services and Bitbucket Cloud are now supported (8.7)**  \nSonarQube now officially supports Azure DevOps Services and Bitbucket Cloud. If you were running analysis using Bitbucket Pipelines previously, when you upgrade, the Main branch name in your SonarQube project needs to match the branch name in your code repository to continue writing history to the branch. You may have to rename it before running analysis again.\n\n**Analysis summary for GitHub Pull Requests (8.3)**\n* Pull Request analysis can be shown under the Conversation tab in GitHub. You can enable or disable it at **Project Settings > General Settings > Pull Request Decoration**. \n* If you already have Pull Request analysis under the GitHub Checks tab, you\'ll need to update your GitHub App to give Pull Requests read & write access. For more information see [Pull Requests](/analysis/pull-request/). ([MMF-1892](https://jira.sonarsource.com/browse/MMF-1892)).\n\n**Configuration of Pull Request decoration (8.1)**  \nThe configuration of Pull Request decoration changes. Previous settings are replaced by a new configuration in the UI. Also, decoration of Pull Requests now supports multiple instances of a same ALM provider in Enterprise Edition and above. ([MMF-1814](https://jira.sonarsource.com/browse/MMF-1814)).\n\n## Operations\n**Plugins require risk consent (8.9)**  \nWhen upgrading, if you\'re using plugins, a SonarQube administrator needs to acknowledge the risk involved with plugin installation when prompted in SonarQube. ([MMF-2301](https://jira.sonarsource.com/browse/MMF-2301)).\n\n**Database support updated (8.9)**  \nSonarQube 8.9 supports the following database versions:\n\n* PostgreSQL versions 9.6 to 13. PostgreSQL versions <9.6 are no longer supported.\n* MSSQL Server 2014, 2016, 2017, and 2019.\n* Oracle XE, 12C, 18C, and 19C. Oracle 11G is no longer supported.\n\n**Webhooks aren\'t allowed to target the instance (8.9)**  \nTo improve security, webhooks, by default, aren\'t allowed to point to the SonarQube server. You can change this behavior in the configuration. ([SONAR-14682](https://jira.sonarsource.com/browse/SONAR-14682)).\n\n**Docker Images for commercial SonarQube Editions (8.2, 8.7)**  \nIf you wish to deploy SonarQube in a containerized environment, we recommend using the Docker Images provided by SonarSource available on [Docker Hub](https://hub.docker.com/_/sonarqube), now for all SonarQube editions. \n\n**Microsoft SQL Server and Integrated Authentication (8.7)**  \nIf you are using Microsoft SQL Server with Integrated Authentication, you will need to replace the `sqljdbc_auth.dll` file on your `PATH` with `mssql-jdbc_auth-9.2.0.x64.dll` from the [Microsoft SQL JDBC Driver 9.2.0 package](https://docs.microsoft.com/en-us/sql/connect/jdbc/release-notes-for-the-jdbc-driver?view=sql-server-ver15#92). See [Install the Server](/setup/install-server/) for more information.\n\n**Elasticsearch update and change in cluster configuration (8.6)**  \nFor non-DCE editions, the Elasticsearch upgrade doesn\'t change the configuration. SonarQube automatically binds to the loopback address an additional Elasticsearch port which can be configured optionally.  \n\nWhen running a cluster with Data Center Edition, the configuration of search nodes has changed. The old search properties will now fail. You need to configure two new sets of properties. See [Configure and Operate a Cluster](/setup/operate-cluster/) for more information.  \n\nWe recommend only giving external access to the application nodes and to the main port. ([SONAR-12686](https://jira.sonarsource.com/browse/SONAR-12686)).\n\n**Upgrade simplified: Languages, Git and SVN, LDAP/GitHub/SAML support now built-in (8.0, 8.5)**  \nAll plugins related to languages, Git/SVN support, and LDAP/GitHub/SAML authentication are now built into SonarQube itself. If you were using these plugins, you need to remove them from your extensions/plugins directory before upgrading. Read more in this community guide: [SonarQube v8.5 and Beyond: Where did all the plugins go?](https://community.sonarsource.com/t/sonarqube-v8-5-and-beyond-where-did-all-the-plugins-go/32792) ([MMF-2042](https://jira.sonarsource.com/browse/MMF-2042))\n\n**Updated system settings recommendation (8.4)**  \nIn previous versions, the recommended limits regarding threads, file descriptors, and vm.max_map_count were taken from Elasticsearch dependencies. This release can reach these limits occasionally, so we recommend increasing the following settings of your OS when upgrading:\n\n* `vm.max_map_` count is greater than or equal to 524288\n* `fs.file-max` is greater than or equal to 131072\n* the user running SonarQube can open at least 131072 file descriptors\n* the user running SonarQube can open at least 8192 threads\n\nFor more information, see the [Requirements](/requirements/requirements/) documentation. \n\n**Project, Application, and Portfolio availability when rebuilding Elasticsearch indexes (8.4)**  \nFrom now on if your upgrade requires the rebuild of Elasticsearch indexes, your projects and Applications will become available as they are reindexed. Portfolios won\'t be available until all projects are reindexed. ([MMF-2010](https://jira.sonarsource.com/browse/MMF-2010))\n\n**Deprecated configuration (8.2)**  \nThe old way of referencing environment variables in server configuration is deprecated and replaced with the support of default environment variables. ([SONAR-13113](https://jira.sonarsource.com/browse/SONAR-13113)).\n\n## User Interface\n**Applications on the Projects page (8.3)**  \n[Applications](/user-guide/applications/) are now found on the Projects page. You can filter, favorite, and tag applications like you can with projects. ([MMF-1382](https://jira.sonarsource.com/browse/MMF-1382)).\n\n**Security Hotspots: dedicated space and workflow (8.2)**  \n* The Security Hotspots have a brand new space where developers can perform security reviews. The review process has been simplified. It\'s no longer necessary to transform a Security Hotspot into a Manual Vulnerability and back. A developer can now simply mark a Security Hotspot as Safe, Fixed, or leave it as-is if more time is needed. ([MMF-1868](https://jira.sonarsource.com/browse/MMF-1868)).\n* Manual Vulnerabilities created from Security Hotspots are migrated to Security Hotspots with the status "To Review". A comment "Migrated from Manual Vulnerability" is added to the review history to recognize them.  \n* The formula to compute the Security Review Rating, which was previously only available at the portfolio level, has been updated to be more meaningful. Historical values for this indicator have been removed to avoid confusion. ([MMF-1890](https://jira.sonarsource.com/browse/MMF-1890)).\n* A Security Hotspots Reviewed metric has been added and is available to Quality Gates along with the Security Review Rating.\n\n**New project homepage (8.2)**  \nThe project homepage has been redesigned to focus on New Code. ([MMF-1886](https://jira.sonarsource.com/browse/MMF-1886)). Projects details are now tucked into a new "Project information" pane. The project administration menu has been renamed "Project Settings".\n\n## Web/Plugin API\n**Deprecated web services have been dropped (8.1, 8.8)**  \nWeb services that were deprecated in 6.x versions have been dropped. ([SONAR-13848](https://jira.sonarsource.com/browse/SONAR-13848)).\n\n**Changes in web services and plugin APIs (8.4)**  \nThe format of several IDs exposed in web services changed and their use is deprecated. See [SONAR-13248](https://jira.sonarsource.com/browse/SONAR-13248), [SONAR-13249](https://jira.sonarsource.com/browse/SONAR-13249), and [SONAR-13300](https://jira.sonarsource.com/browse/SONAR-13300).  \nA related change is introduced in a plugin API method. See [SONAR-13420](https://jira.sonarsource.com/browse/SONAR-13420).\n'},{path:"setup/operate-cluster",content:"---\ntitle: Configure & Operate a Cluster\nurl: /setup/operate-cluster/\n---\n\n_High availability and cluster scalability are features of the [Data Center Edition](https://redirect.sonarsource.com/editions/datacenter.html)._\n\nOnce the [SonarQube cluster is installed](/setup/install-cluster/), you have a high availability configuration that allows your SonarQube instance to stay up and running even if there is a crash or failure in one of the cluster's nodes. Your SonarQube cluster is also scalable, and you can add application nodes to increase your computing capabilities.\n\n## Start, Stop, or Upgrade the Cluster\n\n### Start the Cluster\nTo start a cluster, you need to follow these steps in order:\n\n1. Start the search nodes\n1. Start the application nodes\n\n### Stop the Cluster\nTo stop a cluster, you need to follow these steps in order:\n\n1. Stop the application nodes\n1. Stop the search nodes\n\n### Upgrade SonarQube\n1. Stop the cluster.\n1. Upgrade SonarQube on all nodes (application part, plugins, JDBC driver if required) following the usual upgrade procedure but without triggering the /setup phase.\n1. Once all nodes have the same binaries: restart the cluster.\n1. At this point, only one of the application nodes is up. Try to access `node_ip:port/setup` on each application node, and trigger the setup operation on the one that responds.\n\n## Start or Stop a Node\nYou can start or stop a single node in the same way as starting and stopping an instance using a single server. By default, it's a graceful shutdown where no new analysis report processing can start, but the tasks in progress are allowed to finish.\n\n## Install or Upgrade a Plugin\n1. Stop the application nodes.\n1. Install or upgrade the plugin on the application nodes.\n\t* If upgrading, remove the old version.\n\t* You don't need to install plugins on search nodes.\n1. Restart the application nodes.\n\n## Scalability\nYou have the option of adding application nodes (up to 10 total application nodes) to your cluster to increase computing capabilities. \n\n### Scaling in a Traditional Environment\n\n#### **Adding an Application Node**\nTo add an Application Node:\n\n1. Configure your new application node in sonar.properties. The following is an example of the configuration to be added to sonar.properties for a sixth application node (server6, ip6) in a cluster with the default five servers:\n\n\t**server6**\n\t```\n\t...\n\tsonar.cluster.enabled=true\n\tsonar.cluster.node.type=application\n\tsonar.cluster.node.host=ip6 \n\tsonar.cluster.node.port=9003\n\tsonar.cluster.hosts=ip1,ip2,ip6\n\tsonar.cluster.search.hosts=ip3:9001,ip4:9001,ip5:9001\n\tsonar.auth.jwtBase64Hs256Secret=YOURGENERATEDSECRET\n\t...\n\t```\n2. Update the configuration of the preexisting nodes to include your new node. \n\n\tWhile you don't need to restart the cluster after adding a node, you should ensure the configuration is up to date on all of your nodes to avoid issues when you eventually do need to restart.\n\n#### **Removing an Application Node**\nWhen you remove an application node, make sure to update the configuration of the remaining nodes. Much like adding a node, while you don't need to restart the cluster after removing a node, you should ensure the configuration is up to date on all of your nodes to avoid issues when you eventually do need to restart.\n\n### Scaling in a Docker Environment\n\n#### **Adding Application Nodes**\n\nIf you're using docker-compose, you can scale the application nodes using the following command:\n\n`docker-compose up -d --scale sonarqube=3`\n\n#### Removing Application Nodes\nYou can reduce the number of application nodes with the same command used to add application nodes by lowering the number.\n\n## Monitoring\nCPU and RAM usage on each node have to be monitored separately with an APM. \n\nIn addition, we provide a Web API _api/system/health_ you can use to validate that all of the nodes in your cluster are operational.  \n\n* GREEN: SonarQube is fully operational\n* YELLOW: SonarQube is usable, but it needs attention in order to be fully operational\n* RED: SonarQube is not operational\n\nTo call it from a monitoring system without having to give admin credentials, it is possible to setup a system passcode. You can configure this through the `sonar.web.systemPasscode` property in _$SONARQUBE-HOME/conf/sonar.properties_ if you're using a traditional environment or through the corresponding environment variable if you're using a Docker environment.\n\n### Cluster Status\nOn the System Info page at **Administration > System**, you can check whether your cluster is running safely (green) or has some nodes with problems (orange or red).\n\n### Maximum Pending Time for Tasks\nOn the global Background Tasks page at **Administration > Projects > Background Tasks**, you can see the number of **pending** tasks as well as the maximum **pending time** for the tasks in the queue. This shows the pending time of the oldest background task waiting to be processed. You can use this to evaluate if it might be worth configuring additional Compute Engine workers (Enterprise Edition) or additional nodes (Data Center Edition) to improve SonarQube performance. \n\n## Compute Engine Workers\nIf you change the number of [Compute Engine workers](/instance-administration/compute-engine-performance/) in the UI, you must restart each application node to have the change take effect.\n\n## Project Move\nWhen the [Project Move](/instance-administration/project-move/) feature is used in a DC installation:\n\n* Projects are exported on only one of the application nodes \n* The archive of the exported projects must be copied to all the applications nodes in the target server\n\n## Configuration details\nThere are three TCP networks to configure: \n\n- the network of application nodes that relies on Hazelcast.\n- the network used for Elasticsearch internal communication between search nodes (`es` properties).\n- the network between application nodes and search nodes (`search` properties).\n\n[Hazelcast](https://hazelcast.org/) is used to manage the communication between the cluster's application nodes. You don't need to install it yourself, it's provided out of the box.\n\n## Docker Environment Configuration\nIn a Docker environment, your properties are configured using [Environment Variables](/setup/environment-variables/).\n\n## Traditional Environment Configuration\nThe following properties may be defined in the _$SONARQUBE-HOME/conf/sonar.properties_ file of each node in a cluster. When defining a property that contains a list of hosts (`*.hosts`) the port is not required if the default port was not overridden in the configuration.\n\n[[warning]]\n| Ports can be unintentionally exposed. We recommend only giving external access to the application nodes and to main port (`sonar.web.port`).\n\n### All nodes\nProperty | Description | Default | Required | \n---|---|---|---|\n`sonar.cluster.enabled`|Set to `true` in each node to activate the cluster mode|`false`|yes\n`sonar.cluster.name`|The name of the cluster. **Required if multiple clusters are present on the same network.** For example this prevents mixing Production and Preproduction clusters. This will be the name stored in the Hazelcast cluster and used as the name of the Elasticsearch cluster.|`sonarqube`|no\n`sonar.cluster.node.name`|The name of the node that is used on Elasticsearch and stored in Hazelcast member attribute (NODE_NAME) for sonar-application|`sonarqube-{UUID}`|no\n`sonar.cluster.node.type`|Type of node: either `application` or `search`| |yes\n\n### Application nodes\nProperty  | Description | Required \n---|---|---\n`sonar.cluster.hosts`|Comma-delimited list of all **application** hosts in the cluster. This value must contain **only application hosts**. Each item in the list must contain the port if the default `sonar.cluster.node.port` value is not used. Item format is `sonar.cluster.node.host` or `sonar.cluster.node.host:sonar.cluster.node.port`.|yes\n`sonar.cluster.node.host`|IP address of the network card that will be used by Hazelcast to communicate with the members of the cluster.|yes\n`sonar.cluster.node.port`|The Hazelcast port for communication with each application member of the cluster. Default: `9003`|no\n`sonar.cluster.node.web.port`|The Hazelcast port for communication with the WebServer process. Port must be accessible to all other application nodes. If not specified, a dynamic port will be chosen and all ports must be open among the nodes.|no\n`sonar.cluster.node.ce.port`|The Hazelcast port for communication with the ComputeEngine process. Port must be accessible to all other application nodes. If not specified, a dynamic port will be chosen and all ports must be open among the nodes.|no\n`sonar.cluster.search.hosts`|Comma-delimited list of search hosts in the cluster. The list can contain either the host or the host and port, but not both. The item format is `sonar.cluster.node.search.host` for host only or`sonar.cluster.node.search.host:sonar.cluster.node.search.port` for host and port.| yes\n`sonar.auth.jwtBase64Hs256Secret`|Required for authentication with multiple web servers. It is used to keep user sessions opened when they are redirected from one web server to another by the load balancer. See _$SONARQUBE-HOME/conf/sonar.properties_) for details about how to generate this secret key.| yes\n\n### Search nodes\nProperty  | Description | Default | Required \n---|---|---|---\n`sonar.cluster.node.search.host`|Elasticsearch host of the current node used for HTTP communication between search and application nodes. IP must be accessible to all application nodes.|`127.0.0.1`|yes\n`sonar.cluster.node.search.port`|Elasticsearch port of the current node used for HTTP communication between search and application nodes. Port must be accessible to all application nodes.|`9001`|yes\n`sonar.cluster.es.hosts`|Comma-delimited list of search hosts in the cluster. The list can contain either the host or the host and port but not both. The item format is `sonar.cluster.node.es.host` for host only or`sonar.cluster.node.es.host:sonar.cluster.node.es.port` for host and port.| |yes\n`sonar.cluster.node.es.host`|Elasticsearch host of the current node used by Elasticsearch internal communication to form a cluster (TCP transport).|localhost|yes\n`sonar.cluster.node.es.port`|Elasticsearch port of the current node used by Elasticsearch internal communication to form a cluster (TCP transport). Port must be accessible to all other search nodes|9002| yes\n`sonar.search.initialStateTimeout`|The timeout for the Elasticsearch nodes to elect a master node. The default value will be fine in most cases, but in a situation where startup is failing because of a timeout, this may need to be adjusted. The value must be set in the format: `{integer}{timeunit}`. Valid `{timeunit}` values are: `ms` (milliseconds); `s` (seconds); `m` (minutes); `h` (hours); `d` (days); `w` (weeks)|cluster: 120s; standalone: 30s|no\n\n### Elasticsearch authentication\n\n[[info]]\n| This configuration is optional. To secure access to your setup, you may want to first limit access to the nodes in your network. Elasticsearch authentication just adds another layer of security.\n\nFor Elasticsearch authentication, the following properties need to be configured on specific nodes:\n\n#### Application nodes\nProperty  | Description | Default | Required\n---|---|---|---\n`sonar.cluster.search.password`|Password for Elasticsearch built-in user (elastic) which will be used on the client site. If provided, it enables authentication. If this property is set, `sonar.cluster.search.password` on the search nodes must also be set to exact same value.| |no\n\n#### Search nodes\nProperty  | Description | Default | Required\n---|---|---|---\n`sonar.cluster.search.password`|Password for Elasticsearch built-in user (elastic) which will be set in ES. If provided, it enables authentication, and the instance will require additional properties to be set. If this property is set, `sonar.cluster.search.password` on the application nodes must also be set to exact same value.| |no\n`sonar.cluster.es.ssl.keystore`|File path to a keystore in PKCS#12 format. The user running SonarQube must have READ permission to that file. Required if password provided.| |no\n`sonar.cluster.es.ssl.truststore`|File path to a truststore in PKCS#12 format. The user running SonarQube must have READ permission to that file. Required if password provided.| |no\n`sonar.cluster.es.ssl.keystorePassword`|Password to the keystore.| |no\n`sonar.cluster.es.ssl.truststorePassword`|Password to the truststore.| | no\n\nWhen you're using Docker image, truststore and keystore should be provided as volumes.\n\n## Limitations\n* Cluster downtime is required for SonarQube upgrades or plugin installations.\n* All application nodes must be stopped when installing, uninstalling, or upgrading a plugin.\n* Plugins are not shared, meaning if you install/uninstall/upgrade a given plugin on one application node, you need to perform the same actions on the other application node.\n* There is no way to perform actions on the cluster from a central app - all operations must be done manually on each node of the cluster.\n\n## Frequently Asked Questions\n\n### Does Elasticsearch discover automatically other ES nodes? \nNo. Multicast is disabled. All hosts (IP+port) must be listed.\n\n### Can different nodes run on the same machine? \nYes, but it's best to have one machine for each node to be resilient to failures. To maintain an even higher level of availability, each of your three search nodes can be located in a separate availability zone *within the same region*.\n\n### Can the members of a cluster be discovered automatically? \nNo, all nodes must be configured in _$SONARQUBE-HOME/conf/sonar.properties_\n"},{path:"setup/operate-server",content:'---\ntitle: Operating the Server\nurl: /setup/operate-server/\n---\n\n## Running SonarQube as a Service on Windows\n\n### Installing SonarQube as a service\n\n[[warning]]\n| When installing SonarQube as a service on Windows, the path to the executable should be quoted to prevent unquoted service path attacks. \n\n```\n> sc create SonarQube binPath= "\\"%SONAR_HOME%\\bin\\windows-x86-64\\wrapper.exe\\" -s \\"%SONAR_HOME%\\conf\\wrapper.conf\\""\n```\n\n### Start or Stop the Service\n\n```\n> "%SONAR_HOME%\\bin\\windows-x86-64\\StartNTService.bat"\n> "%SONAR_HOME%\\bin\\windows-x86-64\\StopNTService.bat"\n```\n**Note:** `> "%SONAR_HOME%\\bin\\windows-x86-64\\StopNTService.bat"` does a graceful shutdown where no new analysis report processing can start, but the tasks in progress are allowed to finish. The time a stop will take depends on the processing time of the tasks in progress. You\'ll need to kill all SonarQube processes manually to force a stop.\n\n## Running SonarQube Manually on Linux\n\n### Start or Stop the Instance\n\n```\nStart:\n$SONAR_HOME/bin/linux-x86-64/sonar.sh start\n\nGraceful shutdown:\n$SONAR_HOME/bin/linux-x86-64/sonar.sh stop\n\nHard stop:\n$SONAR_HOME/bin/linux-x86-64/sonar.sh force-stop\n```\n**Note:** Stop does a graceful shutdown where no new analysis report processing can start, but the tasks in progress are allowed to finish. The time a stop will take depends on the processing time of the tasks in progress. Use force stop for a hard stop. \n\n## Running SonarQube as a Service on Linux with SystemD\n\nOn a Unix system using SystemD, you can install SonarQube as a service. You cannot run SonarQube as `root` in \'nix systems. Ideally, you will created a new account dedicated to the purpose of running SonarQube.\nLet\'s suppose:\n\n* The user used to start the service is `sonarqube`\n* The group used to start the service is `sonarqube`\n* The Java Virtual Machine is installed in `/opt/java/`\n* SonarQube has been unzipped into `/opt/sonarqube/`\n\nThen create the file `/etc/systemd/system/sonarqube.service` _based on_ the following \n\n```\n[Unit]\nDescription=SonarQube service\nAfter=syslog.target network.target\n\n[Service]\nType=simple\nUser=sonarqube\nGroup=sonarqube\nPermissionsStartOnly=true\nExecStart=/bin/nohup /opt/java/bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube/lib/sonar-application-8.5.jar\nStandardOutput=syslog\nLimitNOFILE=131072\nLimitNPROC=8192\nTimeoutStartSec=5\nRestart=always\nSuccessExitStatus=143\n\n[Install]\nWantedBy=multi-user.target\n```\n**Note**\n* Because the sonar-application jar name ends with the version of SonarQube, you will need to adjust the `ExecStart` command accordingly on install and at each upgrade.\n* The SonarQube data directory, `/opt/sonarqube/data`, and the extensions directory, `/opt/sonarqube/extensions` should be owned by the `sonarqube` user. As a good practice, the rest should be owned by `root`\n\nOnce your `sonarqube.service` file is created and properly configured, run:\n```\nsudo systemctl enable sonarqube.service\nsudo systemctl start sonarqube.service\n```\n\n## Running SonarQube as a Service on Linux with initd\n\nThe following has been tested on Ubuntu 8.10 and CentOS 6.2.\n\nCreate the file /etc/init.d/sonar with this content:\n\n```\n#!/bin/sh\n#\n# rc file for SonarQube\n#\n# chkconfig: 345 96 10\n# description: SonarQube system (www.sonarsource.org)\n#\n### BEGIN INIT INFO\n# Provides: sonar\n# Required-Start: $network\n# Required-Stop: $network\n# Default-Start: 3 4 5\n# Default-Stop: 0 1 2 6\n# Short-Description: SonarQube system (www.sonarsource.org)\n# Description: SonarQube system (www.sonarsource.org)\n### END INIT INFO\n \n/usr/bin/sonar $*\n```\n\nRegister SonarQube at boot time (RedHat, CentOS, 64 bit):\n\n```\nsudo ln -s $SONAR_HOME/bin/linux-x86-64/sonar.sh /usr/bin/sonar\nsudo chmod 755 /etc/init.d/sonar\nsudo chkconfig --add sonar\n```\nOnce registration is done, run:\n```\nsudo service sonar start\n```\n\n## Securing the Server Behind a Proxy\n\nThis section helps you configure the SonarQube Server if you want to run it behind a proxy. This can be done for security concerns or to consolidate multiple disparate applications. To run the SonarQube server over HTTPS, see the HTTPS Configuration section below.\n\n[[warning]]\n|For security reasons, we recommend only giving external access to the main port.\n\n### Using an Apache Proxy\n\nWe assume that you\'ve already installed Apache 2 with module mod\\_proxy, that SonarQube is running and available on `http://private_sonar_host:sonar_port/`, and that you want to configure a Virtual Host for `www.public_sonar.com`.\n\nAt this point, edit the HTTPd configuration file for the `www.public_sonar.com` virtual host. Include the following to expose SonarQube via `mod_proxy` at `http://www.public_sonar.com/`:\n\n```\nProxyRequests Off\nProxyPreserveHost On\n<VirtualHost *:80>\n  ServerName www.public_sonar.com\n  ServerAdmin admin@somecompany.com\n  ProxyPass / http://private_sonar_host:sonar_port/\n  ProxyPassReverse / http://www.public_sonar.com/\n  ErrorLog logs/somecompany/sonar/error.log\n  CustomLog logs/somecompany/sonar/access.log common\n</VirtualHost>\n```\n\nApache configuration is going to vary based on your own application\'s requirements and the way you intend to expose SonarQube to the outside world. If you need more details about Apache HTTPd and mod\\_proxy, please see [http://httpd.apache.org](http://httpd.apache.org).\n\n### Using Nginx\n\nWe assume that you\'ve already installed Nginx, that you are using a Virtual Host for www.somecompany.com and that SonarQube is running and available on `http://sonarhost:sonarport/`.\n\nAt this point, edit the Nginx configuration file. Include the following to expose SonarQube at http://www.somecompany.com/:\n\n```\n# the server directive is Nginx\'s virtual host directive\nserver {\n  # port to listen on. Can also be set to an IP:PORT\n  listen 80;\n  # sets the domain[s] that this vhost server requests for\n  server_name www.somecompany.com;\n  location / {\n    proxy_pass http://sonarhost:sonarport;\n  }\n}\n```\n\nNginx configuration will vary based on your own application\'s requirements and the way you intend to expose SonarQube to the outside world. If you need more details about Nginx, please see [https://www.nginx.com/resources/admin-guide/reverse-proxy/](https://www.nginx.com/resources/admin-guide/reverse-proxy/).\n\nNote that you may need to increase the max URL length since SonarQube requests can have URLs longer than 2048.\n\n### Using IIS\n\nPlease see: [http://blog.jessehouwing.nl/2016/02/configure-ssl-for-sonarqube-on-windows.html](http://blog.jessehouwing.nl/2016/02/configure-ssl-for-sonarqube-on-windows.html)\n\nNote that the setup described in this blog post is not appropriate for SAML through IIS.\n\n### HTTPS Configuration\n\nThe reverse proxy must be configured to set the value `X_FORWARDED_PROTO: https` in each HTTP request header. Without this property, redirection initiated by the SonarQube server will fall back on HTTP.\n\nFor example, with Nginx as a reverse proxy, you can paste the following or a similar snippet into the configuration file: \n\n ```\n# the server directive is Nginx\'s virtual host directive\nserver { \n  # port to listen on. Can also be set to an IP:PORT\t\n  listen 443 ssl;\n  ssl_certificate ${path_to_your_certificate_file}\n  ssl_certificate_key ${path_to_your_certificate_key_file}\n  location / {\n    proxy_pass ${address_of_your_sonarqube_instance_behind_proxy}\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $remote_addr;\n    proxy_set_header X-Forwarded-Proto https;\n  }\n}\n```\n'},{path:"setup/overview",content:"---\ntitle: Overview\nurl: /setup/overview/\n---\n\n### Try out SonarQube\nTo try out the SonarQube platform, follow the [Try Out SonarQube](/setup/get-started-2-minutes/) guide.\n\n### Install a production instance\nTo install a production instance, read the [Requirements](/requirements/requirements/), and then follow the [Installation Guide](/setup/install-server/).\n\n### After the installation\nAfter your server is up and running, you'll need to install one or more [SonarScanners](https://docs.sonarqube.org/display/SCAN) on the machines where analysis will be performed.\n\n### Upgrade your production instance\nTo upgrade your production instance, read the [Upgrade Guide](/setup/upgrading/) and the relevant, version-specific upgrade notes."},{path:"setup/sonar-properties",content:'---\ntitle: Environment Variables\nurl: /setup/environment-variables/\n---\n\nThis page provides environment variables used for configuring SonarQube with Docker. The values provided in the following environment variables are the default values.\n\n## Database\n\n[[info]]\n|- The embedded H2 database is used by default. It is recommended for tests but not for production use. Supported databases are Oracle, PostgreSQL, and Microsoft SQLServer.\n|- Changes to the database connection URL (sonar.jdbc.url) can affect SonarSource licensed products.\n\n### User Credentials\n\n**`SONAR_JDBC_USERNAME=`**  \n**`SONAR_JDBC_PASSWORD=`**  \nPermissions to create tables, indices, and triggers must be granted to JDBC user. The schema must be created first.  \n\n### Embedded Database (default)\n\n**`SONAR_EMBEDDEDDATABASE_PORT=9092`**  \nH2 embedded database server listening port, defaults to 9092.  \n\n### Oracle 12c/18c/19c\n\n**`SONAR_JDBC_URL=jdbc:oracle:thin:@localhost:1521/XE`**  \nThe Oracle JDBC driver must be copied into the directory extensions/jdbc-driver/oracle/. Only the thin client is supported, and we recommend using the latest Oracle JDBC driver. See https://jira.sonarsource.com/browse/SONAR-9758 for more details. If you need to set the schema, please refer to http://jira.sonarsource.com/browse/SONAR-5000.\n\n### PostgreSQL 9.6 or greater\n\n**`SONAR_JDBC_URL=jdbc:postgresql://localhost/sonarqube?currentSchema=my_schema`**  \nBy default the schema named "public" is used. It can be overridden with the parameter "currentSchema".\n\n### Microsoft SQLServer 2014/2016/2017/2019 and SQL Azure\n\n**`SONAR_JDBC_URL=jdbc:sqlserver://localhost;databaseName=sonar;integratedSecurity=true`**  \nA database named sonar must exist and its collation must be case-sensitive (CS) and accent-sensitive (AS). Use this connection string if you want to use integrated security with Microsoft Sql Server. Do not set the `SONAR_JDBC_USERNAME` or `SONAR_JDBC_PASSWORD` property if you are using Integrated Security. \n\nFor Integrated Security to work, you have to download the Microsoft SQL JDBC Driver 9.2.0 package [here](https://docs.microsoft.com/en-us/sql/connect/jdbc/release-notes-for-the-jdbc-driver?view=sql-server-ver15#92) and copy mssql-jdbc_auth-9.2.0.x64.dll to your path.\n\n**`SONAR_JDBC_URL=jdbc:sqlserver://localhost;databaseName=sonar`**  \nUse this connection string if you want to use SQL Auth while connecting to MS Sql Server. Set the `SONAR_JDBC_USERNAME` and `SONAR_JDBC_PASSWORD` appropriately.\n\n### Connection pool settings\n\n**`SONAR_JDBC_MAXACTIVE=60`**   \nThe maximum number of active connections that can be allocated at the same time, or negative for no limit. The recommended value is 1.2 * max sizes of HTTP pools. For example, if HTTP ports are enabled with default sizes (50, see property `sonar.web.http.maxThreads`) then `SONAR_JDBC_MAXACTIVE` should be 1.2 * 50 = 60.\n\n**`SONAR_JDBC_MAXIDLE=5`**  \nThe maximum number of connections that can remain idle in the pool, without extra ones being released, or negative for no limit.\n\n**`SONAR_JDBC_MINIDLE=2`**  \nThe minimum number of connections that can remain idle in the pool, without extra ones being created, or zero to create none.\n\n**`SONAR_JDBC_MAXWAIT=5000`**  \nThe maximum number of milliseconds that the pool will wait (when there are no available connections) for a connection to be returned before throwing an exception, or <= 0 to wait indefinitely.\n\n**`SONAR_JDBC_MINEVICTABLEIDLETIMEMILLIS=600000`**  \n**`SONAR_JDBC_TIMEBETWEENEVICTIONRUNSMILLIS=30000`**\n\n## Web Server\n\n**`SONAR_WEB_JAVAOPTS=@webJavaOpts@`**  \nthe web server is executed in a dedicated Java process. By default, heap size is @webDefaultHeapSize@. Use this property to customize JVM options.\n\n[[info]]\n| The HotSpot Server VM is recommended. The property -server should be added if server mode\n| is not enabled by default on your environment. See [here](http://docs.oracle.com/javase/8/docs/technotes/guides/vm/server-class.html).\n|\n| Startup can be long if the entropy source is short of entropy. Adding\n| -Djava.security.egd=file:/dev/./urandom is an option to resolve the problem. See [Here](https://cwiki.apache.org/confluence/display/TOMCAT/HowTo+FasterStartUp#HowToFasterStartUp-EntropySource)\n\n**`SONAR_WEB_JAVAADDITIONALOPTS=`**  \nSame as previous property, but allows to not repeat all other settings like -Xmx\n\n**`SONAR_WEB_HOST=0.0.0.0`**  \nBinding IP address. For servers with more than one IP address, this property specifies which address will be used for listening on the specified ports. By default, ports will be used on all IP addresses associated with the server.\n\n**`SONAR_WEB_CONTEXT=`**\nWeb context. When set, it must start with a forward slash (for example /sonarqube).\nThe default value is root context (empty value).\n\n**`SONAR_WEB_PORT=9000`**  \nTCP port for incoming HTTP connections. Default value is 9000.\n\n**`SONAR_WEB_HTTP_MAXTHREADS=50`**  \nThe maximum number of connections that the server will accept and process at any given time. When this number has been reached, the server will not accept any more connections until the number of connections falls below this value. The operating system may still accept connections based on the `SONAR_WEB_CONNECTIONS_ACCEPTCOUNT` property. The default value is 50.\n\n**`SONAR_WEB_HTTP_MINTHREADS=5`**  \nThe minimum number of threads always kept running. The default value is 5.\n\n**`SONAR_WEB_HTTP_ACCEPTCOUNT=25`**  \nThe maximum queue length for incoming connection requests when all possible request processing threads are in use. Any requests received when the queue is full will be refused. The default value is 25.\n\n**`SONAR_AUTH_JWTBASE64HS256SECRET=`**  \nBy default users are logged out and sessions closed when server is restarted. If you prefer keeping user sessions open, a secret should be defined. Value is HS256 key encoded with base64. It must be unique for each installation of SonarQube. Example of command-line:  \necho -n "type_what_you_want" | openssl dgst -sha256 -hmac "key" -binary | base64\n\n**`SONAR_WEB_SESSIONTIMEOUTINMINUTES=4320`**  \nThe inactivity timeout duration of user sessions, in minutes. After the configured period of time, the user is logged out. The default value is set to 3 days (4320 minutes) and cannot be greater than 3 months. Value must be strictly positive.\n\n**`SONAR_WEB_SYSTEMPASSCODE=`**  \nA passcode can be defined to access some web services from monitoring tools without having to use the credentials of a system administrator. Check the Web API documentation to know which web services are supporting this authentication mode. The passcode should be provided in HTTP requests with the header "X-Sonar-Passcode". By default feature is disabled.\n\n## SSO Authentication\n\n**`SONAR_WEB_SSO_ENABLE=false`**  \nEnable authentication using HTTP headers  \n\n**`SONAR_WEB_SSO_LOGINHEADER=X-Forwarded-Login`**  \nName of the header to get the user login. Only alphanumeric, \'.\' and \'@\' characters are allowed  \n\n**`SONAR_WEB_SSO_NAMEHEADER=X-Forwarded-Name`**  \nName of the header to get the user name  \n\n**`SONAR_WEB_SSO_EMAILHEADER=X-Forwarded-Email`**  \nName of the header to get the user email (optional)  \n\n**`SONAR_WEB_SSO_GROUPSHEADER=X-Forwarded-Groups`**  \nName of the header to get the list of user groups, separated by comma (optional). If the SONAR_SSO_GROUPSHEADER is set, the user will belong to those groups if groups exist in SonarQube. If none of the provided groups exists in SonarQube, the user will only belong to the default group. Note that the default group will always be set.  \n \n**`SONAR_WEB_SSO_REFRESHINTERVALINMINUTES=5`**  \nInterval used to know when to refresh name, email, and groups. During this interval, if for instance the name of the user is changed in the header, it will only be updated after X minutes. \n\n## LDAP Configuration\n\n**`SONAR_SECURITY_REALM=LDAP`**  \nEnable the LDAP feature\n\n**`SONAR_AUTHENTICATOR_DOWNCASE=true`**  \nSet to true when connecting to a LDAP server using a case-insensitive setup.\n\n**`LDAP_URL=ldap://localhost:10389`**  \nURL of the LDAP server. Note that if you are using ldaps, then you should install the server certificate into the Java truststore.\n\n**`LDAP_BINDDN=cn=sonar,ou=users,o=mycompany`**  \nBind DN is the username of an LDAP user to connect (or bind) with. Leave this blank for anonymous access to the LDAP directory (optional)\n\n**`LDAP_BINDPASSWORD=secret`**  \nBind Password is the password of the user to connect with. Leave this blank for anonymous access to the LDAP directory (optional)\n\n**`LDAP_AUTHENTICATION=simple`**  \nPossible values: simple | CRAM-MD5 | DIGEST-MD5 | GSSAPI See http://java.sun.com/products/jndi/tutorial/ldap/security/auth.html (default: simple)\n\n**`LDAP_REALM=example.org`**  \nSee :\n  * http://java.sun.com/products/jndi/tutorial/ldap/security/digest.html\n  * http://java.sun.com/products/jndi/tutorial/ldap/security/crammd5.html\n(optional)\n\n**`LDAP_CONTEXTFACTORYCLASS=com.sun.jndi.ldap.LdapCtxFactory`**  \nContext factory class (optional)\n\n**`LDAP_STARTTLS=true`**  \nEnable usage of StartTLS (default : false)\n\n**`LDAP_FOLLOWREFERRALS=false`**\nFollow or not referrals. See http://docs.oracle.com/javase/jndi/tutorial/ldap/referral/jndi.html (default: true)\n\n### User Mapping\n\n**`LDAP_USER_BASEDN=cn=users,dc=example,dc=org`**  \nDistinguished Name (DN) of the root node in LDAP from which to search for users (mandatory)\n\n**`LDAP_USER_REQUEST=(&(objectClass=user)(sAMAccountName={login}))`**  \nLDAP user request. (default: (&(objectClass=inetOrgPerson)(uid={login})) )\n\n**`LDAP_USER_REALNAMEATTRIBUTE=name`**\nAttribute in LDAP defining the user’s real name. (default: cn)\n\n**`LDAP_USER_EMAILATTRIBUTE=email`**  \nAttribute in LDAP defining the user’s email. (default: mail)\n\n### Group Mapping\n\n**`LDAP_GROUP_BASEDN=cn=groups,dc=example,dc=org`**  \nDistinguished Name (DN) of the root node in LDAP from which to search for groups. (optional, default: empty)\n\n**`LDAP_GROUP_REQUEST=(&(objectClass=group)(member={dn}))`**  \nLDAP group request (default: (&(objectClass=groupOfUniqueNames)(uniqueMember={dn})) )\n\n**`LDAP_GROUP_IDATTRIBUTE=sAMAccountName`**  \nProperty used to specifiy the attribute to be used for returning the list of user groups in the compatibility mode. (default: cn)\n\n## Compute Engine\n\n**`SONAR_CE_JAVAOPTS=@ceJavaOpts@`**  \nThe Compute Engine is responsible for processing background tasks.\nCompute Engine is executed in a dedicated Java process. Default heap size is @ceDefaultHeapSize@.\nUse the following property to customize JVM options.\n\n[[info]]\n| The HotSpot Server VM is recommended. The property -server should be added if server mode\n| is not enabled by default on your environment:\n| http://docs.oracle.com/javase/8/docs/technotes/guides/vm/server-class.html\n\n**`SONAR_CE_JAVAADDITIONALOPTS=`**  \nSame as previous property, but allows to not repeat all other settings like -Xmx\n\n## Elasticsearch\n\nElasticsearch is used to facilitate fast and accurate information retrieval.\nIt is executed in a dedicated Java process. Default heap size is @searchDefaultHeapSize@.\n\n[[warning]]\n| Linux users on 64-bit systems, ensure Virtual Memory on your system is correctly configured for Elasticsearch to run properly (see [here](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/vm-max-map-count.html) for details).\n|\n| When SonarQube runs standalone, a warning such as the following may appear in logs/es.log:\n|     "max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]"\n|\n| When SonarQube runs as a cluster, however, Elasticsearch will refuse to start.\n\n**`SONAR_SEARCH_JAVAOPTS=@searchJavaOpts@`**  \nJVM options of Elasticsearch process\n\n**`SONAR_SEARCH_JAVAADDITIONALOPTS=`**  \nSame as previous property, but allows to not repeat all other settings like -Xmx\n\n**`SONAR_SEARCH_PORT=9001`**  \nElasticsearch port. Default is 9001. Use 0 to get a free port.\nAs a security precaution, should be blocked by a firewall and not exposed to the Internet.\n\n**`SONAR_SEARCH_HOST=`**  \nElasticsearch host. The search server will bind this address and the search client will connect to it.\nDefault is loopback address.\nAs a security precaution, should NOT be set to a publicly available address.\n\n## Update Center\n\n**`SONAR_UPDATECENTER_ACTIVATE=true`**  \nUpdate Center requires an internet connection to request https://update.sonarsource.org\nIt is enabled by default.\n\n**`HTTP_PROXYHOST=`**  \n**`HTTP_PROXYPORT=`**  \nHTTP proxy (default none)  \n\n**`HTTPS_PROXYHOST=`**  \n**`HTTPS_PROXYPORT=`**  \nHTTPS proxy (defaults are values of HTTP_PROXYHOST and HTTP_PROXYPORT)  \n  \n**`HTTP_AUTH_NTLM_DOMAIN=`**  \nNT domain name if NTLM proxy is used  \n\n**`SOCKSPROXYHOST=`**  \n**`SOCKSPROXYPORT=`**  \nSOCKS proxy (default none)  \n\n**`HTTP_PROXYUSER=`**  \n**`HTTP_PROXYPASSWORD=`**  \nProxy authentication (used for HTTP, HTTPS and SOCKS proxies)  \n  \n**`HTTP_NONPROXYHOSTS=`**  \nProxy exceptions: list of hosts that can be accessed without going through the proxy separated by the \'|\' character, wildcard character \'*\' can be used for pattern matching used for HTTP and HTTPS (default none) (note: localhost and its literal notations (127.0.0.1, ...) are always excluded).\n\n## Logging\n\nSonarQube produces logs in four logs files located in the same directory (see property `SONAR_PATH_LOGS` below),\none per process:\n* Main process (aka. App) logs in sonar.log\n* Web Server (aka. Web) logs in web.log\n* Compute Engine (aka. CE) logs in ce.log\n* Elasticsearch (aka. ES) logs in es.log\n\nAll four files follow the same rolling policy (see `SONAR_LOG_ROLLINGPOLICY` and `SONAR_LOG_MAXFILES`) but it applies\nindividually (eg. if `SONAR_LOG_MAXFILES=4`, there can be at most 4 of each files, ie. 16 files in total).\n\nAll four files have logs in the same format:\n\n|1|2|3|\n|----|----|-|--------------------|------------------------------|----|\n2016.11.16 16:47:00 INFO  ce[AVht0dNXFcyiYejytc3m][o.s.s.c.t.CeWorkerCallableImpl] Executed task | project=org.sonarqube:example-java-maven | type=REPORT |\n\n|4|5|6|\n|--------------------|----------------------|-------------|\n| id=AVht0dNXFcyiYejytc3m | submitter=admin | time=1699ms|\n\n**1**: timestamp. Format is YYYY.MM.DD HH:MM:SS  \n   YYYY: year on 4 digits  \n   MM: month on 2 digits  \n   DD: day on 2 digits  \n   HH: hour of day on 2 digits in 24 hours format  \n   MM: minutes on 2 digits  \n   SS: seconds on 2 digits  \n   \n**2**: log level.  \n   Possible values (in order of descending criticality): ERROR, WARN, INFO, DEBUG and TRACE  \n   \n**3**: process identifier. Possible values: app (main), web (Web Server), ce (Compute Engine) and es (Elasticsearch)  \n\n**4**: SQ thread identifier. Can be empty. In the Web Server, if present, it will be the HTTP request ID. In the Compute Engine, if present, it will be the task ID.\n   \n**5**: logger name. Usually a class canonical name. Package names are truncated to keep the whole field to 20 characters max\n   \n**6**: log payload. Content of this field does not follow any specific format, can vary in length and include line returns. Some logs, however, will follow the convention to provide data in payload in the format "| key=value"  Especially, log of profiled pieces of code will end with "| time=XXXXms".  \n\n**`SONAR_LOG_LEVEL=INFO`**  \nGlobal level of logs (applies to all 4 processes). Supported values are INFO (default), DEBUG and TRACE\n\n**`SONAR_LOG_LEVEL_APP=INFO`**  \n**`SONAR_LOG_LEVEL_WEB=INFO`**  \n**`SONAR_LOG_LEVEL_CE=INFO`**  \n**`SONAR_LOG_LEVEL_ES=INFO`**  \nLevel of logs of each process can be controlled individually with their respective properties. When specified, they overwrite the level defined at global level. Supported values are INFO, DEBUG and TRACE\n\n**`SONAR_PATH_LOGS=logs`**  \nPath to log files. Can be absolute or relative to installation directory. Default is <installation home>/logs\n\n**`SONAR_LOG_ROLLINGPOLICY=time:yyyy-MM-dd`**  \nRolling policy of log files:\n* based on time if value starts with "time:", for example by day ("time:yyyy-MM-dd") or by month ("time:yyyy-MM")  \n* based on size if value starts with "size:", for example "size:10MB"  \n* disabled if value is "none".  That needs logs to be managed by an external system like logrotate.  \n\n**`SONAR_LOG_MAXFILES=7`**  \nMaximum number of files to keep if a rolling policy is enabled.\n* maximum value is 20 on size rolling policy  \n* unlimited on time rolling policy. Set to zero to disable old file purging.\n\n**`SONAR_WEB_ACCESSLOGS_ENABLE=true`**\nAccess log is the list of all the HTTP requests received by server. If enabled, it is stored\nin the file {`SONAR_PATH_LOGS`}/access.log. This file follows the same rolling policy as other log file\n(see `SONAR_LOG_ROLLINGPOLICY` and `SONAR_LOG_MAXFILES`).\n\n**`SONAR_WEB_ACCESSLOGS_PATTERN=%i{X-Forwarded-For} %l %u [%t] "%r" %s %b "%i{Referer}" "%i{User-Agent}" "%reqAttribute{ID}"`**  \nFormat of access log. It is ignored if `SONAR_WEB_ACCESSLOGS_ENABLE=false`.   \n\nPossible values are:\n   - "common" is the Common Log Format, shortcut to: %h %l %u %user %date "%r" %s %b\n   - "combined" is another format widely recognized, shortcut to: %h %l %u [%t] "%r" %s %b "%i{Referer}" "%i{User-Agent}"\n   - else a custom pattern. See http://logback.qos.ch/manual/layouts.html#AccessPatternLayout.\n   \nThe login of authenticated user is not implemented with "%u" but with "%reqAttribute{LOGIN}" (since version 6.1).  \nThe value displayed for anonymous users is "-".  \n\nThe SonarQube\'s HTTP request ID can be added to the pattern with "%reqAttribute{ID}" (since version 6.2).  \n\nIf SonarQube is behind a reverse proxy, then the following value allows to display the correct remote IP address:\n\nDefault value (which was "combined" before version 6.2) is equivalent to "combined + SQ HTTP request ID":\n`SONAR_WEB_ACCESSLOGS_PATTERN=%h %l %u [%t] "%r" %s %b "%i{Referer}" "%i{User-Agent}" "%reqAttribute{ID}"`\n\n## DataCenter Edition\n\n**`SONAR_CLUSTER_NAME=sonarqube`**\n\nThe name of the cluster. Required if multiple clusters are present on the same network. For example, this prevents mixing Production and Preproduction clusters. This will be the name stored in the Hazelcast cluster and used as the name of the Elasticsearch cluster.\n\n**`SONAR_CLUSTER_SEARCH_HOSTS`**\n\nComma-delimited list of search hosts in the cluster. The list can contain either the host or the host and port, but not both. The item format is `ip/hostname` for host only or`ip/hostname:port` for host and port. `ip/hostname` can also be set to the service name of the search containers .\n\n### Search Nodes Only\n\n**`SONAR_CLUSTER_ES_HOSTS`**\n\nComma-delimited list of search hosts in the cluster. The list can contain either the host or the host and port but not both. The item format is `ip/hostname` for host only or`ip/hostname:port` for host and port, while `ip/hostname` can also be set to the service name of the search containers.\n\n**`SONAR_CLUSTER_NODE_NAME`**\n\nThe name of the node that is used on Elasticsearch and stored in Hazelcast member attribute (NODE_NAME)\n\n### Application Nodes Only\n\n**`SONAR_CLUSTER_HOSTS`**\n\nComma-delimited list of all **application** hosts in the cluster. This value must contain **only application hosts**. Each item in the list must contain the port if the default `SONAR_CLUSTER_NODE_PORT` value is not used. Item format is `ip/hostname`, `ip/hostname:port`. `ip/hostname` can also be set to the service name of the application containers.\n\n**`SONAR_CLUSTER_NODE_PORT`**\n\nThe Hazelcast port for communication with each application member of the cluster. Default: `9003`\n\n## Others\n\n**`SONAR_NOTIFICATIONS_DELAY=60`**  \nDelay in seconds between processing of notification queue. Default is 60 seconds.\n\n**`SONAR_PATH_DATA=data`**  \n**`SONAR_PATH_TEMP=temp`**  \nPaths to persistent data files (embedded database and search index) and temporary files. Can be absolute or relative to installation directory. Defaults are respectively <installation home>/data and <installation home>/temp\n\n**`SONAR_TELEMETRY_ENABLE=true`**\nTelemetry - Share anonymous SonarQube statistics. By sharing anonymous SonarQube statistics, you help us understand how SonarQube is used so we can improve the product to work even better for you. We don\'t collect source code or IP addresses. And we don\'t share the data with anyone else. To see an example of the data shared: login as a global administrator, call the WS api/system/info and check the Statistics field.\n\n## Development – only for developers\n[[warning]]\n| The following properties MUST NOT be used in production environments.\n\n**`SONAR_SEARCH_HTTPPORT=-1`**  \nElasticsearch HTTP connector\n'},{path:"setup/sonarqube-on-kubernetes",content:'---\ntitle: Deploy SonarQube on Kubernetes\nurl: /setup/sonarqube-on-kubernetes/\n---\n\n_Kubernetes Deployment is only available for Community, Developer, and Enterprise Editions._\n\n# Overview \n\nDeploying SonarQube on Kubernetes is still in the early phases. We\'ve only tested deployment with the following recommendations and constraints, and deployment has some limitations as documented below. \n\nYou can find the SonarQube Helm chart on [GitHub](https://github.com/SonarSource/helm-chart-sonarqube/tree/master/charts/sonarqube).\n\nYour feedback is welcome at [our community forum](https://community.sonarsource.com/).\n\n## Kubernetes Environment Recommendations\n\nWhen you want to operate SonarQube on Kubernetes, consider the following recommendations.\n\n### Prerequisites\n\n| Kubernetes Version  | Helm Chart Version | SonarQube Version |\n| -------- | ----------------------------- | ----------------- |\n| 1.19 | 1.0 | 8.9 |\n| 1.20 | 1.0 | 8.9 |\n| 1.21 | 1.0 | 8.9 |\n\n### Pod Security Policies\n\nThe following widely-used Pod Security Policies cannot be used in combination with SonarQube:\n* **[Privileged](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#privileged)** - The SonarQube images are currently intended to start as root in order to provision the PVC and drop to lower privileges after that.\n* **[ReadOnlyFileSystem](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems)** - SonarQube is doing some filesystem operations to the container filesystem in order to deploy the correct language analyzers and community plugins.\n* **[MustRunAsNonRoot](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#example-policies)** - There is a init container that needs to run privileged to ensure that the [Elasticsearch requirements](/requirements/requirements/) to the specific node are fulfilled.\n\n### Taints and Tolerations\n\nWe recommend binding SonarQube to a specific node and reserving this node for SonarQube. It greatly increases the stability of the service.\nThe following sections detail creating a taint on a specific node and letting the SonarQube deployment ignore this taint using a flag in the `values.yaml` of the Helm Chart.\n\n#### Creating a taint\n\nIn order to create a taint, you need to select a node that you want to reserve for SonarQube. Use the following command to get a list of all nodes attached to your Kubernetes Cluster:\n\n```bash\nkubectl get nodes\n```\n\nSelect a node from the output of this command, and create a custom taint using the following command: \n\n```bash\nkubectl taint nodes <node> sonarqube=true:NoSchedule\n```\n\nThis taint ensures that no additional pods are scheduled on this node.\n\n#### Ignoring this Taint for SonarQube\n\nTo let the SonarQube deployment ignore the previously created taint, add the following section to the `values.yaml`:\n\n```yaml\ntolerations: \n  - key: "sonarqube"\n    operator: "Equal"\n    value: "true"\n    effect: "NoSchedule"\n```\nDepending on your taint\'s name, you may need to adjust the key accordingly.\n\n### Node Labels\n\nAs described in the **Taints and Tolerations** section above, for stability, we recommend binding the SonarQube deployment to one node in your cluster. With one node now reserved for SonarQube, you need to label this node to be selected by the Kube-scheduler in the pod assignment.\n\n#### Label a Node\n\nLabel the node for which you previously defined a taint with the following command:\n\n```bash\nkubectl label node <node> sonarqube=true\n```\n\n#### Bind Deployment to Label\n\nTo only let SonarQube be scheduled on nodes with this specific label, add the following section to the `values.yaml`:\n\n```yaml\nnodeSelector: \n  sonarqube: "true"\n```\n\nBy combining node selection with taints and tolerations, SonarQube can run alone on one specific node independently from the rest of your software in your Kubernetes cluster. This results in better stability and performance of SonarQube. \nFor more information, see the official [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/).\n\n### Affinity\n\nNode affinity and anti-affinity can be used in a way similar to node selectors but with more operators to choose from. However, we generally don’t recommend using this in combination with SonarQube as it can lead to recurring rescheduling of the SonarQube pod. \nIf you still want to use affinity and anti-affinity, see the official [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity). \n\n## Helm chart specifics\n\nWe try to provide a good default with the Helm chart, but there are some points to consider while working with SonarQube on Kubernetes. Please read the following sections carefully to make the correct decisions for your environment.\n\n### Installation\n\nCurrently only helm3 is supported.\n\nTo install the Helm Chart from our Helm Repository, you can use the following commands:\n\n```bash \nhelm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube\nhelm repo update\nkubectl create namespace sonarqube-lts\nhelm upgrade --install -n sonarqube-lts sonarqube sonarqube/sonarqube-lts\n```\n\n### Persistency \n\nSonarQube comes with a bundled Elasticsearch and, as Elasticsearch is stateful, so is SonarQube. There is an option to persist the Elasticsearch indexes in a Persistent Volume, but with regular killing operations by the Kubernetes Cluster, these indexes can be corrupted. By default, persistency is disabled in the Helm chart.  \nEnabling persistency decreases the startup time of the SonarQube Pod significantly, but you are risking corrupting your Elasticsearch index. You can enable persistency by adding the following to the `values.yaml`:\n\n```yaml\npersistence:\n  enabled: true\n```\n\nLeaving persistency disabled results in a longer startup time until SonarQube is fully available, but you won\'t lose any data as SonarQube will persist all data in the database.\n\n### Custom Certificate\n\nWhen you\'re working with your own CA or in an environment that uses self-signed certificates for your code repository platform, you can create a secret containing this certificate and add this certificate to the java truststore inside the SonarQube deployment directly during the deployment.\n\nTo enable this behavior, add the following to your `value.yaml` file:\n\n```yaml\ncaCerts:\n  secret: <secret name>\n```\n\n#### Get Certificate via openssl\n\nIf you already have a running installation of your code repository platform, you can extract the certificate with the following snippet using `openssl`\n\n```bash\necho -n | openssl s_client -connect <server url>:443 | sed -ne \'/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p\' > cert.pem\n```\n\nThis certificate needs to be Base64 encoded in order to be added as secret data.  \n\n```bash\nCreate base64 string\ncat cert.pem | base64 | tr -d "\\n"\n```\n\nNote that you can also use `string-data` here if you don\'t want to encode your certificate.\n\n#### Create secret\n\nThe Base64 encoded certificate can be added to the secret\'s data:\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: <secret name>\n  namespace: <sonarqube namespace>\ndata:\n  cert: <base64 string>\n```\n\nThen, create the secret in your Kubernetes cluster with the following command:\n\n```bash\nkubectl apply -f secret.yaml\n```\n\n### Ingress Creation\n\nTo make the SonarQube service accessible from outside of your cluster, you most likely need an ingress. Creating a new ingress is also covered by the Helm chart. See the following section for help with creating one.\n\n#### Ingress Class\n\nThe SonarSource Helm chart has an optional dependency to the [NGINX-ingress helm chart](https://kubernetes.github.io/ingress-nginx). If you already have NGINX-ingress present in your cluster, you can use it. \n\nIf you want to install NGINX as well, add the following to your `values.yaml`.\n\n```yaml\nnginx:\n  enabled: true\n```\n\nWe recommend using the `ingress-class` NGINX with a body size of at least 8MB. This can be achieved with the following changes to your `values.yaml`:\n\n```yaml\ningress:\n  enabled: true\n  # Used to create an Ingress record.\n  hosts:\n    - name: <Your Sonarqube FQDN>\n      # Different clouds or configurations might need /* as the default path\n      path: /\n      # For additional control over serviceName and servicePort\n      # serviceName: someService\n      # servicePort: somePort\n  annotations: \n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/proxy-body-size: "8m"\n```\n\n### Other Configuration Options\n\nWhile we only document the most pressing Helm chart customizations in this documentation, there are other possibilities for you to choose to [Customize the Chart Before Installing](https://helm.sh/docs/intro/using_helm/#customizing-the-chart-before-installing). Please see the Helm chart [README](https://github.com/SonarSource/helm-chart-sonarqube/tree/master/charts/sonarqube) file for more information on these.\n\n## Known Limitations\n\nAs SonarQube is intended to be run anywhere, there are some drawbacks that are currently known when operating in Kubernetes. This list is not comprehensive, but something to keep in mind and points for us to improve on.\n\n### No Sidecar Support\n\nThere is currently no support for additional sidecar containers and, as a result, there is no support for log collection. SonarQube will print the main application log to stdout, but logs on the web, ce, or search component will be printed to separate file streams inside the container.\nIf you want to use a sidecar container with the SonarQube deployment, you have to manually alter the deployment.\n### No Log Complete Collection \n\nAs previously mentioned, there\'s currently no support for a log collection to make SonarQube observable. Logs are printed to separate file streams as plaintext.\nIf you still want to scrape these logs, you will need to manually alter the deployment to read these 4 file streams and send them to your log collection solution manually.\n### Readiness and Startup delays\n\nWhen persistence is disabled, SonarQube startup takes significantly longer as the Elasticsearch indexes need to be rebuilt. As this delay depends on the amount of data in your SonarQube instance, the values for the startup/readiness and liveness probes need to be adjusted to your environment. \nWe also recommend taking a look at the default limits for the SonarQube deployment as the amount of CPU available to SonarQube also impacts the startup time.\n\n### Problems with Azure Fileshare PVC\n\nCurrently, there is a known limitation when working on AKS that resonates around the use of Azure Fileshare. We recommend using another storage class for persistency on AKS.\n\n### Monitoring\n\nCurrently, no cloud-native monitoring solutions play nicely with SonarQube or are supported by SonarSource. It is, however, possible to expose at least the JMX metrics to Prometheus with the help of the Prometheus JMX exporter.\nTo use this option, set the following values in your `values.yaml` file:\n\n```yaml\nprometheusExporter:\n  enabled: true\n  config:\n    rules:\n      - pattern: ".*"\n```\n\nThis downloads the Prometheus JMX exporter agent and adds it to the startup options of SonarQube. With this default configuration, the JMX metrics will be exposed on /metrics for Prometheus to scrape.\n\nThe config scope here defines a configuration that is understandable by the Prometheus JMX exporter. For more information, please see the [documentation](https://github.com/prometheus/jmx_exporter).\n'},{path:"setup/troubleshooting",content:"---\ntitle: Troubleshooting\nurl: /setup/troubleshooting/\n---\n\n## Checking the logs\n\nIf you're having trouble starting your server for the first time (or any subsequent time!) the first thing to do is check your server logs. You'll find them in `$SONARQUBE_HOME/logs`:\n\n* sonar.log - Log for the main process. Holds general information about startup and shutdown. You'll get overall status here but not details. Look to the other logs for that.\n* web.log - Information about initial connection to the database, database migration and reindexing, and the processing of HTTP requests. This includes database and search engine logs related to those requests.\n* ce.log - Information about background task processing and the database and search engine logs related to those tasks.\n* es.log - Ops information from the search engine, such as Elasticsearch startup, health status changes, cluster-, node- and index-level operations, etc.\n\n## Understanding the logs\n\nWhen there's an error, you'll very often find a stacktrace in the logs. If you're not familiar stacktraces, they can be intimidatingly tall walls of incomprehensible text. As a sample, here's a fairly short one:\n\n```\njava.lang.IllegalStateException: Unable to blame file **/**/foo.java\n    at org.sonarsource.scm.git.JGitBlameCommand.blame(JGitBlameCommand.java:128)\n    at org.sonarsource.scm.git.JGitBlameCommand.access$000(JGitBlameCommand.java:44)\n    at org.sonarsource.scm.git.JGitBlameCommand$1.call(JGitBlameCommand.java:112)\n    at org.sonarsource.scm.git.JGitBlameCommand$1.call(JGitBlameCommand.java:109)\n    at java.util.concurrent.FutureTask.run(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    at java.lang.Thread.run(Unknown Source)\nCaused by: java.lang.NullPointerException\n    at org.eclipse.jgit.treewalk.filter.PathFilter.create(PathFilter.java:77)\n    at org.eclipse.jgit.blame.BlameGenerator.<init>(BlameGenerator.java:161)\n    at org.eclipse.jgit.api.BlameCommand.call(BlameCommand.java:203)\n    at org.sonarsource.scm.git.JGitBlameCommand.blame(JGitBlameCommand.java:126)\n    ... 7 more\n```\n\nUnless you wrote the code that produced this error, you really only care about:\n* the first line, which ought to have a human-readable message after the colon. In this case, it's Unable to blame file `**/**/foo.java`\n* and any line that starts with `Caused by:`. There are often several `Caused by` lines, and indentation makes them easy to find as you scroll through the error. Be sure to read each of these lines. Very often one of them - the last one or next to last one - contains the real problem.\n\n## Recovering from Elasticsearch read-only indices\n\nYou may encounter issues with Elasticsearch (ES) indices becoming locked in read-only mode. ES requires free disk space available and implements a safety mechanism to prevent the disk from being flooded with index data that:\n\n* **For non-DCE** –  locks all indices in read-only mode when the 95% used disk usage watermark is reached.  \n* **For DCE** – locks all or some indices in read-only mode when one or more node reaches the 95% used disk usage watermark.\n\nES shows warnings in the logs as soon as disk usage reaches 85% and 90%. At 95% usage and above, indices turning read-only causes errors in the web and compute engine.\n\nFreeing disk space will *not* automatically make the indices return to read-write. To make indices read-write, you also need to:\n\n* **For non-DCE** – restart SonarQube.\n* **For DCE** – restart *ALL* application nodes (the first application node restarted after all have been stopped will make the indices read-write).  \n\nSonarQube's built-in resilience mechanism allows SonarQube to eventually recover from the indices being behind data in the DB (this process can take a while).\n\nIf you still have inconsistencies, you'll need to rebuild the indices (this operation can take a long time depending on the number of issues and components):\n\n**non-DCE:**  \n\n1. Stop SonarQube  \n1. Delete the data/es7 directory  \n1. Restart SonarQube  \n\n**DCE:**  \n\n1. Stop the whole cluster (ES and application nodes)  \n1. Delete the data/es7 directory on each ES node  \n1. Restart the whole cluster  \n    \n**Note:** See [Configure & Operate a Cluster](/setup/operate-cluster/) for information on stopping and starting a cluster.\n\n## Failed tasks during reindexing\n\nDuring Elasticsearch reindexing due to disaster recovery or an upgrade, you may have a failed tasks in your branches or Pull Requests. If you only have a few failed tasks, you can reanalyze your branch or Pull Request. You may want to use web services to remove branches and Pull Requests that can't be reanalyzed because they have been removed from version control. If you have many failed tasks, you may want to delete your Elasticsearch directory and reindex again. To delete your Elasticsearch directory:\n\n**non-DCE:**  \n\n1. Stop SonarQube  \n1. Delete the data/es6 directory  \n1. Restart SonarQube  \n\n**DCE:**  \n\n1. Stop the whole cluster (ES and application nodes)  \n1. Delete the data/es6 directory on each ES node  \n1. Restart the whole cluster  \n"},{path:"setup/upgrade-notes",content:'---\ntitle: Release Upgrade Notes\nurl: /setup/upgrade-notes/\n---\n\nUpgrading directly from SonarQube _v7.9 LTS_? Refer to the [LTS to LTS Release Upgrade Notes](/setup/lts-to-lts-upgrade-notes/).\n\n## Release 8.9 LTS Upgrade Notes  \n**GitHub Enterprise compatibility**  \nSonarQube 8.9 only supports GitHub Enterprise 2.21+ for pull request decoration (the previous minimum version was 2.15).\n\n**Plugins require risk consent**  \nWhen upgrading, if you\'re using plugins, a SonarQube administrator needs to acknowledge the risk involved with plugin installation when prompted in SonarQube. ([MMF-2301](https://jira.sonarsource.com/browse/MMF-2301)).\n\n**Database support updated**  \nSonarQube 8.9 supports the following database versions:\n\n* PostgreSQL versions 9.6 to 13. PostgreSQL versions <9.6 are no longer supported.\n* MSSQL Server 2014, 2016, 2017, and 2019.\n* Oracle XE, 12C, 18C, and 19C. Oracle 11G is no longer supported.\n\n**Webhooks aren\'t allowed to target the instance**  \nTo improve security, webhooks, by default, aren\'t allowed to point to the SonarQube server. You can change this behavior in the configuration. ([SONAR-14682](https://jira.sonarsource.com/browse/SONAR-14682)).\n\n[Full release notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=16710)\n\n## Release 8.8 Upgrade Notes  \n**CSS analysis now requires Node.js 10+**  \nIn order to analyze CSS code, you now need to have Node.js 10+ installed on the machine running the scan.\n\n**Deprecated web services have been dropped**  \nWeb services that were deprecated in 6.x versions have been dropped. ([SONAR-13848](https://jira.sonarsource.com/browse/SONAR-13848)).\n\n**JavaScript security analysis can take longer**  \nThe JavaScript security analysis in commercial editions has been overhauled for far better accuracy. This overhaul results in an expected increase in memory requirement for analysis. Additionally, there is an impact on the duration of JavaScript taint analysis which can be significant for some projects. \n\n[Full release notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=16674)  \n\n## Release 8.7 Upgrade Notes  \n**JavaScript and TypeScript analysis now requires Node.js 10+**  \nIn order to analyze JavaScript or TypeScript code, you now need to have Node.js 10+ installed on the machine running the scan.\n\n**Azure DevOps Services and Bitbucket Cloud are now supported**  \nSonarQube now officially supports Azure DevOps Services and Bitbucket Cloud. If you were running analysis using Bitbucket Pipelines previously, when you upgrade, the Main branch name in your SonarQube project needs to match the branch name in your code repository to continue writing history to the branch. You may have to rename it before running analysis again.\n\n**Microsoft SQL Server and Integrated Authentication**  \nIf you are using Microsoft SQL Server with Integrated Authentication, you will need to replace the `sqljdbc_auth.dll` file on your `PATH` with `mssql-jdbc_auth-9.2.0.x64.dll` from the [Microsoft SQL JDBC Driver 9.2.0 package](https://docs.microsoft.com/en-us/sql/connect/jdbc/release-notes-for-the-jdbc-driver?view=sql-server-ver15#92). See [Install the Server](/setup/install-server/) for more information.\n\n[Full release notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=16540)  \n\n## Release 8.6 Upgrade Notes  \n**Elasticsearch update and change in cluster configuration**  \nFor non-DCE editions, the Elasticsearch upgrade doesn\'t change the configuration. SonarQube automatically binds to the loopback address an additional Elasticsearch port which can be configured optionally.  \n\nWhen running a cluster with Data Center Edition, the configuration of search nodes has changed. The old search properties will now fail. You need to configure two new sets of properties. See [Configure and Operate a Cluster](/setup/operate-cluster/) for more information.  \n\nWe recommend only giving external access to the application nodes and to the main port. ([SONAR-12686](https://jira.sonarsource.com/browse/SONAR-12686)).\n\n**Default Authentication and Administrator credentials**  \nOn a fresh install to avoid misconfiguration and related security risks, authentication is now required by default, and you need to change the default password for the administrator account. \nWhen upgrading, if you were still using default credentials, you\'ll be asked to change the password the next time you authenticate with the admin account. ([MMF-1352](https://jira.sonarsource.com/browse/MMF-1352), [MMF-2146](https://jira.sonarsource.com/browse/MMF-2146)).\n\n[Full release notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=16435)  \n\n## Release 8.5 Upgrade Notes  \n**GitHub Enterprise compatibility**  \nSonarQube 8.5 only supports GitHub Enterprise 2.15+ for pull request decoration (the previous minimum version was 2.14).\n\n**SonarScanner for MSBuild compatibility**  \nAnalyzing a C# / VB.NET solution in SonarQube 8.5 requires SonarScanner for MSBuild 4.0+.\n\n**Upgrade simplified: Languages, GIT and SVN support now built-in**  \nLanguages provided with your edition and support for GIT and SVN version control are now built-in and don’t require plugins. If you were using these plugins, you need to remove them from SonarQube before upgrading. ([MMF-2042](https://jira.sonarsource.com/browse/MMF-2042)).\n\n[Full release notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=16342)\n\n## Release 8.4 Upgrade Notes  \n**Updated system settings recommendations**  \nIn previous versions, the recommended limits regarding threads, file descriptors, and vm.max_map_count were taken from Elasticsearch dependencies. This release can reach these limits occasionally, so we recommend increasing the following settings of your OS when upgrading:\n\n* `vm.max_map_` count is greater than or equal to 524288\n* `fs.file-max` is greater than or equal to 131072\n* the user running SonarQube can open at least 131072 file descriptors\n* the user running SonarQube can open at least 8192 threads\n\nFor more information, see the [Requirements](/requirements/requirements/) documentation. \n\n**Project, Application, and Portfolio availability when rebuilding Elasticsearch indexes**  \nFrom now on if your upgrade requires the rebuild of Elasticsearch indexes, your projects and Applications will become available as they are reindexed. Portfolios won\'t be available until all projects are reindexed. ([MMF-2010](https://jira.sonarsource.com/browse/MMF-2010)).\n\n**Additionnal SAML checks**  \nSAML authentication adds additional checks for validating SAML responses from the identity provider. This could reveal a non-standard configuration that needs to be updated. Information will appear in the logs upon a failed login attempt in the event that the configuration needs to be tweaked.\n\n**Changes in web services and plugin APIs**  \nThe format of several IDs exposed in web services changed and their use is deprecated. See [SONAR-13248](https://jira.sonarsource.com/browse/SONAR-13248), [SONAR-13249](https://jira.sonarsource.com/browse/SONAR-13249), and [SONAR-13300](https://jira.sonarsource.com/browse/SONAR-13300).  \nA related change is introduced in a plugin API method. See [SONAR-13420](https://jira.sonarsource.com/browse/SONAR-13420).\n\n[Full release notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=15833)\n\n## Release 8.3 Upgrade Notes  \n**Security Hotspots in the built-in Quality Gate**   \nWe\'ve added a new condition to the built-in "Sonar way" Quality Gate to make sure all Security Hotspots on New Code are reviewed. The Quality Gate fails if the percentage of new Hotspots reviewed is less than 100%. ([MMF-1907](https://jira.sonarsource.com/browse/MMF-1907)).\n\n**Jenkins automatic branch and Pull Request detection**  \nWith [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) and [above](https://www.sonarsource.com/plans-and-pricing/), Scanners now automatically detect branches and Pull Requests in Jenkins Multibranch Pipelines. You no longer need to pass branch and Pull Request parameters. When upgrading from Community Edition or an old commercial edition version, the branch name in your SonarQube project needs to match the branch name in your code repository to continue writing history to the branch. Because SonarQube names the Main Branch "master" by default, you may have to rename it before running analysis again. See the [Jenkins CI Integration](/analysis/jenkins/) page for more information. ([MMF-1676](https://jira.sonarsource.com/browse/MMF-1676)).\n\n**Updated .NET code coverage**  \nThe code coverage for .NET projects now takes into account the branch/condition coverage in addition to the line coverage. The coverage of your projects may decrease to be closer to reality, and it can impact your Quality Gate. (See more details [here](https://community.sonarsource.com/t/c-vb-net-sonarqube-and-sonarcloud-support-branch-condition-coverage-data/22384)).\n\n**Analysis summary for GitHub Pull Requests**\n* Pull Request analysis can be shown under the Conversation tab in GitHub. You can enable or disable it at **Project Settings > General Settings > Pull Request Decoration**. \n* If you already have Pull Request analysis under the GitHub Checks tab, you\'ll need to update your GitHub App to give Pull Requests read & write access. For more information see [Pull Requests](/analysis/pull-request/). ([MMF-1892](https://jira.sonarsource.com/browse/MMF-1892)).\n\n**Applications on the Projects page**  \n[Applications](/user-guide/applications/) are now found on the Projects page. You can filter, favorite, and tag applications like you can with projects. ([MMF-1382](https://jira.sonarsource.com/browse/MMF-1382)).\n\n[Full Release Notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=15640)\n\n## Release 8.2 Upgrade Notes  \n**Security Hotspots: dedicated space and workflow**\n* The Security Hotspots have a brand new space where developers can perform security reviews. The review process has been simplified. It\'s no longer necessary to transform a Security Hotspot into a Manual Vulnerability and back. A developer can now simply mark a Security Hotspot as Safe, Fixed, or leave it as-is if more time is needed. ([MMF-1868](https://jira.sonarsource.com/browse/MMF-1868)).\n* Manual Vulnerabilities created from Security Hotspots are migrated to Security Hotspots with the status "To Review". A comment "Migrated from Manual Vulnerability" is added to the review history to recognize them.  \n* The formula to compute the Security Review Rating, which was previously only available at the portfolio level, has been updated to be more meaningful. Historical values for this indicator have been removed to avoid confusion. ([MMF-1890](https://jira.sonarsource.com/browse/MMF-1890)).\n* A Security Hotspots Reviewed metric has been added and is available to Quality Gates along with the Security Review Rating.\n\n**New project homepage**  \nThe project homepage has been redesigned to focus on New Code. ([MMF-1886](https://jira.sonarsource.com/browse/MMF-1886)). Projects details are now tucked into a new "Project information" pane. The project administration menu has been renamed "Project Settings".\n\n**Deprecated configuration**  \nThe old way of referencing environment variables in server configuration is deprecated and replaced with the support of default environment variables. ([SONAR-13113](https://jira.sonarsource.com/browse/SONAR-13113)).\n\n[Full Release Notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=15301)\n\n## Release 8.1 Upgrade Notes  \n**Short-lived and Long-lived branches are now just branches**  \nThe concept for branches is now simplified, with a single way to handle all of them. ([MMF-1786](https://jira.sonarsource.com/browse/MMF-1786)).\n* Analysis is the same for all branches. The parameter `sonar.branch.target` is no longer used and can be removed.\n* All branches behave as previous Long-lived branches: all measures are available. The New Code period is configurable and starts by default after the first analysis. The Quality Gate check applies on all conditions.\n* As a consequence, branches that were previously Short-Lived branches may display incomplete measures before they are analyzed again. With the first analysis, measures on New Code and the Quality Gate status may change.\n* New housekeeping settings replace the Long-lived branch pattern and allow you to choose the branches which should be kept when inactive.\n* Detection of new issues in branches and PRs is simplified. The list of issues reported as new may change slighlty. ([SONAR-12627](https://jira.sonarsource.com/browse/SONAR-12627)).\n\n**Configuration of Pull Request decoration**  \nThe configuration of Pull Request decoration changes. Previous settings are replaced by a new configuration in the UI. Also, decoration of Pull Requests now supports multiple instances of a same ALM provider in Enterprise Edition and above. ([MMF-1814](https://jira.sonarsource.com/browse/MMF-1814)).\n\n**Deprecated web services and parameters dropped**  \nSome Web services and parameters which were deprecated in 6.x versions have been dropped, including some related to Quality Profiles. See Full Release Notes for more info.\n\n[Full Release Notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=15243)\n\n\n## Release 8.0 Upgrade Notes  \n**GitHub, LDAP, and SAML authentication now built in**  \nGitHub, LDAP, and SAML authentication is now built in. If you were using the authentication plugins (sonar-ldap, sonar-auth-github, and sonar-auth-saml), you need to remove them from SonarQube before upgrading. ([SONAR-12471](https://jira.sonarsource.com/browse/SONAR-12471)).\n\n**GitLab Authentication now available**  \nGitLab OAuth2 authentication is now available in all editions. If you were using the community plugin, you need to remove it from SonarQube before upgrading. The configured variable of the plugin will be migrated, so the authentication will work without having to rewrite the configuration. Due to changes in group mapping, GitLab subgroups mapped using the community plugin will need to be renamed in SonarQube for the mapping to work. ([SONAR-12460](https://jira.sonarsource.com/browse/SONAR-12460)).\n\n**New Code Period values simplified**  \nIt\'s now easier to set your New Code Period in the UI. With the new settings, specific analysis has replaced setting the New Code Period to a specific date or version. If you were using a specific date or version for your New Code Period, now you\'ll need to use a specific analysis. See the [Setting Your New Code Period](/project-administration/new-code-period/) for more info. ([MMF-1579](https://jira.sonarsource.com/browse/MMF-1579)).  \n\n[Full Release Notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=14962)\n\n\n## Release 7.9.1 LTS Upgrade Notes  \n**Upgrade on Microsoft SQL Server fixed**  \nUpgrade failure and performance issues with Microsoft SQL Server have been fixed ([SONAR-12260](https://jira.sonarsource.com/browse/SONAR-12260), [SONAR-12251](https://jira.sonarsource.com/browse/SONAR-12251)).\n\n**Pylint execution on Windows fixed**  \nAutomatic execution of Pylint during python analysis on Windows has been fixed. Note that automatic execution of pylint during analysis remains deprecated on all OSes. ([SONAR-12274](https://jira.sonarsource.com/browse/SONAR-12274)).\n\n[Full Release Notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=15029)\n\n\n## Release 7.9 LTS Upgrade Notes  \n**Upgrade can fail on Microsoft SQL Server**  \nMigration from SonarQube v6.7.x to v7.9 fails on Microsoft SQL Server ([SONAR-12260](https://jira.sonarsource.com/browse/SONAR-12260)). \n\n**MySQL No Longer Supported**  \nSonarQube no longer supports MySQL. To migrate from MySQL to a supported database, see the free [MySQL Migrator tool](https://github.com/SonarSource/mysql-migrator).\n\n**Java 11 Required**  \nThe SonarQube server now requires Java 11. Analyses may continue to use Java 8 if necessary.\n\n**Pylint should be run manually**  \nRunning Pylint automatically during python analysis has been deprecated. Additionally, it is broken in this version on Windows. If needed, Pylint must be run ahead of time and the resulting report passed in to analysis. \n\n[Full Release Notes](https://jira.sonarsource.com/secure/ReleaseNote.jspa?projectId=10930&version=14945)\n'},{path:"setup/upgrading",content:"---\ntitle: Upgrade the Server\nurl: /setup/upgrading/\n---\n\n## SonarQube Version Number Format\nBefore upgrading, it helps to understand how SonarQube version numbers work. Version numbers have up to three digits with each digit representing part of the release cycle:\n\n![SonarQube version number format](/images/version.png)\n\n**Major version number**  \nThe major version number represents a series of releases with high-level objectives for the release cycle. It's incremented with the release following an LTS version (for example, the release following 7.9 LTS was 8.0).\n\n**Minor version number**  \nThe minor version number corresponds to incremental functional changes within a major release cycle. At the time of an LTS release, the release cycle is closed and the minor version number is frozen.\n\n**Patch release number**  \nOnly on LTS versions, the patch release number represents patches to an LTS that fixed blocker or critical problems. The patch release number isn't considered in your upgrade migration path, and your migration path is the same no matter which patch number you are on.\n\n## Migration Path\nUpgrading across multiple non-LTS versions is handled automatically. However, if there's one or multiple LTS versions in your migration path, you must first migrate to each intermediate LTS and then to your target version, as shown in **Example 3** below.\n\n[[info]]\n|If you're migrating from an earlier patch version of an LTS, you can upgrade directly to the next LTS. You don't need to install any intermediate patch versions.\n\n**Migration Path Examples**:\n\n**Example 1** – From 7.1 > 8.1, the migration path is 7.1 > 7.9.6 LTS > 8.1  \n**Example 2** – From 8.2 > 8.9 LTS, the migration path is 8.2 > the latest 8.9 LTS patch.  \n**Example 3** – From 6.7.7 LTS > 8.9 LTS, the migration path is 6.7.7 LTS > 7.9.6 LTS > the latest 8.9 LTS patch.\n\n## Upgrade Guide\n\nThis is a generic guide for upgrading across versions of SonarQube. Carefully read the [Release Upgrade Notes](/setup/upgrade-notes/) of your target version and of any intermediate version(s).\n\n[[warning]]\n| Before you start, back up your SonarQube Database. Upgrade problems are rare, but you'll want the backup if anything does happen.\n\n### Database disk usage recommendations\nDuring your upgrade, tables may be duplicated to speed up the migration process, and this could cause your database disk usage to double. Because of this, we recommend that your database disk usage is below 50% before starting a migration.\n\n### Upgrading from the ZIP file\n\n1. Download and unzip the SonarQube distribution of your edition in a fresh directory, let's say `$NEW_SONAR_HOME`\n2. Manually install additional plugins that are compatible with your version of SonarQube. Use the [Compatibility Matrix](https://docs.sonarqube.org/8.9/instance-administration/plugin-version-matrix/) to ensure that the versions you install are compatible with your server version. Simply copying plugins from the old server to the new is not recommended; incompatible or duplicate plugins could cause startup errors. Analysis of all languages provided by your edition is available by default without plugins.\n3. Update the contents of `sonar.properties` and `wrapper.conf` files (in `$NEW_SONAR_HOME/conf`) with the settings of the related files in the `$OLD_SONAR_HOME/conf` directory (web server URL, database, ldap settings, etc.). Do not copy-paste the old files.\nIf you are using the Oracle DB, copy its JDBC driver into `$NEW_SONAR_HOME/extensions/jdbc-driver/oracle`\n4. Stop your old SonarQube Server\n5. Start your new SonarQube Server\n6. Browse to `http://yourSonarQubeServerURL/setup` and follow the setup instructions\n7. Reanalyze your projects to get fresh data\n\n### Upgrading from the Docker image\n\n[[info]]\n| If you're upgrading with an Oracle database or you're using additional plugins, you can reuse your extensions volume from the previous version to avoid moving plugins or drivers. Use the [Compatibility Matrix](https://docs.sonarqube.org/8.9/instance-administration/plugin-version-matrix/) to ensure that your plugins are compatible with your version. Analysis of all languages provided by your edition is available by default without plugins.\n\nTo upgrade SonarQube using the Docker image:\n\n1. Stop and remove the existing SonarQube container (a restart from the UI is not enough as the environment variables are only evaluated during the first run, not during a restart):\n    \n\t```console\n\t$ docker stop <container_id>\n    $ docker rm <container_id>\n\t```\n\n2. Run docker:\n\n\t```bash\n\t$> docker run -d --name sonarqube \\\n\t\t-p 9000:9000 \\\n\t\t-e SONAR_JDBC_URL=... \\\n\t\t-e SONAR_JDBC_USERNAME=... \\\n\t\t-e SONAR_JDBC_PASSWORD=... \\\n\t\t-v sonarqube_data:/opt/sonarqube/data \\\n\t\t-v sonarqube_extensions:/opt/sonarqube/extensions \\\n\t\t-v sonarqube_logs:/opt/sonarqube/logs \\\n\t\t<image_name>\n\t```\n\n3. Go to `http://yourSonarQubeServerURL/setup` and follow the setup instructions.\n\n4. Reanalyze your projects to get fresh data.\n\n#### **From 8.9.x LTS to another 8.9.x LTS**\n\nNo specific Docker operations are needed, just use the new tag.\n\n## Edition Upgrade\nIf you're moving to a different edition within the same version (upgrade or downgrade) the steps are exactly the same as above, without the need to browse to `http://yourSonarQubeServerURL/setup` or reanalyze your projects.\n\n## Additional Information\n\n### Oracle Clean-up\n\nStarting with version 6.6, there's an additional step you may want to perform if you're using Oracle. On Oracle, the database columns to be dropped are now marked as UNUSED and are not physically dropped anymore. To reclaim disk space, Oracle administrators must drop these unused columns manually. The SQL request is `ALTER TABLE foo DROP UNUSED COLUMNS`. The relevant tables are listed in the system table `all_unused_col_tabs`.\n\n### Additional Database Maintenance\n\nWe recommend refreshing your database's statistics and rebuilding your database's indices once you've finished the technical upgrade, but before you reanalyze your projects.\n\nFor PostgreSQL, that means executing `VACUUM FULL`. According to the PostgreSQL documentation:\n\n```\nIn normal PostgreSQL operation, tuples that are deleted or obsoleted by an update are not physically removed from their table; they remain present until a VACUUM is done.\n```\n\n### Scanner Update\n\nWhen upgrading SonarQube, you should also make sure you’re using the latest versions of the SonarQube scanners to take advantage of features and fixes on the scanner side. Please check the documentation pages of the Scanners you use for the most recent version compatible with SonarQube and your build tools.\n\n### SonarQube as a Linux or Windows Service\n\nIf you use external configuration, such as a script or Windows Service to control your server, you'll need to update it to point to `$NEW_SONAR_HOME`.\n- For Linux it depends how you implemented the service\n- For Windows you can update your service by running:\n```\nsc config SonarQube binPath= \"\\\"$NEW_SONAR_HOME\\bin\\windows-x86-64\\wrapper.exe\\\" -s \\\"$NEW_SONAR_HOME\\conf\\wrapper.conf\\\"\"\n```\n\n### Rebuilding Indexes\nIf your upgrade requires the rebuild of Elasticsearch indexes, your projects and Applications will become available as they are reindexed. Portfolios won't be available until all projects are indexed.\n\n## Release Upgrade Notes\n\nUsually SonarQube releases come with some specific recommendations for upgrading from the previous version. You should read the upgrade notes for each version between your current version and the target version.\n"},{path:"sonarcloud/autoscan",content:'---\ntitle: AutoScan Beta Feature\nnav: AutoScan\nurl: /autoscan/\n---\n\nSonarCloud can autonomously scan your code, by simply reading it from your repository! We call that AutoScan.\n\n[[info]]\n| This is currently a Beta feature, with a limited scope and some caveats. Those limitations will be removed along the way.\n\n\n## Prerequisites\n\n* The first version of this Beta feature works only for GitHub repositories. \n* The automatic analysis can be activated only on projects which are bound to their remote repository. This implies that the the project was set up through the SonarCloud web interface by selecting a repository (i.e. not "manually").\n\n## What to expect\n\nOnce activated, SonarCloud will automatically analyze: \n* the default branch of the repository\n* the pull requests (PR)\n\nIt will take care of doing it whenever you push on your repository.\n\nThe following languages are currently supported: \n* ABAP\n* Apex\n* CSS\n* Flex\n* Go\n* HTML\n* JS\n* Kotlin\n* PHP\n* Python\n* Ruby\n* Scala\n* Swift\n* TypeScript\n* TSQL\n* XML\n\n## How to activate the feature?\n\nTo enable the automatic analysis, you need to add a `.sonarcloud.properties` file in your repository.\n\nIf you\'re starting from scratch:\n\n1. Do the [setup for your project](/#sonarcloud#/projects/create) (from the `+ > Analyze new project` top right menu)\n    * ![](/images/exclamation.svg) Remember that your project must absolutely be created by selecting a GitHub repository - otherwise it won\'t work.\n1. Once the setup is done on SonarCloud, you end up on the project home page which shows a tutorial. Ignore it and simply add a `.sonarcloud.properties` file in the base directory of your default branch or on a PR. \n1. After a while, the analysis results will be visible in SonarCloud (and your PR will be annotated with comments if you pushed the file on a PR)\n\nHere are the supported optional settings for the `.sonarcloud.properties` file:\n```\n# Path to sources\n#sonar.sources=.\n#sonar.exclusions=\n#sonar.inclusions=\n\n# Path to tests\n#sonar.tests=\n#sonar.test.exclusions=\n#sonar.test.inclusions=\n\n# Source encoding\n#sonar.sourceEncoding=UTF-8\n\n# Exclusions for copy-paste detection\n#sonar.cpd.exclusions=\n```\n\nNote that you can just push an empty `.sonarcloud.properties` file, this will work fine. In this case, every file in the repository will be considered as a source file.\n\n## Current limitations/caveats\n\n* There is no visual feedback (yet) in the UI when SonarCloud runs an analysis.\n* A consequence of the previous point is that if - for any reason, SonarCloud fails to successfully run the analysis, nothing will be displayed. In that case, just come on [the forum](https://community.sonarsource.com/tags/c/help/sc/autoscan) and ask a question, we\'ll monitor that closely.\n* Code coverage information is not supported\n* Import of external rule engine reports is not supported\n\n## Noteworthy\n\n* This Beta feature works for any project - public or private.\n* It can be activated with no extra cost.\n* Sources are cloned only during the analysis, and only when the `.sonarcloud.properties` file exists (i.e. when the feature is activated). The cloned repository is fully deleted at the end of the analysis, and SonarCloud does not keep a copy of it.\n* Non supported languages (Java, C#, VB.NET, C/C++, ObjectiveC) are not analyzed at all.\n\n## How to give feedback?\n\nCreate a new thread on the forum, under ["Get Help > SonarCloud"](https://community.sonarsource.com/tags/c/help/sc/autoscan), with the "autoscan" tag.\n\nWe\'d love to hear your feedback about this new upcoming feature, may it be about bugs, improvements, or anything you want to share with us!\n'},{path:"sonarcloud/integrations/bitbucketcloud-azurepipelines",content:"---\ntitle: Analyze your repository with Azure Pipelines\nnav: With Azure Pipelines\nurl: /integrations/bitbucketcloud/azure-pipelines/\n---\n\nIf you are analyzing .NET applications and want to benefit from the Azure DevOps / Pipelines experience and features, you have the possibility to setup a build pipeline, targeting your Bitbucket Cloud repository, and connected to SonarCloud.\n\n## Analyzing branches\n\nPlease be advised that the team where the Bitbucket Cloud repository is has to be bound to your SonarCloud organization in order to get this work.\n\n1. Install the SonarCloud extension for Azure DevOps in your Azure DevOps organization : [SonarCloud extension](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarcloud). You can have a look a [this chapter](https://docs.microsoft.com/en-us/labs/devops/sonarcloudlab/index?tutorial-step=1) of the global tutorial for Azure DevOps.\n\n2. Configure a new build pipeline (YAML or classic editor), targeting your Bitbucket Cloud repository. You will have to create a new service connection to that repository.\n\n3. Configure the Prepare SonarCloud configuration task just the way you will do for a regular Azure Git Repository.\n\n4. Go to the triggers tab of the pipeline configuration, click on the repository below `Continuous Integration` then click on `Enable continuous integration`, add a new branch filter with following configuration :\n   * Type : Include\n   * Branch specification : master\n\nWant to see how it is working ? Have a look at our [sample .NET project](https://bitbucket.org/sonarsource/sample-dotnet-project-azuredevops)\n\n## Analyzing pull requests\n\nPre-requisites :\n\n* Follow the initiation steps of Analyzing branches with Azure pipelines above.\n* Version 1.6.4+ of the Azure DevOps extension is needed.\n\nAs for branches, you can trigger an analysis for Pull requests with an Azure DevOps pipeline and get your PR decorated.\n\n1. On the Azure pipeline that will be used, click on the `Triggers` tab, then click on the repository below `Pull request validation`\n\n2. Click on `Enable pull request validation` then configure the proper branch filters.\n"},{path:"sonarcloud/integrations/bitbucketcloud-bitbucketpipelines",content:'---\ntitle: Analyze your repository with Bitbucket Pipelines\nnav: With Bitbucket Pipelines\nurl: /integrations/bitbucketcloud/bitbucket-pipelines/\n---\n\n## Analyzing branches\n\nOnce your project is created and initiated from the repository you selected:\n\n1. Generate a token to allow to publish analysis from Bitbucket Pipelines. To generate a token, follow the first step of the tutorial on the dashboard of the project, or go to your user security page.\n\n2. On Bitbucket Cloud, go to the "Settings > Pipelines > Account variables" page of your team, and add a new SONAR_TOKEN variable that contains the value of the SonarCloud token (something like `9ad01c85336b265406fa6554a9a681a4b281135f`).\n   * **Make sure that you click on the "Lock" icon to encrypt and hide this token.**\n\n3. Edit the `bitbucket-pipelines.yml` file of your repository to trigger the SonarCloud analysis.\n\nOnce those changes are pushed, Pipelines will automatically trigger analyses on the repository.\n\nYou can see our multiple sample projects to see how it is working :\n\n  * [Built with Gradle](https://bitbucket.org/sonarsource/sample-gradle-project)\n  * [Built with Maven](https://bitbucket.org/sonarsource/sample-maven-project)\n  * [Javascript project](https://bitbucket.org/sonarsource/sample-nodejs-project)\n\nIf you target a .NET application, see a [sample .NET project](https://bitbucket.org/sonarsource/sample-dotnet-project-azuredevops) built with Azure Pipelines\n\n## Analyzing pull requests\n\nIn order to trigger SonarCloud analysis on each pull request update, you have to supply the same command in the `pull-requests` section of `bitbucket-pipelines.yml` (check [Configure bitbucket-pipelines.yml](https://confluence.atlassian.com/bitbucket/configure-bitbucket-pipelines-yml-792298910.html#Configurebitbucket-pipelines.yml-ci_pull-requests) for more details about that section). Here is a sample configuration:\n```\npipelines:\n  ...\n  pull-requests:\n    feature/*:\n      - step:\n          script:\n            - mvn sonar:sonar\n  ...\n```\n\nIn order to avoid duplication between the different sections of your `bitbucket-pipelines.yml`, you can use [yaml anchors and aliases](https://confluence.atlassian.com/bitbucket/yaml-anchors-960154027.html).\n'},{path:"sonarcloud/integrations/bitbucketcloud",content:'---\ntitle: Get started with Bitbucket Cloud\nnav: Bitbucket Cloud\nurl: /integrations/bitbucketcloud/\n---\n\n## Sign up and set up your first project\n1. On the [login page](/#sonarcloud#/sessions/new), click on the "Log in with Bitbucket" button and connect to SonarCloud using your Bitbucket Cloud account.\n2. Click on "Analyze your code" and follow the path to set up a first project\n3. You will be asked to install the SonarCould application on your team or user account, which will allow you to \n  choose which repositories you want to analyze.\n\n## Analyzing your repository\n\n* [With Bitbucket Pipelines](/integrations/bitbucketcloud/bitbucket-pipelines/)\n* [With Azure Pipelines](/integrations/bitbucketcloud/azure-pipelines/), if you analyze .NET applications and want to benefit from Azure DevOps features.\n\n## Quality widget\n\nSonarCloud can provide a widget that shows the current quality metrics of your project directly on the repository\'s Overview page on Bitbucket Cloud.\n\nIf you want to see this widget, you can go to the "Settings > SonarCloud" page of your repository and check "Show repository overview widget".\n\n## FAQ\n\n**Do you have sample projects on Bitbucket Cloud?**\nYou can take a look at these various projects: [Sample projects analyzed on SonarCloud](https://bitbucket.org/account/user/sonarsource/projects/SAMPLES)\n\n**I don\'t see the widget with quality information whereas I configured everything**\nMake sure that your browser is not using some extensions like AdBlocks. They tend to break the integration of third-party applications in BitBucket Cloud.\n\n## Upcoming features and improvements\n\nThere are various areas in which you can expect new features and improvements:\n\n* Pull request decoration with inline comments to show the issues within the PR\n* Better and easier team onboarding\n* Automatic analysis (i.e. no need to configure anything from Pipelines)\n'},{path:"sonarcloud/integrations/github",content:'---\ntitle: Get started with GitHub.com\nnav: GitHub\nurl: /integrations/github/\n---\n\n## Sign up and set up your first project\n\n1. On the [login page](/#sonarcloud#/sessions/new), click on the "Log in with GitHub" button and connect to SonarCloud using your GitHub account.\n2. Click on "Analyze your code" and follow the path to set up a first project\n3. You will be asked to install the SonarCould application on your organization, which will allow you to choose which\n   repository you want to analyze.\n\n## Trigger analyses\n\nFor GitHub repositories, there are 2 ways to have your code analyzed:\n\n### ... with AutoScan\n\nWith AutoScan, SonarCloud will autonomously pull your code and scan your default branch and your pull requests.\nPlease read the ["AutoScan Beta Feature"](/autoscan/) documentation page to get the details.\n\n[[warning]]\n| This is currently a Beta feature which does not work for all languages and comes with limitations. \n\n### ... using your CI service\n\nIf AutoScan does not make sense yet for your repository, you need to configure your CI service to trigger the analysis.\n\n**If you are using Travis CI**, the SonarCloud Travis Add-on will make it easier to activate analyses:\n\n* Read the [guide to integrate with Travis CI](https://docs.travis-ci.com/user/sonarcloud/)\n* Check out the [various sample projects](https://github.com/SonarSource/sonarcloud_examples) (Java, TypeScript, C/C++, Go, ... etc) that are analyzed on SonarCloud on a frequent basis\n\n**If you are using another CI service**, you will need to read:\n\n* the ["Analyzing Source Code" overview page](/analysis/overview/)\n* the ["Branches" overview page](/branches/overview/)\n* the ["Pull Request Analysis" page](/analysis/pull-request/)\n\nHere is an example of configuration for pull requests when you are not on Travis CI and you need to configure your CI jobs:\n```\nsonar.pullrequest.base=master\nsonar.pullrequest.branch=feature/my-new-feature\nsonar.pullrequest.key=5\nsonar.pullrequest.provider=GitHub\nsonar.pullrequest.github.repository=my-company/my-repo\n```\n\n[[info]]\n| Pull request decoration works only if [the SonarCloud application](https://github.com/apps/sonarcloud) is installed on your GitHub organization(s) and configured to have acccess to the repositories.\n'},{path:"sonarcloud/integrations/vsts",content:'---\ntitle: Get started with Azure DevOps Services\nnav: Azure DevOps Services\nurl: /integrations/vsts/\n---\n\n[[info]]\n| This page is about Azure DevOps Services, formerly known as VSTS.\n\nYou can connect to SonarCloud using your Azure DevOps account. On the [login page](/#sonarcloud#/sessions/new), just click on the "Log in with Azure DevOps" button.\n\n[[warning]]\n| Only work and school Azure DevOps accounts are authorized to login on SonarCloud.\n\n## Install the SonarCloud Azure DevOps extension\n\nThe SonarCloud Azure DevOps extension brings everything you need to have your projects analyzed on SonarCloud \nvery quickly:\n* Integration with the Build definitions to easily trigger the analysis\n* Pull request decoration to get quick feedback on the code changes\n* Widget to have the overview quality of your projects inside Azure DevOps dashboards\n\nInstall [SonarCloud extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarcloud)by clicking on the "Get it free" button.\n\nThen follow the comprehensive [Microsoft lab on how to integrate Azure DevOps with SonarCloud](https://aka.ms/sonarcloudlab).\n\n## Quality Gate Status widget \n\nYou can monitor the Quality Gate status of your projects directly in your Azure DevOps dashboard. Follow these simple steps to configure your widget:\n\n1. Once the Azure DevOps extension is installed and your project has been successfully analyzed, go to one of your Azure DevOps dashboards (or create one). Click on the pen icon in the bottom right corner of the screen, and then on the "+" icon to add a widget. \n\n2. In the list of widgets, select the "Code Quality" one and then click on the "Add" button. An empty widget is added to your dashboard. \n\n3. You can then click on the widget\'s cogwheel icon to configure it.\n\n    * **For public projects:** you can simply select your project from the dropdown. A searchbar inside the dropdown will help you find it easily. Just select it and click on the "Save" button.\n\n    * **For private projects:** you\'ll have to log in using the links provided under the dropdown. Once logged in, your private projects will appear in the dropdown. Select the one you are interested in, and click on "Save".\n\n## FAQ\n\n1. Which kind of analysis scenario are supported for .Net projects ?\n\n    * Using Sonar Scanner for MSBuild, you can build multiple .Net projects / solutions between the "Prepare Analysis on SonarCloud" and "Run Analysis" tasks. You will have full support of Issues and Code Coverage on both branches and PR Analysis. Other kind of scenarios are not yet supported.'},{path:"sonarcloud/organizations/index",content:'---\ntitle: Organizations\nurl: /organizations/overview/\n---\n\n## Overview\n\nAn organization is a space where a team or a whole company can collaborate across many projects.\n\nAn organization consists of:\n\n- Projects, on which users collaborate\n- [Members](/organizations/manage-team/), who can have different permissions on the projects\n- [Quality Profiles](/instance-administration/quality-profiles/) and [Quality Gates](/user-guide/quality-gates/), which can be customized and shared accross projects\n\nOrganizations can be on:\n\n- **Free plan**. This is the default plan. Every project in an organization on the free plan is public.\n- **Paid plan**. This plan unlocks the ability to have private projects. Go to the "Billing" page of your organization to upgrade it to the paid plan.\n\nDepending on which plan the organization is in, its [visibility](/organizations/organization-visibility/) will change.\n\nYou can create organizations from the top right menu "+ > Create new organization"\n\n## FAQ\n\n### How to bind an existing organization to GitHub or Bitbucket Cloud?\n\nYou might notice the following warning message on your pull requests inside SonarCloud:\n\n    The SonarCloud GitHub application is installed on your GitHub organization, but the\n    SonarCloud organization is not bound to it. Please read "How to bind an existing\n    organization?" section in the "Organizations" documentation page to fix your setup.\n\nThis means that your SonarCloud organization is not bound to GitHub or Bitbucket Cloud whereas you had already installed the SonarCloud application (probably to annotate pull requests). To fix your setup, here are the steps to follow.\n\n**For GitHub:**\n\n1. Click your profile picture in the top right menu and select the organization.\n2. In the organization menu, click "Administration > Organization settings"\n3. Click on "Choose an organization on GitHub".\n4. On GitHub page, you should see a list of organization you are admin of. The organization you want to bind is marked as already configured. Click on it.\n5. Click on "Uninstall" at the bottom of the page.\n6. Go back to SonarCloud, to the settings page of your organization, and click on "Choose an organization on GitHub" again. The organization you want to bind should not be marked as configured anymore. Click on it, and then on "Install". After the installation, you will be redirected to SonarCloud.\n7. You are all set! You should see a GitHub icon close to the name of your organization at the top of the page.\n\n**For Bitbucket Cloud:**\n\n1. Click your profile picture in the top right menu and select the organization.\n2. In the organization menu, click "Administration > Organization settings"\n3. Click on "Choose a team on Bitbucket".\n4. On Bitbucket Cloud page, select the name of the team you want to bind and click on "Grant access". You will then be redirected to SonarCloud.\n   [[warning]]\n   | If you get a 405 error page from Bitbucket Cloud at this stage, this means that you did not approve a recent scope change - for which you should have received an email from Bitbucket Cloud. The easiest way to get around this is to uninstall the SonarCloud application in your Bitbucket Cloud "Install apps" settings, and reinstall it.\n5. You are all set! You should see a Bitbucket Cloud icon close to the name of your organization at the top of the page.\n\n### How to transfer ownership of an organization?\n\nYou may want to transfer ownership of you organization when you want to delete your account, or when you are leaving a team or company.  \nYou can manage your organization members permissions in: "Administration > Permissions" and [grant "Administer Organization" permission](/organizations/manage-team/#granting-permissions) to another member.\n\n### How to delete an organization?\n\nYou can delete your organization in: "Administration > Organization Settings > Delete Organization".\n'},{path:"sonarcloud/organizations/manage-team",content:'---\ntitle: Manage a Team\nurl: /organizations/manage-team/\n---\n\nMembers can collaborate on the projects in the organizations to which they belong. Depending on their permisssions within the organization, members can:\n* Analyze projects\n* Manage project settings (permissions, visibility, Quality Profiles, ...)\n* Update issues\n* Manage quality gates and Quality Profiles\n* Administer the organization itself\n\nMembers are managed on the "Members" page of the organization. Only organization administrators can manage members. \n\n## Managing Members Manually\nMembers are managed manually when synchronization is not available (for Bitbucket Cloud or Azure Devops for example) or when synchronization is deactivated.\n\n### Adding Members\nYou can add members to an organization using the "Add a member" button. Administrators can search manually for SonarCloud users and add them as members.\n\n## Managing Members in GitHub\nFor organizations that are bound to GitHub, members can be synchronized with GitHub organizations or managed manually. \n\nNote that in all cases, members should have a SonarCloud account before being synchronized with GitHub or added manually.\n\n### Synchronizing Members with your GitHub Organization\nWhen [importing](/organizations/overview/) a GitHub organization into SonarCloud, members are automatically synchronized with your GitHub organization.  \nThis means that each member of your GitHub organization who has a SonarCloud account will be automatically added to the SonarCloud organization, \nand will have direct access in SonarCloud to the organizations they\'ve been added to. \n\nYou can synchronize a bound organization with manually managed members using the "Configure synchronization" button. \nDuring synchronization, members of the SonarCloud organization who are not part of the GitHub organization are removed from the SonarCloud \norganization and members of the GitHub organization who are not members of the SonarCloud organization are added to the SonarCloud organization.\n\nAfter creating an organization or activating synchronization, SonarCloud users that are added or removed from the GitHub organization are automatically added or removed from \nthe SonarCloud organization. It\'s not possible to manually add or remove a member when synchronization is activated.\n\nPermissions are not synchronized and must be managed manually (see below).\n\n### Deactivating Member Synchronization\nYou can deactivate member synchronization using the "Configure synchronization" button. \nWhen you deactivate member synchronization, no members will be added or removed automatically.\nAfter deactivating synchronization, members will be managed manually.\n\n\n## Granting permissions\nOnce users are added or synchronized, organization administrators can grant them permissions to perform specific operations in the organization. It is up to the \nadministrators to make sure each member gets the relevant permissions.\n\nTo avoid having to manage individual permissions at a project level, organization admins can create groups to manage permissions \nand add new users to those groups on the "Members" page.\n\n## Future evolutions\nFuture versions of SonarCloud will make this onboarding process easier for BitBucket Cloud, Azure Devops, and others. \nUsers\' permissions will be retrieved from systems and mapped to SonarCloud permissions on a best-effort basis.'},{path:"sonarcloud/organizations/organization-visibility",content:'---\ntitle: Organization Visibility\nurl: /organizations/organization-visibility/\n---\n\n## Free plan organization\n\nFree plan organizations are public. This means that almost everything is visible to any user - even anonymous ones:\n\n* Projects\n* Issues\n* Quality Profiles\n* Quality Gates\n* Rules\n\nThe following pages are restricted:\n\n* Members: to members of the organization\n* Administration pages: to administrators of the organization\n\n## Paid plan organization\n\nPaid plan organizations are private. This means that nothing is visible to non-members of the organization. In other words, you need to be a member of the organization to see:\n\n* Projects - which are private by default\n* Issues\n* Quality Profiles\n* Quality Gates\n* Rules\n* Members\n\nThe administration pages are obviously also restricted to administrators of the organization.\n\n### Want to make one project public?\n\nIf you are on a paid plan organization but want to make a project public (for instance because you are developing an open-source library), this is possible. You will have to manually make the project public in its **Administration > Permissions** page. Once done, you will notice the "Public" badge on the project.\n\nAs soon as you have one public project, the following pages will become visible to any user:\n\n* Projects\n* Issues\n* Rules\n\n"Quality Profiles" and "Quality Gates" pages will remain restricted to members only - since you might not want to unveil some information used by your private projects.\n'},{path:"sonarcloud/privacy",content:"---\ntitle: Privacy Policy\nurl: /privacy/\n---\n\nThe privacy policy specifies how data collected on this website is used. Thank you for visiting our website and your interest in our services and products. As the protection of your personal data is an important concern for us, we will explain below what information we collect during your visit to our website, as they are processed and whether or how these may be used.\n\n## PERSONAL DATA\n\nPersonal information is data about personal or material circumstances of an identified or identifiable natural person. This includes information such as your first and last name, your postal or residential address, telephone numbers and date of birth. Information that can not be directly related to your real identity – such as your favorite websites or the number of users of a page – are not considered as personal data.\n\n## COLLECTION AND PROCESSING OF PERSONAL DATA\n\nAs the operator and creator of the website, we do not store personal data itself automatically. If you go to our website, the provider – where the web server is hosted – may temporarily store data for the purpose of system security such as the connection of the computer, the web pages you visit, the date and duration of the visit, data about the used browser software and operating system and the web page from which you visit us. In addition to that, personal information such as your name, address, phone number or e-mail will only be stored, if you have provided this information voluntarily, eg. as part of a registration, a survey, a contest, to carry out an order or contract or an information request.\n\n## USE AND DISCLOSURE OF PERSONAL DATA\n\nPersonal data you provided may be used solely for the purpose of technical website administration and to fulfill your wishes and requirements, thus primarily to processing the order with you or to respond to your request. Only if you have previously given your consent or – if stipulated by legal regulations – you entered no objection, we use this data for product surveys and marketing purposes. We don’t share, sell or transfer your personal data to third parties, unless this is necessary for the purpose of the contract or unless you have explicitly consented. For example it may be necessary, that in case of an product order we share your address and order with our suppliers.\n\n## USE OF WEB ANALYSIS SOFTWARE\n\nTo improve the structure and the data we offer on our website, we might use open source or proprietary web analysis software. Our evaluations will be based on summary or averaged information amalgamated for the large numbers of people visiting the vebsite. The data provided by won’t be matched with any individual’s data from other sources.\n\nData collected might include IP, time and duration of the visit, what pages are visited, used browser and add-ons/plugins, search-engines and referrer. While statistic tools might use a “cookie” to distinguish between individual visitors, the collected data doesn’t allow to identify individuals.\n\n## INFORMATION USED DURING AUTHENTICATION\n\nWe use the following information for authentication with GitHub / Bitbucket / Azure DevOps.\n\n### GitHub\n* ID\n* Login\n* Name\n* Email\n* List of organizations the user is member of\n\nFor more information:\n* https://developer.github.com/v3/users/#get-the-authenticated-user\n* https://developer.github.com/v3/users/emails/#list-email-addresses-for-a-user\n* https://developer.github.com/v3/orgs/#list-your-organizations\n\n### Bitbucket\n* UUID\n* Username\n* Display name\n* Email\n* Is email defined as primary\n\nFor more information:\n* https://developer.atlassian.com/bitbucket/api/2/reference/resource/user\n* https://developer.atlassian.com/bitbucket/api/2/reference/resource/user/emails\n\n### Azure DevOps\n* Tenant ID\n* Object ID\n* Display name\n* User Principal Name\n* Email\n\nFor more information:\n* https://docs.microsoft.com/en-us/graph/api/user-get?view=graph-rest-1.0\n\n## SECURITY\n\nWe take all the necessary technical and organisational security measures to protect your personal data from loss and misuse. Your data is stored in a secure operating environment that is not accessible to the public. If you communicate with us via e-mail, please note that the confidentiality of the information is not guaranteed. The contents of e-mails can be intercepted by third parties. In case of doubt we therefore recommend to send confidential information only by snail mail.\n\n## RIGHT OF ACCESS TO PERSONAL DATA\n\nUpon written request you will be informed by us what information we stored about you (such as name or address).\n\n## CONTACT\n\nIf you have questions regarding the processing of personal data or in case of requests for information, suggestions or complaints, please [contact us](/#sonarcloud#/about/contact) directly.\n"},{path:"sonarcloud/security",content:'---\ntitle: Security Statement\nurl: /security/\n---\n\nWe know that your code is very important to you and your business. We also know that no one wants proven bugs or vulnerabilities found on their source code to be unveiled to third-parties. This is why we take security extremely seriously.\n\n## Hosting\n\nSonarCloud runs primarily off the AWS Frankfurt region. It also uses marginally services located in the AWS Ireland region when they are not available in Frankfurt.\n\n## System security\n\nSonarCloud uses its own Virtual Private Cloud (AWS VPC). Accesses to the infrastructure are restricted through firewalls, allowing accesses from SonarSource networks only. Secure protocols are required for accesses and SSL keys are used for authentication. Access to the infrastructure, inclusive of storage, is restricted to the Technology Operations team.\n\n\n## Data security\n\nAt the infrastructure level, access to data is controlled by virtue of being hosted in network zones which only the Technology Operations have access to. \n\nTo insure data availability, the SonarCloud database is replicated in quasi real time between 2 availability zones both within the Frankfurt region. In addition, the database is fully backed up every day with a 7 days retention. \n\nAt the software level, SonarCloud ensures private source code is accessible to organization members only, in addition to SonarSource Technology Operations team for support purposes only.\n\n\n\n## Software security\n\nSonarCloud UI and APIs regularly pass penetration testing conducted by a an external company, specialized in cyber and application security, certified in accordance to ISO-27001 and which is also member of the OWASP.\n\nIn case you find a vulnerability, please follow our [Responsible Vulnerability Disclosure process](https://community.sonarsource.com/t/responsible-vulnerability-disclosure/9317) to report it to our Security team.\n\n## Communications\n\nAll communications are done over TLS and support TLS 1.2:\n* Navigating in the Web application\n* Using WS APIs\n* Running analysis (by the scanners) from CI services and pushing analysis reports to SonarCloud\n\n## SonarCloud Webhooks \n\nYou can use secrets to secure webhooks and ensure they are coming from SonarCloud (see the "Securing your webhooks" section of the [Webhooks](/project-administration/webhooks/#securing-your-webhooks) page for more information). \n\n\n## Authentication\n\nPrimary authentication on the system is available through the SonarCloud GitHub application, through OAuth authentication with Bitbucket Cloud and Microsoft Azure DevOps. As a consequence, users don’t have a password on SonarCloud, and are as protected as what they expect (especially with 2FA activated on those systems). \n \nFor WS API calls or source code analysis triggered from CI services, only revocable user tokens are accepted.\n\n## Payment\n\nWhen you subscribe to the paid plan on SonarCloud, your credit card information never transit through our system nor it gets stored on the server. It\'s handed off to [Braintree Payment Solutions](https://www.braintreepayments.com), a company dedicated to storing your sensitive data on [PCI-Compliant](http://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard) servers.\n'},{path:"sonarcloud/sonarcloud-pricing",content:'---\ntitle: Pricing\nurl: /sonarcloud-pricing/\n---\n\nSubscribing to a paid plan on SonarCloud allows you to analyze unlimited private projects, to know more about all the advantages of a paid plan check our [pricing page](/#sonarcloud#/about/pricing).\n\n## How do I activate the paid plan?\n\nYou can activate the paid plan on the **Administration > Billing** page of your organization.\n\n## How do I get invoices?\n\nYou can download PDF invoices for every payment from the **Administration > Billing** page of your organization.\n\nIf you want to get invoices by email, go to **Administration > Billing > Edit billing info** and check "Send the monthly receipt to this email".\n'},{path:"sonarcloud/supported-languages",content:"---\ntitle: Supported languages\nurl: /analysis/supported-languages/\n---\n\nHere is the list of all the languages currently supported in SonarCloud :\n\n* [ABAP](https://redirect.sonarsource.com/plugins/abap.html)\n* [Apex](https://redirect.sonarsource.com/plugins/apex.html)\n* [C](https://redirect.sonarsource.com/plugins/cpp.html)\n* [C++](https://redirect.sonarsource.com/plugins/cpp.html)\n* [C#](https://redirect.sonarsource.com/plugins/csharp.html)\n* [Objective-C](https://redirect.sonarsource.com/plugins/objectivec.html)\n* [COBOL](https://redirect.sonarsource.com/plugins/cobol.html)\n* [CSS](https://redirect.sonarsource.com/plugins/css.html)\n* [Flex](https://redirect.sonarsource.com/plugins/flex.html)\n* [Go](https://redirect.sonarsource.com/plugins/go.html)\n* [HTML](https://redirect.sonarsource.com/plugins/web.html)\n* [Java](https://redirect.sonarsource.com/plugins/java.html)\n* [JavaScript](https://redirect.sonarsource.com/plugins/javascript.html)\n* [Kotlin](https://redirect.sonarsource.com/plugins/kotlin.html)\n* [PHP](https://redirect.sonarsource.com/plugins/php.html)\n* [PL/SQL](https://redirect.sonarsource.com/plugins/plsql.html)\n* [Python](https://redirect.sonarsource.com/plugins/python.html)\n* [Ruby](https://redirect.sonarsource.com/plugins/ruby.html)\n* [Scala](https://redirect.sonarsource.com/plugins/scala.html)\n* [Swift](https://redirect.sonarsource.com/plugins/swift.html)\n* [TypeScript](https://redirect.sonarsource.com/plugins/typescript.html)\n* [T-SQL](https://redirect.sonarsource.com/plugins/tsql.html)\n* [Visual Basic .NET](https://redirect.sonarsource.com/plugins/vbnet.html)\n* [XML](https://redirect.sonarsource.com/plugins/xml.html)\n"},{path:"user-guide/activity-history",content:"---\ntitle: Activity and History\nurl: /user-guide/activity-history/\n---\n\nThe Project Activity page offers a comprehensive list of the analyses on file for a project (subject to [Housekeeping](/instance-administration/housekeeping/)), and the ability to see the evolution of project measures over time.\n\nGraphs on the activity page help you understand the evolution of up to three measures of your choice against each other. Graph mouseovers show the measure values and events associated with particular analyses.\n\n## Events\nThere are four types of events:\n\n* Quality Gate - the status of the [quality gate](/user-guide/quality-gates/) changed.\n* Profile - the [Quality Profile](/instance-administration/quality-profiles/) used to analyze the project changed - either the profile was edited, or a different profile was used to analyze the project.\n* Version - the project's version changed.\n* Other - an event was manually created on a snapshot. See [Managing History](/project-administration/managing-project-history/)\n\nEvents are shown on the [project front page](/user-guide/project-page/) and in the project Activity page. \n"},{path:"user-guide/applications",content:"---\ntitle: Applications\nurl: /user-guide/applications/\n---\n\n*Applications are available starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html).*\n\n## Using Applications\n\nAn Application aggregates projects into a synthetic project. Assume you have a set of projects which has been split for technical reasons, but which shares a life cycle; they interact directly in production and are always released together. With an Application, they can be treated as a single entity in {instance} with a unified Project Homepage, Issues list, Measures space, and most importantly: Quality Gate.\n\n### Applications vs. Portfolios\n\nApplications and Portfolios are both aggregations of projects, but they have different goals and therefore different presentations. A Portfolio is designed to be a very high-level, executive overview that shows how a package of projects that may only be tangentially related are doing quality-wise, and what the trends are. Applications allow you to see your set of projects as a larger, overall meta-project. For instance, because all the projects in an application ship together, if one of them isn't releasable then none of them are, and an Application's consolidated Quality Gate gives you an immediate summary of what must be fixed across all projects in order to allow you to release the set.\n\n## Application Setup\n\nYou can create an Application by clicking the **Create Application** button in the upper-right corner of the **Projects** homepage. \n\nStarting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), you can also create and edit applications in the global Portfolio administration interface at **Administration > Configuration > Portfolios**. \n\nFor more information on setting up Applications, see [Managing Applications](/project-administration/managing-applications/). \n\n[[info]]\n|Applications must be created initially by a user with global administration rights, but after set-up, administration of an individual Application can be delegated to other users.\n\n### Populating Application Data\n\nAn Application is automatically re-calculated after each analysis of one of its projects. If you want immediate (re)calculation, a user with administration rights on the Application can use the **Recompute** button in the Application-level **Application Settings > Edit Definition** interface. \n\nStarting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html), the global Portfolio administration interface: **Administration > Configuration > Portfolios** offers the ability to queue re-computation of all Applications and Portfolios at once.\n\n## Applications and Branch Analysis\n\nBranches are available for Applications. They allow you to aggregate branches from the projects in an Application.\n\n**Note:** Avoid adding branches to your application that will be deleted to prevent issues with your Application status.\n\nOnce an Application has been set up, anyone with administration rights on the Application can manually create a new branch in the **Application Settings > Edit Definition** interface. In Enterprise Edition and above, you can also manage branches from the global **Administration > Configuration > Portfolios** interface. For each Application branch you can choose which project branch should be included, or whether the project should be represented in the branch at all."},{path:"user-guide/built-in-rule-tags",content:"---\ntitle: Built-in Rule Tags\nurl: /user-guide/built-in-rule-tags/\n---\nTags are a way to categorize rules and issues. Issues inherit the tags on the rules that raised them. Some tags are language-specific, but many more appear across languages. Users can add tags to rules and issues, but most rules have some tags out of the box. Here is a non-comprehensive list of what some of those built-in tags mean:\n\n*NOTE : Links below to [rules.sonarsource.com](https://rules.sonarsource.com) will be initially filtered for Java language rules*\n\n* [brain-overload](https://rules.sonarsource.com/java/tag/brain-overload) - there is too much to keep in your head at one time\n* [bad-practice](https://rules.sonarsource.com/java/tag/bad-practice) - the code likely works as designed, but the way it was designed is widely recognized as being a bad idea.\n* [cert](https://rules.sonarsource.com/java/tag/cert) - relates to a rule in a [CERT](https://www.securecoding.cert.org/confluence/x/BgE) standard. There are currently three CERT standards: [C](https://www.securecoding.cert.org/confluence/x/HQE), [C++](https://www.securecoding.cert.org/confluence/x/fQI), and [Java](https://www.securecoding.cert.org/confluence/x/Ux). Many of these rules are not language-specific, but are good programming practices. That's why you'll see this tag on non-C/C++, Java rules.\n* [clumsy](https://rules.sonarsource.com/java/tag/clumsy) - extra steps are used to accomplish something that could be done more clearly and concisely. (E.G. calling .toString() on a String).\n* [confusing](https://rules.sonarsource.com/java/tag/confusing) - will take maintainers longer to understand than is really justified by what the code actually does\n* [convention](https://rules.sonarsource.com/java/tag/convention) - coding convention - typically formatting, naming, whitespace...\n* [cwe](https://rules.sonarsource.com/java/tag/cwe) - relates to a rule in the [Common Weakness Enumeration](http://cwe.mitre.org/). For more on CWE and on security-related rules in general, see [Security-related rules](/user-guide/security-rules/).\n* [design](https://rules.sonarsource.com/java/tag/design) - there is something questionable about the design of the code\n* [lock-in](https://rules.sonarsource.com/java/tag/lock-in) - environment-specific features are used\n* [misra](https://rules.sonarsource.com/java/tag/misra) - relates to a rule in one of the [MISRA](http://www.misra.org.uk/) standards. While the MISRA rules are primarily about C and C++, many of them are not language-specific (E.G. don't use a float as a loop counter) but are simply good programming practices. That's why you'll see these tags on non-C/C++ rules.\n* [owasp](https://rules.sonarsource.com/java/tag/owasp) - relates to a rule in the [OWASP Top Ten](https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project) security standards. Note, that the OWASP Top Ten is a list of high-level vulnerabilities which translates to many, many potential rules.\n* [pitfall](https://rules.sonarsource.com/java/tag/pitfall) - nothing is wrong yet, but something could go wrong in the future; a trap has been set for the next guy and he'll probably fall into it and screw up the code.\n* [sans-top25](https://rules.sonarsource.com/java/tag/sans-top25) - This tag is based on outdated statistics and should no longer be used. Instead, it's recommended to rely on the \"CWE Top 25\" reports, which are available in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html).\n* [suspicious](https://rules.sonarsource.com/java/tag/suspicious) - it's not guaranteed that this is a **bug**, but it looks suspiciously like one. At the very least, the code should be re-examined & likely refactored for clarity.\n* [unpredictable](https://rules.sonarsource.com/java/tag/unpredictable) - the code may work fine under current conditions, but may fail erratically if conditions change.\n* [unused](https://rules.sonarsource.com/java/tag/unused) - unused code, E.G. a private variable that is never used.\n* [user-experience](https://rules.sonarsource.com/java/tag/user-experience) - there's nothing technically wrong with your code, but it may make some or all of your users hate you.\n"},{path:"user-guide/clean-as-you-code",content:"---\ntitle: Clean as You Code\nurl: /user-guide/clean-as-you-code/\n---\n\n## What is Clean as You Code?\n\nClean as You Code is an approach to Code Quality that eliminates a lot of the challenges that come with traditional approaches. As a developer, you focus on maintaining high standards and taking responsibility specifically in the New Code you're working on. SonarQube gives you the tools that let you set high standards and take pride in knowing that your code meets those standards.\n\n## Focus on New Code\n\nWith Clean as You Code, your focus is always on New Code (code that has been added or changed according to your New Code definition) and making sure the code you write today is clean and safe.\n\nThe New Code definition can be set at different levels (global, project, and starting in [Developer Edition](https://redirect.sonarsource.com/editions/developer.html) at the branch level). Depending on the level at which your New Code definition is set, you can change the starting point to fit your situation.\n\nFor more information on setting your New Code definition, check out [Defining New Code](/project-administration/new-code-period/).\n\n## Personal Responsibility\n\nWith Clean as You Code, you aren't responsible for anyone else's code. You own the quality and security of the New Code you are working on today. If you add new issues, SonarQube automatically assigns them to you so you can maintain quality in your code.\n\nFor more information on issues and how they are assigned, check out the [Issues](/user-guide/issues/) documentation.\n\n## Quality Gate\n\nYour Quality Gate is a set of conditions that tells you whether or not your project is ready for release. With the Clean as You Code approach, your Quality Gate should:\n\n- **Focus on New Code metrics** – When your Quality Gate is set to focus on New Code metrics (like the built-in Sonar way Quality Gate), new features will be delivered cleanly. As long as your Quality gate is green, your releases will continue to improve.\n- **Set and enforce high standards** – When standards are set and enforced on New Code, you aren't worried about having to meet those standards in old code and having to clean up someone else's code. You can take pride in meeting high standards on _your_ code. If a project doesn't meet these high standards, it won't pass the Quality Gate, and it's obviously not ready to be released.\n\nFor more information on Quality Gates and making sure your Quality Gate is enforcing your standards, check out the [Quality Gates](/user-guide/quality-gates/) documentation.\n\n## Pull Request Analysis\n\nYou can use Pull Request analysis and decoration to make sure your code is meeting your standards before you merge. Pull Request analysis lets you see your Pull Request's Quality Gate in the SonarQube UI. You can then decorate your Pull Requests with SonarQube issues directly in your ALM's interface.\n\nFor more information on setting up Pull Request analysis and decoration, see the [Pull Request](/analysis/pull-request/) documentation.\n"},{path:"user-guide/concepts",content:"---\ntitle: Concepts\nurl: /user-guide/concepts/\n---\n\n## Architecture\n| Concept  | Definition                                                                            |\n| -------- | ------------------------------------------------------------------------------------- |\n| Analyzer | A client application that analyzes the source code to compute **snapshots**.          |\n| Database | Stores configuration and **snapshots**                                                |\n| Server   | Web interface that is used to browse **snapshot** data and make configuration changes | \n\n## Quality\n| Concept                    | Definition                                                                                                                                                                                                                                                                                                                                                                                                         |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| Bug                        | An issue that represents something wrong in the code. If this has not broken yet, it will, and probably at the worst possible moment. This needs to be fixed. Yesterday.                                                                                                                                                                                                                                           |\n| Code Smell                 | A maintainability-related issue in the code. Leaving it as-is means that at best maintainers will have a harder time than they should making changes to the code. At worst, they'll be so confused by the state of the code that they'll introduce additional errors as they make changes.                                                                                                                         |\n| Cost                       | See Remediation Cost                                                                                                                                                                                                                                                                                                                                                                                               |\n| Debt                       | See Technical Debt                                                                                                                                                                                                                                                                                                                                                                                                 |\n| Issue                      | When a piece of code does not comply with a rule, an issue is logged on the **snapshot**. An issue can be logged on a source file or a unit test file. There are 3 types of issue: **Bugs**, **Code Smells** and **Vulnerabilities**                                                                                                                                                                    |\n| Measure                    | The value of a **metric** for a given file or project at a given time. For example, 125 lines of code on class MyClass or density of duplicated lines of 30.5% on project myProject                                                                                                                                                                                                                                  |\n| Metric                     | A type of measurement. Metrics can have varying values, or **measures**, over time. Examples: number of lines of code, complexity, etc. A metric may be either _qualitative_ (gives a quality indication on the component, E.G. density of duplicated lines, line coverage by tests, etc.) or _quantitative_ (does not give a quality indication on the component, E.G. number of lines of code, complexity, etc.) |\n| New Code definition                | A changeset or period that you're keeping a close watch on for the introduction of new problems in the code. Ideally this is since the `previous_version`, but if you don't use a Maven-like versioning scheme you may need to set a time period such as 21 days, since a specific analysis, or use a reference branch.                                                                                                            |\n| Quality Profile            | A set of **rules**. Each **snapshot** is based on a single Quality Profile. See also [Quality Profiles](/instance-administration/quality-profiles/)                                                                                                                                                                                                                                                         | \n| Rule                | A coding standard or practice which should be followed. Not complying with coding rules leads to **Bugs**, **Vulnerabilities**, **Security Hotspots**, and **Code Smells**. Rules can check quality on code files or unit tests.                                                                                                                                                                                                                                 |\n| Remediation Cost           | The estimated time required to fix Vulnerability and Reliability Issues.                                                                                                                                                                                                                                                                                                                                           |\n| Snapshot                   | A set of **measures** and **issues** on a given project at a given time. A snapshot is generated for each analysis.                                                                                                                                                                                                                                                                                          |\n| Security Hotspot           | Security-sensitive pieces of code that need to be manually reviewed. Upon review, you'll either find that there is no threat or that there is vulnerable code that needs to be fixed.                                                                                               |\n| Technical Debt             | The estimated time required to fix all Maintainability Issues / code smells                                                                                                                                                                                                                                                                                                                                        |\n| Vulnerability              | A security-related issue which represents a backdoor for attackers. See also [Security-related rules](/user-guide/security-rules/).                                                                                                                                                                                                                                                                                |\n"},{path:"user-guide/issues",content:"---\ntitle: Issues\nurl: /user-guide/issues/\n---\n\nWhile running an analysis, {instance} raises an issue every time a piece of code breaks a coding rule. The set of coding rules is defined through the associated [Quality Profile](/instance-administration/quality-profiles/) for each language in the project. \n\n### Issue Types\n\nThere are three types of issues:\n\n1. **Bug** – A coding error that will break your code and needs to be fixed immediately.\n1. **Vulnerability** – A point in your code that's open to attack.\n1. **Code Smell** – A maintainability issue that makes your code confusing and difficult to maintain.\n\n### Issue Severity\n\nEach issue has one of five severities:\n\n1. **BLOCKER**  \nBug with a high probability to impact the behavior of the application in production: memory leak, unclosed JDBC connection, .... The code MUST be immediately fixed.\n1. **CRITICAL**  \nEither a bug with a low probability to impact the behavior of the application in production or an issue which represents a security flaw: empty catch block, SQL injection, ... The code MUST be immediately reviewed. \n1. **MAJOR**  \nQuality flaw which can highly impact the developer productivity: uncovered piece of code, duplicated blocks, unused parameters, ...\n1. **MINOR**  \nQuality flaw which can slightly impact the developer productivity: lines should not be too long, \"switch\" statements should have at least 3 cases, ...\n1. **INFO**  \nNeither a bug nor a quality flaw, just a finding.\n\nIdeally, the team wouldn't introduce any new issues (any new technical debt). [SonarLint](https://sonarlint.org) can help developers because it provides the ability to perform local analyses to check their code before pushing it back to the SCM. But in real life, it's not always possible to code without any new technical debt, and sometimes it's not worth it.\n\nSo new issues get introduced.\n\n## Understanding issue context\nSometimes, issues are self-evident once they're pointed out. For instance, if your team has agreed to a init-lower, camelCase variable naming convention, and an issue is raised on `My_variable`, you don't need a lot of context to understand the problem. But in other situations context may be essential to understanding why an issue was raised. That's why {instance} supports not just the primary issue location, where the issue message is shown, but also secondary issue locations. For instance, secondary issues locations are used to mark the pieces of code in a method which add Cognitive Complexity to a method. \n\nBut there are times when a simple laundry list of contributing locations isn't enough to understand an issue. For instance, when a null pointer can be dereferenced on some paths through the code, what you really need are issue flows. Each flow is a _set_ of secondary locations ordered to show the exact path through the code on which a problem can happen. And because there can be multiple paths through the code on which, for instance a resource is not released, {instance} supports multiple flows.\n\nCheck out this [![YouTube link](/images/youtube.png) video](https://youtu.be/17G-aZcuMKw) for more on issues with multiple locations.\n\n## Issues lifecycle\n### Statuses\nAfter creation, issues flow through a lifecycle, taking one of five possible statuses:\n\n* **Open** - set by {instance} on new issues\n* **Confirmed** - set manually to indicate that the issue is valid\n* **Resolved** - set manually to indicate that the next analysis should Close the issue\n* **Reopened** - set automatically by {instance} when a Resolved issue hasn't actually been corrected\n* **Closed** - set automatically by {instance} for automatically created issues. \n\n### Resolutions\nClosed issues will have one of two resolutions:\n\n* **Fixed** - set automatically when a subsequent analysis shows that the issue has been corrected or the file is no longer available (removed from the project, excluded or renamed)\n* **Removed** - set automatically when the related rule is no longer available. The rule may not be available either because it has been removed from the Quality Profile or because the underlying plugin has been uninstalled.\n\nResolved issues will have one of two resolutions:\n* **False Positive** - set manually\n* **Won't Fix** - set manually\n\n### Issue Workflow \nIssues are automatically closed (status: Closed) when:\n* an issue (of any status) has been properly fixed => Resolution: Fixed\n* an issue no longer exists because the related coding rule has been deactived or is no longer available (ie: plugin has been removed) => Resolution: Removed\n\nIssues are automatically reopened (status: Reopened) when:\n* an issue that was manually Resolved as Fixed(but Resolution is not False positive) is shown by a subsequent analysis to still exist\n\n## Understanding which Issues are \"New\"\nTo determine the creation date of an issue, an algorithm is executed during each analysis to determine whether an issue is new or existed previously. This algorithm relies on content hashes (excluding whitespace) for the line the issue is reported on. For multi-line issues, the hash of the first line is used. For each file (after detection of file renaming), the algorithm takes the base list of issues from the previous analysis, and tries to match those issues with the raw issue list reported by the new analysis. The algorithm tries to first match using the strongest evidence, and then falls back to weaker heuristics.\n\n* if the issue is on the same rule, with the same line number and with the same line hash (but not necessarily with the same message) > MATCH\n* detect block move inside file, then if the issue is on the same (moved) line and on the same rule (but not necessarily with the same message) > MATCH\n* on the same rule, with the same message and with the same line hash (but not necessarily with the same line) > MATCH\n* on the same rule, with the same message and with the same line number (but not necessarily with the same line hash) > MATCH\n* on the same rule and with the same line hash (but not the same message and not the same line) > MATCH\n* is there a matching **CLOSED** issue > MATCH and Reopen\n\nUnmatched \"base\" issues are closed as fixed.\n\nUnmatched \"raw\" issues are new.\n\n## Understanding Issue Backdating\nOnce an issue has been determied to be \"new\", as described above, the next question is what date to give it. For instance, what if it has existed in code for a long time, but only found in the most recent analysis because new rules were added to the profile? Should this issue be given the date of the last change on its line, or the date of the analysis where it was first raised? That is, should it be backdated? If the date of the last change to the line is available (this requires [SCM integration](/analysis/scm-integration/)) then under certain circumstances, the issue will be backdated:\n\n* On first analysis of a project or branch\n* When the rule is new in the profile (a brand new rule activated or a rule that was deactivated and is now activated)\n* When SonarQube has just been upgraded (because rule implementations could be smarter now)\n* When the rule is external\n\nAs a consequence, it is possible that backdating will keep newly raised issues out of New Code.\n\n\n## Automatic Issue Assignment\n### For Bug, Vulnerability and Code Smell\nNew issues are automatically assigned during analysis to the last committer on the issue line if the committer can be correlated to a {instance} user. Note that currently, issues on any level above a file, e.g. directory / project, cannot be automatically assigned.\n\n### User Correlation\nLogin and email correlations are made automatically. I.e. if the user commits with her email address and that email address is part of her {instance} profile, then new issues raised on lines where she was the last committer will be automatically assigned to her.\n\nAdditional correlations can be made manually in the user's profile (see \"SCM accounts\" in Authorization for more).\n\n### Known Limitation\nIf the SCM login associated with an issue is longer than 255 characters allowed for an issue author, the author will be left blank.\n\n## Issue edits\n{instance}'s issues workflow can help you manage your issues. There are seven different things you can do to an issue (other than fixing it in the code!): Comment, Assign, Confirm, Change Severity, Resolve, Won't Fix, and False Positive.\n\nThese actions break out into three different categories. First up is the \"technical review\" category.\n\n### Technical Review\nThe Confirm, False Positive, Won't Fix, Severity change, and Resolve actions all fall into this category, which presumes an initial review of an issue to verify its validity. Assume it's time to review the technical debt added in the last review period - whether that's a day, a week, or an entire sprint. You go through each new issue and do one:\n\n* **Confirm** - By confirming an issue, you're basically saying \"Yep, that's a problem.\" Doing so moves it out of \"Open\" status to \"Confirmed\".\n* **False Positive** - Looking at the issue in context, you realize that for whatever reason, this issue isn't actually a problem. So you mark it False Positive and move on. Requires Administer Issues permission on the project.\n* **Won't Fix** - Looking at the issue in context, you realize that while it's a valid issue it's not one that actually needs fixing. In other words, it represents accepted technical debt. So you mark it Won't Fix and move on. Requires Administer Issues permission on the project.\n* **Severity change** - This is the middle ground between the first two options. Yes, it's a problem, but it's not as bad a problem as the rule's default severity makes it out to be. Or perhaps it's actually far worse. Either way, you adjust the severity of the issue to bring it in line with what you feel it deserves.  Requires Administer Issues permission on the project.\n* **Resolve** - If you think you've fixed an open issue, you can Resolve it. If you're right, the next analysis will move it to closed status. If you're wrong, its status will go to re-opened.\n\nIf you tend to mark a lot of issues False Positive or Won't Fix, it means that some coding rules are not appropriate for your context. So, you can either completely deactivate them in the Quality Profile or use issue exclusions to narrow the focus of the rules so they are not used on specific parts (or types of object) of your application. Similarly, making a lot of severity changes should prompt you to consider updating the rule severities in your profiles.\n\nAs you edit issues, the related metrics (e.g. New Bugs), will update automatically, as will the Quality Gate status if it's relevant.\n\n### Dispositioning\nOnce issues have been through technical review, it's time to decide who's going to deal them. By default they're assigned to the last committer on the issue line (at the time the issue is raised), but you can certainly reassign them to yourself or someone else. The assignee will receive email notification of the assignment if he signed up for notifications, and the assignment will show up everywhere the issue is displayed, including in the My Issues list in the My Account space.\n\n### General\nAt any time during the lifecycle of an issue, you can log a comment on it. Comments are displayed in the issue detail in a running log. You have the ability to edit or delete the comments you made.\n\nYou can also edit an issue's tags. Issues inherit the tags of the rules that created them, but the tag set on an issue is fully editable. Tags can be created, added and removed at will for users with the Browse permission on the project.\n\nAlthough they are initially inherited from the relevant rule, the tags on an issue are not synchronized with the rule, so adding tags to a rule will not add those tags to the rule's issues. \n\n### Bulk Change\nAll of these changes and more can be made to multiple issues at once using the Bulk Change option in the issues search results pane.\n\n\n## Purging Closed Issues\nBy default, Closed issues are kept for 30 days. For more details, see [Housekeeping](/instance-administration/housekeeping/).\n\n"},{path:"user-guide/keyboard-shortcuts",content:"---\ntitle: Keyboard Shortcuts\nurl: /user-guide/keyboard-shortcuts/\n---\n\n## Global\n\n| Shortcut | Action          |\n| -------- | --------------- |\n| `s`      | open search bar |\n| `?`      | open help       |\n\n## Code Page\n\n| Shortcut | Action                                        |\n| -------- | --------------------------------------------- |\n| `↑` `↓`  | select files                                  |\n| `→`      | open file                                     |\n| `←`      | return back to the list                       |\n\n## Issues Page\n\n| Shortcut         | Action                                        |\n| ---------------- | --------------------------------------------- |\n| `↑` `↓`          | navigate between issues                       |\n| `→`              | go from the list of issues to the source code |\n| `←`              | return back to the list                       |\n| `alt` + `↑` `↓`  | to navigate issue locations                   |\n| `alt` + `←` `→`  | to switch flows                               |\n| `f`              | do an issue transition                        |\n| `a`              | assign issue                                  |\n| `m`              | assign issue to the current user              |\n| `i`              | change severity of issue                      |\n| `c`              | comment issue                                 |\n| `ctrl` + `enter` | submit comment                                |\n| `t`              | change tags of issue                          |\n\n## Measures Page\n\n| Shortcut | Action                                        |\n| -------- | --------------------------------------------- |\n| `↑` `↓`  | select files                                  |\n| `→`      | open file                                     |\n| `←`      | return back to the list                       |\n\n## Rules Page\n\n| Shortcut | Action                                        |\n| -------- | --------------------------------------------- |\n| `↑` `↓`  | navigate between rules                        |\n| `→`      | go from the list of rules to the rule details |\n| `←`      | return back to the list                       |\n"},{path:"user-guide/metric-definitions",content:"---\ntitle: Metric Definitions\nurl: /user-guide/metric-definitions/\n---\n\n   \n## Complexity\n**Complexity** (`complexity`)  \nIt is the Cyclomatic Complexity calculated based on the number of paths through the code. Whenever the control flow of a function splits, the complexity counter gets incremented by one. Each function has a minimum complexity of 1. This calculation varies slightly by language because keywords and functionalities do.\n\n[[collapse]]\n| ## Language-specific details\n| Language | Notes\n| ---|---\n| ABAP | The following keywords increase the complexity by one: `AND`, `CATCH`, `CONTINUE`, `DO`, `ELSEIF`, `IF`, `LOOP`, `LOOPAT`, `OR`, `PROVIDE`, `SELECT…ENDSELECT`, `TRY`, `WHEN`, `WHILE`\n| C/C++/Objective-C | The complexity gets incremented by one for: function definitions, `while`, `do while`, `for`, `throw` statements, `switch`, `case`, `default`, `&&` operator, `||` operator, `?` ternary operator, `catch`, `break`, `continue`, `goto`.\n| COBOL | The following commands increase the complexity by one (except when they are used in a copybook): `ALSO`, `ALTER`, `AND`, `DEPENDING`, `END_OF_PAGE`, `ENTRY`, `EOP`, `EXCEPTION`, `EXIT`, `GOBACK`, `CONTINUE`, `IF`, `INVALID`, `OR`, `OVERFLOW`, `SIZE`, `STOP`, `TIMES`, `UNTIL`, `USE`, `VARYING`, `WHEN`, `EXEC CICS HANDLE`, `EXEC CICS LINK`, `EXEC CICS XCTL`, `EXEC CICS RETURN`\n| Java | Keywords incrementing the complexity: `if`, `for`, `while`, `case`, `catch`, `throw`, `&&`, `||`, `?`\n| JavaScript, PHP | Complexity is incremented by one for each: function (i.e non-abstract and non-anonymous constructors, functions, procedures or methods), `if`, short-circuit (AKA lazy) logical conjunction (`&&`), short-circuit (AKA lazy) logical disjunction (`||`), ternary conditional expressions, loop, `case` clause of a `switch` statement, `throw` and `catch` statement, `go to` statement (only for PHP)\n| PL/I | The following keywords increase the complexity by one: `PROC`, `PROCEDURE`, `GOTO`, `GO TO`, `DO`, `IF`, `WHEN`, `|`, `!`, `|=`, `!=`, `&`, `&=`\n| PL/SQL | The complexity gets incremented by one for: the main PL/SQL anonymous block (not inner ones), create procedure, create trigger, procedure_definition, basic loop statement, when_clause_statement (the “when” of simple_case_statement and searched_case_statement), continue_statement, cursor_for_loop_statement, continue_exit_when_clause (The “WHEN” part of the continue and exit statements), exception_handler (every individual “WHEN”), exit_statement, for_loop_statement, forall_statement, if_statement, elsif_clause, raise_statement, return_statement, while_loop_statement, and_expression (“and” reserved word used within PL/SQL expressions), or_expression (“or” reserved word used within PL/SQL expressions), when_clause_expression (the “when” of simple_case_expression and searched_case_expression)\n| VB.NET | The complexity gets incremented by one for: method or constructor declaration (Sub, Function), `AndAlso`, `Case`, `Continue`, `End`, `Error`, `Exit`, `If`, `Loop`, `On Error`, `GoTo`, `OrElse`, `Resume`, `Stop`, `Throw`, `Try`.\n\n**Cognitive Complexity** (`cognitive_complexity`)  \nHow hard it is to understand the code's control flow. See [the Cognitive Complexity White Paper](https://www.sonarsource.com/resources/white-papers/cognitive-complexity.html) for a complete description of the mathematical model applied to compute this measure.\n\n---\n## Duplications\n**Duplicated blocks** (`duplicated_blocks`)  \nNumber of duplicated blocks of lines.\n\n[[collapse]]\n| ## Language-specific details\n| For a block of code to be considered as duplicated:\n|\n| Non-Java projects:  \n| * There should be at least 100 successive and duplicated tokens.\n| * Those tokens should be spread at least on:\n| * 30 lines of code for COBOL\n| * 20 lines of code for ABAP\n| * 10 lines of code for other languages\n|\n|Java projects:  \n| There should be at least 10 successive and duplicated statements whatever the number of tokens and lines. Differences in indentation and in string literals are ignored while detecting duplications.\n \n**Duplicated files** (`duplicated_files`)  \nNumber of files involved in duplications.\n\n**Duplicated lines** (`duplicated_lines`)  \nNumber of lines involved in duplications.\n\n**Duplicated lines (%)** (`duplicated_lines_density`)  \n= `duplicated_lines` / `lines` * 100\n\n---\n## Issues\n**New issues** (`new_violations`)  \nNumber of issues raised for the first time on New Code.\n\n**New xxx issues** (`new_xxx_violations`)  \nNumber of issues of the specified severity raised for the first time on New Code, where xxx is one of: `blocker`, `critical`, `major`, `minor`, `info`.\n\n**Issues** (`violations`)  \nTotal count of issues in all states.\n\n**xxx issues** (`xxx_violations`)  \nTotal count of issues of the specified severity, where xxx is one of: `blocker`, `critical`, `major`, `minor`, `info`.\n\n**False positive issues** (`false_positive_issues`)  \nTotal count of issues marked False Positive\n\n**Open issues** (`open_issues`)  \nTotal count of issues in the Open state.\n\n**Confirmed issues** (`confirmed_issues`)  \nTotal count of issues in the Confirmed state.\n\n**Reopened issues** (`reopened_issues`)  \nTotal count of issues in the Reopened state\n\n---\n## Maintainability\n**Code Smells** (`code_smells`)   \nTotal count of Code Smell issues.\n\n**New Code Smells** (`new_code_smells`)  \nTotal count of Code Smell issues raised for the first time on New Code.\n\n**Maintainability Rating** (`sqale_rating`)  \n(Formerly the SQALE rating.)\nRating given to your project related to the value of your Technical Debt Ratio. The default Maintainability Rating grid is:\n\nA=0-0.05, B=0.06-0.1, C=0.11-0.20, D=0.21-0.5, E=0.51-1\n\nThe Maintainability Rating scale can be alternately stated by saying that if the outstanding remediation cost is:\n\n* <=5% of the time that has already gone into the application, the rating is A\n* between 6 to 10% the rating is a B\n* between 11 to 20% the rating is a C\n* between 21 to 50% the rating is a D\n* anything over 50% is an E\n\n**Technical Debt** (`sqale_index`)  \nEffort to fix all Code Smells. The measure is stored in minutes in the database. An 8-hour day is assumed when values are shown in days.\n\n**Technical Debt on New Code** (`new_technical_debt`)  \nEffort to fix all Code Smells raised for the first time on New Code.\n\n**Technical Debt Ratio** (`sqale_debt_ratio`)  \nRatio between the cost to develop the software and the cost to fix it. The Technical Debt Ratio formula is:  \n\t`Remediation cost / Development cost`  \nWhich can be restated as:  \n\t`Remediation cost / (Cost to develop 1 line of code * Number of lines of code)`  \nThe value of the cost to develop a line of code is 0.06 days.\n\n**Technical Debt Ratio on New Code** (`new_sqale_debt_ratio`)  \nRatio between the cost to develop the code changed on New Code and the cost of the issues linked to it.\n\n---\n## Quality Gates\n**Quality Gate Status** (`alert_status`)  \nState of the Quality Gate associated to your Project. Possible values are : `ERROR`, `OK`\nWARN value has been removed since 7.6.\n\n**Quality Gate Details** (`quality_gate_details`)  \nFor all the conditions of your Quality Gate, you know which condition is failing and which is not.\n\n---\n## Reliability\n**Bugs** (`bugs`)  \nNumber of bug issues.\n\n**New Bugs** (`new_bugs`)  \nNumber of new bug issues.\n\n**Reliability Rating** (`reliability_rating`)  \nA = 0 Bugs  \nB = at least 1 Minor Bug  \nC = at least 1 Major Bug  \nD = at least 1 Critical Bug  \nE = at least 1 Blocker Bug  \n\n**Reliability remediation effort** (`reliability_remediation_effort`)  \nEffort to fix all bug issues. The measure is stored in minutes in the DB. An 8-hour day is assumed when values are shown in days.\n\n**Reliability remediation effort on new code** (`new_reliability_remediation_effort`)  \nSame as _Reliability remediation effort_ but on the code changed on New Code.\n\n---\n## Security\n**Vulnerabilities** (`vulnerabilities`)  \nNumber of vulnerability issues.\n\n**Vulnerabilities on new code** (`new_vulnerabilities`)  \nNumber of new vulnerability issues.\n\n**Security Rating** (`security_rating`)  \nA = 0 Vulnerabilities  \nB = at least 1 Minor Vulnerability  \nC = at least 1 Major Vulnerability  \nD = at least 1 Critical Vulnerability  \nE = at least 1 Blocker Vulnerability  \n\n**Security remediation effort** (`security_remediation_effort`)  \nEffort to fix all vulnerability issues. The measure is stored in minutes in the DB. An 8-hour day is assumed when values are shown in days.\n\n**Security remediation effort on new code** (`new_security_remediation_effort`)  \nSame as _Security remediation effort_ but on the code changed on New Code.\n\n**Security Hotspots** (`security_hotspots`)\nNumber of Security Hotspots\n\n**Security Hotspots on new code** (`new_security_hotspots`)\nNumber of new Security Hotspots on New Code.\n\n**Security Review Rating** (`security_review_rating`)\n\nThe Security Review Rating is a letter grade based on the percentage of Reviewed (Fixed or Safe) Security Hotspots.\t\n\nA = >= 80%  \nB = >= 70% and <80%  \nC = >= 50% and <70%  \nD = >= 30% and <50%  \nE = < 30%  \n\n**Security Review Rating on new code** (`new_security_review_rating`)\n\nSecurity Review Rating for New Code.\n\n**Security Hotspots Reviewed** (`security_hotspots_reviewed`)\n\nPercentage of Reviewed (Fixed or Safe) Security Hotspots.\n\nRatio Formula: \n`Number of Reviewed (Fixed or Safe) Hotspots x 100 / (To_Review Hotspots + Reviewed Hotspots)`\n\n**New Security Hotspots Reviewed**\n\nPercentage of Reviewed Security Hotspots (Fixed or Safe) on New Code.\n\n---\n## Size\n**Classes** (`classes`)  \nNumber of classes (including nested classes, interfaces, enums and annotations).\n\n**Comment lines** (`comment_lines`)  \nNumber of lines containing either comment or commented-out code.\n\nNon-significant comment lines (empty comment lines, comment lines containing only special characters, etc.) do not increase the number of comment lines.\n\nThe following piece of code contains 9 comment lines:\n```\n/**                                    +0 => empty comment line\n *                                     +0 => empty comment line\n * This is my documentation            +1 => significant comment\n * although I don't                    +1 => significant comment\n * have much                           +1 => significant comment\n * to say                              +1 => significant comment\n *                                     +0 => empty comment line\n ***************************           +0 => non-significant comment\n *                                     +0 => empty comment line\n * blabla...                           +1 => significant comment\n */                                    +0 => empty comment line\n  \n/**                                    +0 => empty comment line\n * public String foo() {               +1 => commented-out code\n *   System.out.println(message);      +1 => commented-out code\n *   return message;                   +1 => commented-out code\n * }                                   +1 => commented-out code\n */                                    +0 => empty comment line\n ```\n[[collapse]]\n| ## Language-specific details\n| Language | Note\n| ---|---\n| COBOL | Lines containing the following instructions are counted both as comments and lines of code: `AUTHOR`, `INSTALLATION`, `DATE-COMPILED`, `DATE-WRITTEN`, `SECURITY`.\n| Java | File headers are not counted as comment lines (becuase they usually define the license).\n\n**Comments (%)** (`comment_lines_density`)  \nDensity of comment lines = Comment lines / (Lines of code + Comment lines) * 100\n\nWith such a formula:\n* 50% means that the number of lines of code equals the number of comment lines  \n* 100% means that the file only contains comment lines  \n\n**Directories** (`directories`)  \nNumber of directories.\n\n**Files** (`files`)  \nNumber of files.\n\n**Lines** (`lines`)  \nNumber of physical lines (number of carriage returns).\n\n**Lines of code** (`ncloc`)  \nNumber of physical lines that contain at least one character which is neither a whitespace nor a tabulation nor part of a comment.\n[[collapse]]\n| ## Language-specific details\n| Language | Note\n| --- | ---\n| COBOL | Generated lines of code and pre-processing instructions (`SKIP1`, `SKIP2`, `SKIP3`, `COPY`, `EJECT`, `REPLACE`) are not counted as lines of code.\n\n**Lines of code per language** (`ncloc_language_distribution`)  \nNon Commenting Lines of Code Distributed By Language\n\n**Functions** (`functions`)  \nNumber of functions. Depending on the language, a function is either a function or a method or a paragraph.\n[[collapse]]\n| ## Language-specific details\n| Language | Note\n| ---|---\n| COBOL | It is the number of paragraphs.\n| Java | Methods in anonymous classes are ignored.\n| VB.NET | Accesors are not considered to be methods.\n\n**Projects** (`projects`)  \nNumber of projects in a Portfolio.\n\n**Statements** (`statements`)  \nNumber of statements.\n\n---\n## Tests\n**Condition coverage** (`branch_coverage`)  \nOn each line of code containing some boolean expressions, the condition coverage simply answers the following question: 'Has each boolean expression been evaluated both to true and false?'. This is the density of possible conditions in flow control structures that have been followed during unit tests execution.\n\n`Condition coverage = (CT + CF) / (2*B)`   \nwhere  \n* CT = conditions that have been evaluated to 'true' at least once\n* CF = conditions that have been evaluated to 'false' at least once\n* B = total number of conditions\n\n**Condition coverage on new code** (`new_branch_coverage`)  \nIdentical to Condition coverage but restricted to new / updated source code.\n\n**Condition coverage hits** (`branch_coverage_hits_data`)  \nList of covered conditions.\n\n**Conditions by line** (`conditions_by_line`)  \nNumber of conditions by line.\n\n**Covered conditions by line** (`covered_conditions_by_line`)  \nNumber of covered conditions by line.\n\n**Coverage** (`coverage`)  \nIt is a mix of Line coverage and Condition coverage. Its goal is to provide an even more accurate answer to the following question: How much of the source code has been covered by the unit tests?\n\n`Coverage = (CT + CF + LC)/(2*B + EL)`  \nwhere  \n* CT = conditions that have been evaluated to 'true' at least once\n* CF = conditions that have been evaluated to 'false' at least once\n* LC = covered lines = lines_to_cover - uncovered_lines\n* B = total number of conditions\n* EL = total number of executable lines (`lines_to_cover`)\n\n**Coverage on new code** (`new_coverage`)  \nIdentical to Coverage but restricted to new / updated source code.\n\n**Line coverage** (`line_coverage`)  \nOn a given line of code, Line coverage simply answers the following question: Has this line of code been executed during the execution of the unit tests?. It is the density of covered lines by unit tests:\n\n`Line coverage = LC / EL`  \nwhere\n* LC = covered lines (`lines_to_cover` - `uncovered_lines`)\n* EL = total number of executable lines (`lines_to_cover`)\n\n**Line coverage on new code** (`new_line_coverage`)  \nIdentical to Line coverage but restricted to new / updated source code.\n\n**Line coverage hits** (`coverage_line_hits_data`)  \nList of covered lines.\n\n**Lines to cover** (`lines_to_cover`)  \nNumber of lines of code which could be covered by unit tests (for example, blank lines or full comments lines are not considered as lines to cover).\n\n**Lines to cover on new code** (`new_lines_to_cover`)  \nIdentical to Lines to cover but restricted to new / updated source code.\n\n**Skipped unit tests** (`skipped_tests`)  \nNumber of skipped unit tests.\n\n**Uncovered conditions** (`uncovered_conditions`)  \nNumber of conditions which are not covered by unit tests.\n\n**Uncovered conditions on new code** (`new_uncovered_conditions`)  \nIdentical to Uncovered conditions but restricted to new / updated source code.\n\n**Uncovered lines** (`uncovered_lines`)  \nNumber of lines of code which are not covered by unit tests.\n\n**Uncovered lines on new code** (`new_uncovered_lines`)  \nIdentical to Uncovered lines but restricted to new / updated source code.\n\n**Unit tests** (`tests`)  \nNumber of unit tests.\n\n**Unit tests duration** (`test_execution_time`)  \nTime required to execute all the unit tests.\n\n**Unit test errors** (`test_errors`)  \nNumber of unit tests that have failed.\n\n**Unit test failures** (`test_failures`)  \nNumber of unit tests that have failed with an unexpected exception.\n\n**Unit test success density (%)** (`test_success_density`)  \n`Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100`\n"},{path:"user-guide/portfolios",content:'---\ntitle: Portfolios\nurl: /user-guide/portfolios/\n---\n\n*Portfolios are available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html).*\n\n## Portfolios Home Page\n\nThe Portfolio Home Page is the central place for managers and tech leads to keep an eye on the Releasability of the projects under their supervision. Releasability is based on the project\'s quality gate: Passed is releasable and Failed is not. Each Portfolio home page offers an aggregate view of the releasability of all projects in the Portfolio.\n\nAt the top of the page, you can easily see whether the overall Portfolio is currently rated as releasable and if any projects in the Portfolio have failed their Quality Gate. And the Reliability, Security Vulnerabilities, Security Review, and Maintainability ratings show the overall health of the Portfolio in these three domains, along with an indicator of the worst-performing project(s) in each domain. Note that Portfolios only focus on projects\' main branches.\n\nFor each domain, you\'ll see:\n\n* the rating (see [Metric Definitions](/user-guide/metric-definitions/) for more details about how they are computed)\n* an indicator of when the rating last changed\n* an indicator of the worst-performing project(s) in the domain\n\n## Releasability Rating\n\nThe Releasability rating is the ratio of projects in the Portfolio that have a **Passed** Quality Gate:\n\n**A**: > 80%  \n**B**: > 60%  \n**C**: > 40%  \n**D**: > 20%  \n**E**: <= 20%  \n\n## Reliability, Security Vulnerabilities, Security Review, and Maintainability Ratings\n\nThe Reliability, Security Vulnerabilities, Security Review, and Maintainability ratings for a Portfolio are calculated as the average of the ratings for all projects included in the Portfolio. \n\nSonarQube converts each project\'s letter rating to a number (see conversion table below), calculates an average number for the projects in the portfolio, and converts that average to a letter rating. Averages ending with .5 are rounded up resulting in the "lower" of the two possible ratings, so an average of 2.5 would be rounded up to 3 and result in a "C" rating).\n\nThis gives an "problem density" measure on the four axes of Reliability, Security Vulnerabilities, Security Review, and Maintainability for your Portfolio.\n\nRating conversion:\n\n**E**: 5  \n**D**: 4  \n**C**: 3  \n**B**: 2  \n**A**: 1  \n\n*Note: the Portfolio Home Page is also available at Sub-Portfolio level*\n\n## Portfolio PDF Report\n\nOn a Portfolio Home Page, you can download a PDF overview of the Portfolio by selecting **Download as PDF** from the "Portfolio PDF Report" dropdown menu in the upper-right corner. This is really convenient, for example, if you\'re going into a meeting where you may not have access to your SonarQube instance.\n\nYou can subscribe to receive a PDF by email by selecting **Subscribe** from the "Portfolio PDF Report" dropdown. You can set the frequency of the report at the portfolio and global levels to **daily**, **weekly**, or **monthly**. The default frequency is monthly.\n\n**Note:** You will only receive the PDF if the Portfolio is computed.\n\nPortfolios are created and edited in the global Portfolio administration interface: **Administration > Configuration > Portfolios**. For more information, see [Managing Portfolios](/project-administration/managing-portfolios/).'},{path:"user-guide/project-page",content:"---\ntitle: Project Page\nurl: /user-guide/project-page/\n---\n\n\nThe Project Hompepage is the entry point of any project showing:\n* the releasability status of the project\n* the current state of its quality\n* the quality of what has been produced since the start of the [New Code](/user-guide/clean-as-you-code/).\n \n\nThe Project Page answers two questions:\n* can I release my project today?\n* if not, what should I improve to make the project pass the Quality Gate? \n\n## Can I release today?\n\nSince the [Quality Gate](/user-guide/quality-gates/) is your most powerful tool to enforce your quality policy, the page starts with the project's current Quality Gate status. If the project passes, a simple, green all-clear is shown.\n\nIf not, details and drill-downs are immediately available to quickly identify what went wrong, with a section for each error condition showing what the current project value is and what it should be. As usual, you'll be able to click through on current values to get to drilldowns.\n\n## What should I fix first?\nBecause the best way to improve a project's quality is to catch and fix new problems before they become entrenched, the first view of a project is centered around New Code, which is highlighted in yellow on the right of the project homepage. The project space page shows a high-level summary of critical metrics, both current values and their New Code values.\n\nJust below the Quality Gate information, you have the numbers of old and new Issues in the Reliability and Security domains and then the Maintainability domain. Clicking on any figure on the page will take you to a detailed view, either in the Measures Page or the Issues Page.\n\nThe most important thing a developer must do is to ensure the new Issues in the yellow part of the screen are acknowledged, reviewed and fixed and to make sure that new code is covered by tests to help prevent future regressions. Regardless of how many Issues were introduced in the past or how little test coverage there is overall, a focus on the newly added Issues will ensure that the situation won't degrade versus the version you previously released in production.\n\nSo, which issues should you go after first: Bugs, Vulnerabilities or Code Smells? It depends, because the answer is dependent on the nature of your Issues. Let's say you have issues for a block of code that is duplicated 5 times, and inside this duplicated block of code, you have 3 Bugs and 5 Security Issues. The best approach is probably to fix the duplication first and then resolve the Bugs and Vulnerabilities in the newly centralized location, rather than fixing them 5 times.\n\nThat's why you need to review your new Issues before jumping into resolving them. \n\n## How can I ...\n### How can I see project measures at a lower level?\nThe project-level **Measures** menu item takes you to a dedicated sub-space where you see all project measures. Choose a measure for more details. Both list and tree views are available for each measure, and treemaps are available for percentages and ratings.\n\n### How can I see all the issues in a project?\nThe project-level **Issues** menu item takes you to a project-specific Issues page, where you can perform all the same actions you can at the higher level.\nOn this page, you can easily narrow the list to the New Issues as set by your New Code definition, by selecting `New Code` in **Creation Date** facet.\n\n### How can I see the project structure and code?\nThe project-level **Code** menu item takes you to an outline of your project structure. Drill down to see files in a directory, and choose a file to see its code.\n\nIf your project is too large for easy exploration via drilling, the search feature on this page will help. While the global search in the main menu returns results from throughout the {instance} instance, the localized search on the code page is restricted to files and directories in the current project.\n\n### How can I see the project activity / history?\nThe project-level **Activity** menu item takes you to the full list of code scans performed on your project since it was created in {instance}. By going there you can follow the evolution of the Quality Gate, see the changes of Quality Profiles and know when a given version of your code has been scanned.\n\n### How can I easily spot the risks in a project?\nVisualizations allow you to compare project components and quickly spot the ones that represent the greatest risks. The **Activity** page offers several pre-defined visualizations, and you can also create Custom visualizations with the metrics of your choice.\n\n### How can I promote the health of my project to peers ?\nIf your project is publicly visible, then you can further promote its status in external tools and websites using native Project Badges. The **Get project badges** button on the homepage of a public project lets you choose/fine-tune your badge and gives you the URL for it.\n"},{path:"user-guide/quality-gates",content:"---\ntitle: Quality Gates\nurl: /user-guide/quality-gates/\n---\n\n## Overview\n\nQuality Gates enforce a quality policy in your organization by answering one question: is my project ready for release?\n\nTo answer this question, you define a set of conditions against which projects are measured. For example:\n\n* No new blocker issues\n* Code coverage on new code greater than 80%\n\nSee the **Defining Quality Gates** section below for more information on defining conditions.\n\nIdeally, all projects will use the same quality gate, but that's not always practical. For instance, you may find that:\n\n* Technological implementation differs from one application to another (you might not require the same code coverage on new code for Web or Java applications).\n* You want to ensure stronger requirements on some of your applications (internal frameworks for example).\n\nWhich is why you can define as many quality gates as you need. You can access the **[Quality Gates](/#sonarqube#/quality_gates)** page from the top menu. From here you can define and manage your Quality Gates.\n\n## Use the best Quality Gate configuration\n\nThe \"Sonar way\" Quality Gate is provided by SonarSource, activated by default, and considered as built-in and read-only. This Quality Gate represents the best way to implement the [Clean as You Code](/user-guide/clean-as-you-code/) concept by focusing on new code. With each SonarQube release, we automatically adjust this default quality gate according to SonarQube's capabilities.\n\nWith the Quality Gate, you can enforce ratings (reliability, security, security review, and maintainability) based on metrics on overall code and new code. These metrics are part of the default quality gate. Note that, while test code quality impacts your Quality Gate, it's only measured based on the maintainability and reliability metrics. Duplication and security issues aren't measured on test code.\n\nYou should adjust your quality gates so they provide clear feedback to developers looking at their project page.\n\nDon't forget that Quality Gate conditions must use differential values. For example, there's no point in checking an absolute value such as: `Number of Lines of Code is greater than 1000`.\n\n### Recommended Quality Gate\n\nWe recommend the built-in `Sonar way` quality gate for most projects. It focuses on keeping new code clean, rather than spending a lot of effort remediating old code. Out of the box, it's already set as the default profile.\n\n## Quality Gate status\n\nThe current status is displayed prominently at the top of the Project Page:\n\n![Quality Gate Status](/images/quality-gate-status.jpeg)\n\n## Getting notified when a Quality Gate fails\n\nThanks to the notification mechanism, users can be notified when a quality gate fails. To do so, subscribe to the **New quality gate status** notification either for all projects or a set of projects you're interested in.\n\n## Security\n\nQuality Gates can be accessed by any user (even anonymous users). All users can view every aspect of a quality gate.\n\nTo make changes (create, edit or delete) users must be granted the **Administer Quality Profiles and Gates** permission.\n\nA **project administrator** can choose which quality gates his/her project is associated with. See Project Settings for more.\n\n## Defining Quality Gates\n\nEach Quality Gate condition is a combination of:\n\n* a measure\n* a comparison operator\n* an error value\n\nFor instance, a condition might be:\n\n* measure: Blocker issue\n* comparison operator: >\n* error value: 0\n\nWhich can be stated as: No blocker issues.\n"},{path:"user-guide/rules",content:'---\ntitle: Rules\nurl: /user-guide/rules/\n---\n## Overview\nSonarQube executes rules on source code to generate issues. There are four types of rules:\n* Code Smell (Maintainability domain)\n* Bug (Reliability domain)\n* Vulnerability (Security domain)\n* Security Hotspot (Security domain)\n\nFor Code Smells and Bugs, zero false-positives are expected. At least this is the target so that developers don\'t have to wonder if a fix is required.\n\nFor Vulnerabilities, the target is to have more than 80% of issues be true-positives.\n\nSecurity Hotspot rules draw attention to code that is security-sensitive. It is expected that more than 80% of the issues will be quickly resolved as "Reviewed" after review by a developer.\n\nThe Rules page is the entry point where you can discover all the existing rules or create new ones based on provided templates.\n\n## Rules\n\nBy default, when entering the top menu item "Rules", you will see all the available rules installed on your SonarQube instance. You have the ability to narrow the selection based on search criteria in the left pane:\n\n* **Language**: the language to which a rule applies.\n* **Type**: Bug, Vulnerability, Code Smell or Security Hotspot rules.\n* **Tag**: it is possible to add tags to rules in order to classify them and to help discover them more easily.\n* **Repository**: the engine/analyzer that contributes rules to SonarQube.\n* **Default Severity**: the original severity of the rule - as defined by SonarQube.\n* **Status**: rules can have 3 different statuses:\n  * **Beta**: The rule has been recently implemented and we haven\'t gotten enough feedback from users yet, so there may be false positives or false negatives.\n  * **Deprecated**: The rule should no longer be used because a similar, but more powerful and accurate rule exists.\n  * **Ready**: The rule is ready to be used in production.\n* **Available Since**: date when a rule was first added on SonarQube. This is useful to list all the new rules since the last upgrade of a plugin for instance.\n* **Template**: display rule templates that allow to create custom rules (see later on this page).\n* **Quality Profile**: inclusion in or exclusion from a specific profile\n\nIf a Quality Profile is selected, it is also possible to check for its active severity and whether it is inherited or not. See the Quality Profile documentation for more.\n\n## Rule Details\n\nTo see the details of a rule, either click on it, or use the right arrow key. Along with basic rule data, you\'ll also be able to see which, if any, profiles it\'s active in and how many open issues have been raised with it.\n\nThe following actions are available only if you have the right permissions ("Administer Quality Profiles and Gates"):\n\n* **Add/Remove Tags**:\n  * It is possible to add existing tags on a rule, or to create new ones (just enter a new name while typing in the text field).\n  * Note that some rules have built-in tags that you cannot remove - they are provided by the plugins which contribute the rules.\n* **Extend Description**:\n  * You can extend rule descriptions to let users know how your organization is using a particular rule or to give more insight on a rule.\n  * Note that the extension will be available to non-admin users as a normal part of the rule details.\n\n\x3c!-- sonarqube --\x3e\n## Rule Templates and Custom Rules\n\nRule Templates are provided by plugins as a basis for users to define their own custom rules in {instance}. To find templates, select the **Show Templates Only** facet from the the "Template" dropdown:\n\n![Rule templates.](/images/rule-templates.png)\n\nTo create a custom rule from a template click the **Create** button next to the "Custom Rules" heading and fill in the following information:\n* Name\n* Key (auto-suggested)\n* Description (Markdown format is supported)\n* Default Severity\n* Status\n* The parameters specified by the template\n\nYou can navigate from a template to the details of custom rules defined from it by clicking the link in the "Custom Rules" section.\n\n![Rule template details.](/images/rule-template-details.png)\n\n### Custom Rules\nCustom Rules are considered like any other rule, except that you can edit or delete them:\n\n![Custom rules.](/images/rules-custom.png)\n\n**Note:** When deleting a custom rule, it is not physically removed from the {instance} instance. Instead, its status is set to "REMOVED". This allows current or old issues related to this rule to be displayed properly in {instance} until they are fully removed.\n\n## Extending Coding Rules\n\nCustom coding rules can be added. See [Adding Coding Rules](/extend/adding-coding-rules/) for detailed information and tutorials.\n\x3c!-- /sonarqube --\x3e\n\n## Rule Types and Severities\n\n### How are rules categorized?\n\nThe {instance} Quality Model divides rules into four categories: Bugs, Vulnerabilities, Security Hotspots, and Code Smells. Rules are assigned to categories based on the answers to these questions:\n\n**Is the rule about code that is demonstrably wrong, or more likely wrong than not?**  \nIf the answer is "yes", then it\'s a Bug rule.  \nIf not...\n\n**Is the rule about code that could be exploited by a hacker?**  \nIf so, then it\'s a Vulnerability rule.  \nIf not...\n\n**Is the rule about code that is security-sensitive?**  \nIf so, then it\'s a Security Hotspot rule.  \nIf not...\n\n**Is the rule neither a Bug nor a Vulnerability?**  \nIf so, then it\'s a Code Smell rule.\n\n## How are severities assigned?\nTo assign severity to a rule, we ask a further series of questions. The first one is basically:\n\n**What\'s the worst thing that could happen?**\n\nIn answering this question, we try to factor in Murphy\'s Law without predicting Armageddon.\n\nThen we assess whether the impact and likelihood of the Worst Thing (see _How are severity and likelihood decided?_, below) are high or low, and plug the answers into a truth table:\n\n|          | Impact                 | Likelihood             |\n| -------- | ---------------------- | ---------------------- |\n| Blocker  | ![](/images/check.svg) | ![](/images/check.svg) |\n| Critical | ![](/images/check.svg) | ![](/images/cross.svg) |\n| Major    | ![](/images/cross.svg) | ![](/images/check.svg) |\n| Minor    | ![](/images/cross.svg) | ![](/images/cross.svg) |\n\n## How are severity and likelihood decided?\nTo assess the severity of a rule, we start from the Worst Thing (see _How are severities assigned?_, above) and ask category-specific questions.\n\n### Bugs\nImpact: **Could the Worst Thing cause the application to crash or to corrupt stored data?**\n\nLikelihood: **What\'s the probability that the Worst Thing will happen?**\n\n### Vulnerabilities\nImpact: **Could the exploitation of the Worst Thing result in significant damage to your assets or your users?**\n\nLikelihood: **What is the probability that a hacker will be able to exploit the Worst Thing?**\n\n### Security Hotspots\nSecurity Hotspots are not assigned severities as it is unknown whether there is truly an underlying vulnerability until they are reviewed.\n'},{path:"user-guide/security-hotspots",content:"---\ntitle: Security Hotspots\nurl: /user-guide/security-hotspots/\n---\n\n## What is a Security Hotspot?\nA Security Hotspot highlights a security-sensitive piece of code that the developer needs to review. Upon review, you'll either find there is no threat or you need to apply a fix to secure the code. \n\nAnother way of looking at hotspots may be [the concept of defense in depth](https://en.wikipedia.org/wiki/Defense_in_depth_(computing)) in which several redundant protection layers are placed in an application so that it becomes more resilient in the event of an attack.\n\n## Vulnerability or Hotspot?\nThe main difference between a hotspot and a vulnerability is **the need of a review** before deciding whether to apply a fix:\n\n* With a Hotspot, a security-sensitive piece of code is highlighted, but the overall application security may not be impacted. It's up to the developer to review the code to determine whether or not a fix is needed to secure the code.\n* With a vulnerability, a problem that impacts the application's security has been discovered that needs to be fixed immediately.\n\nAn example is the [RSPEC-2092](https://jira.sonarsource.com/browse/RSPEC-2092) where the use of *cookie secure flag* is recommended to prevent cookies from being sent over non-HTTPS connections but a review is needed because:\n* HTTPS is the main protection against MITM attacks and so the secure flag is only an additional protection in case of some failures of network security. \n* The cookie may be designed to be sent everywhere (non-HTTPS websites included) because it's a tracking cookie or similar.\n\nWith hotspots we try to give some freedom to users and to educate them on how to choose the most relevant/appropriate protections depending on the context (budget, threats, etc).\n\n## Why are Security Hotspots Important?\nWhile the need to fix individual hotspots depends on the context, you should view Security Hotspots as an essential part of improving an application's robustness. The more fixed hotspots there are, the more secure your code is in the event of an attack. Reviewing Security Hotspots allows you to:\n\n* **Understand the risk** – Understanding when and why you need to apply a fix in order to reduce an information security risk (threats and impacts).\n* **Identify protections** – While reviewing Hotspots, you'll see how to avoid writing code that's at risk, determine which fixes are in place, and determine which fixes still need to be implemented to fix the highlighted code.\n* **Identify impacts** – With hotspots you'll learn how to apply fixes to secure your code based on the impact on overall application security. Recommended secure coding practices are included on the Hotspots page to assist you during your review.\n\n## Lifecycle\nSecurity Hotspots have a dedicated lifecycle. To make status changes, the user needs the **Administer Security Hotspots** permission. This permission is enabled by default. Users with the **Browse** permission can comment on or change the user assigned to a Security Hotspot.\n\n### Statuses  \nThrough the lifecycle, a Security Hotspot takes one of the following statuses:\n\n* **To Review** – the default status of new Security Hotspots set by SonarQube. A Security Hotspot has been reported and needs to be checked.\n* **Reviewed** – a developer has manually assessed the Security Hotspot and decided whether or not to apply a fix.\n\n## Workflow  \nFollow this workflow to review Security Hotspots and apply any fixes needed to secure your code.\n\n### Review Priority\nWhen SonarQube detects a Security Hotspot, it's added to the list of Security Hotspots according to its review priority from High to Low. Hotspots with a High Review Priority are the most likely to contain code that needs to be secured and require your attention first. \n\nReview Priority is determined by the security category of each security rule. Rules in categories that are ranked high on the OWASP Top 10 and CWE Top 25 standards are considered to have a High Review Priority. Rules in categories that aren't ranked high or aren't mentioned on the OWASP Top 10 or CWE Top 25 standards are rated as Medium or Low.\n\n### Reviewing Hotspots  \nWhen reviewing a Hotspot, you should:\n\n1. Review the **What's the risk** tab to understand why the Security Hotspot was raised.\n1. From the **Are you at risk** tab, read the **Ask Yourself Whether** section to determine if you need to apply a fix to secure the code highlighted in the Hotspot.\n1. From the **How can you fix it** tab, follow the **Recommended Secure Coding Practices** to fix your code if you've determined it's unsafe.\n\nAfter following these steps, set the Security Hotspot to one of the following:\n\n* **Fixed** – if you have applied a fix to secure the code highlighted by the Hotspot.\n* **Safe** – if the code is already secure and doesn't need to be fixed. (for example, other more relevant protections are already in place).\n* **To review** – if you need another user's review.\n\n### Review History\n\nThe **Review history** tab shows the history of the Security Hotspot including the status it's been assigned and any comments the reviewer had regarding the Hotspot.\n\n### Reviewing Hotspots in your IDE\n\nSeeing a Security Hotspot directly in the IDE can help you better understand its context and decide whether it is safe or not. This is the purpose of the **Open in IDE** button that you'll see as an authenticated user.\n\nThis feature is available to users of:\n* [SonarLint for Visual Studio](https://www.sonarlint.org/visualstudio) 4.29 and above \n* [SonarLint for IntelliJ](https://www.sonarlint.org/intellij) 4.13 and above\n* [SonarLint for VS Code](https://www.sonarlint.org/vscode) 1.20 and above\n* [SonarLint for Eclipse](https://www.sonarlint.org/eclipse) 5.7 and above\n\nThe project needs to be open in the appropriate IDE and bound to the server through SonarLint's connected mode.\n\nKeep in mind that the revision or branch analyzed by SonarQube may not be the same as what you have opened in the IDE. In this case, SonarLint will do its best to locate the Security Hotspot in your local code.\n"},{path:"user-guide/security-reports",content:"---\ntitle: Security Reports\nurl: /user-guide/security-reports/\n---\n\n*Security Reports are available starting in [Enterprise Edition](https://redirect.sonarsource.com/editions/enterprise.html).*\n\n## What do Security Reports show?\nSecurity Reports quickly give you the big picture on your application's security, with breakdowns of just where you stand in regard to each of the [OWASP Top 10](https://www.owasp.org/index.php/Top_10-2017_Top_10), both [CWE Top 25 2019](https://cwe.mitre.org/top25/archive/2019/2019_cwe_top25.html) and [CWE Top 25 2020](https://cwe.mitre.org/top25/archive/2020/2020_cwe_top25.html), and [CWE](https://cwe.mitre.org/) -specific details.\n\n[[warning]]\n| The SANS Top 25 report is based on outdated statistics and should no longer be used. Instead, we recommend using the CWE Top 25 reports.\n\nSecurity Reports rely on the rules activated in your Quality Profiles to raise security issues. If there are no rules corresponding to a given OWASP category activated in your Quality Profile, you won't get issues linked to that specific category and the rating displayed will be **A**. That doesn't mean you are safe for that category, but that you need to activate more rules (assuming some exist) in your Quality Profile.\n\n## What's the difference between a Security Hotspot and a Vulnerability?\n\nSecurity Hotspots and Vulnerabilities differ in that:\n\n* A Security Hotspot is a security-sensitive piece of code that is highlighted but doesn't necessarily impact the overall application security. It's up to the developer to review the code to determine whether or not a fix is needed to secure the code.\n* A vulnerability is a problem that impacts the application's security that needs to be fixed immediately.\n\nFor more details, see the [Security Hotspots](/user-guide/security-hotspots/) page. \n\n## Why don't I see any Vulnerabilities or Security Hotspots?\nYou might not see any Vulnerabilities or Security Hotspots for the following reasons:\n* Your code has been written without using any security-sensitive API. \n* Vulnerability or Security Hotspot rules are available but not activated in your Quality Profile so no Security Hotspots or Vulnerabilities are raised.\n* SonarQube might not currently have many rules for your language, so it won't raise any or only a few Vulnerabilities or Security Hotspots.\n\n## Downloading a PDF copy\nYou can download a PDF copy of your Security Reports by clicking the **Download as PDF** button in the upper-right corner of the **Security Reports** page. \n\nThe PDF contains:\n\n- the number of open Vulnerabilities and the Security Rating on both overall code and new code.\n- the number of Security Hotspots, the percentage of reviewed Security Hotspots, and the Security Review rating on both overall and new code. \n- your SonarSource, OWASP Top 10, and CWE Top 25 2020 reports."},{path:"user-guide/security-rules",content:"---\ntitle: Security-related Rules\nurl: /user-guide/security-rules/\n---\nThe {instance} Quality Model has four different types of rules: Reliability (bug), Maintainability (code smell), Security (vulnerability and hotspot) rules. There are a lot of expectations about security, so below we explain some key concepts and how the security rules differ from others.\n\n## What to expect from security-related rules\nAs with other types of rules, we try to raise no false positives: you should be confident that anything reported to you as an issue is really an issue.\n\nUnder the hood SonarQube is based on different representations of the source code and technologies in order to be able to detect any kind of security issue:\n* **Security-injection rules**: there is a vulnerability here when the inputs handled by your application are controlled by a user (potentially an attacker) and not validated or sanitized, when this occurs, the flow from sources (user-controlled inputs) to sinks (sensitive functions) will be presented. To do this, SonarQube uses well-known taint analysis technology on source code which allows, for example, the detection of:\n  * [CWE-89](https://cwe.mitre.org/data/definitions/89.html): SQL Injection\n  * [CWE-79](https://cwe.mitre.org/data/definitions/79.html): Cross-site Scripting\n  * [CWE-94](https://cwe.mitre.org/data/definitions/94.html): Code Injection\n* **Security-configuration rules**: here there is a security issue because the wrong parameter (eg: invalid cryptographic algorithm or TLS version) when calling a sensitive function has been set or when a check (eg: check_permissions() kind of function) was not done or not in the correct order, this problem is likely to appear often when the program is executed (no injected/complex attacks are required unlike in the previous category):\n  * [CWE-1004](https://cwe.mitre.org/data/definitions/1004.html): Sensitive Cookie Without 'HttpOnly' Flag\n  * [CWE-297](https://cwe.mitre.org/data/definitions/297.html): Improper Validation of Certificate with Host Mismatch\n  * [CWE-327](https://cwe.mitre.org/data/definitions/327.html): Use of a Broken or Risky Cryptographic Algorithm\n\nThese security issues are then divided into two categories: vulnerabilities and hotspots (see the main differences on the [Security Hotspots](/user-guide/security-hotspots/) page). Security Hotspots have been introduced for security protections that have no direct impact on the overall application's security. Most injection rules are vulnerabilities, for example, if a SQL injection is found, it is certain that a fix (input validation) is required, so this is a vulnerability. On the contrary, the *httpOnly* flag when creating a cookie is an additional protection desired (to reduce the impact when XSS vulnerabilities appear) but not always possible to implement or relevant depending on the context of the application, so it's a hotspot. \n\nWith Hotspots, we want to help developers understand information security risks, threats, impacts, root causes of security issues, and the choice of relevant software protections. In short, we really want to educate developers and help them develop secure, ethical, and privacy-friendly applications.\n\n## Which security-standards are covered?\nOur security rules are classified according to well-established security-standards such as:\n* [CWE](https://cwe.mitre.org/): SonarQube is a CWE compatible product [since 2015](https://cwe.mitre.org/compatible/questionnaires/33.html).\n* [OWASP Top 10 ](https://www.owasp.org/index.php/Top_10-2017_Top_10))\n* [SANS Top 25 - outdated](https://www.sans.org/top25-software-errors/)\n\nThe standards to which a rule relates will be listed in the **See** section at the bottom of the rule description. More generally, you can search for a rule on [rules.sonarsource.com](https://rules.sonarsource.com/):\n* [Java-vulnerability-issue-type](https://rules.sonarsource.com/java/type/Vulnerability): all vulnerability rules for Java language.\n* [Java-hotspots-issue-type](https://rules.sonarsource.com/java/type/Security%20Hotspot): all security-hotspot rules for Java language.\n* [Java-tag-injection](https://rules.sonarsource.com/java/tag/injection): all security-injection rules for Java language.\n\n## How to propose new security-rules?\nSecurity is a lively world where new types of attacks and vulnerabilities appear very often, so we welcome any suggestions for new security-rules. You can read the [adding coding rules](/extend/adding-coding-rules/) page to see how to develop a new rule or propose a new one [on our community forum](https://community.sonarsource.com/c/suggestions/rules/13).\n\nRegarding the security-injection rules mentioned above, it's possible to [extend the taint analysis configuration](/analysis/security_configuration/) to allow the SonarQube engine to use new sources, sanitizers, validators and sinks of the homemade-frameworks that you use. Security Engine Custom Configuration is available as part of the Enterprise Edition and above.\n"},{path:"user-guide/sonarlint-notifications",content:"---\ntitle: SonarLint Smart Notifications\nurl: /user-guide/sonarlint-notifications/\n---\n\nSmart notifications allow developers using Connected Mode in SonarLint to receive in-IDE notifications from SonarQube when:\n\n* the Quality Gate status (failed / success) of a project /solution _open in the IDE_ changes\n* a {instance} analysis raises new issues _introduced by this developer in a project /solution open in the IDE_\n\n## Activate/deactivate Notifications\nThe activation or deactivation of notifications must be done individually, by each developer directly in SonarLint (on the IDE side).\n\nReceiving notifications is configurable on the SonarLint side on a SonarQube server-by-server basis."},{path:"user-guide/user-account",content:"---\ntitle: Overview\nurl: /user-guide/user-account/\n---\n\nAs a {instance} user you have your own space where you can see the things that are relevant to you:\n\n## Profile\n\n\x3c!-- sonarqube --\x3e\n\nIt gives you a summary of:\n\n- your Groups\n- your SCM accounts\n\n## Security\n\nIf your instance is not using a 3rd party authentication mechanism such as LDAP or an OAuth provider (GitHub, Google Account, ...), you can change your password from here. Additionally, you can also manage your own authentication tokens.\n\nYou can create as many Tokens as you want. Once a Token is created, you can use it to perform analysis on a project where you have the [Execute Analysis](/instance-administration/security/) permission.\n\n\x3c!-- /sonarqube --\x3e\n\n\x3c!-- sonarcloud --\x3e\n\nIt gives you a summary of your SCM accounts and allows you to delete your account.\n\n## Security\n\nYou can create as many Tokens as you want. Once a Token is created, you can use it to perform analysis on a project where you have the [Execute Analysis](/instance-administration/security/) permission.\n\n## Organizations\n\nThis is an overview of all the organizations you are member of.\n\n## Delete your user account\n\nGo to [User > My Account > Profile](/#sonarcloud#/account) and click on **Delete**. Once your account is deleted, all you data will be removed except your login that will still be displayed in different places:\n\n- issues assignee\n- issues comments\n- issues changelog\n\nNote that you can manually unassign yourself from all your issues and/or remove your comments before deleting your account.\n\nThe information used to identify yourself in SCM (name, email) are part of the SCM data and can not be removed.\n\n\x3c!-- /sonarcloud --\x3e\n"},{path:"user-guide/user-token",content:"---\ntitle: Generating and Using Tokens\nurl: /user-guide/user-token/\n---\n\nUsers can generate tokens that can be used to run analyses or invoke web services without access to the user's actual credentials.\n\n## Generating a token\n\nYou can generate new tokens at **User > My Account > Security**.\n\nThe form at the bottom of the page allows you to generate new tokens. Once you click the **Generate** button, you will see the token value. Copy it immediately; once you dismiss the notification you will not be able to retrieve it.\n\n## Revoking a token\n\nYou can revoke an existing token at **User > My Account > Security** by clicking the **Revoke** button next to the token.\n\n## Using a token\n\nUser tokens must replace your normal login process in the following scenarios:\n\n* when running analyses on your code: replace your login with the token in the `sonar.login` property. \n* when invoking web services: just pass the token instead of your login while doing the basic authentication.\n\nIn both cases, you don't need to provide a password (so when running analyses on your code, the property `sonar.password` is optional). Using a token is the preferred method over using a login and password."},{path:"user-guide/visualizations",content:"---\ntitle: Visualizations\nurl: /user-guide/visualizations/\n---\nVisualizations are available to help you gain deeper insights into your projects' current statuses and histories.\n\n## How do I compare current state for multiple projects or project components?\nThe Projects space allows you to filter the projects in your instance by multiple, measure-based criteria. Once you've chosen your set, you don't have to stare at the raw numbers to identify the risks its projects face. Instead, several visualizations (**Projects > Perspective**) are available to help you understand each project's relative position in terms of each of the major axes:\n\n* Risk - Reliability and Security ratings, test coverage, technical debt, and lines of code\n* Reliability - Reliability rating, Reliability remediation effort, lines of code, and Bug count\n* Security - Security rating, Security remediation effort, lines of code, and Vulnerability count\n* Maintainability - Maintainability rating, Technical debt, lines of code, and Code Smell count\n* Coverage - Coverage, complexity, and uncovered lines\n* Duplications - Duplicated Lines %, lines of code, and duplicated blocks\n* At the project level these same visualizations are available in the Measures tab to help you compare project components. The Project Overview corresponds to the Risk visualization in the Projects space, For the other five graphs, choose the Overview option under the relevant domain.\n\nAdditionally, treemaps are also available for percentage and rating metrics at the project level. Navigate to them in the Measures tab using the perspective selector in the right pane.\n\n## How do I visualize metric history?\nAt the project level, the Activity tab offers several canned line graphs of selected metrics across time, with convenient mouseovers to show graph details and the ability to easily narrow the graph to a slice of the project's history. Beyond the canned graphs, you also have the ability to map the metrics of your choice against each other in a Custom graph.\n\n![](/images/visualizations.png)\n"}]},1666:function(e,n,t){var o=t(313),a=t(1667);"string"==typeof(a=a.__esModule?a.default:a)&&(a=[[e.i,a,""]]);var s={insert:"head",singleton:!1},i=(o(a,s),a.locals?a.locals:{});e.exports=i},1667:function(e,n,t){(n=t(314)(!1)).push([e.i,'.documentation-page-header{margin:10px 20px}.documentation-footer .page-footer-menu,.documentation-footer div{max-width:740px}.documentation-content{padding:32px 64px}.documentation-content.markdown{position:relative;font-size:16px;line-height:1.7}.documentation-content.markdown .documentation-title{font-size:24px;padding-top:8px;margin-bottom:2em}.documentation-content.markdown h2{font-size:18px;font-weight:800;margin-top:3em}.documentation-content.markdown h3{font-size:16px;margin-bottom:.8em}.documentation-content.markdown pre{border:1px solid #e6e6e6;border-radius:3px;background-color:rgba(0,0,0,.06)}.documentation-content.markdown .alert,.documentation-content.markdown p,.documentation-content.markdown pre,.documentation-content.markdown table{margin:.8em 0 2em}.documentation-content.markdown ul{margin:0 0 2em}.documentation-content.markdown ul>ul{margin:0}.documentation-content.markdown p+ol,.documentation-content.markdown p+pre,.documentation-content.markdown p+ul{margin:-1em 0 2em}.documentation-content.markdown li>p,.documentation-content.markdown li>p+ol,.documentation-content.markdown li>p+pre,.documentation-content.markdown li>p+ul{margin:0}.documentation-content.markdown img[src$=".svg"]{vertical-align:text-bottom}.documentation-content.markdown .alert{display:block;padding:8px 16px}.documentation-content.markdown .alert .custom-block-body{padding-left:24px;background-position:left 6px;background-repeat:no-repeat}.documentation-content.markdown .alert-success .custom-block-body{background-image:url(/images/check.svg)}.documentation-content.markdown .alert-info .custom-block-body{background-image:url(/images/info.svg)}.documentation-content.markdown .alert-warning .custom-block-body{background-image:url(/images/exclamation.svg)}.documentation-content.markdown .alert-danger .custom-block-body,.documentation-content.markdown .alert-error .custom-block-body{background-image:url(/images/cross.svg)}.documentation-content.markdown .collapse-container{border:1px solid #e6e6e6;border-radius:2px;background-color:#f3f3f3;padding:8px;margin:.8em 0 2em}.documentation-content.markdown .collapse-container>a:first-child{display:block}.documentation-content.markdown .collapse-container>a:first-child:focus{color:#236a97}.documentation-content.markdown .collapse-container :last-child{margin-bottom:0}.markdown.has-toc{display:flex}.markdown.has-toc .markdown-content{flex-shrink:1;overflow:hidden;text-overflow:ellipsis;overflow-x:auto}.markdown-toc{flex:0 0 240px;margin-right:-40px}.markdown-toc-content{margin-left:32px;padding:0 8px;font-size:13px;background:#fff;position:-webkit-sticky;position:sticky;top:68px}.markdown-toc-content h4{margin:0 8px 8px;font-size:14px}.markdown-toc-content a{display:block;color:#070706;padding:4px 8px;border:1px solid #fff;line-height:1.2;transition:none}.markdown-toc a:hover{border-color:#4b9fd5}.markdown-toc a.active{font-weight:700}',""]),e.exports=n},1844:function(e,n,t){"use strict";t.r(n),t.d(n,"default",(function(){return de}));var o=t(1076),a=t(2),s=t(335),i=t(318),r=t(319),l=t.n(r),c=t(31),u=t(427),d=t(402),h=t(639),p=t(9);var m=t(368),g=t(487),y=t(449),f=t(1160),b=t(1140),v=t(520),w=t(665),S=t.n(w);function k(e){return S()(e.map(e=>A(e)?k(e.children):C(e)?[e.url]:[e]))}function x(e,n){let t=[],o=!1;const a=(n,s=[])=>{o||(s=s.concat(n),A(n)?n.children.forEach(n=>{"string"==typeof n&&T(n,e)?(t=s.concat(n),o=!0):a(n,s)}):"string"==typeof n&&T(n,e)&&(t=s,o=!0))};return n.forEach(e=>a(e)),t}function A(e){return"object"==typeof e&&void 0!==e.children}function C(e){return"object"==typeof e&&void 0!==e.url}function T(e,n){const t=/^\//,o=/\/$/;return e.replace(t,"").replace(o,"")===n.replace(t,"").replace(o,"")}var P=t(752),j=t.n(P),E=t(751),I=t.n(E),R=t(1665);function O(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function N(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?O(Object(t),!0).forEach((function(n){M(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):O(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function M(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function D(e={}){const n=R.map(n=>{let t=Object(b.separateFrontMatter)(n.content);if(e[n.path]){const o=e[n.path];t={content:o.content,frontmatter:N({},t.frontmatter,{},o.frontmatter)},delete e[n.path]}return{parsed:t,file:n}});return Object.keys(e).forEach(t=>{const o=e[t];n.push({parsed:o,file:{content:o.content,path:t}})}),n.map(({parsed:e,file:n})=>{let t="",o="";try{t=Object(b.filterContent)(e.content),o=function(e){const n=j()().parse(e),t=[];return I()(n,e=>{"text"!==e.type&&"inlineCode"!==e.type||t.push(e.value)}),t.join(" ").replace(/\s+/g," ")}(t)}catch(t){console.error('Documentation - an error occured while parsing page "'.concat(e.frontmatter.url||n.path,'":'),t)}return{relativeName:n.path,url:e.frontmatter.url||"/".concat(n.path,"/"),title:e.frontmatter.title,navTitle:e.frontmatter.nav||void 0,order:Number(e.frontmatter.order||-1),scope:e.frontmatter.scope?e.frontmatter.scope.toLowerCase():void 0,text:o,content:t}})}t(1666);var L=t(355),q=t.n(L),Q=t(330),_=t.n(Q);function G(e,n){return e.find(e=>e.url===n)}function B(e){let n=0;for(let t=0;t<e.length;t++)if(/\s/.test(e[t])&&n++,6===n)return t<e.length-1?"".concat(e.substring(0,t),"..."):e;return e}function F(e){const n=[];let t=0;const o=e.findIndex(e=>e.marked);if(o>0){const a=function(e){let n=0;for(let t=e.length-1;t>=0;t--)if(/\s/.test(e[t])&&n++,6===n)return t>0?"...".concat(e.substring(t+1)):e;return e}(e[o-1].text);n.push({text:a,marked:!1}),t+=a.length}n.push(e[o]),t+=e[o].text.length;for(let a=o+1;a<e.length;a++){if(t+e[a].text.length>100){const t=B(e[a].text);return n.push({text:t,marked:!1}),n}n.push(e[a]),t+=e[a].text.length}return n}function H(e,n){const t=_()([...n.map(e=>({pos:e.from,start:!0})),...n.map(e=>({pos:e.to,start:!1}))],e=>e.pos,e=>Number(!e.start)),o=[];let a=0,s=0;for(const n of t)n.start?(0===s&&a!==n.pos&&(o.push({text:e.substring(a,n.pos),marked:!1}),a=n.pos),s++):(s--,0===s&&a!==n.pos&&(o.push({text:e.substring(a,n.pos),marked:!0}),a=n.pos));return a<e.length-1&&o.push({text:e.substr(a),marked:!1}),o}var z=t(311),U=t(312),W=t(453),J=t.n(W);function Y({depth:e=0,node:n,splat:t}){if(!n)return null;const o=T(n.url,t),s=Math.min(e,3);return a.createElement(i.c,{className:z("list-group-item",{active:o,["depth-".concat(s)]:e>0}),key:n.url,to:"/documentation"+n.url},a.createElement("h3",{className:"list-group-item-heading"},n.navTitle||n.title))}class V extends a.PureComponent{constructor(e){super(e),this.handleClick=()=>{this.setState(e=>({open:!e.open}))},this.renderMenuItems=e=>{const{depth:n=0,openChain:t,pages:o,splat:s}=this.props;return e.children.map(e=>"string"==typeof e?a.createElement(Y,{depth:n+1,key:e,node:G(o,e),splat:s}):A(e)?a.createElement(V,{block:e,depth:n+1,key:e.title,openByDefault:t.includes(e),openChain:t,pages:o,splat:s,title:e.title}):null)},this.state={open:void 0!==e.openByDefault&&e.openByDefault}}render(){const{block:e,depth:n=0,title:t}=this.props,{open:o}=this.state,s=Math.min(n,3);return a.createElement(a.Fragment,null,a.createElement(U.ButtonLink,{className:z("list-group-item",{["depth-".concat(s)]:n>0}),onClick:this.handleClick},a.createElement("h3",{className:"list-group-item-heading"},a.createElement(J.a,{className:"little-spacer-right",open:o}),t)),o&&this.renderMenuItems(e))}}var K=t(383),X=t.n(K);function $({title:e,url:n}){return a.createElement("a",{href:n,key:e,target:"_blank",rel:"noopener noreferrer"},a.createElement("h3",{className:"list-group-item-heading"},a.createElement(X.a,{className:"spacer-right"}),e))}class Z extends a.PureComponent{constructor(e){super(e),this.state={openChain:x(this.props.splat,this.props.navigation)}}componentWillReceiveProps(e){this.props.splat!==e.splat&&this.setState({openChain:x(e.splat,e.navigation)})}render(){const{openChain:e}=this.state;return a.createElement(a.Fragment,null,this.props.navigation.map(n=>A(n)?a.createElement(V,{block:n,key:n.title,openByDefault:e.includes(n),openChain:e,pages:this.props.pages,splat:this.props.splat,title:n.title}):C(n)?a.createElement($,{key:n.title,title:n.title,url:n.url}):a.createElement(Y,{key:n,node:G(this.props.pages,n),splat:this.props.splat})))}}var ee=t(1668),ne=t.n(ee);function te({active:e,result:n}){return a.createElement(i.c,{className:z("list-group-item",{active:e}),to:"/documentation"+n.page.url},a.createElement(oe,{result:n}),a.createElement(ae,{result:n}))}function oe({result:e}){let n;const t=e.highlights.title;if(t&&t.length>0){const{title:o}=e.page,s=H(o,t.map(e=>({from:e[0],to:e[0]+e[1]})));n=a.createElement(se,{tokens:s})}else n=e.page.title;return a.createElement("h3",{className:"list-group-item-heading",style:{fontWeight:"normal"}},n)}function ae({result:e}){const n=e.highlights.text,{text:t}=e.page;let o=[];if(e.exactMatch){const n=e.page.text.toLowerCase(),a=[];let s=0,i=n.indexOf(e.query,s),r=0;for(;i>-1&&r<10;)r++,a.push({from:i,to:i+e.query.length}),s=i+1,i=n.indexOf(e.query,s);a.length&&(o=H(t,a))}return 0===o.length&&n&&n.length>0&&(o=H(t,n.map(e=>({from:e[0],to:e[0]+e[1]})))),o.length?a.createElement("div",{className:"note"},a.createElement(se,{tokens:F(o)})):null}function se({tokens:e}){return a.createElement(a.Fragment,null,e.map((e,n)=>a.createElement(a.Fragment,{key:n},e.marked?a.createElement("mark",{key:n},e.text):e.text)))}class ie extends a.PureComponent{constructor(e){super(e),this.index=ne()((function(){this.use(re),this.ref("relativeName"),this.field("title",{boost:10}),this.field("text"),this.metadataWhitelist=["position","tokenContext"],e.pages.filter(n=>k(e.navigation).includes(n.url)).forEach(e=>this.add(e))}))}render(){const e=this.props.query.toLowerCase(),n=this.index.search(e.split(/\s+/).map(e=>"".concat(e,"~1 ").concat(e,"*")).join(" ")).map(n=>{const t=this.props.pages.find(e=>e.relativeName===n.ref);if(!t)return null;const o={};let a="",s=!1;return Object.keys(n.matchData.metadata).forEach(t=>{e.includes(t.toLowerCase())&&a.length<t.length&&(a=t),Object.keys(n.matchData.metadata[t]).forEach(a=>{const{position:i,tokenContext:r}=n.matchData.metadata[t][a];o[a]=[...o[a]||[],...i],!s&&r&&r.forEach(n=>{!s&&n.includes(e)&&(s=!0)})})}),{exactMatch:s,highlights:o,longestTerm:a,page:t,query:e}}).filter(d.isDefined),t=_()(_()(n,e=>-e.longestTerm.length),e=>e.exactMatch&&-1);return a.createElement(a.Fragment,null,t.map(e=>a.createElement(te,{active:e.page.relativeName===this.props.splat,key:e.page.relativeName,result:e})))}}function re(e){const n=(e,n,t)=>{const o=t[n-1]||"",a=t[n+1]||"";return e.metadata.tokenContext=[o.toString(),e.toString(),a.toString()].filter(e=>e.length).join(" ").toLowerCase(),e};ne.a.Pipeline.registerFunction(n,"tokenContext"),e.pipeline.before(ne.a.stemmer,n),e.metadataWhitelist.push("tokenContext")}class le extends a.PureComponent{constructor(){super(...arguments),this.state={query:""},this.handleSearch=e=>{this.setState({query:e.trim()})}}render(){return a.createElement(a.Fragment,null,a.createElement(q.a,{className:"big-spacer-top spacer-bottom",minLength:2,onChange:this.handleSearch,placeholder:"Search for pages or keywords",value:this.state.query}),a.createElement("div",{className:"documentation-results panel"},a.createElement("div",{className:"list-group"},this.state.query?a.createElement(ie,{navigation:this.props.navigation,pages:this.props.pages,query:this.state.query,splat:this.props.splat}):a.createElement(Z,{navigation:this.props.navigation,pages:this.props.pages,splat:this.props.splat}))))}}function ce(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function ue(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}class de extends a.PureComponent{constructor(){super(...arguments),this.mounted=!1,this.state={loading:!1,pages:[],tree:[]},this.getLanguagePluginsDocumentation=async e=>{const n=await Object(h.c)(v.a.Bundled).catch(()=>[]),t=await Promise.all(n.map(e=>{if(e.documentationPath){const o=/^static\/(.*)/.exec(e.documentationPath);if(o&&o.length>1)return(n=e.key,t=o[1],Object(p.request)("/static/".concat(n,"/").concat(t)).submit().then(p.checkStatus).then(e=>e.text())).then(n=>function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?ce(Object(t),!0).forEach((function(n){ue(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):ce(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}({},e,{content:n}),()=>{})}var n,t})),o=new RegExp("/".concat("analysis/languages","/\\w+/$")),a=k(e).filter(e=>o.test(e)&&e!=="/".concat("analysis/languages","/overview/")),s={};return t.filter(d.isDefined).forEach(e=>{var n;const t=Object(b.separateFrontMatter)(e.content);if(e.issueTrackerUrl){let n="## Issue Tracker";n+="\r\n",n+="Check the [issue tracker](".concat(e.issueTrackerUrl,") for this language."),t.content="".concat(t.content,"\r\n").concat(n)}(null===(n=null==t?void 0:t.frontmatter)||void 0===n?void 0:n.key)&&a.includes("/".concat("analysis/languages","/").concat(t.frontmatter.key,"/"))&&(s["".concat("analysis/languages","/").concat(t.frontmatter.key)]=t)}),s}}componentDidMount(){this.mounted=!0,Object(u.addSideBarClass)(),this.setState({loading:!0});const e=o;this.getLanguagePluginsDocumentation(e).then(n=>{this.mounted&&this.setState({loading:!1,pages:D(n),tree:e})},()=>{this.mounted&&this.setState({loading:!1})})}componentWillUnmount(){this.mounted=!1,Object(u.removeSideBarClass)()}render(){const{loading:e,pages:n,tree:t}=this.state,{params:{splat:o=""},location:{hash:r}}=this.props;if(e)return a.createElement("div",{className:"page page-limited"},a.createElement(l.a,null));const u=n.find(e=>e.url==="/".concat(o)),d=Object(c.translate)("documentation.page_title.sonarqube"),h="index"===o;return u?a.createElement("div",{className:"layout-page"},a.createElement(s.a,{defer:!1,title:h||!u.title?d:"".concat(u.title," | ").concat(d)},a.createElement("meta",{content:"noindex nofollow",name:"robots"})),a.createElement(y.a,{className:"layout-page-side-outer"},({top:e})=>a.createElement("div",{className:"layout-page-side",style:{top:e}},a.createElement("div",{className:"layout-page-side-inner"},a.createElement("div",{className:"layout-page-filters"},a.createElement("div",{className:"documentation-page-header"},a.createElement(m.a,{anchor:"documentation_menu",label:Object(c.translate)("documentation.skip_to_nav"),weight:10}),a.createElement(i.c,{to:"/documentation/"},a.createElement("h1",null,Object(c.translate)("documentation.page")))),a.createElement(le,{navigation:t,pages:n,splat:o}))))),a.createElement("div",{className:"layout-page-main"},a.createElement("div",{className:"layout-page-main-inner"},a.createElement("div",{className:"boxed-group"},a.createElement(m.a,{anchor:"documentation_main"}),a.createElement(f.default,{className:"documentation-content cut-margins boxed-group-inner",content:u.content,stickyToc:!0,title:u.title,scrollToHref:r}))))):a.createElement(a.Fragment,null,a.createElement(s.a,{title:d},a.createElement("meta",{content:"noindex nofollow",name:"robots"})),a.createElement(m.a,{anchor:"documentation_main"}),a.createElement(g.default,{withContainer:!1}))}}},368:function(e,n,t){"use strict";t.d(n,"a",(function(){return i}));var o=t(2),a=t(31),s=t(433);function i(e){return o.createElement(s.a.Consumer,null,({addA11ySkipLink:n,removeA11ySkipLink:t})=>o.createElement(r,Object.assign({addA11ySkipLink:n,removeA11ySkipLink:t},e)))}class r extends o.PureComponent{constructor(){super(...arguments),this.getLink=()=>{const{anchor:e,label:n=Object(a.translate)("skip_to_content"),weight:t}=this.props;return{key:e,label:n,weight:t}}}componentDidMount(){this.props.addA11ySkipLink(this.getLink())}componentWillUnmount(){this.props.removeA11ySkipLink(this.getLink())}render(){const{anchor:e}=this.props;return o.createElement("span",{id:"a11y_target__".concat(e)})}}},449:function(e,n,t){"use strict";t.d(n,"a",(function(){return i}));var o=t(382),a=t.n(o),s=t(2);class i extends s.PureComponent{constructor(e){super(e),this.getPosition=()=>{const e=this.container&&this.container.getBoundingClientRect();return e?{top:window.pageYOffset+e.top,left:window.pageXOffset+e.left}:{top:0,left:0}},this.debouncedOnResize=a()(()=>this.forceUpdate(),250)}componentDidMount(){this.forceUpdate(),window.addEventListener("resize",this.debouncedOnResize)}componentWillUnmount(){window.removeEventListener("resize",this.debouncedOnResize)}render(){return s.createElement("div",{className:this.props.className,ref:e=>this.container=e},this.props.children(this.getPosition()))}}},462:function(e,n,t){"use strict";t.r(n),t.d(n,"default",(function(){return l}));var o=t(2),a=t(518),s=t.n(a),i=t(350),r=t(543);function l({children:e}){return o.createElement("div",{className:"global-container"},o.createElement("div",{className:"page-wrapper",id:"container"},o.createElement(s.a,{className:"navbar-global",height:i.rawSizes.globalNavHeightRaw}),e),o.createElement(r.a,null))}},487:function(e,n,t){"use strict";t.r(n),t.d(n,"default",(function(){return l}));var o=t(2),a=t(335),s=t(318),i=t(31),r=t(462);function l({withContainer:e=!0}){const n=e?r.default:o.Fragment;return o.createElement(n,null,o.createElement(a.a,{defaultTitle:Object(i.translate)("404_not_found"),defer:!1}),o.createElement("div",{className:"page-wrapper-simple",id:"bd"},o.createElement("div",{className:"page-simple",id:"nonav"},o.createElement("h2",{className:"big-spacer-bottom"},Object(i.translate)("page_not_found")),o.createElement("p",{className:"spacer-bottom"},Object(i.translate)("address_mistyped_or_page_moved")),o.createElement("p",null,o.createElement(s.c,{to:"/"},Object(i.translate)("go_back_to_homepage"))))))}},520:function(e,n,t){"use strict";var o,a;function s(e){return void 0!==e.release}function i(e){return function(e){return void 0!==e.version}(e)&&void 0!==e.updatedAt}t.d(n,"a",(function(){return o})),t.d(n,"b",(function(){return a})),t.d(n,"c",(function(){return s})),t.d(n,"d",(function(){return i})),function(e){e.Bundled="BUNDLED",e.External="EXTERNAL"}(o||(o={})),function(e){e.Accepted="ACCEPTED",e.NotAccepted="NOT_ACCEPTED",e.Required="REQUIRED"}(a||(a={}))},639:function(e,n,t){"use strict";t.d(n,"b",(function(){return h})),t.d(n,"e",(function(){return p})),t.d(n,"c",(function(){return b})),t.d(n,"d",(function(){return v})),t.d(n,"f",(function(){return w})),t.d(n,"g",(function(){return S})),t.d(n,"h",(function(){return k})),t.d(n,"i",(function(){return x})),t.d(n,"a",(function(){return A}));var o=t(568),a=t.n(o),s=t(9),i=t(402),r=t(324),l=t(520);function c(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function u(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?c(Object(t),!0).forEach((function(n){d(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):c(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function d(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function h(){return Object(s.getJSON)("/api/plugins/available").catch(r.a)}function p(){return Object(s.getJSON)("/api/plugins/pending").catch(r.a)}function m(e){if(!e)return[];return["COMPATIBLE","REQUIRES_SYSTEM_UPGRADE","DEPS_REQUIRE_SYSTEM_UPGRADE"].map(n=>{const t=a()(e,e=>e.status===n);return t>-1?e[t]:void 0}).filter(i.isDefined)}function g(e,n){if(!n)return e;const t=n.indexOf(e);return u({},e,{previousUpdates:t>0?n.slice(0,t):[]})}function y(e=l.a.External){return Object(s.getJSON)("/api/plugins/installed",{f:"category",type:e})}function f(){return Object(s.getJSON)("/api/plugins/updates")}function b(e=l.a.External){return y(e).then(({plugins:e})=>e,r.a)}function v(){return Promise.all([y(),f()]).then(([e,n])=>e.plugins.map(e=>{const t=n.plugins.find(n=>n.key===e.key);return t?u({},t,{},e,{updates:m(t.updates).map(e=>g(e,t.updates))}):e})).catch(r.a)}function w(){return Promise.all([f(),y()]).then(([e,n])=>e.plugins.map(e=>{const t=m(e.updates).map(n=>g(n,e.updates)),o=n.plugins.find(n=>n.key===e.key);return o?u({},o,{},e,{updates:t}):u({},e,{updates:t})})).catch(r.a)}function S(e){return Object(s.post)("/api/plugins/install",e).catch(r.a)}function k(e){return Object(s.post)("/api/plugins/uninstall",e).catch(r.a)}function x(e){return Object(s.post)("/api/plugins/update",e).catch(r.a)}function A(){return Object(s.post)("/api/plugins/cancel_all").catch(r.a)}},936:function(e,n,t){var o=t(313),a=t(937);"string"==typeof(a=a.__esModule?a.default:a)&&(a=[[e.i,a,""]]);var s={insert:"head",singleton:!1},i=(o(a,s),a.locals?a.locals:{});e.exports=i},937:function(e,n,t){(n=t(314)(!1)).push([e.i,".markdown-content .alert{margin-bottom:8px;border:1px solid;border-radius:2px}.markdown-content .alert.is-inline{display:inline-flex}.markdown-content .alert:empty{display:none}.markdown-content .alert-danger,.markdown-content .alert-error{border-color:#f4b1b0;background-color:#f2dede;color:#862422}.markdown-content .alert-danger .alert-icon,.markdown-content .alert-error .alert-icon{border-color:#f4b1b0}.markdown-content .alert-warning{border-color:#faebcc;background-color:#fcf8e3;color:#6f4f17}.markdown-content .alert-warning .alert-icon{border-color:#faebcc}.markdown-content .alert-info{border-color:#b1dff3;background-color:#d9edf7;color:#0e516f}.markdown-content .alert-info .alert-icon{border-color:#b1dff3}.markdown-content .alert-success{border-color:#d6e9c6;background-color:#dff0d8;color:#215821}.markdown-content .alert-success .alert-icon{border-color:#d6e9c6}",""]),e.exports=n}}]);
//# sourceMappingURL=docs.m.fc04e835.chunk.js.map